
------------------------------------------------------------------
- (1/3) Profiling moe_2.4B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_2.4B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f2322a516a0>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=4.048 GB, invar_size=3.892 GB, outvar_size=0.027 GB, temp_buffer_size=0.129 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.052, peak_memory=2.130 GB, invar_size=1.946 GB, outvar_size=0.055 GB, temp_buffer_size=0.129 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.095, peak_memory=0.986 GB, invar_size=0.829 GB, outvar_size=0.027 GB, temp_buffer_size=0.129 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=3.599, peak_memory=13.527 GB, invar_size=9.027 GB, outvar_size=4.500 GB, temp_buffer_size=4.500 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=1.674, peak_memory=6.805 GB, invar_size=4.555 GB, outvar_size=2.250 GB, temp_buffer_size=2.250 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=0.632, peak_memory=2.818 GB, invar_size=2.027 GB, outvar_size=1.000 GB, temp_buffer_size=0.792 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 86.38 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.025, peak_memory=1.157 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.673 GB, invar_size=1.126 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.688 GB, invar_size=1.141 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.052, peak_memory=1.157 GB, invar_size=0.578 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.188 GB, invar_size=0.594 GB, outvar_size=0.062 GB, temp_buffer_size=0.532 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.173 GB, invar_size=0.626 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.025, peak_memory=1.157 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.019, peak_memory=1.657 GB, invar_size=1.110 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.054, peak_memory=1.157 GB, invar_size=0.563 GB, outvar_size=0.047 GB, temp_buffer_size=0.547 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.019, peak_memory=1.657 GB, invar_size=1.110 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.052, peak_memory=1.157 GB, invar_size=0.578 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.758 GB, invar_size=2.283 GB, outvar_size=1.126 GB, temp_buffer_size=2.475 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.128, peak_memory=3.917 GB, invar_size=1.188 GB, outvar_size=0.563 GB, temp_buffer_size=2.729 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.131, peak_memory=3.821 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.602 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.188 GB, invar_size=0.641 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=3.456 GB, invar_size=1.235 GB, outvar_size=0.610 GB, temp_buffer_size=2.205 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=3.456 GB, invar_size=1.235 GB, outvar_size=0.610 GB, temp_buffer_size=2.205 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.065, peak_memory=4.455 GB, invar_size=2.235 GB, outvar_size=1.110 GB, temp_buffer_size=2.205 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.071, peak_memory=4.878 GB, invar_size=2.297 GB, outvar_size=1.141 GB, temp_buffer_size=2.565 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.688 GB, invar_size=1.141 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.131, peak_memory=3.821 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.602 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.758 GB, invar_size=1.283 GB, outvar_size=0.626 GB, temp_buffer_size=2.475 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.065, peak_memory=4.455 GB, invar_size=2.235 GB, outvar_size=1.110 GB, temp_buffer_size=2.205 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.188 GB, invar_size=0.594 GB, outvar_size=0.062 GB, temp_buffer_size=0.532 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.188 GB, invar_size=0.641 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.019, peak_memory=1.657 GB, invar_size=1.110 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.009, peak_memory=1.094 GB, invar_size=0.563 GB, outvar_size=0.016 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=0.868 GB, invar_size=0.305 GB, outvar_size=0.031 GB, temp_buffer_size=0.532 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.012, peak_memory=0.844 GB, invar_size=0.313 GB, outvar_size=0.016 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.057, peak_memory=1.173 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=0.532 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.141, peak_memory=3.975 GB, invar_size=1.219 GB, outvar_size=0.594 GB, temp_buffer_size=2.725 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=3.909 GB, invar_size=1.313 GB, outvar_size=0.641 GB, temp_buffer_size=2.580 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.025, peak_memory=1.157 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.141, peak_memory=4.194 GB, invar_size=1.219 GB, outvar_size=0.594 GB, temp_buffer_size=2.944 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=3.893 GB, invar_size=1.297 GB, outvar_size=0.641 GB, temp_buffer_size=2.580 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.071, peak_memory=4.893 GB, invar_size=2.297 GB, outvar_size=1.141 GB, temp_buffer_size=2.580 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.065, peak_memory=4.565 GB, invar_size=2.235 GB, outvar_size=1.110 GB, temp_buffer_size=2.315 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.131, peak_memory=3.916 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.697 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.077, peak_memory=5.508 GB, invar_size=2.341 GB, outvar_size=1.171 GB, temp_buffer_size=3.151 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.147, peak_memory=4.542 GB, invar_size=1.218 GB, outvar_size=0.609 GB, temp_buffer_size=3.293 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=3.565 GB, invar_size=1.235 GB, outvar_size=0.610 GB, temp_buffer_size=2.315 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=4.462 GB, invar_size=1.280 GB, outvar_size=0.640 GB, temp_buffer_size=3.166 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 31.86 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.642 GB, invar_size=0.579 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.642 GB, invar_size=0.579 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.568 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.380 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.568 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.380 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.055, peak_memory=6.108 GB, invar_size=1.189 GB, outvar_size=0.579 GB, temp_buffer_size=4.919 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.055, peak_memory=6.108 GB, invar_size=1.189 GB, outvar_size=0.579 GB, temp_buffer_size=4.919 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.568 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.380 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.568 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.380 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.673 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.673 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.568 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.380 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.568 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.380 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.061, peak_memory=6.380 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=5.129 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.061, peak_memory=6.380 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=5.129 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.849 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.661 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.787 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.599 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.849 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.661 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.051, peak_memory=5.787 GB, invar_size=1.156 GB, outvar_size=0.578 GB, temp_buffer_size=4.599 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=7.580 GB, invar_size=1.247 GB, outvar_size=0.639 GB, temp_buffer_size=6.301 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=7.580 GB, invar_size=1.247 GB, outvar_size=0.639 GB, temp_buffer_size=6.301 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 17.96 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO comm 0x540a560 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO comm 0x4de0e00 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO comm 0x6fe0480 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO comm 0x7cbb740 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2601055)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO comm 0x46765a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO comm 0xb5b0f60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO comm 0x69886f0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO comm 0xce58fa0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO comm 0xbd74fc0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [0] NCCL INFO comm 0x538fcd0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879011 [1] NCCL INFO comm 0x73dc9c0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO comm 0xbc1ef10 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 177.89 s
compilation time breakdown: {'stage-construction': '139.76', 'stage-construction-dp': '1.40', 'stage-construction-compilation': '71.73', 'stage-construction-profiling': '35.04'}
 - Compile (worker): 9.45 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093151 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601055 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1812997 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO comm 0x7f1d53f56130 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879075 [1] NCCL INFO comm 0x7f1d5fe905e0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1879011, ip=192.168.0.35)[0m gpu20:1879011:1879073 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813189 [1] NCCL INFO comm 0x7f10435d6110 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO comm 0x7f1039383b80 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2601055)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2601055)[0m 
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601138 [1] NCCL INFO comm 0x7f2cb22c3fc0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO comm 0x7f2cbb5f7c70 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093257 [1] NCCL INFO comm 0x7ef164725550 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO comm 0x7ef1868d03e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1812997, ip=192.168.0.34)[0m gpu19:1812997:1813187 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2601055)[0m gpu16:2601055:2601136 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3093151, ip=192.168.0.39)[0m gpu24:3093151:3093255 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 66.53 s

[21.933346033096313, 6.45630407333374, 6.433155298233032, 6.523252010345459, 6.482386589050293, 6.43871545791626, 6.532326698303223]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 34.178 s.
 - Average e2e iteration time: 6.836000442504883 s.
 - Total local training time: 32.40999984741211 s.
 - Average local iteration time: 6.482000350952148 s.
 - Max allocated memory among devices: 7.135 GB.
 - Compilation times:  {'stage-construction': 139.75576496124268, 'stage-construction-dp': 1.4041788578033447, 'stage-construction-compilation': 71.7305555343628, 'stage-construction-profiling': 35.03606295585632}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 6.481967449188232
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_2.4B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling moe_2.4B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_2.4B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f5378b1a5b0>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.036, peak_memory=4.204 GB, invar_size=3.892 GB, outvar_size=0.055 GB, temp_buffer_size=0.258 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.066, peak_memory=2.564 GB, invar_size=1.946 GB, outvar_size=0.055 GB, temp_buffer_size=0.563 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=3.656, peak_memory=13.554 GB, invar_size=9.054 GB, outvar_size=4.500 GB, temp_buffer_size=4.500 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.187, peak_memory=1.142 GB, invar_size=0.829 GB, outvar_size=0.055 GB, temp_buffer_size=0.258 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=1.804, peak_memory=6.805 GB, invar_size=4.555 GB, outvar_size=2.250 GB, temp_buffer_size=2.250 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=0.861, peak_memory=3.637 GB, invar_size=2.054 GB, outvar_size=1.000 GB, temp_buffer_size=1.583 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 91.73 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=2.251 GB, invar_size=1.156 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.123, peak_memory=1.814 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.064 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.046, peak_memory=1.719 GB, invar_size=0.625 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.038, peak_memory=2.220 GB, invar_size=1.126 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.050, peak_memory=1.720 GB, invar_size=0.626 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.104, peak_memory=1.752 GB, invar_size=0.563 GB, outvar_size=0.094 GB, temp_buffer_size=1.095 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.035, peak_memory=2.219 GB, invar_size=1.125 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.046, peak_memory=1.719 GB, invar_size=0.625 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.035, peak_memory=2.219 GB, invar_size=1.125 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.100, peak_memory=1.767 GB, invar_size=0.610 GB, outvar_size=0.094 GB, temp_buffer_size=1.064 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.100, peak_memory=1.767 GB, invar_size=0.610 GB, outvar_size=0.094 GB, temp_buffer_size=1.064 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=7.264 GB, invar_size=2.314 GB, outvar_size=1.126 GB, temp_buffer_size=4.950 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.247, peak_memory=6.707 GB, invar_size=1.251 GB, outvar_size=0.563 GB, temp_buffer_size=5.456 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=5.724 GB, invar_size=1.282 GB, outvar_size=0.625 GB, temp_buffer_size=4.411 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=6.546 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.202 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=6.722 GB, invar_size=2.282 GB, outvar_size=1.125 GB, temp_buffer_size=4.409 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.122, peak_memory=7.505 GB, invar_size=2.344 GB, outvar_size=1.156 GB, temp_buffer_size=5.129 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=2.251 GB, invar_size=1.156 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=6.546 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.202 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.050, peak_memory=1.751 GB, invar_size=0.656 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=5.724 GB, invar_size=1.282 GB, outvar_size=0.625 GB, temp_buffer_size=4.411 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=6.722 GB, invar_size=2.282 GB, outvar_size=1.125 GB, temp_buffer_size=4.409 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=6.264 GB, invar_size=1.314 GB, outvar_size=0.626 GB, temp_buffer_size=4.950 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.123, peak_memory=1.814 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.064 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.050, peak_memory=1.751 GB, invar_size=0.656 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.035, peak_memory=2.219 GB, invar_size=1.125 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.055, peak_memory=1.462 GB, invar_size=0.336 GB, outvar_size=0.062 GB, temp_buffer_size=1.063 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.109, peak_memory=1.798 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=1.064 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=1.391 GB, invar_size=0.328 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=6.824 GB, invar_size=1.313 GB, outvar_size=0.625 GB, temp_buffer_size=5.449 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=6.567 GB, invar_size=1.375 GB, outvar_size=0.656 GB, temp_buffer_size=5.161 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.046, peak_memory=1.719 GB, invar_size=0.625 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.122, peak_memory=7.536 GB, invar_size=2.344 GB, outvar_size=1.156 GB, temp_buffer_size=5.161 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=7.262 GB, invar_size=1.313 GB, outvar_size=0.625 GB, temp_buffer_size=5.887 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=6.942 GB, invar_size=2.282 GB, outvar_size=1.125 GB, temp_buffer_size=4.630 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=6.536 GB, invar_size=1.344 GB, outvar_size=0.656 GB, temp_buffer_size=5.161 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=6.734 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.390 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=8.705 GB, invar_size=2.373 GB, outvar_size=1.186 GB, temp_buffer_size=6.301 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=5.942 GB, invar_size=1.282 GB, outvar_size=0.625 GB, temp_buffer_size=4.630 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.285, peak_memory=7.928 GB, invar_size=1.280 GB, outvar_size=0.640 GB, temp_buffer_size=6.585 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.150, peak_memory=7.705 GB, invar_size=1.373 GB, outvar_size=0.686 GB, temp_buffer_size=6.301 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 30.27 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=2.705 GB, invar_size=0.579 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=2.705 GB, invar_size=0.579 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.042 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=8.760 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.042 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=8.760 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=11.058 GB, invar_size=1.220 GB, outvar_size=0.579 GB, temp_buffer_size=9.838 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=11.058 GB, invar_size=1.220 GB, outvar_size=0.579 GB, temp_buffer_size=9.838 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.042 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=8.760 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.042 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=8.760 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=2.767 GB, invar_size=0.641 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=2.767 GB, invar_size=0.641 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.042 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=8.760 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.042 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=8.760 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=11.603 GB, invar_size=1.282 GB, outvar_size=0.641 GB, temp_buffer_size=10.259 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=11.603 GB, invar_size=1.282 GB, outvar_size=0.641 GB, temp_buffer_size=10.259 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.603 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=9.322 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.479 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=9.198 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.603 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=9.322 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=10.479 GB, invar_size=1.219 GB, outvar_size=0.609 GB, temp_buffer_size=9.198 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.146, peak_memory=13.944 GB, invar_size=1.279 GB, outvar_size=0.671 GB, temp_buffer_size=12.603 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.146, peak_memory=13.944 GB, invar_size=1.279 GB, outvar_size=0.671 GB, temp_buffer_size=12.603 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 17.79 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2611189)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO comm 0x3f3e230 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO comm 0x3a0d3b0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO comm 0x6323bf0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO comm 0x8e0ef50 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO comm 0x9cd3e10 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO comm 0x431cca0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO comm 0x664a000 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO comm 0x9d3cf50 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [0] NCCL INFO comm 0x49a51d0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO comm 0xba1acc0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819422 [1] NCCL INFO comm 0x6cb24b0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO comm 0xb8c5b10 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 181.21 s
compilation time breakdown: {'stage-construction': '143.37', 'stage-construction-dp': '1.39', 'stage-construction-compilation': '76.18', 'stage-construction-profiling': '36.31'}
 - Compile (worker): 9.38 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611189 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097576 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1880935 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO comm 0x7f83bc6763e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819532 [1] NCCL INFO comm 0x7f83b30096e0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1819422, ip=192.168.0.34)[0m gpu19:1819422:1819530 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881083 [1] NCCL INFO comm 0x7fcaee932300 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO comm 0x7fcaf8ea0070 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097640 [1] NCCL INFO comm 0x7f54696e8ae0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO comm 0x7f5475924330 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2611189)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2611189)[0m 
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611300 [1] NCCL INFO comm 0x7ee74aee41c0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO comm 0x7ee70ffe50b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1880935, ip=192.168.0.35)[0m gpu20:1880935:1881081 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3097576, ip=192.168.0.39)[0m gpu24:3097576:3097638 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2611189)[0m gpu16:2611189:2611298 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 85.04 s

[20.693825244903564, 9.96974778175354, 9.793887615203857, 9.725282907485962, 9.724618673324585, 9.804397344589233, 9.743276357650757]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 51.448 s.
 - Average e2e iteration time: 10.290000915527344 s.
 - Total local training time: 48.7910041809082 s.
 - Average local iteration time: 9.758000373840332 s.
 - Max allocated memory among devices: 10.802 GB.
 - Compilation times:  {'stage-construction': 143.36775422096252, 'stage-construction-dp': 1.3945860862731934, 'stage-construction-compilation': 76.17984247207642, 'stage-construction-profiling': 36.311190366744995}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 9.758293151855469
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_2.4B_512.pkl`...

------------------------------------------------------------------
- (3/3) Profiling moe_2.4B with batch size: 1024...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_2.4B_1024.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7fabc3367370>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.069, peak_memory=4.517 GB, invar_size=3.892 GB, outvar_size=0.109 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.111, peak_memory=2.814 GB, invar_size=1.946 GB, outvar_size=0.109 GB, temp_buffer_size=0.758 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.372, peak_memory=1.455 GB, invar_size=0.829 GB, outvar_size=0.109 GB, temp_buffer_size=0.516 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=3.769, peak_memory=13.609 GB, invar_size=9.109 GB, outvar_size=4.500 GB, temp_buffer_size=4.500 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=2.042, peak_memory=9.460 GB, invar_size=4.610 GB, outvar_size=2.250 GB, temp_buffer_size=4.850 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=1.323, peak_memory=5.276 GB, invar_size=2.109 GB, outvar_size=1.000 GB, temp_buffer_size=3.166 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 90.61 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.076, peak_memory=3.315 GB, invar_size=1.126 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.076, peak_memory=3.376 GB, invar_size=1.188 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.815 GB, invar_size=0.626 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.243, peak_memory=3.065 GB, invar_size=0.688 GB, outvar_size=0.250 GB, temp_buffer_size=2.127 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=3.345 GB, invar_size=1.157 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.845 GB, invar_size=0.657 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=2.987 GB, invar_size=0.672 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.205, peak_memory=2.941 GB, invar_size=0.564 GB, outvar_size=0.188 GB, temp_buffer_size=2.190 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.845 GB, invar_size=0.657 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=3.345 GB, invar_size=1.157 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=2.987 GB, invar_size=0.672 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.489, peak_memory=12.287 GB, invar_size=1.376 GB, outvar_size=0.563 GB, temp_buffer_size=10.910 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.247, peak_memory=10.259 GB, invar_size=1.375 GB, outvar_size=0.656 GB, temp_buffer_size=8.821 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.218, peak_memory=12.276 GB, invar_size=2.377 GB, outvar_size=1.126 GB, temp_buffer_size=9.900 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.229, peak_memory=12.759 GB, invar_size=2.438 GB, outvar_size=1.188 GB, temp_buffer_size=10.259 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.247, peak_memory=10.259 GB, invar_size=1.375 GB, outvar_size=0.656 GB, temp_buffer_size=8.821 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.210, peak_memory=11.256 GB, invar_size=2.375 GB, outvar_size=1.156 GB, temp_buffer_size=8.818 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.076, peak_memory=3.376 GB, invar_size=1.188 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.500, peak_memory=11.993 GB, invar_size=1.469 GB, outvar_size=0.672 GB, temp_buffer_size=10.399 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.500, peak_memory=11.993 GB, invar_size=1.469 GB, outvar_size=0.672 GB, temp_buffer_size=10.399 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.210, peak_memory=11.256 GB, invar_size=2.375 GB, outvar_size=1.156 GB, temp_buffer_size=8.818 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.876 GB, invar_size=0.688 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.256, peak_memory=11.276 GB, invar_size=1.377 GB, outvar_size=0.626 GB, temp_buffer_size=9.900 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.876 GB, invar_size=0.688 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.243, peak_memory=3.065 GB, invar_size=0.688 GB, outvar_size=0.250 GB, temp_buffer_size=2.127 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=3.345 GB, invar_size=1.157 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.108, peak_memory=2.651 GB, invar_size=0.399 GB, outvar_size=0.125 GB, temp_buffer_size=2.127 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.216, peak_memory=3.049 GB, invar_size=0.672 GB, outvar_size=0.250 GB, temp_buffer_size=2.127 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.486 GB, invar_size=0.360 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.538, peak_memory=12.520 GB, invar_size=1.500 GB, outvar_size=0.688 GB, temp_buffer_size=10.895 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.845 GB, invar_size=0.657 GB, outvar_size=0.125 GB, temp_buffer_size=2.064 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.267, peak_memory=11.884 GB, invar_size=1.500 GB, outvar_size=0.688 GB, temp_buffer_size=10.321 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.229, peak_memory=12.822 GB, invar_size=2.438 GB, outvar_size=1.188 GB, temp_buffer_size=10.321 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.538, peak_memory=13.396 GB, invar_size=1.500 GB, outvar_size=0.688 GB, temp_buffer_size=11.770 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.267, peak_memory=11.822 GB, invar_size=1.438 GB, outvar_size=0.688 GB, temp_buffer_size=10.321 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.210, peak_memory=11.697 GB, invar_size=2.375 GB, outvar_size=1.156 GB, temp_buffer_size=9.259 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.500, peak_memory=12.369 GB, invar_size=1.469 GB, outvar_size=0.672 GB, temp_buffer_size=10.775 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.256, peak_memory=15.101 GB, invar_size=2.435 GB, outvar_size=1.218 GB, temp_buffer_size=12.603 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.565, peak_memory=14.700 GB, invar_size=1.406 GB, outvar_size=0.703 GB, temp_buffer_size=13.170 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.247, peak_memory=10.697 GB, invar_size=1.375 GB, outvar_size=0.656 GB, temp_buffer_size=9.259 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.294, peak_memory=14.101 GB, invar_size=1.435 GB, outvar_size=0.718 GB, temp_buffer_size=12.603 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 31.09 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.831 GB, invar_size=0.579 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.831 GB, invar_size=0.579 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=18.988 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=17.519 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=18.988 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=17.519 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=18.988 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=17.519 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=18.988 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=17.519 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.214, peak_memory=20.959 GB, invar_size=1.283 GB, outvar_size=0.579 GB, temp_buffer_size=19.676 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.214, peak_memory=20.959 GB, invar_size=1.283 GB, outvar_size=0.579 GB, temp_buffer_size=19.676 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.955 GB, invar_size=0.703 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.955 GB, invar_size=0.703 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=18.988 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=17.519 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=18.988 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=17.519 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=4.924 GB, invar_size=0.672 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=22.050 GB, invar_size=1.407 GB, outvar_size=0.703 GB, temp_buffer_size=20.518 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=22.050 GB, invar_size=1.407 GB, outvar_size=0.703 GB, temp_buffer_size=20.518 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=20.112 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=18.643 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=20.112 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=18.643 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=19.863 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=18.394 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=19.863 GB, invar_size=1.344 GB, outvar_size=0.672 GB, temp_buffer_size=18.394 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.290, peak_memory=26.672 GB, invar_size=1.342 GB, outvar_size=0.733 GB, temp_buffer_size=25.206 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.290, peak_memory=26.672 GB, invar_size=1.342 GB, outvar_size=0.733 GB, temp_buffer_size=25.206 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 17.51 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2621280)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO comm 0x35eff10 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO comm 0x48f8740 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO comm 0x69941a0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO comm 0x6cda330 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO comm 0x99e3800 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO comm 0x45e0d90 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO comm 0x7985830 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO comm 0x997a6c0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO comm 0xa9d52d0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [0] NCCL INFO comm 0x5081d80 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO comm 0xa96c190 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825680 [1] NCCL INFO comm 0x73933b0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 181.60 s
compilation time breakdown: {'stage-construction': '142.87', 'stage-construction-dp': '1.37', 'stage-construction-compilation': '74.10', 'stage-construction-profiling': '36.59'}
 - Compile (worker): 9.22 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621280 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102120 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883107 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825791 [1] NCCL INFO comm 0x7f1955a73a30 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO comm 0x7f19602be750 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1825680, ip=192.168.0.34)[0m gpu19:1825680:1825789 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO comm 0x7f319be76d90 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883213 [1] NCCL INFO comm 0x7f318c7eaf70 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO comm 0x7f19291751c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102227 [1] NCCL INFO comm 0x7f1934648190 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2621280)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2621280)[0m 
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO comm 0x7fc70672b580 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621391 [1] NCCL INFO comm 0x7fc71298e730 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1883107, ip=192.168.0.35)[0m gpu20:1883107:1883211 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3102120, ip=192.168.0.39)[0m gpu24:3102120:3102225 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2621280)[0m gpu16:2621280:2621389 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 170.30 s

[47.184993267059326, 19.193126916885376, 20.398934364318848, 19.20604109764099, 19.076833486557007, 19.054176807403564, 19.05646824836731]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 101.289 s.
 - Average e2e iteration time: 20.25800132751465 s.
 - Total local training time: 96.79200744628906 s.
 - Average local iteration time: 19.358001708984375 s.
 - Max allocated memory among devices: 18.137 GB.
 - Compilation times:  {'stage-construction': 142.8676881790161, 'stage-construction-dp': 1.3713338375091553, 'stage-construction-compilation': 74.09950113296509, 'stage-construction-profiling': 36.58735752105713}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 19.358489990234375
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_2.4B_1024.pkl`...
