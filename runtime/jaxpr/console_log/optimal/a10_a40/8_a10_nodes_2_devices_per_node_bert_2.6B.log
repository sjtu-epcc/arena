
------------------------------------------------------------------
- (1/3) Profiling bert_2.6B with batch size: 128...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_2.6B_128.pkl`, updating/rewriting it...
[WARN] Local batch size 8 is not divisible by num devices 16, skipping...
[TMP] Current profiling results of key `8_a10_8_n_2_d`: none
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_2.6B_128.pkl`...

------------------------------------------------------------------
- (2/3) Profiling bert_2.6B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_2.6B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7fd6a414b9a0>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.157, peak_memory=1.184 GB, invar_size=0.371 GB, outvar_size=0.156 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.076, peak_memory=1.595 GB, invar_size=0.735 GB, outvar_size=0.078 GB, temp_buffer_size=0.781 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.072, peak_memory=1.418 GB, invar_size=0.723 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.162, peak_memory=1.266 GB, invar_size=0.368 GB, outvar_size=0.117 GB, temp_buffer_size=0.781 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.178, peak_memory=1.233 GB, invar_size=0.420 GB, outvar_size=0.156 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.072, peak_memory=1.418 GB, invar_size=0.723 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.072, peak_memory=1.418 GB, invar_size=0.723 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.149, peak_memory=1.145 GB, invar_size=0.371 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.072, peak_memory=1.418 GB, invar_size=0.723 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=1.549 GB, invar_size=0.612 GB, outvar_size=0.078 GB, temp_buffer_size=0.859 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.178, peak_memory=1.233 GB, invar_size=0.420 GB, outvar_size=0.156 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.157, peak_memory=1.184 GB, invar_size=0.371 GB, outvar_size=0.156 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.157, peak_memory=1.184 GB, invar_size=0.371 GB, outvar_size=0.156 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.359, peak_memory=5.099 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.200 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.381, peak_memory=5.567 GB, invar_size=0.892 GB, outvar_size=0.368 GB, temp_buffer_size=4.675 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.187, peak_memory=4.738 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.410 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.395, peak_memory=5.588 GB, invar_size=0.918 GB, outvar_size=0.420 GB, temp_buffer_size=4.592 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.376, peak_memory=5.103 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.204 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.412, peak_memory=5.357 GB, invar_size=0.918 GB, outvar_size=0.420 GB, temp_buffer_size=4.361 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.211, peak_memory=5.319 GB, invar_size=1.548 GB, outvar_size=0.735 GB, temp_buffer_size=3.771 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.212, peak_memory=5.324 GB, invar_size=1.524 GB, outvar_size=0.723 GB, temp_buffer_size=3.761 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.212, peak_memory=5.285 GB, invar_size=1.485 GB, outvar_size=0.723 GB, temp_buffer_size=3.761 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.223, peak_memory=5.110 GB, invar_size=1.302 GB, outvar_size=0.612 GB, temp_buffer_size=3.808 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.584 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.255 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.584 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.255 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.217, peak_memory=5.324 GB, invar_size=1.524 GB, outvar_size=0.723 GB, temp_buffer_size=3.761 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.217, peak_memory=5.246 GB, invar_size=1.485 GB, outvar_size=0.723 GB, temp_buffer_size=3.722 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.157, peak_memory=1.184 GB, invar_size=0.371 GB, outvar_size=0.156 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.369 GB, invar_size=0.674 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.376, peak_memory=5.183 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.284 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.369 GB, invar_size=0.674 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.166, peak_memory=1.169 GB, invar_size=0.396 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.187, peak_memory=4.738 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.410 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.369 GB, invar_size=0.674 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.376, peak_memory=5.103 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.204 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.738 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.410 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.166, peak_memory=1.169 GB, invar_size=0.396 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.699 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.370 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.369 GB, invar_size=0.674 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.699 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.370 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.738 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.410 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.149, peak_memory=1.145 GB, invar_size=0.371 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.699 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.370 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.376, peak_memory=5.103 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.204 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.149, peak_memory=1.145 GB, invar_size=0.371 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.699 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.370 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.149, peak_memory=1.145 GB, invar_size=0.371 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.149, peak_memory=1.145 GB, invar_size=0.371 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.209, peak_memory=5.914 GB, invar_size=1.387 GB, outvar_size=0.674 GB, temp_buffer_size=4.488 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.404, peak_memory=5.670 GB, invar_size=0.870 GB, outvar_size=0.396 GB, temp_buffer_size=4.722 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.031, peak_memory=0.988 GB, invar_size=0.332 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.350, peak_memory=5.015 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.116 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=0.959 GB, invar_size=0.225 GB, outvar_size=0.078 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.321 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.031, peak_memory=0.988 GB, invar_size=0.332 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.209, peak_memory=5.992 GB, invar_size=1.426 GB, outvar_size=0.674 GB, temp_buffer_size=4.527 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.190, peak_memory=4.659 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.330 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.208, peak_memory=5.953 GB, invar_size=1.387 GB, outvar_size=0.674 GB, temp_buffer_size=4.527 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.391, peak_memory=6.305 GB, invar_size=0.870 GB, outvar_size=0.396 GB, temp_buffer_size=5.358 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.208, peak_memory=5.992 GB, invar_size=1.426 GB, outvar_size=0.674 GB, temp_buffer_size=4.527 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.190, peak_memory=4.698 GB, invar_size=1.329 GB, outvar_size=0.625 GB, temp_buffer_size=3.330 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.350, peak_memory=5.015 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.116 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.190, peak_memory=4.659 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.330 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.350, peak_memory=5.015 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.116 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.190, peak_memory=4.698 GB, invar_size=1.329 GB, outvar_size=0.625 GB, temp_buffer_size=3.330 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.190, peak_memory=4.659 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.330 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.190, peak_memory=4.698 GB, invar_size=1.329 GB, outvar_size=0.625 GB, temp_buffer_size=3.330 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.191, peak_memory=4.659 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.330 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.363, peak_memory=5.024 GB, invar_size=0.821 GB, outvar_size=0.371 GB, temp_buffer_size=4.125 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.434, peak_memory=5.139 GB, invar_size=0.950 GB, outvar_size=0.475 GB, temp_buffer_size=4.111 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.191, peak_memory=4.659 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=3.330 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.248, peak_memory=5.324 GB, invar_size=1.666 GB, outvar_size=0.833 GB, temp_buffer_size=3.619 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.262, peak_memory=5.119 GB, invar_size=1.422 GB, outvar_size=0.711 GB, temp_buffer_size=3.658 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 32.09 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=2.098 GB, invar_size=0.442 GB, outvar_size=0.078 GB, temp_buffer_size=1.578 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=2.098 GB, invar_size=0.442 GB, outvar_size=0.078 GB, temp_buffer_size=1.578 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=1.781 GB, invar_size=0.469 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=1.781 GB, invar_size=0.469 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.564 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.743 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.564 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.743 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.215, peak_memory=8.502 GB, invar_size=0.962 GB, outvar_size=0.442 GB, temp_buffer_size=7.540 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.215, peak_memory=8.502 GB, invar_size=0.962 GB, outvar_size=0.442 GB, temp_buffer_size=7.540 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.718 GB, invar_size=0.743 GB, outvar_size=0.371 GB, temp_buffer_size=6.897 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.718 GB, invar_size=0.743 GB, outvar_size=0.371 GB, temp_buffer_size=6.897 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=7.561 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.741 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.224, peak_memory=8.462 GB, invar_size=0.938 GB, outvar_size=0.469 GB, temp_buffer_size=7.446 GB, available_memory=17.580 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.224, peak_memory=8.462 GB, invar_size=0.938 GB, outvar_size=0.469 GB, temp_buffer_size=7.446 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.071, peak_memory=1.733 GB, invar_size=0.420 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.071, peak_memory=1.733 GB, invar_size=0.420 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=7.561 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.741 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.329 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.509 GB, available_memory=17.580 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.329 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.509 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.329 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.509 GB, available_memory=17.580 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.329 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.509 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.564 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.743 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.564 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.743 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.564 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.743 GB, available_memory=17.580 GB)
result[(13, 13, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(13, 13, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.564 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.743 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=7.402 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.582 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.210, peak_memory=9.893 GB, invar_size=0.840 GB, outvar_size=0.420 GB, temp_buffer_size=8.975 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.210, peak_memory=9.893 GB, invar_size=0.840 GB, outvar_size=0.420 GB, temp_buffer_size=8.975 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=7.402 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.582 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=7.402 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.582 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=7.402 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.582 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=7.402 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.582 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=7.402 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.582 GB, available_memory=17.580 GB)
result[(13, 13, 0, 0), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=7.402 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.582 GB, available_memory=17.580 GB)
result[(13, 13, 0, 1), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=7.402 GB, invar_size=0.742 GB, outvar_size=0.371 GB, temp_buffer_size=6.582 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.483 GB, invar_size=0.743 GB, outvar_size=0.371 GB, temp_buffer_size=6.663 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=7.483 GB, invar_size=0.743 GB, outvar_size=0.371 GB, temp_buffer_size=6.663 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.288, peak_memory=8.396 GB, invar_size=1.080 GB, outvar_size=0.579 GB, temp_buffer_size=7.238 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.288, peak_memory=8.396 GB, invar_size=1.080 GB, outvar_size=0.579 GB, temp_buffer_size=7.238 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 16.56 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (1, 10, 3, 0) has been pruned...
[TMP] Stage (1, 10, 3, 1) has been pruned...
[TMP] Stage (1, 10, 3, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (2, 11, 3, 0) has been pruned...
[TMP] Stage (2, 11, 3, 1) has been pruned...
[TMP] Stage (2, 11, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (3, 12, 3, 0) has been pruned...
[TMP] Stage (3, 12, 3, 1) has been pruned...
[TMP] Stage (3, 12, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 8, 2, 0) has been pruned...
[TMP] Stage (4, 8, 2, 1) has been pruned...
[TMP] Stage (4, 8, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (4, 13, 3, 0) has been pruned...
[TMP] Stage (4, 13, 3, 1) has been pruned...
[TMP] Stage (4, 13, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 9, 2, 0) has been pruned...
[TMP] Stage (5, 9, 2, 1) has been pruned...
[TMP] Stage (5, 9, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 10, 2, 0) has been pruned...
[TMP] Stage (6, 10, 2, 1) has been pruned...
[TMP] Stage (6, 10, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}, {}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO comm 0x35264a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO comm 0x350c220 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO comm 0x5847160 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO comm 0x556eb60 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO comm 0x4565810 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO comm 0xac14b50 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO comm 0x65ad9e0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO comm 0xaabf630 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO comm 0xa340c70 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO comm 0x4f1e4c0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO comm 0x7241600 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO comm 0xa59e020 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO comm 0x48ffa70 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO comm 0xc81eea0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO comm 0xc63cf30 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO comm 0x6d0d740 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4004897)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO comm 0x54678f0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO comm 0xc16b390 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO comm 0xc2925f0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO comm 0x74eef40 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO comm 0xb283530 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO comm 0x4eb8a00 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO comm 0xb4da300 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO comm 0x71a48d0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO comm 0xc7848c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [0] NCCL INFO comm 0x3e9a0c0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO comm 0xc582dd0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374471 [1] NCCL INFO comm 0x609fc00 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
 - Compile (driver): 100.06 s
compilation time breakdown: {'stage-construction': '52.70', 'stage-construction-dp': '1.23', 'stage-construction-compilation': '10.81', 'stage-construction-profiling': '11.11'}
 - Compile (worker): 3.68 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325452 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691892 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243594 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075292 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4004897 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927644 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238159 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4004897)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO comm 0x7fe0abeb0b00 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374619 [1] NCCL INFO comm 0x7fe0b4a80810 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2374471, ip=192.168.0.57)[0m gpu27:2374471:2374617 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238223 [1] NCCL INFO comm 0x7f78b3c64360 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO comm 0x7f78ad3e1980 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3238159, ip=192.168.0.58)[0m gpu28:3238159:3238221 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927707 [1] NCCL INFO comm 0x7fe333cf15d0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO comm 0x7fe32c59d840 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1927644, ip=192.168.0.56)[0m gpu26:1927644:1927705 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4004897)[0m 
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO comm 0x7f1afc89b740 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005146 [1] NCCL INFO comm 0x7f1b0411f830 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4004897)[0m gpu37:4004897:4005144 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO comm 0x7ef8754bef50 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075402 [1] NCCL INFO comm 0x7ef882677df0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO comm 0x7fbd2fe43780 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243659 [1] NCCL INFO comm 0x7fbd398bb680 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO comm 0x7f15ac3b13a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691998 [1] NCCL INFO comm 0x7f15b0b53450 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2691892, ip=192.168.0.60)[0m gpu30:2691892:2691996 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325529 [1] NCCL INFO comm 0x7f3c702d7850 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO comm 0x7f3c68b44970 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3075292, ip=192.168.0.72)[0m gpu42:3075292:3075400 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3243594, ip=192.168.0.59)[0m gpu29:3243594:3243657 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2325452, ip=192.168.0.55)[0m gpu25:2325452:2325527 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 100.93 s

[24.78139090538025, 11.789297819137573, 11.840540409088135, 11.876605987548828, 11.891951560974121, 11.88789701461792, 11.94662618637085]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 61.792 s.
 - Average e2e iteration time: 12.358000755310059 s.
 - Total local training time: 59.44400405883789 s.
 - Average local iteration time: 11.88900089263916 s.
 - Max allocated memory among devices: 9.109 GB.
 - Compilation times:  {'stage-construction': 52.70026707649231, 'stage-construction-dp': 1.2291903495788574, 'stage-construction-compilation': 10.806474208831787, 'stage-construction-profiling': 11.113940238952637}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 11.888724327087402
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_2.6B_256.pkl`...

------------------------------------------------------------------
- (3/3) Profiling bert_2.6B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_2.6B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f2c85fe9370>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.307, peak_memory=2.075 GB, invar_size=0.450 GB, outvar_size=0.312 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.137, peak_memory=2.153 GB, invar_size=0.762 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.291, peak_memory=1.996 GB, invar_size=0.450 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.137, peak_memory=2.153 GB, invar_size=0.762 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.146, peak_memory=2.454 GB, invar_size=0.735 GB, outvar_size=0.156 GB, temp_buffer_size=1.563 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.137, peak_memory=2.153 GB, invar_size=0.762 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.146, peak_memory=2.454 GB, invar_size=0.735 GB, outvar_size=0.156 GB, temp_buffer_size=1.563 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.137, peak_memory=2.153 GB, invar_size=0.762 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.349, peak_memory=2.123 GB, invar_size=0.498 GB, outvar_size=0.312 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.349, peak_memory=2.123 GB, invar_size=0.498 GB, outvar_size=0.312 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.318, peak_memory=2.165 GB, invar_size=0.368 GB, outvar_size=0.234 GB, temp_buffer_size=1.563 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.307, peak_memory=2.075 GB, invar_size=0.450 GB, outvar_size=0.312 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.307, peak_memory=2.075 GB, invar_size=0.450 GB, outvar_size=0.312 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.700, peak_memory=9.606 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.395 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.733, peak_memory=9.612 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.400 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.746, peak_memory=10.394 GB, invar_size=1.048 GB, outvar_size=0.368 GB, temp_buffer_size=9.346 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.352, peak_memory=8.304 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.819 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.802, peak_memory=10.023 GB, invar_size=1.153 GB, outvar_size=0.498 GB, temp_buffer_size=8.714 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.769, peak_memory=10.487 GB, invar_size=1.153 GB, outvar_size=0.498 GB, temp_buffer_size=9.178 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.399, peak_memory=9.202 GB, invar_size=1.602 GB, outvar_size=0.762 GB, temp_buffer_size=7.522 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.409, peak_memory=9.280 GB, invar_size=1.680 GB, outvar_size=0.762 GB, temp_buffer_size=7.522 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.400, peak_memory=9.167 GB, invar_size=1.627 GB, outvar_size=0.735 GB, temp_buffer_size=7.540 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.400, peak_memory=9.167 GB, invar_size=1.627 GB, outvar_size=0.735 GB, temp_buffer_size=7.540 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.362, peak_memory=7.994 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.509 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.399, peak_memory=9.281 GB, invar_size=1.680 GB, outvar_size=0.762 GB, temp_buffer_size=7.522 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.409, peak_memory=9.124 GB, invar_size=1.602 GB, outvar_size=0.762 GB, temp_buffer_size=7.444 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.362, peak_memory=7.994 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.509 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.307, peak_memory=2.075 GB, invar_size=0.450 GB, outvar_size=0.312 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.130, peak_memory=2.104 GB, invar_size=0.713 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.733, peak_memory=9.771 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.560 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.352, peak_memory=8.304 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.819 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.130, peak_memory=2.104 GB, invar_size=0.713 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.325, peak_memory=2.021 GB, invar_size=0.474 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.130, peak_memory=2.104 GB, invar_size=0.713 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.733, peak_memory=9.612 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.401 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.362, peak_memory=8.304 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.819 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.362, peak_memory=8.226 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.741 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.130, peak_memory=2.104 GB, invar_size=0.713 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.325, peak_memory=2.021 GB, invar_size=0.474 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.362, peak_memory=8.226 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.741 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.362, peak_memory=8.304 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.819 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.290, peak_memory=1.996 GB, invar_size=0.450 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.362, peak_memory=8.226 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.741 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.733, peak_memory=9.612 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.401 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.290, peak_memory=1.996 GB, invar_size=0.450 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.362, peak_memory=8.226 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.741 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.290, peak_memory=1.996 GB, invar_size=0.450 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.291, peak_memory=1.996 GB, invar_size=0.450 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.788, peak_memory=10.705 GB, invar_size=1.104 GB, outvar_size=0.474 GB, temp_buffer_size=9.444 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.394, peak_memory=10.558 GB, invar_size=1.504 GB, outvar_size=0.713 GB, temp_buffer_size=8.975 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.119, peak_memory=2.055 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.153, peak_memory=1.772 GB, invar_size=0.303 GB, outvar_size=0.156 GB, temp_buffer_size=1.313 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.357, peak_memory=8.145 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.660 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.762, peak_memory=11.969 GB, invar_size=1.104 GB, outvar_size=0.474 GB, temp_buffer_size=10.709 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.684 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.394, peak_memory=10.714 GB, invar_size=1.583 GB, outvar_size=0.713 GB, temp_buffer_size=9.053 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.681, peak_memory=9.440 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.229 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.391, peak_memory=10.636 GB, invar_size=1.504 GB, outvar_size=0.713 GB, temp_buffer_size=9.053 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.391, peak_memory=10.714 GB, invar_size=1.583 GB, outvar_size=0.713 GB, temp_buffer_size=9.053 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.357, peak_memory=8.223 GB, invar_size=1.485 GB, outvar_size=0.664 GB, temp_buffer_size=6.660 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.357, peak_memory=8.145 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.660 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.681, peak_memory=9.440 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.229 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.681, peak_memory=9.440 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.229 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.357, peak_memory=8.145 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.660 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.357, peak_memory=8.223 GB, invar_size=1.485 GB, outvar_size=0.664 GB, temp_buffer_size=6.660 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.357, peak_memory=8.223 GB, invar_size=1.485 GB, outvar_size=0.664 GB, temp_buffer_size=6.660 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.707, peak_memory=9.453 GB, invar_size=1.055 GB, outvar_size=0.449 GB, temp_buffer_size=8.242 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.359, peak_memory=8.145 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.660 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.359, peak_memory=8.145 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=6.660 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.850, peak_memory=9.479 GB, invar_size=1.107 GB, outvar_size=0.553 GB, temp_buffer_size=8.216 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.474, peak_memory=9.060 GB, invar_size=1.744 GB, outvar_size=0.872 GB, temp_buffer_size=7.238 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.502, peak_memory=8.894 GB, invar_size=1.500 GB, outvar_size=0.750 GB, temp_buffer_size=7.316 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 31.31 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.154, peak_memory=3.172 GB, invar_size=0.547 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.173, peak_memory=3.755 GB, invar_size=0.442 GB, outvar_size=0.156 GB, temp_buffer_size=3.156 GB, available_memory=17.580 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.154, peak_memory=3.172 GB, invar_size=0.547 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.173, peak_memory=3.755 GB, invar_size=0.442 GB, outvar_size=0.156 GB, temp_buffer_size=3.156 GB, available_memory=17.580 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.540 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.485 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.540 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.485 GB, available_memory=17.580 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.428, peak_memory=16.119 GB, invar_size=1.041 GB, outvar_size=0.442 GB, temp_buffer_size=15.078 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.428, peak_memory=16.119 GB, invar_size=1.041 GB, outvar_size=0.442 GB, temp_buffer_size=15.078 GB, available_memory=17.580 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.444, peak_memory=16.142 GB, invar_size=1.094 GB, outvar_size=0.547 GB, temp_buffer_size=14.891 GB, available_memory=17.580 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.444, peak_memory=16.142 GB, invar_size=1.094 GB, outvar_size=0.547 GB, temp_buffer_size=14.891 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.140, peak_memory=3.123 GB, invar_size=0.498 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.335, peak_memory=14.537 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.481 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.335, peak_memory=14.537 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.481 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.849 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.794 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.071 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.016 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.071 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.016 GB, available_memory=17.580 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.071 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.016 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.140, peak_memory=3.123 GB, invar_size=0.498 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.849 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.794 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.071 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.016 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.540 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.485 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.540 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.485 GB, available_memory=17.580 GB)
result[(13, 13, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(13, 13, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.540 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.485 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.118, peak_memory=3.074 GB, invar_size=0.449 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.540 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.485 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=14.218 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.163 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.416, peak_memory=19.103 GB, invar_size=0.996 GB, outvar_size=0.498 GB, temp_buffer_size=17.950 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.416, peak_memory=19.103 GB, invar_size=0.996 GB, outvar_size=0.498 GB, temp_buffer_size=17.950 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=14.218 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.163 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=14.218 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.163 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=14.218 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.163 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=14.218 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.163 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=14.218 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.163 GB, available_memory=17.580 GB)
result[(13, 13, 0, 0), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=14.218 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.163 GB, available_memory=17.580 GB)
result[(13, 13, 0, 1), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=14.218 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.163 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.574, peak_memory=15.790 GB, invar_size=1.158 GB, outvar_size=0.657 GB, temp_buffer_size=14.476 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.574, peak_memory=15.790 GB, invar_size=1.158 GB, outvar_size=0.657 GB, temp_buffer_size=14.476 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.381 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.325 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.353, peak_memory=14.381 GB, invar_size=0.899 GB, outvar_size=0.449 GB, temp_buffer_size=13.325 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 16.59 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (1, 10, 3, 0) has been pruned...
[TMP] Stage (1, 10, 3, 1) has been pruned...
[TMP] Stage (1, 10, 3, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (2, 11, 3, 0) has been pruned...
[TMP] Stage (2, 11, 3, 1) has been pruned...
[TMP] Stage (2, 11, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (3, 12, 3, 0) has been pruned...
[TMP] Stage (3, 12, 3, 1) has been pruned...
[TMP] Stage (3, 12, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 8, 2, 0) has been pruned...
[TMP] Stage (4, 8, 2, 1) has been pruned...
[TMP] Stage (4, 8, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (4, 13, 3, 0) has been pruned...
[TMP] Stage (4, 13, 3, 1) has been pruned...
[TMP] Stage (4, 13, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 9, 2, 0) has been pruned...
[TMP] Stage (5, 9, 2, 1) has been pruned...
[TMP] Stage (5, 9, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 10, 2, 0) has been pruned...
[TMP] Stage (6, 10, 2, 1) has been pruned...
[TMP] Stage (6, 10, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(1, 2), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4018245)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO comm 0x507b930 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO comm 0x3d64960 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO comm 0x6c913b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO comm 0x710daf0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO comm 0x6efff50 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO comm 0xaea17a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO comm 0x9c47670 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO comm 0xb0f8570 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO comm 0x10298ef0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO comm 0x3551cc0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO comm 0xb13d7b0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO comm 0x55995c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO comm 0x34d3240 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO comm 0x932cfe0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO comm 0x958a390 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO comm 0x51f11a0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO comm 0x9521290 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO comm 0x48d4820 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO comm 0x94b8150 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO comm 0x6bb7cd0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO comm 0x4ccbfa0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO comm 0xbf83890 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO comm 0xbf8e910 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO comm 0xa081de0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO comm 0x4c17dd0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO comm 0xaf4b1b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO comm 0x6edad70 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO comm 0xafb42f0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO comm 0xc4d65c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [0] NCCL INFO comm 0x515dc80 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO comm 0xc2d4ad0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077251 [1] NCCL INFO comm 0x71a5370 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
 - Compile (driver): 99.37 s
compilation time breakdown: {'stage-construction': '52.00', 'stage-construction-dp': '1.29', 'stage-construction-compilation': '10.88', 'stage-construction-profiling': '11.07'}
 - Compile (worker): 3.59 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4018245)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4018245)[0m 
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018325 [1] NCCL INFO comm 0x7f3f1b8c2d10 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO comm 0x7f3f0864a5d0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018323 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4018245)[0m gpu37:4018245:4018245 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932089 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242613 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378352 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329325 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695871 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247826 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO comm 0x7fd6fa9cdc10 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077416 [1] NCCL INFO comm 0x7fd702141060 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3077251, ip=192.168.0.72)[0m gpu42:3077251:3077414 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO comm 0x7f8c8c4a1e30 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247890 [1] NCCL INFO comm 0x7f8c831be660 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3247826, ip=192.168.0.59)[0m gpu29:3247826:3247888 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO comm 0x7f9f3fbc5e30 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695977 [1] NCCL INFO comm 0x7f9f480bb590 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2695871, ip=192.168.0.60)[0m gpu30:2695871:2695975 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO comm 0x7f276e5c1fd0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329388 [1] NCCL INFO comm 0x7f2783250000 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2329325, ip=192.168.0.55)[0m gpu25:2329325:2329386 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO comm 0x7fa7886c4c10 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378458 [1] NCCL INFO comm 0x7fa798ebab90 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO comm 0x7f5f5f054a80 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242719 [1] NCCL INFO comm 0x7f5f67011470 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO comm 0x7fd71121f040 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932278 [1] NCCL INFO comm 0x7fd70b0d6d40 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1932089, ip=192.168.0.56)[0m gpu26:1932089:1932276 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2378352, ip=192.168.0.57)[0m gpu27:2378352:2378456 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3242613, ip=192.168.0.58)[0m gpu28:3242613:3242717 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 198.65 s

[39.15653347969055, 25.48219633102417, 25.437560319900513, 25.440656423568726, 25.3811993598938, 25.35205101966858, 25.431055068969727]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 131.444 s.
 - Average e2e iteration time: 26.28900146484375 s.
 - Total local training time: 127.04300689697266 s.
 - Average local iteration time: 25.409000396728516 s.
 - Max allocated memory among devices: 15.042 GB.
 - Compilation times:  {'stage-construction': 52.004067182540894, 'stage-construction-dp': 1.2927343845367432, 'stage-construction-compilation': 10.883243799209595, 'stage-construction-profiling': 11.073219537734985}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 25.408506393432617
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_2.6B_512.pkl`...
