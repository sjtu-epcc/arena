
------------------------------------------------------------------
- (1/3) Profiling wide_resnet_6.8B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_6.8B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 320
    width_factor = 16
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (256, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.683 GB, invar_size=0.167 GB, outvar_size=0.239 GB, temp_buffer_size=1.277 GB, available_memory=35.446 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.678 GB, invar_size=0.282 GB, outvar_size=0.239 GB, temp_buffer_size=1.158 GB, available_memory=35.446 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.790 GB, invar_size=0.533 GB, outvar_size=0.180 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.049, peak_memory=2.246 GB, invar_size=1.433 GB, outvar_size=0.120 GB, temp_buffer_size=0.694 GB, available_memory=35.446 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.835 GB, invar_size=2.685 GB, outvar_size=0.060 GB, temp_buffer_size=1.090 GB, available_memory=35.446 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.365 GB, invar_size=0.707 GB, outvar_size=0.120 GB, temp_buffer_size=0.538 GB, available_memory=35.446 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.678 GB, invar_size=0.282 GB, outvar_size=0.239 GB, temp_buffer_size=1.158 GB, available_memory=35.446 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=1.281 GB, invar_size=0.443 GB, outvar_size=0.239 GB, temp_buffer_size=0.598 GB, available_memory=35.446 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.365 GB, invar_size=0.707 GB, outvar_size=0.120 GB, temp_buffer_size=0.538 GB, available_memory=35.446 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.810 GB, invar_size=0.947 GB, outvar_size=0.180 GB, temp_buffer_size=0.683 GB, available_memory=35.446 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.882 GB, invar_size=1.080 GB, outvar_size=0.120 GB, temp_buffer_size=0.683 GB, available_memory=35.446 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.895 GB, invar_size=1.715 GB, outvar_size=0.090 GB, temp_buffer_size=1.090 GB, available_memory=35.446 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.154, peak_memory=2.036 GB, invar_size=0.320 GB, outvar_size=0.479 GB, temp_buffer_size=1.237 GB, available_memory=35.446 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.736 GB, invar_size=0.683 GB, outvar_size=0.281 GB, temp_buffer_size=1.934 GB, available_memory=35.446 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.736 GB, invar_size=0.683 GB, outvar_size=0.281 GB, temp_buffer_size=1.934 GB, available_memory=35.446 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.790 GB, invar_size=0.533 GB, outvar_size=0.180 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.556 GB, invar_size=0.776 GB, outvar_size=0.120 GB, temp_buffer_size=0.660 GB, available_memory=35.446 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.095, peak_memory=1.683 GB, invar_size=0.568 GB, outvar_size=0.239 GB, temp_buffer_size=0.876 GB, available_memory=35.446 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.683 GB, invar_size=0.167 GB, outvar_size=0.239 GB, temp_buffer_size=1.277 GB, available_memory=35.446 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.134, peak_memory=2.001 GB, invar_size=0.446 GB, outvar_size=0.359 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.737 GB, invar_size=2.619 GB, outvar_size=0.060 GB, temp_buffer_size=1.059 GB, available_memory=35.446 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.192, peak_memory=1.805 GB, invar_size=0.090 GB, outvar_size=0.479 GB, temp_buffer_size=1.236 GB, available_memory=35.446 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.049, peak_memory=2.246 GB, invar_size=1.433 GB, outvar_size=0.120 GB, temp_buffer_size=0.694 GB, available_memory=35.446 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.050, peak_memory=9.397 GB, invar_size=5.369 GB, outvar_size=2.685 GB, temp_buffer_size=3.968 GB, available_memory=35.446 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=2.168 GB, invar_size=1.354 GB, outvar_size=0.120 GB, temp_buffer_size=0.694 GB, available_memory=35.446 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=2.725 GB, invar_size=1.474 GB, outvar_size=0.707 GB, temp_buffer_size=1.191 GB, available_memory=35.446 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.270, peak_memory=3.332 GB, invar_size=0.880 GB, outvar_size=0.201 GB, temp_buffer_size=2.333 GB, available_memory=35.446 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=2.168 GB, invar_size=1.354 GB, outvar_size=0.120 GB, temp_buffer_size=0.694 GB, available_memory=35.446 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.707 GB, invar_size=2.619 GB, outvar_size=0.060 GB, temp_buffer_size=1.029 GB, available_memory=35.446 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.032, peak_memory=6.820 GB, invar_size=3.458 GB, outvar_size=1.714 GB, temp_buffer_size=3.302 GB, available_memory=35.446 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=2.725 GB, invar_size=1.474 GB, outvar_size=0.707 GB, temp_buffer_size=1.191 GB, available_memory=35.446 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.135, peak_memory=2.194 GB, invar_size=1.006 GB, outvar_size=0.383 GB, temp_buffer_size=1.128 GB, available_memory=35.446 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=2.725 GB, invar_size=1.474 GB, outvar_size=0.707 GB, temp_buffer_size=1.191 GB, available_memory=35.446 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.054, peak_memory=3.693 GB, invar_size=2.219 GB, outvar_size=1.079 GB, temp_buffer_size=1.415 GB, available_memory=35.446 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=2.093 GB, invar_size=1.354 GB, outvar_size=0.120 GB, temp_buffer_size=0.619 GB, available_memory=35.446 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=2.093 GB, invar_size=1.354 GB, outvar_size=0.120 GB, temp_buffer_size=0.619 GB, available_memory=35.446 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.707 GB, invar_size=2.619 GB, outvar_size=0.060 GB, temp_buffer_size=1.029 GB, available_memory=35.446 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.178 GB, invar_size=5.266 GB, outvar_size=2.618 GB, temp_buffer_size=3.882 GB, available_memory=35.446 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.425 GB, invar_size=0.707 GB, outvar_size=0.120 GB, temp_buffer_size=0.598 GB, available_memory=35.446 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.094, peak_memory=4.187 GB, invar_size=2.864 GB, outvar_size=1.372 GB, temp_buffer_size=1.263 GB, available_memory=35.446 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=2.093 GB, invar_size=1.354 GB, outvar_size=0.120 GB, temp_buffer_size=0.619 GB, available_memory=35.446 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.094, peak_memory=4.187 GB, invar_size=2.864 GB, outvar_size=1.372 GB, temp_buffer_size=1.263 GB, available_memory=35.446 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=3.215 GB, invar_size=1.126 GB, outvar_size=0.533 GB, temp_buffer_size=1.969 GB, available_memory=35.446 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=3.349 GB, invar_size=1.954 GB, outvar_size=0.887 GB, temp_buffer_size=1.336 GB, available_memory=35.446 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.425 GB, invar_size=0.707 GB, outvar_size=0.120 GB, temp_buffer_size=0.598 GB, available_memory=35.446 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=2.967 GB, invar_size=1.552 GB, outvar_size=0.776 GB, temp_buffer_size=1.295 GB, available_memory=35.446 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.707 GB, invar_size=2.619 GB, outvar_size=0.060 GB, temp_buffer_size=1.029 GB, available_memory=35.446 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=2.093 GB, invar_size=1.354 GB, outvar_size=0.120 GB, temp_buffer_size=0.619 GB, available_memory=35.446 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=1.443 GB, invar_size=0.443 GB, outvar_size=0.239 GB, temp_buffer_size=0.760 GB, available_memory=35.446 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.987 GB, invar_size=2.768 GB, outvar_size=1.324 GB, temp_buffer_size=1.189 GB, available_memory=35.446 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=3.275 GB, invar_size=1.186 GB, outvar_size=0.533 GB, temp_buffer_size=1.969 GB, available_memory=35.446 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.556 GB, invar_size=0.776 GB, outvar_size=0.120 GB, temp_buffer_size=0.660 GB, available_memory=35.446 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.987 GB, invar_size=2.768 GB, outvar_size=1.324 GB, temp_buffer_size=1.189 GB, available_memory=35.446 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.897 GB, invar_size=2.768 GB, outvar_size=1.324 GB, temp_buffer_size=1.099 GB, available_memory=35.446 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.178 GB, invar_size=5.266 GB, outvar_size=2.618 GB, temp_buffer_size=3.882 GB, available_memory=35.446 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=2.093 GB, invar_size=1.354 GB, outvar_size=0.120 GB, temp_buffer_size=0.619 GB, available_memory=35.446 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.251, peak_memory=2.951 GB, invar_size=0.650 GB, outvar_size=0.081 GB, temp_buffer_size=2.301 GB, available_memory=35.446 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.660 GB, invar_size=0.569 GB, outvar_size=0.162 GB, temp_buffer_size=2.091 GB, available_memory=35.446 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.897 GB, invar_size=2.768 GB, outvar_size=1.324 GB, temp_buffer_size=1.099 GB, available_memory=35.446 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.247, peak_memory=3.193 GB, invar_size=1.012 GB, outvar_size=0.326 GB, temp_buffer_size=2.062 GB, available_memory=35.446 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.780 GB, invar_size=0.688 GB, outvar_size=0.162 GB, temp_buffer_size=2.091 GB, available_memory=35.446 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=2.093 GB, invar_size=1.354 GB, outvar_size=0.120 GB, temp_buffer_size=0.619 GB, available_memory=35.446 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.315 GB, invar_size=6.647 GB, outvar_size=0.045 GB, temp_buffer_size=3.623 GB, available_memory=35.446 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.178 GB, invar_size=5.266 GB, outvar_size=2.618 GB, temp_buffer_size=3.882 GB, available_memory=35.446 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.957 GB, invar_size=2.768 GB, outvar_size=1.324 GB, temp_buffer_size=1.159 GB, available_memory=35.446 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.957 GB, invar_size=2.768 GB, outvar_size=1.324 GB, temp_buffer_size=1.159 GB, available_memory=35.446 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.178 GB, invar_size=5.266 GB, outvar_size=2.618 GB, temp_buffer_size=3.882 GB, available_memory=35.446 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.001, peak_memory=14.182 GB, invar_size=10.530 GB, outvar_size=0.030 GB, temp_buffer_size=3.623 GB, available_memory=35.446 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.135, peak_memory=2.343 GB, invar_size=1.006 GB, outvar_size=0.383 GB, temp_buffer_size=1.277 GB, available_memory=35.446 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=5.371 GB, invar_size=3.369 GB, outvar_size=0.090 GB, temp_buffer_size=1.912 GB, available_memory=35.446 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=5.371 GB, invar_size=3.369 GB, outvar_size=0.090 GB, temp_buffer_size=1.912 GB, available_memory=35.446 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=7.282 GB, invar_size=5.310 GB, outvar_size=0.060 GB, temp_buffer_size=1.912 GB, available_memory=35.446 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.001, peak_memory=14.017 GB, invar_size=10.407 GB, outvar_size=0.015 GB, temp_buffer_size=3.595 GB, available_memory=35.446 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=7.282 GB, invar_size=5.310 GB, outvar_size=0.060 GB, temp_buffer_size=1.912 GB, available_memory=35.446 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.957 GB, invar_size=2.768 GB, outvar_size=1.324 GB, temp_buffer_size=1.159 GB, available_memory=35.446 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=7.141 GB, invar_size=5.227 GB, outvar_size=0.030 GB, temp_buffer_size=1.885 GB, available_memory=35.446 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=7.141 GB, invar_size=5.227 GB, outvar_size=0.030 GB, temp_buffer_size=1.885 GB, available_memory=35.446 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=2.725 GB, invar_size=1.474 GB, outvar_size=0.707 GB, temp_buffer_size=1.191 GB, available_memory=35.446 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.957 GB, invar_size=2.768 GB, outvar_size=1.324 GB, temp_buffer_size=1.159 GB, available_memory=35.446 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.125, peak_memory=26.547 GB, invar_size=13.308 GB, outvar_size=6.647 GB, temp_buffer_size=13.209 GB, available_memory=35.446 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.197, peak_memory=36.957 GB, invar_size=21.058 GB, outvar_size=10.529 GB, temp_buffer_size=15.870 GB, available_memory=35.446 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=2.691 GB, invar_size=1.135 GB, outvar_size=0.448 GB, temp_buffer_size=1.437 GB, available_memory=35.446 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=3.027 GB, invar_size=1.612 GB, outvar_size=0.776 GB, temp_buffer_size=1.295 GB, available_memory=35.446 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=9.707 GB, invar_size=6.767 GB, outvar_size=3.338 GB, temp_buffer_size=2.910 GB, available_memory=35.446 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.195, peak_memory=36.395 GB, invar_size=20.813 GB, outvar_size=10.406 GB, temp_buffer_size=15.567 GB, available_memory=35.446 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=9.707 GB, invar_size=6.767 GB, outvar_size=3.338 GB, temp_buffer_size=2.910 GB, available_memory=35.446 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.059, peak_memory=13.752 GB, invar_size=10.619 GB, outvar_size=5.280 GB, temp_buffer_size=3.103 GB, available_memory=35.446 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.030, peak_memory=13.412 GB, invar_size=10.451 GB, outvar_size=5.211 GB, temp_buffer_size=2.946 GB, available_memory=35.446 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.030, peak_memory=13.412 GB, invar_size=10.451 GB, outvar_size=5.211 GB, temp_buffer_size=2.946 GB, available_memory=35.446 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.059, peak_memory=13.752 GB, invar_size=10.619 GB, outvar_size=5.280 GB, temp_buffer_size=3.103 GB, available_memory=35.446 GB)
Profiling for submesh 1 (1, 2) takes 17.55 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.640 GB, invar_size=0.443 GB, outvar_size=0.120 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.640 GB, invar_size=0.443 GB, outvar_size=0.120 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.640 GB, invar_size=0.443 GB, outvar_size=0.120 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.713 GB, invar_size=0.320 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.866 GB, invar_size=0.572 GB, outvar_size=0.120 GB, temp_buffer_size=1.174 GB, available_memory=35.446 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.866 GB, invar_size=0.572 GB, outvar_size=0.120 GB, temp_buffer_size=1.174 GB, available_memory=35.446 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.640 GB, invar_size=0.443 GB, outvar_size=0.120 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.713 GB, invar_size=0.320 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.713 GB, invar_size=0.320 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.304 GB, invar_size=0.091 GB, outvar_size=0.239 GB, temp_buffer_size=1.974 GB, available_memory=35.446 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.304 GB, invar_size=0.091 GB, outvar_size=0.239 GB, temp_buffer_size=1.974 GB, available_memory=35.446 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.713 GB, invar_size=0.320 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.842 GB, invar_size=0.886 GB, outvar_size=0.443 GB, temp_buffer_size=1.836 GB, available_memory=35.446 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.842 GB, invar_size=0.886 GB, outvar_size=0.443 GB, temp_buffer_size=1.836 GB, available_memory=35.446 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.404 GB, invar_size=0.640 GB, outvar_size=0.320 GB, temp_buffer_size=3.525 GB, available_memory=35.446 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.404 GB, invar_size=0.640 GB, outvar_size=0.320 GB, temp_buffer_size=3.525 GB, available_memory=35.446 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.813 GB, invar_size=1.451 GB, outvar_size=0.060 GB, temp_buffer_size=1.302 GB, available_memory=35.446 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.080 GB, invar_size=0.886 GB, outvar_size=0.443 GB, temp_buffer_size=2.074 GB, available_memory=35.446 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.080 GB, invar_size=0.886 GB, outvar_size=0.443 GB, temp_buffer_size=2.074 GB, available_memory=35.446 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.813 GB, invar_size=1.451 GB, outvar_size=0.060 GB, temp_buffer_size=1.302 GB, available_memory=35.446 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.414 GB, invar_size=1.024 GB, outvar_size=0.572 GB, temp_buffer_size=2.150 GB, available_memory=35.446 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.404 GB, invar_size=0.640 GB, outvar_size=0.320 GB, temp_buffer_size=3.525 GB, available_memory=35.446 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.404 GB, invar_size=0.640 GB, outvar_size=0.320 GB, temp_buffer_size=3.525 GB, available_memory=35.446 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.414 GB, invar_size=1.024 GB, outvar_size=0.572 GB, temp_buffer_size=2.150 GB, available_memory=35.446 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.785 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=2.017 GB, available_memory=35.446 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.815 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=2.047 GB, available_memory=35.446 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.815 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=2.047 GB, available_memory=35.446 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.785 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=2.017 GB, available_memory=35.446 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.005 GB, invar_size=0.411 GB, outvar_size=0.081 GB, temp_buffer_size=3.593 GB, available_memory=35.446 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.005 GB, invar_size=0.411 GB, outvar_size=0.081 GB, temp_buffer_size=3.593 GB, available_memory=35.446 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.592 GB, invar_size=1.354 GB, outvar_size=0.060 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.726 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=1.958 GB, available_memory=35.446 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.210 GB, invar_size=2.841 GB, outvar_size=1.450 GB, temp_buffer_size=2.250 GB, available_memory=35.446 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.726 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=1.958 GB, available_memory=35.446 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.726 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=1.958 GB, available_memory=35.446 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.210 GB, invar_size=2.841 GB, outvar_size=1.450 GB, temp_buffer_size=2.250 GB, available_memory=35.446 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.726 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=1.958 GB, available_memory=35.446 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.909 GB, invar_size=5.207 GB, outvar_size=0.030 GB, temp_buffer_size=3.673 GB, available_memory=35.446 GB)
result[(13, 13, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.143 GB, invar_size=5.384 GB, outvar_size=0.030 GB, temp_buffer_size=3.729 GB, available_memory=35.446 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.640 GB, invar_size=0.443 GB, outvar_size=0.120 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.909 GB, invar_size=5.207 GB, outvar_size=0.030 GB, temp_buffer_size=3.673 GB, available_memory=35.446 GB)
result[(13, 13, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.143 GB, invar_size=5.384 GB, outvar_size=0.030 GB, temp_buffer_size=3.729 GB, available_memory=35.446 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.726 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=1.958 GB, available_memory=35.446 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.640 GB, invar_size=0.443 GB, outvar_size=0.120 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.726 GB, invar_size=2.708 GB, outvar_size=1.354 GB, temp_buffer_size=1.958 GB, available_memory=35.446 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.919 GB, invar_size=5.246 GB, outvar_size=0.000 GB, temp_buffer_size=3.673 GB, available_memory=35.446 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.919 GB, invar_size=5.246 GB, outvar_size=0.000 GB, temp_buffer_size=3.673 GB, available_memory=35.446 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=15.865 GB, invar_size=10.412 GB, outvar_size=5.206 GB, temp_buffer_size=5.422 GB, available_memory=35.446 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=15.865 GB, invar_size=10.412 GB, outvar_size=5.206 GB, temp_buffer_size=5.422 GB, available_memory=35.446 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.961 GB, invar_size=0.886 GB, outvar_size=0.443 GB, temp_buffer_size=1.955 GB, available_memory=35.446 GB)
result[(13, 13, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.493 GB, invar_size=10.735 GB, outvar_size=5.383 GB, temp_buffer_size=5.698 GB, available_memory=35.446 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.961 GB, invar_size=0.886 GB, outvar_size=0.443 GB, temp_buffer_size=1.955 GB, available_memory=35.446 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=15.853 GB, invar_size=10.460 GB, outvar_size=5.245 GB, temp_buffer_size=5.363 GB, available_memory=35.446 GB)
result[(13, 13, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.493 GB, invar_size=10.735 GB, outvar_size=5.383 GB, temp_buffer_size=5.698 GB, available_memory=35.446 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=15.853 GB, invar_size=10.460 GB, outvar_size=5.245 GB, temp_buffer_size=5.363 GB, available_memory=35.446 GB)
Profiling for submesh 0 (1, 1) takes 12.45 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
Result mesh_shapes: [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]
Result logical_mesh_shapes: [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}]
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO comm 0x4cf2030 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO comm 0x4d40f60 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO comm 0x4958050 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO comm 0x7855a90 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO comm 0x746d8f0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO comm 0x49f1c00 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO comm 0x9f5c160 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO comm 0x4281050 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO comm 0x6c4b4b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO comm 0x499afa0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=787536)[0m 
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=787536)[0m 
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=787536)[0m 
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO comm 0x3f15b30 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO comm 0x9f05d80 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=787538)[0m 
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=787538)[0m 
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=787538)[0m 
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=787536)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=787536)[0m 
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO comm 0x410b3d0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=787538)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO comm 0x6fbd640 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=787538)[0m 
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO comm 0x99ef6f0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO comm 0x43043e0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO comm 0x44d77e0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO comm 0x70f4950 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO comm 0x9a42220 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO comm 0x396fbd0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO comm 0x676b8f0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO comm 0x3e5b880 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO comm 0x69708b0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO comm 0x4a12e60 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO comm 0xa2432c0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO comm 0x4b95730 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO comm 0x7985f00 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO comm 0x3fd55d0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2559882, ip=192.168.0.38)[0m gpu23:2559882:2559882 [0] NCCL INFO comm 0x3cc3a50 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO comm 0x5feb8e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
 - Compile (driver): 55.58 s
compilation time breakdown: {'stage-construction': '32.20', 'stage-construction-dp': '1.36', 'stage-construction-compilation': '6.43', 'stage-construction-profiling': '11.59'}
 - Compile (worker): 3.55 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2417820, ip=192.168.0.27)[0m gpu12:2417820:2417820 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2417822, ip=192.168.0.27)[0m gpu12:2417822:2417822 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3321239, ip=192.168.0.31)[0m gpu16:3321239:3321239 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3321241, ip=192.168.0.31)[0m gpu16:3321241:3321241 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2217009, ip=192.168.0.18)[0m gpu3:2217009:2217009 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2217011, ip=192.168.0.18)[0m gpu3:2217011:2217011 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=787536)[0m gpu2:787536:787536 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=787538)[0m gpu2:787538:787538 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3709516, ip=192.168.0.39)[0m gpu24:3709516:3709516 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3709517, ip=192.168.0.39)[0m gpu24:3709517:3709517 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1021070, ip=192.168.0.26)[0m gpu11:1021070:1021070 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1021078, ip=192.168.0.26)[0m gpu11:1021078:1021078 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1536084, ip=192.168.0.32)[0m gpu17:1536084:1536084 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1536070, ip=192.168.0.32)[0m gpu17:1536070:1536070 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2559876, ip=192.168.0.38)[0m gpu23:2559876:2559876 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 381.64 s

[102.64545154571533, 46.04942083358765, 45.88455533981323, 45.83460712432861, 45.88702702522278, 45.96427083015442, 45.844578981399536]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 231.879 s.
 - Average e2e iteration time: 46.37600326538086 s.
 - Total local training time: 229.41500854492188 s.
 - Average local iteration time: 45.88300323486328 s.
 - Max allocated memory among devices: 22.823 GB.
 - Compilation times:  {'stage-construction': 32.20143699645996, 'stage-construction-dp': 1.3643248081207275, 'stage-construction-compilation': 6.433485269546509, 'stage-construction-profiling': 11.58676266670227}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a40_8_n_2_d`: 45.88300704956055
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_6.8B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling wide_resnet_6.8B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_6.8B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 320
    width_factor = 16
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (512, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.256 GB, invar_size=1.774 GB, outvar_size=0.180 GB, temp_buffer_size=1.302 GB, available_memory=35.446 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.083 GB, invar_size=0.767 GB, outvar_size=0.239 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.083 GB, invar_size=0.767 GB, outvar_size=0.239 GB, temp_buffer_size=1.077 GB, available_memory=35.446 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.124 GB, invar_size=0.171 GB, outvar_size=0.479 GB, temp_buffer_size=2.474 GB, available_memory=35.446 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.154, peak_memory=2.238 GB, invar_size=0.563 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.097, peak_memory=2.740 GB, invar_size=1.552 GB, outvar_size=0.239 GB, temp_buffer_size=0.948 GB, available_memory=35.446 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.383, peak_memory=3.489 GB, invar_size=0.099 GB, outvar_size=0.957 GB, temp_buffer_size=2.432 GB, available_memory=35.446 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.167 GB, invar_size=2.745 GB, outvar_size=0.120 GB, temp_buffer_size=1.302 GB, available_memory=35.446 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.451 GB, invar_size=0.896 GB, outvar_size=0.239 GB, temp_buffer_size=1.316 GB, available_memory=35.446 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.190, peak_memory=2.880 GB, invar_size=0.807 GB, outvar_size=0.479 GB, temp_buffer_size=1.594 GB, available_memory=35.446 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.114 GB, invar_size=0.401 GB, outvar_size=0.479 GB, temp_buffer_size=2.234 GB, available_memory=35.446 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.134, peak_memory=2.622 GB, invar_size=1.067 GB, outvar_size=0.359 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.056, peak_memory=2.336 GB, invar_size=1.140 GB, outvar_size=0.239 GB, temp_buffer_size=0.957 GB, available_memory=35.446 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.124 GB, invar_size=0.171 GB, outvar_size=0.479 GB, temp_buffer_size=2.474 GB, available_memory=35.446 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.266, peak_memory=3.796 GB, invar_size=0.686 GB, outvar_size=0.718 GB, temp_buffer_size=2.393 GB, available_memory=35.446 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.165 GB, invar_size=0.653 GB, outvar_size=0.359 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.165 GB, invar_size=0.653 GB, outvar_size=0.359 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.307, peak_memory=3.950 GB, invar_size=0.560 GB, outvar_size=0.957 GB, temp_buffer_size=2.433 GB, available_memory=35.446 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=3.832 GB, invar_size=1.653 GB, outvar_size=0.767 GB, temp_buffer_size=2.059 GB, available_memory=35.446 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.270, peak_memory=3.629 GB, invar_size=1.365 GB, outvar_size=0.443 GB, temp_buffer_size=2.145 GB, available_memory=35.446 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.114 GB, invar_size=0.401 GB, outvar_size=0.479 GB, temp_buffer_size=2.234 GB, available_memory=35.446 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.006 GB, invar_size=2.649 GB, outvar_size=0.120 GB, temp_buffer_size=1.238 GB, available_memory=35.446 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.097, peak_memory=2.740 GB, invar_size=1.552 GB, outvar_size=0.239 GB, temp_buffer_size=0.948 GB, available_memory=35.446 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=3.832 GB, invar_size=1.653 GB, outvar_size=0.767 GB, temp_buffer_size=2.059 GB, available_memory=35.446 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.050, peak_memory=9.577 GB, invar_size=5.489 GB, outvar_size=2.745 GB, temp_buffer_size=3.968 GB, available_memory=35.446 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=3.832 GB, invar_size=1.653 GB, outvar_size=0.767 GB, temp_buffer_size=2.059 GB, available_memory=35.446 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=2.601 GB, invar_size=1.414 GB, outvar_size=0.239 GB, temp_buffer_size=0.948 GB, available_memory=35.446 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.501, peak_memory=5.711 GB, invar_size=1.137 GB, outvar_size=0.081 GB, temp_buffer_size=4.574 GB, available_memory=35.446 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=4.914 GB, invar_size=0.812 GB, outvar_size=0.162 GB, temp_buffer_size=4.102 GB, available_memory=35.446 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.537, peak_memory=6.503 GB, invar_size=1.597 GB, outvar_size=0.320 GB, temp_buffer_size=4.666 GB, available_memory=35.446 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=2.601 GB, invar_size=1.414 GB, outvar_size=0.239 GB, temp_buffer_size=0.948 GB, available_memory=35.446 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=5.154 GB, invar_size=1.052 GB, outvar_size=0.162 GB, temp_buffer_size=4.102 GB, available_memory=35.446 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.184, peak_memory=5.089 GB, invar_size=3.104 GB, outvar_size=1.432 GB, temp_buffer_size=1.866 GB, available_memory=35.446 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.249, peak_memory=4.416 GB, invar_size=2.253 GB, outvar_size=0.947 GB, temp_buffer_size=2.044 GB, available_memory=35.446 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=4.327 GB, invar_size=1.791 GB, outvar_size=0.896 GB, temp_buffer_size=2.296 GB, available_memory=35.446 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.946 GB, invar_size=2.649 GB, outvar_size=0.120 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.203 GB, invar_size=0.767 GB, outvar_size=0.239 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=2.452 GB, invar_size=1.414 GB, outvar_size=0.239 GB, temp_buffer_size=0.798 GB, available_memory=35.446 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=4.675 GB, invar_size=2.947 GB, outvar_size=1.354 GB, temp_buffer_size=1.668 GB, available_memory=35.446 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.154, peak_memory=2.400 GB, invar_size=0.563 GB, outvar_size=0.479 GB, temp_buffer_size=1.358 GB, available_memory=35.446 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.298 GB, invar_size=5.356 GB, outvar_size=2.648 GB, temp_buffer_size=3.882 GB, available_memory=35.446 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=5.065 GB, invar_size=3.104 GB, outvar_size=1.432 GB, temp_buffer_size=1.841 GB, available_memory=35.446 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.032, peak_memory=7.030 GB, invar_size=3.608 GB, outvar_size=1.774 GB, temp_buffer_size=3.302 GB, available_memory=35.446 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=4.488 GB, invar_size=2.398 GB, outvar_size=1.139 GB, temp_buffer_size=1.970 GB, available_memory=35.446 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=4.831 GB, invar_size=1.041 GB, outvar_size=0.401 GB, temp_buffer_size=3.551 GB, available_memory=35.446 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.946 GB, invar_size=2.649 GB, outvar_size=0.120 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=4.831 GB, invar_size=1.041 GB, outvar_size=0.401 GB, temp_buffer_size=3.551 GB, available_memory=35.446 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.946 GB, invar_size=2.649 GB, outvar_size=0.120 GB, temp_buffer_size=1.178 GB, available_memory=35.446 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=2.452 GB, invar_size=1.414 GB, outvar_size=0.239 GB, temp_buffer_size=0.798 GB, available_memory=35.446 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.203 GB, invar_size=0.767 GB, outvar_size=0.239 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=2.452 GB, invar_size=1.414 GB, outvar_size=0.239 GB, temp_buffer_size=0.798 GB, available_memory=35.446 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=2.452 GB, invar_size=1.414 GB, outvar_size=0.239 GB, temp_buffer_size=0.798 GB, available_memory=35.446 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=2.452 GB, invar_size=1.414 GB, outvar_size=0.239 GB, temp_buffer_size=0.798 GB, available_memory=35.446 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=5.544 GB, invar_size=1.545 GB, outvar_size=0.653 GB, temp_buffer_size=3.760 GB, available_memory=35.446 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=5.424 GB, invar_size=1.425 GB, outvar_size=0.653 GB, temp_buffer_size=3.760 GB, available_memory=35.446 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.492, peak_memory=5.944 GB, invar_size=1.610 GB, outvar_size=0.446 GB, temp_buffer_size=4.095 GB, available_memory=35.446 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=2.452 GB, invar_size=1.414 GB, outvar_size=0.239 GB, temp_buffer_size=0.798 GB, available_memory=35.446 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.497 GB, invar_size=6.677 GB, outvar_size=0.090 GB, temp_buffer_size=3.729 GB, available_memory=35.446 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=4.615 GB, invar_size=2.947 GB, outvar_size=1.354 GB, temp_buffer_size=1.608 GB, available_memory=35.446 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.451 GB, invar_size=0.896 GB, outvar_size=0.239 GB, temp_buffer_size=1.316 GB, available_memory=35.446 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.298 GB, invar_size=5.356 GB, outvar_size=2.648 GB, temp_buffer_size=3.882 GB, available_memory=35.446 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=4.615 GB, invar_size=2.947 GB, outvar_size=1.354 GB, temp_buffer_size=1.608 GB, available_memory=35.446 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=4.675 GB, invar_size=2.947 GB, outvar_size=1.354 GB, temp_buffer_size=1.668 GB, available_memory=35.446 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=4.696 GB, invar_size=2.947 GB, outvar_size=1.354 GB, temp_buffer_size=1.689 GB, available_memory=35.446 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.070, peak_memory=5.614 GB, invar_size=3.429 GB, outvar_size=0.180 GB, temp_buffer_size=2.006 GB, available_memory=35.446 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=4.696 GB, invar_size=2.947 GB, outvar_size=1.354 GB, temp_buffer_size=1.689 GB, available_memory=35.446 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.070, peak_memory=5.614 GB, invar_size=3.429 GB, outvar_size=0.180 GB, temp_buffer_size=2.006 GB, available_memory=35.446 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=4.696 GB, invar_size=2.947 GB, outvar_size=1.354 GB, temp_buffer_size=1.689 GB, available_memory=35.446 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.298 GB, invar_size=5.356 GB, outvar_size=2.648 GB, temp_buffer_size=3.882 GB, available_memory=35.446 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.001, peak_memory=14.349 GB, invar_size=10.560 GB, outvar_size=0.060 GB, temp_buffer_size=3.729 GB, available_memory=35.446 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=7.496 GB, invar_size=5.370 GB, outvar_size=0.120 GB, temp_buffer_size=2.006 GB, available_memory=35.446 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=7.496 GB, invar_size=5.370 GB, outvar_size=0.120 GB, temp_buffer_size=2.006 GB, available_memory=35.446 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=4.696 GB, invar_size=2.947 GB, outvar_size=1.354 GB, temp_buffer_size=1.689 GB, available_memory=35.446 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.298 GB, invar_size=5.356 GB, outvar_size=2.648 GB, temp_buffer_size=3.882 GB, available_memory=35.446 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=7.328 GB, invar_size=5.256 GB, outvar_size=0.060 GB, temp_buffer_size=2.012 GB, available_memory=35.446 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.270, peak_memory=3.818 GB, invar_size=1.365 GB, outvar_size=0.443 GB, temp_buffer_size=2.334 GB, available_memory=35.446 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=7.328 GB, invar_size=5.256 GB, outvar_size=0.060 GB, temp_buffer_size=2.012 GB, available_memory=35.446 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.001, peak_memory=14.125 GB, invar_size=10.422 GB, outvar_size=0.030 GB, temp_buffer_size=3.673 GB, available_memory=35.446 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=3.832 GB, invar_size=1.653 GB, outvar_size=0.767 GB, temp_buffer_size=2.059 GB, available_memory=35.446 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.365, peak_memory=4.610 GB, invar_size=1.613 GB, outvar_size=0.567 GB, temp_buffer_size=2.757 GB, available_memory=35.446 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.125, peak_memory=26.652 GB, invar_size=13.383 GB, outvar_size=6.677 GB, temp_buffer_size=13.209 GB, available_memory=35.446 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.133, peak_memory=10.250 GB, invar_size=6.916 GB, outvar_size=3.368 GB, temp_buffer_size=3.274 GB, available_memory=35.446 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.133, peak_memory=10.250 GB, invar_size=6.916 GB, outvar_size=3.368 GB, temp_buffer_size=3.274 GB, available_memory=35.446 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.101, peak_memory=14.308 GB, invar_size=10.738 GB, outvar_size=5.309 GB, temp_buffer_size=3.509 GB, available_memory=35.446 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=13.894 GB, invar_size=10.511 GB, outvar_size=5.226 GB, temp_buffer_size=3.352 GB, available_memory=35.446 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=13.894 GB, invar_size=10.511 GB, outvar_size=5.226 GB, temp_buffer_size=3.352 GB, available_memory=35.446 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=4.525 GB, invar_size=1.911 GB, outvar_size=0.896 GB, temp_buffer_size=2.375 GB, available_memory=35.446 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.195, peak_memory=36.440 GB, invar_size=20.843 GB, outvar_size=10.421 GB, temp_buffer_size=15.568 GB, available_memory=35.446 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.101, peak_memory=14.308 GB, invar_size=10.738 GB, outvar_size=5.309 GB, temp_buffer_size=3.509 GB, available_memory=35.446 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.197, peak_memory=37.048 GB, invar_size=21.117 GB, outvar_size=10.559 GB, temp_buffer_size=15.870 GB, available_memory=35.446 GB)
Profiling for submesh 1 (1, 2) takes 17.29 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.956 GB, invar_size=0.563 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.956 GB, invar_size=0.563 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.956 GB, invar_size=0.563 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.345 GB, invar_size=0.560 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.345 GB, invar_size=0.560 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.956 GB, invar_size=0.563 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.302 GB, invar_size=0.812 GB, outvar_size=0.239 GB, temp_buffer_size=2.251 GB, available_memory=35.446 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.302 GB, invar_size=0.812 GB, outvar_size=0.239 GB, temp_buffer_size=2.251 GB, available_memory=35.446 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.815 GB, invar_size=1.126 GB, outvar_size=0.563 GB, temp_buffer_size=3.450 GB, available_memory=35.446 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.815 GB, invar_size=1.126 GB, outvar_size=0.563 GB, temp_buffer_size=3.450 GB, available_memory=35.446 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.345 GB, invar_size=0.560 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.345 GB, invar_size=0.560 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.054 GB, invar_size=1.126 GB, outvar_size=0.563 GB, temp_buffer_size=3.689 GB, available_memory=35.446 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.054 GB, invar_size=1.126 GB, outvar_size=0.563 GB, temp_buffer_size=3.689 GB, available_memory=35.446 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.591 GB, invar_size=1.119 GB, outvar_size=0.559 GB, temp_buffer_size=6.994 GB, available_memory=35.446 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.591 GB, invar_size=1.119 GB, outvar_size=0.559 GB, temp_buffer_size=6.994 GB, available_memory=35.446 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.526 GB, invar_size=0.100 GB, outvar_size=0.479 GB, temp_buffer_size=3.948 GB, available_memory=35.446 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.526 GB, invar_size=0.100 GB, outvar_size=0.479 GB, temp_buffer_size=3.948 GB, available_memory=35.446 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.931 GB, invar_size=1.383 GB, outvar_size=0.811 GB, temp_buffer_size=4.069 GB, available_memory=35.446 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.931 GB, invar_size=1.383 GB, outvar_size=0.811 GB, temp_buffer_size=4.069 GB, available_memory=35.446 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.681 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.734 GB, available_memory=35.446 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.591 GB, invar_size=1.119 GB, outvar_size=0.559 GB, temp_buffer_size=6.994 GB, available_memory=35.446 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.415 GB, invar_size=1.571 GB, outvar_size=0.120 GB, temp_buffer_size=1.725 GB, available_memory=35.446 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.591 GB, invar_size=1.119 GB, outvar_size=0.559 GB, temp_buffer_size=6.994 GB, available_memory=35.446 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.415 GB, invar_size=1.571 GB, outvar_size=0.120 GB, temp_buffer_size=1.725 GB, available_memory=35.446 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.681 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.734 GB, available_memory=35.446 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.800 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.853 GB, available_memory=35.446 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.350 GB, invar_size=3.020 GB, outvar_size=1.570 GB, temp_buffer_size=3.090 GB, available_memory=35.446 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.800 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.853 GB, available_memory=35.446 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.041 GB, invar_size=1.414 GB, outvar_size=0.120 GB, temp_buffer_size=1.507 GB, available_memory=35.446 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.791 GB, invar_size=0.659 GB, outvar_size=0.081 GB, temp_buffer_size=7.132 GB, available_memory=35.446 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.681 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.733 GB, available_memory=35.446 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.791 GB, invar_size=0.659 GB, outvar_size=0.081 GB, temp_buffer_size=7.132 GB, available_memory=35.446 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.350 GB, invar_size=3.020 GB, outvar_size=1.570 GB, temp_buffer_size=3.090 GB, available_memory=35.446 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.681 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.733 GB, available_memory=35.446 GB)
result[(13, 13, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.446 GB, invar_size=5.443 GB, outvar_size=0.060 GB, temp_buffer_size=3.943 GB, available_memory=35.446 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.126 GB, invar_size=5.237 GB, outvar_size=0.060 GB, temp_buffer_size=3.830 GB, available_memory=35.446 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.126 GB, invar_size=5.237 GB, outvar_size=0.060 GB, temp_buffer_size=3.830 GB, available_memory=35.446 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.681 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.733 GB, available_memory=35.446 GB)
result[(13, 13, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.446 GB, invar_size=5.443 GB, outvar_size=0.060 GB, temp_buffer_size=3.943 GB, available_memory=35.446 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.681 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.733 GB, available_memory=35.446 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.681 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.733 GB, available_memory=35.446 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.956 GB, invar_size=0.563 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.106 GB, invar_size=5.276 GB, outvar_size=0.000 GB, temp_buffer_size=3.830 GB, available_memory=35.446 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.681 GB, invar_size=2.828 GB, outvar_size=1.414 GB, temp_buffer_size=2.733 GB, available_memory=35.446 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.956 GB, invar_size=0.563 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.298 GB, invar_size=10.472 GB, outvar_size=5.236 GB, temp_buffer_size=5.766 GB, available_memory=35.446 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.106 GB, invar_size=5.276 GB, outvar_size=0.000 GB, temp_buffer_size=3.830 GB, available_memory=35.446 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.298 GB, invar_size=10.472 GB, outvar_size=5.236 GB, temp_buffer_size=5.766 GB, available_memory=35.446 GB)
result[(13, 13, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=17.005 GB, invar_size=10.825 GB, outvar_size=5.442 GB, temp_buffer_size=6.060 GB, available_memory=35.446 GB)
result[(13, 13, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=17.005 GB, invar_size=10.825 GB, outvar_size=5.442 GB, temp_buffer_size=6.060 GB, available_memory=35.446 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.197 GB, invar_size=10.490 GB, outvar_size=5.275 GB, temp_buffer_size=5.647 GB, available_memory=35.446 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.197 GB, invar_size=10.490 GB, outvar_size=5.275 GB, temp_buffer_size=5.647 GB, available_memory=35.446 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.054 GB, invar_size=1.126 GB, outvar_size=0.563 GB, temp_buffer_size=3.689 GB, available_memory=35.446 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.054 GB, invar_size=1.126 GB, outvar_size=0.563 GB, temp_buffer_size=3.689 GB, available_memory=35.446 GB)
Profiling for submesh 0 (1, 1) takes 12.29 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
Result mesh_shapes: [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]
Result logical_mesh_shapes: [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO comm 0x40286e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO comm 0x3b8f170 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO comm 0x92b66e0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO comm 0x39d22d0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO comm 0x92079b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO comm 0x44e9d60 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO comm 0x9a55020 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO comm 0x545fca0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO comm 0x748b5f0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO comm 0x350ff30 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=797820)[0m 
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797820)[0m 
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=797820)[0m 
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO comm 0x54fb9b0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO comm 0x630c050 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=797819)[0m 
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=797820)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=797819)[0m 
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=797819)[0m 
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO comm 0x45263b0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=797820)[0m 
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO comm 0xad2a4f0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=797819)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797819)[0m 
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO comm 0x9948900 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO comm 0x5354430 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO comm 0xaa65140 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO comm 0x3529400 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO comm 0x5535c70 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO comm 0x3a763b0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO comm 0x5a701e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO comm 0x34f9c90 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO comm 0x4b176f0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO comm 0x8a64840 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO comm 0x79080b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO comm 0x4cdb4d0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO comm 0x3a430e0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO comm 0x6ce7ea0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO comm 0x92721d0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1542433, ip=192.168.0.32)[0m gpu17:1542433:1542433 [0] NCCL INFO comm 0x463bca0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
 - Compile (driver): 55.65 s
compilation time breakdown: {'stage-construction': '31.63', 'stage-construction-dp': '1.12', 'stage-construction-compilation': '6.28', 'stage-construction-profiling': '11.54'}
 - Compile (worker): 3.90 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2424502, ip=192.168.0.27)[0m gpu12:2424502:2424502 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2424504, ip=192.168.0.27)[0m gpu12:2424504:2424504 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2223548, ip=192.168.0.18)[0m gpu3:2223548:2223548 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2223555, ip=192.168.0.18)[0m gpu3:2223555:2223555 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2563053, ip=192.168.0.38)[0m gpu23:2563053:2563053 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2563054, ip=192.168.0.38)[0m gpu23:2563054:2563054 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=797820)[0m gpu2:797820:797820 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=797819)[0m gpu2:797819:797819 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3715846, ip=192.168.0.39)[0m gpu24:3715846:3715846 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3715844, ip=192.168.0.39)[0m gpu24:3715844:3715844 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3324046, ip=192.168.0.31)[0m gpu16:3324046:3324046 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3324047, ip=192.168.0.31)[0m gpu16:3324047:3324047 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1026376, ip=192.168.0.26)[0m gpu11:1026376:1026376 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1026377, ip=192.168.0.26)[0m gpu11:1026377:1026377 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1542434, ip=192.168.0.32)[0m gpu17:1542434:1542434 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 579.07 s

[98.63564133644104, 79.3384153842926, 80.21589231491089, 79.16186141967773, 78.62005615234375, 78.41499757766724, 78.14332032203674]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 399.435 s.
 - Average e2e iteration time: 79.88700103759766 s.
 - Total local training time: 394.5560302734375 s.
 - Average local iteration time: 78.91100311279297 s.
 - Max allocated memory among devices: 24.292 GB.
 - Compilation times:  {'stage-construction': 31.633718729019165, 'stage-construction-dp': 1.1160480976104736, 'stage-construction-compilation': 6.279358386993408, 'stage-construction-profiling': 11.537607908248901}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a40_8_n_2_d`: 78.9112319946289
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_6.8B_512.pkl`...

------------------------------------------------------------------
- (3/3) Profiling wide_resnet_6.8B with batch size: 1024...
------------------------------------------------------------------
[TMP] Profiling results not found in `./jaxpr/prof_log/optimal/wide_resnet_6.8B_1024.pkl`, creating it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 320
    width_factor = 16
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (1024, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.406 GB, invar_size=1.894 GB, outvar_size=0.359 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.519 GB, invar_size=0.887 GB, outvar_size=0.479 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.519 GB, invar_size=0.887 GB, outvar_size=0.479 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.307, peak_memory=4.152 GB, invar_size=0.802 GB, outvar_size=0.957 GB, temp_buffer_size=2.393 GB, available_memory=35.446 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.917 GB, invar_size=0.892 GB, outvar_size=0.718 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.378, peak_memory=5.272 GB, invar_size=1.285 GB, outvar_size=0.957 GB, temp_buffer_size=3.030 GB, available_memory=35.446 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.985 GB, invar_size=0.640 GB, outvar_size=0.957 GB, temp_buffer_size=4.388 GB, available_memory=35.446 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.531, peak_memory=7.385 GB, invar_size=1.164 GB, outvar_size=1.436 GB, temp_buffer_size=4.785 GB, available_memory=35.446 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.004 GB, invar_size=0.180 GB, outvar_size=0.957 GB, temp_buffer_size=4.866 GB, available_memory=35.446 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.829 GB, invar_size=2.865 GB, outvar_size=0.239 GB, temp_buffer_size=1.725 GB, available_memory=35.446 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.191, peak_memory=3.727 GB, invar_size=1.791 GB, outvar_size=0.479 GB, temp_buffer_size=1.457 GB, available_memory=35.446 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.406 GB, invar_size=1.894 GB, outvar_size=0.359 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.538, peak_memory=6.501 GB, invar_size=2.083 GB, outvar_size=0.563 GB, temp_buffer_size=4.179 GB, available_memory=35.446 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.267, peak_memory=4.416 GB, invar_size=1.306 GB, outvar_size=0.718 GB, temp_buffer_size=2.393 GB, available_memory=35.446 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.917 GB, invar_size=0.892 GB, outvar_size=0.718 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.985 GB, invar_size=0.640 GB, outvar_size=0.957 GB, temp_buffer_size=4.388 GB, available_memory=35.446 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.330 GB, invar_size=1.135 GB, outvar_size=0.479 GB, temp_buffer_size=2.716 GB, available_memory=35.446 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.004 GB, invar_size=0.180 GB, outvar_size=0.957 GB, temp_buffer_size=4.866 GB, available_memory=35.446 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.766, peak_memory=6.856 GB, invar_size=0.117 GB, outvar_size=1.914 GB, temp_buffer_size=4.825 GB, available_memory=35.446 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=6.045 GB, invar_size=2.012 GB, outvar_size=0.886 GB, temp_buffer_size=3.793 GB, available_memory=35.446 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=6.045 GB, invar_size=2.012 GB, outvar_size=0.886 GB, temp_buffer_size=3.793 GB, available_memory=35.446 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=6.045 GB, invar_size=2.012 GB, outvar_size=0.886 GB, temp_buffer_size=3.793 GB, available_memory=35.446 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.613, peak_memory=7.778 GB, invar_size=1.038 GB, outvar_size=1.914 GB, temp_buffer_size=4.826 GB, available_memory=35.446 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.574 GB, invar_size=2.708 GB, outvar_size=0.239 GB, temp_buffer_size=1.627 GB, available_memory=35.446 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.190, peak_memory=3.751 GB, invar_size=1.816 GB, outvar_size=0.479 GB, temp_buffer_size=1.457 GB, available_memory=35.446 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.981, peak_memory=11.447 GB, invar_size=2.806 GB, outvar_size=0.685 GB, temp_buffer_size=8.163 GB, available_memory=35.446 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=9.915 GB, invar_size=2.263 GB, outvar_size=0.892 GB, temp_buffer_size=7.173 GB, available_memory=35.446 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.155, peak_memory=3.476 GB, invar_size=1.534 GB, outvar_size=0.479 GB, temp_buffer_size=1.464 GB, available_memory=35.446 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.366, peak_memory=6.937 GB, invar_size=3.582 GB, outvar_size=1.552 GB, temp_buffer_size=3.116 GB, available_memory=35.446 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.050, peak_memory=9.936 GB, invar_size=5.728 GB, outvar_size=2.864 GB, temp_buffer_size=3.968 GB, available_memory=35.446 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.155, peak_memory=3.476 GB, invar_size=1.534 GB, outvar_size=0.479 GB, temp_buffer_size=1.464 GB, available_memory=35.446 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=9.257 GB, invar_size=1.759 GB, outvar_size=0.640 GB, temp_buffer_size=7.020 GB, available_memory=35.446 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=1.074, peak_memory=12.844 GB, invar_size=3.033 GB, outvar_size=0.559 GB, temp_buffer_size=9.332 GB, available_memory=35.446 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.425 GB, invar_size=2.708 GB, outvar_size=0.239 GB, temp_buffer_size=1.477 GB, available_memory=35.446 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.425 GB, invar_size=2.708 GB, outvar_size=0.239 GB, temp_buffer_size=1.477 GB, available_memory=35.446 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.842 GB, invar_size=0.887 GB, outvar_size=0.479 GB, temp_buffer_size=2.477 GB, available_memory=35.446 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=9.257 GB, invar_size=1.759 GB, outvar_size=0.640 GB, temp_buffer_size=7.020 GB, available_memory=35.446 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.155, peak_memory=3.209 GB, invar_size=1.534 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.494, peak_memory=7.029 GB, invar_size=2.851 GB, outvar_size=1.067 GB, temp_buffer_size=3.939 GB, available_memory=35.446 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.155, peak_memory=3.209 GB, invar_size=1.534 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.155, peak_memory=3.209 GB, invar_size=1.534 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=9.675 GB, invar_size=2.024 GB, outvar_size=0.892 GB, temp_buffer_size=7.173 GB, available_memory=35.446 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.155, peak_memory=3.209 GB, invar_size=1.534 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.032, peak_memory=8.773 GB, invar_size=3.907 GB, outvar_size=1.894 GB, temp_buffer_size=4.627 GB, available_memory=35.446 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=6.202 GB, invar_size=3.306 GB, outvar_size=1.414 GB, temp_buffer_size=2.776 GB, available_memory=35.446 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.538 GB, invar_size=5.535 GB, outvar_size=2.708 GB, temp_buffer_size=3.883 GB, available_memory=35.446 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.032, peak_memory=8.893 GB, invar_size=4.027 GB, outvar_size=1.894 GB, temp_buffer_size=4.627 GB, available_memory=35.446 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=9.422 GB, invar_size=1.300 GB, outvar_size=0.162 GB, temp_buffer_size=8.123 GB, available_memory=35.446 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.425 GB, invar_size=2.708 GB, outvar_size=0.239 GB, temp_buffer_size=1.477 GB, available_memory=35.446 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.276, peak_memory=7.262 GB, invar_size=3.631 GB, outvar_size=1.576 GB, temp_buffer_size=3.392 GB, available_memory=35.446 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.155, peak_memory=3.209 GB, invar_size=1.534 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=6.921 GB, invar_size=2.270 GB, outvar_size=1.135 GB, temp_buffer_size=4.173 GB, available_memory=35.446 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.307, peak_memory=4.314 GB, invar_size=0.802 GB, outvar_size=0.957 GB, temp_buffer_size=2.554 GB, available_memory=35.446 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.842 GB, invar_size=0.887 GB, outvar_size=0.479 GB, temp_buffer_size=2.477 GB, available_memory=35.446 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=1.001, peak_memory=11.232 GB, invar_size=2.112 GB, outvar_size=0.081 GB, temp_buffer_size=9.120 GB, available_memory=35.446 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.330 GB, invar_size=1.135 GB, outvar_size=0.479 GB, temp_buffer_size=2.716 GB, available_memory=35.446 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.155, peak_memory=3.209 GB, invar_size=1.534 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=35.446 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=9.901 GB, invar_size=1.778 GB, outvar_size=0.162 GB, temp_buffer_size=8.123 GB, available_memory=35.446 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=5.978 GB, invar_size=3.306 GB, outvar_size=1.414 GB, temp_buffer_size=2.552 GB, available_memory=35.446 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=6.202 GB, invar_size=3.306 GB, outvar_size=1.414 GB, temp_buffer_size=2.776 GB, available_memory=35.446 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.538 GB, invar_size=5.535 GB, outvar_size=2.708 GB, temp_buffer_size=3.883 GB, available_memory=35.446 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.860 GB, invar_size=6.737 GB, outvar_size=0.180 GB, temp_buffer_size=3.943 GB, available_memory=35.446 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=5.978 GB, invar_size=3.306 GB, outvar_size=1.414 GB, temp_buffer_size=2.552 GB, available_memory=35.446 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.137, peak_memory=6.162 GB, invar_size=3.548 GB, outvar_size=0.359 GB, temp_buffer_size=2.254 GB, available_memory=35.446 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.137, peak_memory=6.162 GB, invar_size=3.548 GB, outvar_size=0.359 GB, temp_buffer_size=2.254 GB, available_memory=35.446 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.538, peak_memory=6.990 GB, invar_size=2.083 GB, outvar_size=0.563 GB, temp_buffer_size=4.668 GB, available_memory=35.446 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=5.903 GB, invar_size=3.306 GB, outvar_size=1.414 GB, temp_buffer_size=2.477 GB, available_memory=35.446 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.538 GB, invar_size=5.535 GB, outvar_size=2.708 GB, temp_buffer_size=3.883 GB, available_memory=35.446 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=5.903 GB, invar_size=3.306 GB, outvar_size=1.414 GB, temp_buffer_size=2.477 GB, available_memory=35.446 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.001, peak_memory=14.682 GB, invar_size=10.619 GB, outvar_size=0.120 GB, temp_buffer_size=3.943 GB, available_memory=35.446 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=5.903 GB, invar_size=3.306 GB, outvar_size=1.414 GB, temp_buffer_size=2.477 GB, available_memory=35.446 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.272, peak_memory=5.903 GB, invar_size=3.306 GB, outvar_size=1.414 GB, temp_buffer_size=2.477 GB, available_memory=35.446 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.104, peak_memory=7.983 GB, invar_size=5.490 GB, outvar_size=0.240 GB, temp_buffer_size=2.254 GB, available_memory=35.446 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.104, peak_memory=7.983 GB, invar_size=5.490 GB, outvar_size=0.240 GB, temp_buffer_size=2.254 GB, available_memory=35.446 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=9.538 GB, invar_size=5.535 GB, outvar_size=2.708 GB, temp_buffer_size=3.883 GB, available_memory=35.446 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.001, peak_memory=14.342 GB, invar_size=10.452 GB, outvar_size=0.060 GB, temp_buffer_size=3.830 GB, available_memory=35.446 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=7.702 GB, invar_size=5.316 GB, outvar_size=0.120 GB, temp_buffer_size=2.266 GB, available_memory=35.446 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=7.702 GB, invar_size=5.316 GB, outvar_size=0.120 GB, temp_buffer_size=2.266 GB, available_memory=35.446 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.125, peak_memory=26.861 GB, invar_size=13.533 GB, outvar_size=6.737 GB, temp_buffer_size=13.209 GB, available_memory=35.446 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=6.045 GB, invar_size=2.012 GB, outvar_size=0.886 GB, temp_buffer_size=3.793 GB, available_memory=35.446 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.256, peak_memory=11.246 GB, invar_size=7.215 GB, outvar_size=3.428 GB, temp_buffer_size=3.911 GB, available_memory=35.446 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.726, peak_memory=8.447 GB, invar_size=2.570 GB, outvar_size=0.807 GB, temp_buffer_size=5.398 GB, available_memory=35.446 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.013, peak_memory=7.202 GB, invar_size=2.509 GB, outvar_size=1.135 GB, temp_buffer_size=4.214 GB, available_memory=35.446 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.191, peak_memory=14.954 GB, invar_size=10.978 GB, outvar_size=5.369 GB, temp_buffer_size=3.857 GB, available_memory=35.446 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.197, peak_memory=37.276 GB, invar_size=21.237 GB, outvar_size=10.619 GB, temp_buffer_size=15.919 GB, available_memory=35.446 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.191, peak_memory=14.954 GB, invar_size=10.978 GB, outvar_size=5.369 GB, temp_buffer_size=3.857 GB, available_memory=35.446 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.256, peak_memory=11.246 GB, invar_size=7.215 GB, outvar_size=3.428 GB, temp_buffer_size=3.911 GB, available_memory=35.446 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.195, peak_memory=36.530 GB, invar_size=20.902 GB, outvar_size=10.451 GB, temp_buffer_size=15.568 GB, available_memory=35.446 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=14.342 GB, invar_size=10.631 GB, outvar_size=5.256 GB, temp_buffer_size=3.652 GB, available_memory=35.446 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=14.342 GB, invar_size=10.631 GB, outvar_size=5.256 GB, temp_buffer_size=3.652 GB, available_memory=35.446 GB)
Profiling for submesh 1 (1, 2) takes 17.27 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.608 GB, invar_size=1.038 GB, outvar_size=0.957 GB, temp_buffer_size=8.613 GB, available_memory=35.446 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.588 GB, invar_size=0.802 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.608 GB, invar_size=1.038 GB, outvar_size=0.957 GB, temp_buffer_size=8.613 GB, available_memory=35.446 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.588 GB, invar_size=0.802 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.588 GB, invar_size=0.802 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.173 GB, invar_size=1.290 GB, outvar_size=0.479 GB, temp_buffer_size=4.404 GB, available_memory=35.446 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.588 GB, invar_size=0.802 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.173 GB, invar_size=1.290 GB, outvar_size=0.479 GB, temp_buffer_size=4.404 GB, available_memory=35.446 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.965 GB, invar_size=2.076 GB, outvar_size=1.038 GB, temp_buffer_size=13.932 GB, available_memory=35.446 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.241 GB, invar_size=1.604 GB, outvar_size=0.802 GB, temp_buffer_size=7.158 GB, available_memory=35.446 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.965 GB, invar_size=2.076 GB, outvar_size=1.038 GB, temp_buffer_size=13.932 GB, available_memory=35.446 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.763 GB, invar_size=1.604 GB, outvar_size=0.802 GB, temp_buffer_size=6.680 GB, available_memory=35.446 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.241 GB, invar_size=1.604 GB, outvar_size=0.802 GB, temp_buffer_size=7.158 GB, available_memory=35.446 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.763 GB, invar_size=1.604 GB, outvar_size=0.802 GB, temp_buffer_size=6.680 GB, available_memory=35.446 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.608 GB, invar_size=1.038 GB, outvar_size=0.957 GB, temp_buffer_size=8.613 GB, available_memory=35.446 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.608 GB, invar_size=1.038 GB, outvar_size=0.957 GB, temp_buffer_size=8.613 GB, available_memory=35.446 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.964 GB, invar_size=2.101 GB, outvar_size=1.290 GB, temp_buffer_size=7.906 GB, available_memory=35.446 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.964 GB, invar_size=2.101 GB, outvar_size=1.290 GB, temp_buffer_size=7.906 GB, available_memory=35.446 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.620 GB, invar_size=1.810 GB, outvar_size=0.239 GB, temp_buffer_size=2.571 GB, available_memory=35.446 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.620 GB, invar_size=1.810 GB, outvar_size=0.239 GB, temp_buffer_size=2.571 GB, available_memory=35.446 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.970 GB, invar_size=0.118 GB, outvar_size=0.957 GB, temp_buffer_size=7.896 GB, available_memory=35.446 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.970 GB, invar_size=0.118 GB, outvar_size=0.957 GB, temp_buffer_size=7.896 GB, available_memory=35.446 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.655 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.349 GB, available_memory=35.446 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.655 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.349 GB, available_memory=35.446 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.822 GB, invar_size=3.379 GB, outvar_size=1.809 GB, temp_buffer_size=4.964 GB, available_memory=35.446 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.655 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.349 GB, available_memory=35.446 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.655 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.349 GB, available_memory=35.446 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.965 GB, invar_size=2.076 GB, outvar_size=1.038 GB, temp_buffer_size=13.932 GB, available_memory=35.446 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.965 GB, invar_size=2.076 GB, outvar_size=1.038 GB, temp_buffer_size=13.932 GB, available_memory=35.446 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.822 GB, invar_size=3.379 GB, outvar_size=1.809 GB, temp_buffer_size=4.964 GB, available_memory=35.446 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.927 GB, invar_size=1.534 GB, outvar_size=0.239 GB, temp_buffer_size=2.153 GB, available_memory=35.446 GB)
result[(13, 13, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.053 GB, invar_size=5.563 GB, outvar_size=0.120 GB, temp_buffer_size=4.371 GB, available_memory=35.446 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.415 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.109 GB, available_memory=35.446 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.588 GB, invar_size=0.802 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(13, 13, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=10.053 GB, invar_size=5.563 GB, outvar_size=0.120 GB, temp_buffer_size=4.371 GB, available_memory=35.446 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=15.364 GB, invar_size=1.156 GB, outvar_size=0.081 GB, temp_buffer_size=14.208 GB, available_memory=35.446 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=15.364 GB, invar_size=1.156 GB, outvar_size=0.081 GB, temp_buffer_size=14.208 GB, available_memory=35.446 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.415 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.109 GB, available_memory=35.446 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.530 GB, invar_size=5.297 GB, outvar_size=0.120 GB, temp_buffer_size=4.114 GB, available_memory=35.446 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.415 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.109 GB, available_memory=35.446 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.530 GB, invar_size=5.297 GB, outvar_size=0.120 GB, temp_buffer_size=4.114 GB, available_memory=35.446 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.588 GB, invar_size=0.802 GB, outvar_size=0.479 GB, temp_buffer_size=4.307 GB, available_memory=35.446 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.415 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.109 GB, available_memory=35.446 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.415 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.109 GB, available_memory=35.446 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.415 GB, invar_size=3.067 GB, outvar_size=1.533 GB, temp_buffer_size=4.109 GB, available_memory=35.446 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.479 GB, invar_size=5.336 GB, outvar_size=0.000 GB, temp_buffer_size=4.144 GB, available_memory=35.446 GB)
result[(13, 13, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=18.090 GB, invar_size=11.004 GB, outvar_size=5.562 GB, temp_buffer_size=6.847 GB, available_memory=35.446 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.479 GB, invar_size=5.336 GB, outvar_size=0.000 GB, temp_buffer_size=4.144 GB, available_memory=35.446 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=17.165 GB, invar_size=10.592 GB, outvar_size=5.296 GB, temp_buffer_size=6.454 GB, available_memory=35.446 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.241 GB, invar_size=1.604 GB, outvar_size=0.802 GB, temp_buffer_size=7.158 GB, available_memory=35.446 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=17.165 GB, invar_size=10.592 GB, outvar_size=5.296 GB, temp_buffer_size=6.454 GB, available_memory=35.446 GB)
result[(13, 13, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=18.090 GB, invar_size=11.004 GB, outvar_size=5.562 GB, temp_buffer_size=6.847 GB, available_memory=35.446 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.885 GB, invar_size=10.550 GB, outvar_size=5.335 GB, temp_buffer_size=6.215 GB, available_memory=35.446 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.241 GB, invar_size=1.604 GB, outvar_size=0.802 GB, temp_buffer_size=7.158 GB, available_memory=35.446 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=16.885 GB, invar_size=10.550 GB, outvar_size=5.335 GB, temp_buffer_size=6.215 GB, available_memory=35.446 GB)
Profiling for submesh 0 (1, 1) takes 12.20 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
Result mesh_shapes: [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]
Result logical_mesh_shapes: [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}]
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO comm 0x4280bd0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO comm 0x354bbd0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m 
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO comm 0x3bda700 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.26<0>
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO comm 0x97e6fa0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO comm 0x66efba0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO comm 0x39bad40 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m 
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO comm 0x90f5870 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO comm 0x5152960 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.37<0>
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO comm 0x3f966b0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO comm 0x7149780 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=808658)[0m 
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m 
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808658)[0m 
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=808658)[0m 
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO comm 0x4e78ec0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO comm 0x5fa3600 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=808658)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=808657)[0m 
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=808658)[0m 
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO comm 0xa747690 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=808657)[0m 
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=808657)[0m 
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO comm 0x3ee9280 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=808657)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=808657)[0m 
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO comm 0x95f29e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO comm 0x4f54d70 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO comm 0xa783f10 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO comm 0x3e02c70 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO comm 0x9361c60 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO comm 0x48f4330 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO comm 0x365d470 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO comm 0x68eaaa0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO comm 0x6178e70 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO comm 0x42d1690 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.31<0>
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO comm 0x70c88c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO comm 0x4cae910 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m 
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO comm 0xa3d5890 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO comm 0x4bc3760 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO comm 0xa118650 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2230316, ip=192.168.0.18)[0m gpu3:2230316:2230316 [0] NCCL INFO comm 0x3e90720 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
 - Compile (driver): 55.63 s
compilation time breakdown: {'stage-construction': '31.67', 'stage-construction-dp': '1.37', 'stage-construction-compilation': '6.32', 'stage-construction-profiling': '11.47'}
 - Compile (worker): 3.55 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=3327249, ip=192.168.0.31)[0m gpu16:3327249:3327249 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3327214, ip=192.168.0.31)[0m gpu16:3327214:3327214 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2431463, ip=192.168.0.27)[0m gpu12:2431463:2431463 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2431471, ip=192.168.0.27)[0m gpu12:2431471:2431471 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2566522, ip=192.168.0.38)[0m gpu23:2566522:2566522 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2566523, ip=192.168.0.38)[0m gpu23:2566523:2566523 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=808658)[0m gpu2:808658:808658 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=808657)[0m gpu2:808657:808657 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3722653, ip=192.168.0.39)[0m gpu24:3722653:3722653 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3722656, ip=192.168.0.39)[0m gpu24:3722656:3722656 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1032084, ip=192.168.0.26)[0m gpu11:1032084:1032084 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1032083, ip=192.168.0.26)[0m gpu11:1032083:1032083 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1548901, ip=192.168.0.32)[0m gpu17:1548901:1548901 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1548902, ip=192.168.0.32)[0m gpu17:1548902:1548902 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2230275, ip=192.168.0.18)[0m gpu3:2230275:2230275 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 1017.45 s

[178.74214434623718, 138.1411108970642, 137.39539432525635, 137.66760158538818, 137.45533752441406, 137.6792266368866, 137.11541509628296]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 696.902 s.
 - Average e2e iteration time: 139.3800048828125 s.
 - Total local training time: 687.3130493164062 s.
 - Average local iteration time: 137.4630126953125 s.
 - Max allocated memory among devices: 32.358 GB.
 - Compilation times:  {'stage-construction': 31.668312072753906, 'stage-construction-dp': 1.3660669326782227, 'stage-construction-compilation': 6.320687532424927, 'stage-construction-profiling': 11.467024326324463}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a40_8_n_2_d`: 137.4626007080078
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_6.8B_1024.pkl`...
