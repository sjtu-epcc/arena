
------------------------------------------------------------------
- (1/3) Profiling bert_1.3B with batch size: 128...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_128.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f44bc7d0640>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=2.421 GB, invar_size=2.198 GB, outvar_size=0.027 GB, temp_buffer_size=0.195 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=1.252 GB, invar_size=1.099 GB, outvar_size=0.055 GB, temp_buffer_size=0.098 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.416, peak_memory=2.249 GB, invar_size=2.026 GB, outvar_size=0.027 GB, temp_buffer_size=0.195 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=2.162, peak_memory=7.983 GB, invar_size=5.331 GB, outvar_size=2.652 GB, temp_buffer_size=2.652 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=1.097, peak_memory=4.033 GB, invar_size=2.707 GB, outvar_size=1.326 GB, temp_buffer_size=1.326 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=2.691, peak_memory=7.005 GB, invar_size=4.644 GB, outvar_size=2.308 GB, temp_buffer_size=2.362 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 143.68 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.086, peak_memory=0.719 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=0.313 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.024, peak_memory=0.969 GB, invar_size=0.641 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.086, peak_memory=0.719 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=0.313 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.024, peak_memory=0.969 GB, invar_size=0.641 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.026, peak_memory=1.119 GB, invar_size=0.698 GB, outvar_size=0.031 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.052 GB, invar_size=0.599 GB, outvar_size=0.031 GB, temp_buffer_size=0.422 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.080, peak_memory=0.786 GB, invar_size=0.349 GB, outvar_size=0.047 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.022, peak_memory=0.907 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.024, peak_memory=0.969 GB, invar_size=0.641 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.022, peak_memory=0.907 GB, invar_size=0.578 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.024, peak_memory=0.969 GB, invar_size=0.641 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.076, peak_memory=0.672 GB, invar_size=0.313 GB, outvar_size=0.047 GB, temp_buffer_size=0.313 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=0.938 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.076, peak_memory=3.784 GB, invar_size=1.313 GB, outvar_size=0.641 GB, temp_buffer_size=2.456 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.076, peak_memory=3.769 GB, invar_size=1.298 GB, outvar_size=0.641 GB, temp_buffer_size=2.456 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.082, peak_memory=0.688 GB, invar_size=0.328 GB, outvar_size=0.047 GB, temp_buffer_size=0.313 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=0.938 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=0.938 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.189, peak_memory=3.621 GB, invar_size=0.719 GB, outvar_size=0.344 GB, temp_buffer_size=2.870 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.076, peak_memory=3.753 GB, invar_size=1.298 GB, outvar_size=0.641 GB, temp_buffer_size=2.440 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.082, peak_memory=0.688 GB, invar_size=0.328 GB, outvar_size=0.047 GB, temp_buffer_size=0.313 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.456 GB, invar_size=1.172 GB, outvar_size=0.578 GB, temp_buffer_size=2.267 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=3.456 GB, invar_size=1.172 GB, outvar_size=0.578 GB, temp_buffer_size=2.267 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=0.610 GB, invar_size=0.297 GB, outvar_size=0.016 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.180, peak_memory=3.837 GB, invar_size=0.760 GB, outvar_size=0.349 GB, temp_buffer_size=3.077 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.077, peak_memory=3.979 GB, invar_size=1.426 GB, outvar_size=0.698 GB, temp_buffer_size=2.553 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=0.516 GB, invar_size=0.172 GB, outvar_size=0.031 GB, temp_buffer_size=0.313 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=0.938 GB, invar_size=0.610 GB, outvar_size=0.031 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=0.610 GB, invar_size=0.297 GB, outvar_size=0.016 GB, temp_buffer_size=0.297 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.179, peak_memory=3.464 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.776 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.189, peak_memory=3.714 GB, invar_size=0.719 GB, outvar_size=0.344 GB, temp_buffer_size=2.963 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.076, peak_memory=3.769 GB, invar_size=1.298 GB, outvar_size=0.641 GB, temp_buffer_size=2.456 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.082, peak_memory=3.782 GB, invar_size=1.229 GB, outvar_size=0.599 GB, temp_buffer_size=2.553 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=4.097 GB, invar_size=1.235 GB, outvar_size=0.610 GB, temp_buffer_size=2.846 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=4.113 GB, invar_size=1.235 GB, outvar_size=0.610 GB, temp_buffer_size=2.862 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=4.128 GB, invar_size=1.251 GB, outvar_size=0.610 GB, temp_buffer_size=2.862 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.188, peak_memory=3.722 GB, invar_size=0.688 GB, outvar_size=0.328 GB, temp_buffer_size=3.003 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.188, peak_memory=4.092 GB, invar_size=0.688 GB, outvar_size=0.328 GB, temp_buffer_size=3.373 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=4.113 GB, invar_size=1.235 GB, outvar_size=0.610 GB, temp_buffer_size=2.862 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=3.971 GB, invar_size=1.501 GB, outvar_size=0.750 GB, temp_buffer_size=2.455 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.195, peak_memory=3.605 GB, invar_size=0.797 GB, outvar_size=0.399 GB, temp_buffer_size=2.776 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=3.792 GB, invar_size=1.305 GB, outvar_size=0.653 GB, temp_buffer_size=2.470 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 33.12 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.024, peak_memory=1.000 GB, invar_size=0.375 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.024, peak_memory=1.000 GB, invar_size=0.375 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.029, peak_memory=1.237 GB, invar_size=0.416 GB, outvar_size=0.031 GB, temp_buffer_size=0.789 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.029, peak_memory=1.237 GB, invar_size=0.416 GB, outvar_size=0.031 GB, temp_buffer_size=0.789 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=5.663 GB, invar_size=0.750 GB, outvar_size=0.375 GB, temp_buffer_size=4.881 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=5.663 GB, invar_size=0.750 GB, outvar_size=0.375 GB, temp_buffer_size=4.881 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=5.161 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=4.505 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=0.969 GB, invar_size=0.344 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=5.161 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=4.505 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.073, peak_memory=5.970 GB, invar_size=0.864 GB, outvar_size=0.416 GB, temp_buffer_size=5.106 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.073, peak_memory=5.970 GB, invar_size=0.864 GB, outvar_size=0.416 GB, temp_buffer_size=5.106 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=0.969 GB, invar_size=0.344 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=5.161 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=4.505 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=5.161 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=4.505 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=5.318 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=4.661 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=5.318 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=4.661 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=6.411 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=5.692 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=5.224 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=4.567 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=5.879 GB, invar_size=0.938 GB, outvar_size=0.485 GB, temp_buffer_size=4.910 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=5.879 GB, invar_size=0.938 GB, outvar_size=0.485 GB, temp_buffer_size=4.910 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=6.411 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=5.692 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=5.224 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=4.567 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 17.03 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO comm 0x5413500 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO comm 0x51f6e30 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO comm 0x7131b30 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO comm 0x743d2a0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO comm 0xb28bce0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO comm 0x52ca6a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO comm 0xb222ba0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO comm 0x7081530 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2519111)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [0] NCCL INFO comm 0x5087a50 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO comm 0xb057eb0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO comm 0xb74aff0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054270 [1] NCCL INFO comm 0x728bdf0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 237.36 s
compilation time breakdown: {'stage-construction': '197.38', 'stage-construction-dp': '1.37', 'stage-construction-compilation': '132.94', 'stage-construction-profiling': '30.22'}
 - Compile (worker): 5.61 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763299 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850555 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519111 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2519111)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054418 [1] NCCL INFO comm 0x7f32cdec5420 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO comm 0x7f32b99b1550 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3054270, ip=192.168.0.39)[0m gpu24:3054270:3054416 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2519111)[0m 
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519267 [1] NCCL INFO comm 0x7f6c21ad66a0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO comm 0x7f6c16bafd40 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2519111)[0m gpu16:2519111:2519265 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO comm 0x7fd132a4aa50 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850619 [1] NCCL INFO comm 0x7fd13c93d660 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1850555, ip=192.168.0.35)[0m gpu20:1850555:1850617 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763367 [1] NCCL INFO comm 0x7f45cfc27200 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO comm 0x7f45be281ac0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1763299, ip=192.168.0.34)[0m gpu19:1763299:1763365 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 128.14 s

[81.2559654712677, 6.555464029312134, 6.518104791641235, 6.621502161026001, 6.526365518569946, 6.535151720046997, 6.5183844566345215]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 34.131 s.
 - Average e2e iteration time: 6.826000213623047 s.
 - Total local training time: 32.720001220703125 s.
 - Average local iteration time: 6.544000148773193 s.
 - Max allocated memory among devices: 6.645 GB.
 - Compilation times:  {'stage-construction': 197.38368225097656, 'stage-construction-dp': 1.3746578693389893, 'stage-construction-compilation': 132.9422516822815, 'stage-construction-profiling': 30.22244429588318}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 6.5439019203186035
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_128.pkl`...

------------------------------------------------------------------
- (2/3) Profiling bert_1.3B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f7fbce49520>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.448 GB, invar_size=2.198 GB, outvar_size=0.055 GB, temp_buffer_size=0.195 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.146, peak_memory=1.396 GB, invar_size=1.099 GB, outvar_size=0.102 GB, temp_buffer_size=0.195 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.829, peak_memory=2.338 GB, invar_size=2.026 GB, outvar_size=0.055 GB, temp_buffer_size=0.258 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=2.235, peak_memory=8.010 GB, invar_size=5.358 GB, outvar_size=2.652 GB, temp_buffer_size=2.652 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=1.289, peak_memory=4.286 GB, invar_size=2.754 GB, outvar_size=1.326 GB, temp_buffer_size=1.533 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=3.550, peak_memory=7.135 GB, invar_size=4.671 GB, outvar_size=2.308 GB, temp_buffer_size=2.464 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 146.17 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.250 GB, invar_size=0.594 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.167, peak_memory=1.125 GB, invar_size=0.375 GB, outvar_size=0.125 GB, temp_buffer_size=0.625 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.313 GB, invar_size=0.657 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.313 GB, invar_size=0.657 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.058, peak_memory=1.505 GB, invar_size=0.599 GB, outvar_size=0.062 GB, temp_buffer_size=0.844 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.049, peak_memory=1.541 GB, invar_size=0.698 GB, outvar_size=0.062 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.156, peak_memory=1.224 GB, invar_size=0.349 GB, outvar_size=0.094 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.250 GB, invar_size=0.594 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.313 GB, invar_size=0.657 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.167, peak_memory=1.125 GB, invar_size=0.375 GB, outvar_size=0.125 GB, temp_buffer_size=0.625 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.147, peak_memory=1.063 GB, invar_size=0.344 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.313 GB, invar_size=0.657 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.159, peak_memory=1.078 GB, invar_size=0.360 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=5.785 GB, invar_size=1.219 GB, outvar_size=0.594 GB, temp_buffer_size=4.535 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=6.318 GB, invar_size=1.376 GB, outvar_size=0.657 GB, temp_buffer_size=4.911 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.351, peak_memory=6.972 GB, invar_size=0.823 GB, outvar_size=0.349 GB, temp_buffer_size=6.149 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.140, peak_memory=6.563 GB, invar_size=1.458 GB, outvar_size=0.698 GB, temp_buffer_size=5.105 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=6.287 GB, invar_size=1.344 GB, outvar_size=0.657 GB, temp_buffer_size=4.911 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.160, peak_memory=1.078 GB, invar_size=0.360 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.348, peak_memory=6.360 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.547 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.367, peak_memory=6.611 GB, invar_size=0.813 GB, outvar_size=0.375 GB, temp_buffer_size=5.736 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.150, peak_memory=6.367 GB, invar_size=1.260 GB, outvar_size=0.599 GB, temp_buffer_size=5.106 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=5.785 GB, invar_size=1.219 GB, outvar_size=0.594 GB, temp_buffer_size=4.535 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=0.891 GB, invar_size=0.203 GB, outvar_size=0.062 GB, temp_buffer_size=0.625 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.938 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=6.255 GB, invar_size=1.344 GB, outvar_size=0.657 GB, temp_buffer_size=4.880 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.367, peak_memory=6.798 GB, invar_size=0.813 GB, outvar_size=0.375 GB, temp_buffer_size=5.922 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=6.287 GB, invar_size=1.344 GB, outvar_size=0.657 GB, temp_buffer_size=4.911 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.365, peak_memory=6.849 GB, invar_size=0.782 GB, outvar_size=0.360 GB, temp_buffer_size=6.005 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.134, peak_memory=7.005 GB, invar_size=1.282 GB, outvar_size=0.625 GB, temp_buffer_size=5.692 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.134, peak_memory=7.068 GB, invar_size=1.313 GB, outvar_size=0.625 GB, temp_buffer_size=5.724 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.134, peak_memory=7.037 GB, invar_size=1.282 GB, outvar_size=0.625 GB, temp_buffer_size=5.724 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.365, peak_memory=7.584 GB, invar_size=0.782 GB, outvar_size=0.360 GB, temp_buffer_size=6.740 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=6.473 GB, invar_size=1.532 GB, outvar_size=0.766 GB, temp_buffer_size=4.910 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.134, peak_memory=7.037 GB, invar_size=1.282 GB, outvar_size=0.625 GB, temp_buffer_size=5.724 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.381, peak_memory=6.470 GB, invar_size=0.860 GB, outvar_size=0.430 GB, temp_buffer_size=5.547 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=6.309 GB, invar_size=1.337 GB, outvar_size=0.668 GB, temp_buffer_size=4.941 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 32.63 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.047, peak_memory=1.656 GB, invar_size=0.406 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.047, peak_memory=1.656 GB, invar_size=0.406 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.056, peak_memory=2.057 GB, invar_size=0.416 GB, outvar_size=0.062 GB, temp_buffer_size=1.578 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.056, peak_memory=2.057 GB, invar_size=0.416 GB, outvar_size=0.062 GB, temp_buffer_size=1.578 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=10.637 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=9.761 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.625 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=10.637 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=9.761 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=9.760 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=9.009 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=9.760 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=9.009 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.143, peak_memory=11.108 GB, invar_size=0.895 GB, outvar_size=0.416 GB, temp_buffer_size=10.213 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.143, peak_memory=11.108 GB, invar_size=0.895 GB, outvar_size=0.416 GB, temp_buffer_size=10.213 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.625 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=9.760 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=9.009 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=9.760 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=9.009 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=10.073 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=9.322 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=10.073 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=9.322 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.131, peak_memory=12.197 GB, invar_size=0.750 GB, outvar_size=0.375 GB, temp_buffer_size=11.385 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.131, peak_memory=12.197 GB, invar_size=0.750 GB, outvar_size=0.375 GB, temp_buffer_size=11.385 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=9.885 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=9.135 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=10.851 GB, invar_size=0.969 GB, outvar_size=0.516 GB, temp_buffer_size=9.819 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=9.885 GB, invar_size=0.688 GB, outvar_size=0.344 GB, temp_buffer_size=9.135 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=10.851 GB, invar_size=0.969 GB, outvar_size=0.516 GB, temp_buffer_size=9.819 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 16.13 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO comm 0x4fcb1e0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO comm 0x4559200 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO comm 0x686aa90 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO comm 0x73061a0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO comm 0xc8e4aa0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO comm 0x3e64960 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO comm 0xc6e1b70 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO comm 0x5c46750 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2532719)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [0] NCCL INFO comm 0x40e4650 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO comm 0x9c17390 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852793 [1] NCCL INFO comm 0x94e7080 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO comm 0x66431a0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 238.97 s
compilation time breakdown: {'stage-construction': '198.81', 'stage-construction-dp': '1.38', 'stage-construction-compilation': '133.77', 'stage-construction-profiling': '31.13'}
 - Compile (worker): 6.24 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769800 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3058937 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532719 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2532719)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO comm 0x7f54abff7450 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852899 [1] NCCL INFO comm 0x7f54bfd0de50 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1852793, ip=192.168.0.35)[0m gpu20:1852793:1852897 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2532719)[0m 
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO comm 0x7f1adafa0180 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532787 [1] NCCL INFO comm 0x7f1ad39add40 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2532719)[0m gpu16:2532719:2532785 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO comm 0x7fda94418600 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059043 [1] NCCL INFO comm 0x7fda9d39c990 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3058937, ip=192.168.0.39)[0m gpu24:3058937:3059041 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO comm 0x7f90d3d930c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769952 [1] NCCL INFO comm 0x7f90d939d4c0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1769800, ip=192.168.0.34)[0m gpu19:1769800:1769950 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 120.16 s

[27.391086101531982, 14.220284461975098, 14.385267734527588, 14.016676425933838, 14.239116668701172, 14.205859184265137, 13.565782070159912]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 72.521 s.
 - Average e2e iteration time: 14.504000663757324 s.
 - Total local training time: 70.41300201416016 s.
 - Average local iteration time: 14.083001136779785 s.
 - Max allocated memory among devices: 9.819 GB.
 - Compilation times:  {'stage-construction': 198.80815291404724, 'stage-construction-dp': 1.3757939338684082, 'stage-construction-compilation': 133.77322602272034, 'stage-construction-profiling': 31.13387417793274}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 14.082541465759277
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_256.pkl`...

------------------------------------------------------------------
- (3/3) Profiling bert_1.3B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f371a5e07f0>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=2.698 GB, invar_size=2.198 GB, outvar_size=0.109 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.214, peak_memory=1.647 GB, invar_size=1.100 GB, outvar_size=0.156 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=2.698 GB, invar_size=2.198 GB, outvar_size=0.109 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=2.370, peak_memory=8.291 GB, invar_size=5.413 GB, outvar_size=2.652 GB, temp_buffer_size=2.878 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=2.370, peak_memory=8.291 GB, invar_size=5.413 GB, outvar_size=2.652 GB, temp_buffer_size=2.878 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=1.666, peak_memory=5.874 GB, invar_size=2.809 GB, outvar_size=1.326 GB, temp_buffer_size=3.065 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 119.35 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.331, peak_memory=1.938 GB, invar_size=0.438 GB, outvar_size=0.250 GB, temp_buffer_size=1.250 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.095, peak_memory=2.385 GB, invar_size=0.698 GB, outvar_size=0.125 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.095, peak_memory=2.385 GB, invar_size=0.698 GB, outvar_size=0.125 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.308, peak_memory=2.099 GB, invar_size=0.349 GB, outvar_size=0.188 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=2.000 GB, invar_size=0.688 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.331, peak_memory=1.938 GB, invar_size=0.438 GB, outvar_size=0.250 GB, temp_buffer_size=1.250 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=2.000 GB, invar_size=0.688 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=1.938 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=1.938 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.291, peak_memory=1.844 GB, invar_size=0.407 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=2.000 GB, invar_size=0.688 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=2.000 GB, invar_size=0.688 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.969 GB, invar_size=0.657 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.315, peak_memory=1.860 GB, invar_size=0.422 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.693, peak_memory=13.239 GB, invar_size=0.948 GB, outvar_size=0.349 GB, temp_buffer_size=12.291 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.724, peak_memory=12.590 GB, invar_size=1.001 GB, outvar_size=0.438 GB, temp_buffer_size=11.465 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.969 GB, invar_size=0.657 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.969 GB, invar_size=0.657 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=11.730 GB, invar_size=1.520 GB, outvar_size=0.698 GB, temp_buffer_size=10.210 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.315, peak_memory=1.860 GB, invar_size=0.422 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.258, peak_memory=11.385 GB, invar_size=1.501 GB, outvar_size=0.688 GB, temp_buffer_size=9.822 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.258, peak_memory=11.323 GB, invar_size=1.438 GB, outvar_size=0.688 GB, temp_buffer_size=9.822 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.258, peak_memory=11.260 GB, invar_size=1.438 GB, outvar_size=0.688 GB, temp_buffer_size=9.760 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.969 GB, invar_size=0.657 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=11.730 GB, invar_size=1.520 GB, outvar_size=0.698 GB, temp_buffer_size=10.210 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.152, peak_memory=1.641 GB, invar_size=0.266 GB, outvar_size=0.125 GB, temp_buffer_size=1.250 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.238, peak_memory=10.445 GB, invar_size=1.313 GB, outvar_size=0.625 GB, temp_buffer_size=9.069 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.686, peak_memory=12.151 GB, invar_size=0.938 GB, outvar_size=0.406 GB, temp_buffer_size=11.088 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.594 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.238, peak_memory=10.445 GB, invar_size=1.313 GB, outvar_size=0.625 GB, temp_buffer_size=9.069 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.724, peak_memory=12.964 GB, invar_size=1.001 GB, outvar_size=0.438 GB, temp_buffer_size=11.838 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.258, peak_memory=11.323 GB, invar_size=1.438 GB, outvar_size=0.688 GB, temp_buffer_size=9.822 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=12.823 GB, invar_size=1.376 GB, outvar_size=0.657 GB, temp_buffer_size=11.385 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.719, peak_memory=13.105 GB, invar_size=0.969 GB, outvar_size=0.422 GB, temp_buffer_size=12.010 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=12.885 GB, invar_size=1.376 GB, outvar_size=0.657 GB, temp_buffer_size=11.447 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=12.948 GB, invar_size=1.438 GB, outvar_size=0.657 GB, temp_buffer_size=11.447 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.719, peak_memory=14.564 GB, invar_size=0.969 GB, outvar_size=0.422 GB, temp_buffer_size=13.470 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.301, peak_memory=11.476 GB, invar_size=1.595 GB, outvar_size=0.797 GB, temp_buffer_size=9.819 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.753, peak_memory=12.197 GB, invar_size=0.985 GB, outvar_size=0.492 GB, temp_buffer_size=11.087 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=12.885 GB, invar_size=1.376 GB, outvar_size=0.657 GB, temp_buffer_size=11.447 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.324, peak_memory=11.344 GB, invar_size=1.399 GB, outvar_size=0.700 GB, temp_buffer_size=9.882 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 31.88 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.093, peak_memory=2.969 GB, invar_size=0.469 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.093, peak_memory=2.969 GB, invar_size=0.469 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.907 GB, invar_size=0.407 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.907 GB, invar_size=0.407 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.111, peak_memory=3.698 GB, invar_size=0.417 GB, outvar_size=0.125 GB, temp_buffer_size=3.156 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.111, peak_memory=3.698 GB, invar_size=0.417 GB, outvar_size=0.125 GB, temp_buffer_size=3.156 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.907 GB, invar_size=0.407 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.271, peak_memory=20.585 GB, invar_size=0.938 GB, outvar_size=0.469 GB, temp_buffer_size=19.522 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.907 GB, invar_size=0.407 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.907 GB, invar_size=0.407 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.907 GB, invar_size=0.407 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.271, peak_memory=20.585 GB, invar_size=0.938 GB, outvar_size=0.469 GB, temp_buffer_size=19.522 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=2.938 GB, invar_size=0.438 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=18.957 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=18.019 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=18.957 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=18.019 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.284, peak_memory=21.383 GB, invar_size=0.958 GB, outvar_size=0.416 GB, temp_buffer_size=20.425 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.284, peak_memory=21.383 GB, invar_size=0.958 GB, outvar_size=0.416 GB, temp_buffer_size=20.425 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=2.938 GB, invar_size=0.438 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.907 GB, invar_size=0.407 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.907 GB, invar_size=0.407 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=19.582 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=18.644 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=18.957 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=18.019 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=18.957 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=18.019 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=19.582 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=18.644 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.260, peak_memory=23.770 GB, invar_size=0.875 GB, outvar_size=0.438 GB, temp_buffer_size=22.769 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.260, peak_memory=23.770 GB, invar_size=0.875 GB, outvar_size=0.438 GB, temp_buffer_size=22.769 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.355, peak_memory=20.795 GB, invar_size=1.032 GB, outvar_size=0.578 GB, temp_buffer_size=19.638 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.355, peak_memory=20.795 GB, invar_size=1.032 GB, outvar_size=0.578 GB, temp_buffer_size=19.638 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=19.207 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=18.269 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=19.207 GB, invar_size=0.813 GB, outvar_size=0.406 GB, temp_buffer_size=18.269 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 15.94 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO comm 0x3618f50 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO comm 0x36f52c0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO comm 0x8a15070 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO comm 0x576e4e0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO comm 0x4fea120 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO comm 0x9506840 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO comm 0x8d41b70 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2546151)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO comm 0x975d610 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [0] NCCL INFO comm 0x39a06a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO comm 0xb1965b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO comm 0xb3e7e00 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776277 [1] NCCL INFO comm 0x5baaac0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 209.70 s
compilation time breakdown: {'stage-construction': '170.64', 'stage-construction-dp': '1.37', 'stage-construction-compilation': '108.55', 'stage-construction-profiling': '29.85'}
 - Compile (worker): 6.35 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854878 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063659 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546151 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2546151)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO comm 0x7fdfbaa7c130 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776387 [1] NCCL INFO comm 0x7fdfc13b26f0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1776277, ip=192.168.0.34)[0m gpu19:1776277:1776385 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2546151)[0m 
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546230 [1] NCCL INFO comm 0x7efb54039a00 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO comm 0x7ee7837eb120 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2546151)[0m gpu16:2546151:2546228 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063808 [1] NCCL INFO comm 0x7f57234a91f0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO comm 0x7f571ac059a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3063659, ip=192.168.0.39)[0m gpu24:3063659:3063806 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854984 [1] NCCL INFO comm 0x7fab55ef8380 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO comm 0x7fab5c32be60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1854878, ip=192.168.0.35)[0m gpu20:1854878:1854982 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 215.35 s

[39.91988825798035, 27.81182050704956, 27.724693536758423, 27.631415605545044, 27.602545261383057, 27.62851333618164, 27.808043718338013]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 141.922 s.
 - Average e2e iteration time: 28.384000778198242 s.
 - Total local training time: 138.39500427246094 s.
 - Average local iteration time: 27.679000854492188 s.
 - Max allocated memory among devices: 16.668 GB.
 - Compilation times:  {'stage-construction': 170.64144849777222, 'stage-construction-dp': 1.3739068508148193, 'stage-construction-compilation': 108.54638886451721, 'stage-construction-profiling': 29.85075092315674}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 27.679044723510742
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_512.pkl`...
