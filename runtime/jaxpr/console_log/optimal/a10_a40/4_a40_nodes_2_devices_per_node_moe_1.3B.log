
------------------------------------------------------------------
- (1/3) Profiling moe_1.3B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_1.3B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7fa097f73ee0>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.013, peak_memory=2.348 GB, invar_size=2.201 GB, outvar_size=0.021 GB, temp_buffer_size=0.126 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.035, peak_memory=1.252 GB, invar_size=1.101 GB, outvar_size=0.029 GB, temp_buffer_size=0.122 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=2.050, peak_memory=7.684 GB, invar_size=5.130 GB, outvar_size=2.554 GB, temp_buffer_size=2.555 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.074, peak_memory=0.625 GB, invar_size=0.478 GB, outvar_size=0.021 GB, temp_buffer_size=0.126 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=0.980, peak_memory=3.862 GB, invar_size=2.584 GB, outvar_size=1.277 GB, temp_buffer_size=1.277 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=0.423, peak_memory=1.917 GB, invar_size=1.192 GB, outvar_size=0.586 GB, temp_buffer_size=0.725 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 90.96 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=0.765 GB, invar_size=0.331 GB, outvar_size=0.035 GB, temp_buffer_size=0.399 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=0.756 GB, invar_size=0.346 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.013, peak_memory=1.055 GB, invar_size=0.645 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=0.786 GB, invar_size=0.340 GB, outvar_size=0.047 GB, temp_buffer_size=0.399 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=0.756 GB, invar_size=0.346 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.012, peak_memory=1.038 GB, invar_size=0.627 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.018, peak_memory=0.891 GB, invar_size=0.364 GB, outvar_size=0.023 GB, temp_buffer_size=0.504 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=0.862 GB, invar_size=0.323 GB, outvar_size=0.035 GB, temp_buffer_size=0.504 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.013, peak_memory=1.172 GB, invar_size=0.645 GB, outvar_size=0.023 GB, temp_buffer_size=0.504 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.012, peak_memory=1.038 GB, invar_size=0.627 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=0.765 GB, invar_size=0.331 GB, outvar_size=0.035 GB, temp_buffer_size=0.399 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.043, peak_memory=2.651 GB, invar_size=0.703 GB, outvar_size=0.346 GB, temp_buffer_size=1.936 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.090, peak_memory=3.147 GB, invar_size=0.692 GB, outvar_size=0.323 GB, temp_buffer_size=2.455 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.042, peak_memory=3.578 GB, invar_size=1.314 GB, outvar_size=0.645 GB, temp_buffer_size=2.264 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.943 GB, invar_size=0.686 GB, outvar_size=0.331 GB, temp_buffer_size=2.234 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.039, peak_memory=3.213 GB, invar_size=1.266 GB, outvar_size=0.627 GB, temp_buffer_size=1.935 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.046, peak_memory=3.015 GB, invar_size=0.751 GB, outvar_size=0.364 GB, temp_buffer_size=2.264 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=0.774 GB, invar_size=0.363 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.039, peak_memory=3.213 GB, invar_size=1.266 GB, outvar_size=0.627 GB, temp_buffer_size=1.935 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.943 GB, invar_size=0.686 GB, outvar_size=0.331 GB, temp_buffer_size=2.234 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.013, peak_memory=1.055 GB, invar_size=0.645 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.043, peak_memory=3.518 GB, invar_size=1.301 GB, outvar_size=0.645 GB, temp_buffer_size=2.205 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.043, peak_memory=2.651 GB, invar_size=0.703 GB, outvar_size=0.346 GB, temp_buffer_size=1.936 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=0.774 GB, invar_size=0.363 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=0.786 GB, invar_size=0.340 GB, outvar_size=0.047 GB, temp_buffer_size=0.399 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.012, peak_memory=1.038 GB, invar_size=0.627 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.006, peak_memory=0.718 GB, invar_size=0.319 GB, outvar_size=0.012 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=0.777 GB, invar_size=0.331 GB, outvar_size=0.047 GB, temp_buffer_size=0.399 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=3.053 GB, invar_size=0.703 GB, outvar_size=0.340 GB, temp_buffer_size=2.326 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.600 GB, invar_size=0.177 GB, outvar_size=0.023 GB, temp_buffer_size=0.399 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.008, peak_memory=0.577 GB, invar_size=0.179 GB, outvar_size=0.012 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=0.756 GB, invar_size=0.346 GB, outvar_size=0.023 GB, temp_buffer_size=0.387 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.047, peak_memory=2.979 GB, invar_size=0.750 GB, outvar_size=0.363 GB, temp_buffer_size=2.217 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=3.217 GB, invar_size=0.703 GB, outvar_size=0.340 GB, temp_buffer_size=2.490 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.043, peak_memory=3.530 GB, invar_size=1.301 GB, outvar_size=0.645 GB, temp_buffer_size=2.217 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.039, peak_memory=3.296 GB, invar_size=1.266 GB, outvar_size=0.627 GB, temp_buffer_size=2.018 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.047, peak_memory=2.967 GB, invar_size=0.739 GB, outvar_size=0.363 GB, temp_buffer_size=2.217 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=3.014 GB, invar_size=0.686 GB, outvar_size=0.331 GB, temp_buffer_size=2.305 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.043, peak_memory=2.733 GB, invar_size=0.703 GB, outvar_size=0.346 GB, temp_buffer_size=2.018 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.049, peak_memory=4.247 GB, invar_size=1.346 GB, outvar_size=0.673 GB, temp_buffer_size=2.889 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.104, peak_memory=3.727 GB, invar_size=0.708 GB, outvar_size=0.354 GB, temp_buffer_size=2.996 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.057, peak_memory=3.650 GB, invar_size=0.738 GB, outvar_size=0.369 GB, temp_buffer_size=2.901 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 30.24 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.535 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=3.849 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.535 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=3.849 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.535 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=3.849 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.535 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=3.849 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.535 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=3.849 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.535 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=3.849 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.013, peak_memory=1.146 GB, invar_size=0.349 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.369 GB, invar_size=0.338 GB, outvar_size=0.023 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.369 GB, invar_size=0.338 GB, outvar_size=0.023 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.036, peak_memory=5.203 GB, invar_size=0.698 GB, outvar_size=0.337 GB, temp_buffer_size=4.505 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.013, peak_memory=1.146 GB, invar_size=0.349 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.036, peak_memory=5.203 GB, invar_size=0.698 GB, outvar_size=0.337 GB, temp_buffer_size=4.505 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.037, peak_memory=5.124 GB, invar_size=0.697 GB, outvar_size=0.349 GB, temp_buffer_size=4.403 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.745 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=4.059 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.037, peak_memory=5.124 GB, invar_size=0.697 GB, outvar_size=0.349 GB, temp_buffer_size=4.403 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.745 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=4.059 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.699 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=4.013 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=4.699 GB, invar_size=0.662 GB, outvar_size=0.331 GB, temp_buffer_size=4.013 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.048, peak_memory=6.782 GB, invar_size=0.731 GB, outvar_size=0.377 GB, temp_buffer_size=6.028 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.048, peak_memory=6.782 GB, invar_size=0.731 GB, outvar_size=0.377 GB, temp_buffer_size=6.028 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 16.67 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO comm 0x4212760 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO comm 0x37947d0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO comm 0x57e0be0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO comm 0x7389f00 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3987305)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO comm 0xa0cfc60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO comm 0x4f1ec20 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO comm 0xa0df050 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO comm 0x6dd67c0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [0] NCCL INFO comm 0x4dfb150 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO comm 0xb26f930 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508107 [1] NCCL INFO comm 0x6cb0b00 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO comm 0xb2782f0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 192.05 s
compilation time breakdown: {'stage-construction': '141.56', 'stage-construction-dp': '1.12', 'stage-construction-compilation': '75.50', 'stage-construction-profiling': '35.63'}
 - Compile (worker): 9.00 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2123904 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987305 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385499 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508299 [1] NCCL INFO comm 0x7f29c72d6130 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO comm 0x7f29bcef5730 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1508107, ip=192.168.0.18)[0m gpu3:1508107:1508297 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3987305)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO comm 0x7eee36b6ec70 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385563 [1] NCCL INFO comm 0x7eee31c106c0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3987305)[0m 
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO comm 0x7f6c023b6790 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987376 [1] NCCL INFO comm 0x7f6c0ca20180 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124010 [1] NCCL INFO comm 0x7f161da17a70 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO comm 0x7f164abf4420 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=385499, ip=192.168.0.26)[0m gpu11:385499:385561 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3987305)[0m gpu2:3987305:3987374 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2123904, ip=192.168.0.33)[0m gpu18:2123904:2124008 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 147.84 s

[123.65936088562012, 3.3984766006469727, 3.32464337348938, 3.3316569328308105, 3.489839553833008, 3.370929002761841, 3.3499460220336914]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 17.89 s.
 - Average e2e iteration time: 3.578000068664551 s.
 - Total local training time: 16.867000579833984 s.
 - Average local iteration time: 3.373000144958496 s.
 - Max allocated memory among devices: 5.262 GB.
 - Compilation times:  {'stage-construction': 141.556378364563, 'stage-construction-dp': 1.1242897510528564, 'stage-construction-compilation': 75.50317001342773, 'stage-construction-profiling': 35.628161907196045}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 3.373403310775757
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_1.3B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling moe_1.3B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_1.3B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f22aa88d4f0>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=2.494 GB, invar_size=2.201 GB, outvar_size=0.041 GB, temp_buffer_size=0.252 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.531 GB, invar_size=1.101 GB, outvar_size=0.041 GB, temp_buffer_size=0.389 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.136, peak_memory=0.771 GB, invar_size=0.478 GB, outvar_size=0.041 GB, temp_buffer_size=0.252 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=2.085, peak_memory=7.705 GB, invar_size=5.150 GB, outvar_size=2.554 GB, temp_buffer_size=2.555 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=1.067, peak_memory=4.284 GB, invar_size=2.596 GB, outvar_size=1.277 GB, temp_buffer_size=1.688 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=0.577, peak_memory=2.663 GB, invar_size=1.213 GB, outvar_size=0.586 GB, temp_buffer_size=1.450 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 88.58 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.178 GB, invar_size=0.358 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.075, peak_memory=1.401 GB, invar_size=0.323 GB, outvar_size=0.070 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.024, peak_memory=1.477 GB, invar_size=0.656 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.025, peak_memory=1.700 GB, invar_size=0.645 GB, outvar_size=0.047 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.419 GB, invar_size=0.364 GB, outvar_size=0.047 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.460 GB, invar_size=0.639 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.460 GB, invar_size=0.639 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.178 GB, invar_size=0.358 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.071, peak_memory=1.223 GB, invar_size=0.355 GB, outvar_size=0.070 GB, temp_buffer_size=0.798 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.071, peak_memory=1.223 GB, invar_size=0.355 GB, outvar_size=0.070 GB, temp_buffer_size=0.798 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=1.255 GB, invar_size=0.363 GB, outvar_size=0.094 GB, temp_buffer_size=0.798 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=5.195 GB, invar_size=1.301 GB, outvar_size=0.639 GB, temp_buffer_size=3.870 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.073, peak_memory=5.865 GB, invar_size=1.337 GB, outvar_size=0.645 GB, temp_buffer_size=4.528 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.174, peak_memory=5.648 GB, invar_size=0.739 GB, outvar_size=0.323 GB, temp_buffer_size=4.909 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=5.770 GB, invar_size=1.336 GB, outvar_size=0.656 GB, temp_buffer_size=4.411 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=5.195 GB, invar_size=1.301 GB, outvar_size=0.639 GB, temp_buffer_size=3.870 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=1.196 GB, invar_size=0.375 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.303 GB, invar_size=0.775 GB, outvar_size=0.364 GB, temp_buffer_size=4.528 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.080, peak_memory=4.634 GB, invar_size=0.739 GB, outvar_size=0.358 GB, temp_buffer_size=3.872 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=5.269 GB, invar_size=0.756 GB, outvar_size=0.355 GB, temp_buffer_size=4.466 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=5.269 GB, invar_size=0.756 GB, outvar_size=0.355 GB, temp_buffer_size=4.466 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.024, peak_memory=1.477 GB, invar_size=0.656 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.080, peak_memory=4.634 GB, invar_size=0.739 GB, outvar_size=0.358 GB, temp_buffer_size=3.872 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=1.255 GB, invar_size=0.363 GB, outvar_size=0.094 GB, temp_buffer_size=0.798 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=1.196 GB, invar_size=0.375 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.460 GB, invar_size=0.639 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.011, peak_memory=1.129 GB, invar_size=0.331 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.039, peak_memory=1.046 GB, invar_size=0.201 GB, outvar_size=0.047 GB, temp_buffer_size=0.798 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.078, peak_memory=1.246 GB, invar_size=0.355 GB, outvar_size=0.094 GB, temp_buffer_size=0.798 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.015, peak_memory=0.988 GB, invar_size=0.191 GB, outvar_size=0.023 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.189, peak_memory=5.471 GB, invar_size=0.774 GB, outvar_size=0.363 GB, temp_buffer_size=4.651 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.178 GB, invar_size=0.358 GB, outvar_size=0.047 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.068, peak_memory=5.360 GB, invar_size=1.301 GB, outvar_size=0.639 GB, temp_buffer_size=4.036 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.255 GB, invar_size=0.797 GB, outvar_size=0.375 GB, temp_buffer_size=4.434 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.189, peak_memory=5.800 GB, invar_size=0.774 GB, outvar_size=0.363 GB, temp_buffer_size=4.979 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=5.794 GB, invar_size=1.336 GB, outvar_size=0.656 GB, temp_buffer_size=4.434 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.231 GB, invar_size=0.774 GB, outvar_size=0.375 GB, temp_buffer_size=4.434 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.176, peak_memory=5.410 GB, invar_size=0.756 GB, outvar_size=0.355 GB, temp_buffer_size=4.607 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.200, peak_memory=6.793 GB, invar_size=0.755 GB, outvar_size=0.377 GB, temp_buffer_size=5.991 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=7.171 GB, invar_size=1.369 GB, outvar_size=0.685 GB, temp_buffer_size=5.778 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.080, peak_memory=4.798 GB, invar_size=0.739 GB, outvar_size=0.358 GB, temp_buffer_size=4.036 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=6.577 GB, invar_size=0.807 GB, outvar_size=0.403 GB, temp_buffer_size=5.747 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 29.32 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=2.400 GB, invar_size=0.338 GB, outvar_size=0.047 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=2.400 GB, invar_size=0.338 GB, outvar_size=0.047 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.453 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=7.697 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.453 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=7.697 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.453 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=7.697 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.453 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=7.697 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.453 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=7.697 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.453 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=7.697 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=9.732 GB, invar_size=0.722 GB, outvar_size=0.337 GB, temp_buffer_size=9.010 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=9.732 GB, invar_size=0.722 GB, outvar_size=0.337 GB, temp_buffer_size=9.010 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.025, peak_memory=1.967 GB, invar_size=0.372 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.025, peak_memory=1.967 GB, invar_size=0.372 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.072, peak_memory=9.597 GB, invar_size=0.744 GB, outvar_size=0.372 GB, temp_buffer_size=8.806 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.875 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=8.119 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.072, peak_memory=9.597 GB, invar_size=0.744 GB, outvar_size=0.372 GB, temp_buffer_size=8.806 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.875 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=8.119 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.095, peak_memory=12.857 GB, invar_size=0.754 GB, outvar_size=0.400 GB, temp_buffer_size=12.056 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.781 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=8.025 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=8.781 GB, invar_size=0.709 GB, outvar_size=0.355 GB, temp_buffer_size=8.025 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.095, peak_memory=12.857 GB, invar_size=0.754 GB, outvar_size=0.400 GB, temp_buffer_size=12.056 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 17.28 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO comm 0x4a01630 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO comm 0x3dedf30 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO comm 0x5e36660 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO comm 0x7dab020 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO comm 0x4e9f240 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO comm 0xadf22a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO comm 0xad89e50 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO comm 0x709e900 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO comm 0xaef3d60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [0] NCCL INFO comm 0x4c02ab0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO comm 0xae8ac20 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997580 [1] NCCL INFO comm 0xa439e30 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 176.51 s
compilation time breakdown: {'stage-construction': '138.74', 'stage-construction-dp': '1.36', 'stage-construction-compilation': '72.67', 'stage-construction-profiling': '35.49'}
 - Compile (worker): 9.27 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129896 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510768 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390191 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3997580)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3997580)[0m 
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997787 [1] NCCL INFO comm 0x7f6018bbe210 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO comm 0x7f74a7902ee0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3997580)[0m gpu2:3997580:3997785 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390297 [1] NCCL INFO comm 0x7f2d8b1e5e50 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO comm 0x7f19777fa4a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510836 [1] NCCL INFO comm 0x7f1e13d77990 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO comm 0x7f1dfe8f0e90 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129960 [1] NCCL INFO comm 0x7f89d15335d0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO comm 0x7f89d8f163c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=390191, ip=192.168.0.26)[0m gpu11:390191:390295 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1510768, ip=192.168.0.18)[0m gpu3:1510768:1510834 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2129896, ip=192.168.0.33)[0m gpu18:2129896:2129958 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 52.49 s

[13.07095193862915, 5.9349751472473145, 6.011722564697266, 6.013393402099609, 6.048558712005615, 6.031371116638184, 6.045835256576538]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 31.644 s.
 - Average e2e iteration time: 6.329000473022461 s.
 - Total local training time: 30.1510009765625 s.
 - Average local iteration time: 6.03000020980835 s.
 - Max allocated memory among devices: 8.539 GB.
 - Compilation times:  {'stage-construction': 138.7431447505951, 'stage-construction-dp': 1.3575999736785889, 'stage-construction-compilation': 72.66515040397644, 'stage-construction-profiling': 35.489792346954346}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 6.030176639556885
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_1.3B_512.pkl`...

------------------------------------------------------------------
- (3/3) Profiling moe_1.3B with batch size: 1024...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_1.3B_1024.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7fdcdc0ee520>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=2.787 GB, invar_size=2.201 GB, outvar_size=0.082 GB, temp_buffer_size=0.504 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.072, peak_memory=1.722 GB, invar_size=1.109 GB, outvar_size=0.082 GB, temp_buffer_size=0.532 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.270, peak_memory=1.064 GB, invar_size=0.478 GB, outvar_size=0.082 GB, temp_buffer_size=0.504 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=2.154, peak_memory=8.092 GB, invar_size=5.191 GB, outvar_size=2.554 GB, temp_buffer_size=2.901 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=1.206, peak_memory=6.262 GB, invar_size=2.655 GB, outvar_size=1.286 GB, temp_buffer_size=3.607 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=0.907, peak_memory=4.155 GB, invar_size=1.254 GB, outvar_size=0.586 GB, temp_buffer_size=2.901 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 86.63 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.041, peak_memory=2.304 GB, invar_size=0.662 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.139, peak_memory=2.138 GB, invar_size=0.402 GB, outvar_size=0.141 GB, temp_buffer_size=1.596 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=2.023 GB, invar_size=0.381 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.049, peak_memory=2.755 GB, invar_size=0.645 GB, outvar_size=0.094 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.146, peak_memory=2.480 GB, invar_size=0.323 GB, outvar_size=0.141 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.041, peak_memory=2.304 GB, invar_size=0.662 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=2.023 GB, invar_size=0.381 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.066, peak_memory=2.473 GB, invar_size=0.364 GB, outvar_size=0.094 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.172, peak_memory=2.194 GB, invar_size=0.410 GB, outvar_size=0.188 GB, temp_buffer_size=1.596 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.139, peak_memory=2.138 GB, invar_size=0.402 GB, outvar_size=0.141 GB, temp_buffer_size=1.596 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.322 GB, invar_size=0.680 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=9.158 GB, invar_size=1.371 GB, outvar_size=0.662 GB, temp_buffer_size=7.740 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.137, peak_memory=10.440 GB, invar_size=1.384 GB, outvar_size=0.645 GB, temp_buffer_size=9.056 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.342, peak_memory=10.649 GB, invar_size=0.833 GB, outvar_size=0.323 GB, temp_buffer_size=9.815 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.346, peak_memory=9.919 GB, invar_size=0.897 GB, outvar_size=0.401 GB, temp_buffer_size=8.928 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=9.158 GB, invar_size=1.371 GB, outvar_size=0.662 GB, temp_buffer_size=7.740 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.156, peak_memory=8.599 GB, invar_size=0.809 GB, outvar_size=0.381 GB, temp_buffer_size=7.743 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.138, peak_memory=10.275 GB, invar_size=1.407 GB, outvar_size=0.680 GB, temp_buffer_size=8.821 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.156, peak_memory=8.599 GB, invar_size=0.809 GB, outvar_size=0.381 GB, temp_buffer_size=7.743 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.167, peak_memory=9.877 GB, invar_size=0.822 GB, outvar_size=0.364 GB, temp_buffer_size=9.056 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.322 GB, invar_size=0.680 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.040 GB, invar_size=0.399 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.346, peak_memory=9.919 GB, invar_size=0.897 GB, outvar_size=0.401 GB, temp_buffer_size=8.928 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.040 GB, invar_size=0.399 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.172, peak_memory=2.194 GB, invar_size=0.410 GB, outvar_size=0.188 GB, temp_buffer_size=1.596 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.041, peak_memory=2.304 GB, invar_size=0.662 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=1.949 GB, invar_size=0.355 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.076, peak_memory=1.937 GB, invar_size=0.248 GB, outvar_size=0.094 GB, temp_buffer_size=1.596 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.029, peak_memory=1.809 GB, invar_size=0.214 GB, outvar_size=0.047 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.153, peak_memory=2.185 GB, invar_size=0.402 GB, outvar_size=0.188 GB, temp_buffer_size=1.596 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=2.023 GB, invar_size=0.381 GB, outvar_size=0.094 GB, temp_buffer_size=1.548 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.372, peak_memory=10.308 GB, invar_size=0.914 GB, outvar_size=0.410 GB, temp_buffer_size=9.300 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.372, peak_memory=10.964 GB, invar_size=0.914 GB, outvar_size=0.410 GB, temp_buffer_size=9.956 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.168, peak_memory=9.806 GB, invar_size=0.891 GB, outvar_size=0.399 GB, temp_buffer_size=8.868 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.138, peak_memory=10.322 GB, invar_size=1.407 GB, outvar_size=0.680 GB, temp_buffer_size=8.868 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.126, peak_memory=9.490 GB, invar_size=1.371 GB, outvar_size=0.662 GB, temp_buffer_size=8.071 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.168, peak_memory=9.759 GB, invar_size=0.844 GB, outvar_size=0.399 GB, temp_buffer_size=8.868 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.346, peak_memory=10.200 GB, invar_size=0.897 GB, outvar_size=0.401 GB, temp_buffer_size=9.210 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.161, peak_memory=13.019 GB, invar_size=1.416 GB, outvar_size=0.708 GB, temp_buffer_size=11.556 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.395, peak_memory=12.925 GB, invar_size=0.849 GB, outvar_size=0.424 GB, temp_buffer_size=11.982 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.156, peak_memory=8.927 GB, invar_size=0.809 GB, outvar_size=0.381 GB, temp_buffer_size=8.071 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.191, peak_memory=12.394 GB, invar_size=0.854 GB, outvar_size=0.427 GB, temp_buffer_size=11.494 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 31.24 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.055, peak_memory=4.463 GB, invar_size=0.338 GB, outvar_size=0.094 GB, temp_buffer_size=4.031 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.055, peak_memory=4.463 GB, invar_size=0.338 GB, outvar_size=0.094 GB, temp_buffer_size=4.031 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=16.291 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=15.394 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=16.291 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=15.394 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=16.291 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=15.394 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=16.291 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=15.394 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=16.291 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=15.394 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=16.291 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=15.394 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.139, peak_memory=18.788 GB, invar_size=0.769 GB, outvar_size=0.337 GB, temp_buffer_size=18.019 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.139, peak_memory=18.788 GB, invar_size=0.769 GB, outvar_size=0.337 GB, temp_buffer_size=18.019 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.049, peak_memory=3.609 GB, invar_size=0.419 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.049, peak_memory=3.609 GB, invar_size=0.419 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=3.591 GB, invar_size=0.402 GB, outvar_size=0.094 GB, temp_buffer_size=3.096 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.140, peak_memory=18.544 GB, invar_size=0.838 GB, outvar_size=0.419 GB, temp_buffer_size=17.612 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.140, peak_memory=18.544 GB, invar_size=0.838 GB, outvar_size=0.419 GB, temp_buffer_size=17.612 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=17.134 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=16.237 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=17.134 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=16.237 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=16.947 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=16.050 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.118, peak_memory=16.947 GB, invar_size=0.803 GB, outvar_size=0.401 GB, temp_buffer_size=16.050 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.187, peak_memory=25.007 GB, invar_size=0.801 GB, outvar_size=0.447 GB, temp_buffer_size=24.112 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.187, peak_memory=25.007 GB, invar_size=0.801 GB, outvar_size=0.447 GB, temp_buffer_size=24.112 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 17.70 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO comm 0x3f54a20 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO comm 0x4114b50 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO comm 0x5f9d560 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO comm 0x728d5e0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4007663)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO comm 0x3583810 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO comm 0x9fdbfc0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO comm 0x52a1590 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO comm 0xa6104f0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [0] NCCL INFO comm 0x475dd70 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO comm 0x95d1830 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO comm 0x95686f0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135658 [1] NCCL INFO comm 0x695d7f0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 176.78 s
compilation time breakdown: {'stage-construction': '139.31', 'stage-construction-dp': '1.37', 'stage-construction-compilation': '70.13', 'stage-construction-profiling': '36.25'}
 - Compile (worker): 9.23 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394780 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007663 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513110 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135722 [1] NCCL INFO comm 0x7f0f6e86a100 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO comm 0x7f0f741bbf00 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2135658, ip=192.168.0.33)[0m gpu18:2135658:2135720 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO comm 0x7fd7f67c5c50 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513176 [1] NCCL INFO comm 0x7fd7fa790220 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4007663)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4007663)[0m 
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007859 [1] NCCL INFO comm 0x7f6befc6d6c0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO comm 0x7f6bf6caffa0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394886 [1] NCCL INFO comm 0x7f1df8f4f8b0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO comm 0x7f1df0161b60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1513110, ip=192.168.0.18)[0m gpu3:1513110:1513174 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=4007663)[0m gpu2:4007663:4007857 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=394780, ip=192.168.0.26)[0m gpu11:394780:394884 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 90.69 s

[18.34080958366394, 11.36658525466919, 11.33373475074768, 11.256094694137573, 11.389355897903442, 11.296154499053955, 11.39893388748169]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 59.075 s.
 - Average e2e iteration time: 11.815000534057617 s.
 - Total local training time: 56.67400360107422 s.
 - Average local iteration time: 11.335000991821289 s.
 - Max allocated memory among devices: 15.093 GB.
 - Compilation times:  {'stage-construction': 139.31031703948975, 'stage-construction-dp': 1.374563217163086, 'stage-construction-compilation': 70.12906694412231, 'stage-construction-profiling': 36.25411105155945}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 11.334855079650879
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_1.3B_1024.pkl`...
