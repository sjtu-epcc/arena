
------------------------------------------------------------------
- (1/3) Profiling wide_resnet_4B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_4B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 640
    width_factor = 2
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (256, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.133 GB, invar_size=0.486 GB, outvar_size=0.239 GB, temp_buffer_size=0.408 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.049, peak_memory=1.112 GB, invar_size=0.423 GB, outvar_size=0.239 GB, temp_buffer_size=0.450 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.289 GB, invar_size=0.642 GB, outvar_size=0.239 GB, temp_buffer_size=0.408 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.522 GB, invar_size=0.680 GB, outvar_size=0.239 GB, temp_buffer_size=0.602 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.115 GB, invar_size=0.098 GB, outvar_size=0.419 GB, temp_buffer_size=0.598 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.342 GB, invar_size=0.505 GB, outvar_size=0.359 GB, temp_buffer_size=0.479 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.378 GB, invar_size=0.290 GB, outvar_size=0.479 GB, temp_buffer_size=0.610 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.191, peak_memory=2.167 GB, invar_size=0.611 GB, outvar_size=0.598 GB, temp_buffer_size=0.957 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.289 GB, invar_size=0.642 GB, outvar_size=0.239 GB, temp_buffer_size=0.408 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.342 GB, invar_size=0.505 GB, outvar_size=0.359 GB, temp_buffer_size=0.479 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.133 GB, invar_size=0.486 GB, outvar_size=0.239 GB, temp_buffer_size=0.408 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.112, peak_memory=1.616 GB, invar_size=0.414 GB, outvar_size=0.479 GB, temp_buffer_size=0.724 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.378 GB, invar_size=0.290 GB, outvar_size=0.479 GB, temp_buffer_size=0.610 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.007, peak_memory=2.052 GB, invar_size=1.092 GB, outvar_size=0.486 GB, temp_buffer_size=0.841 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.115 GB, invar_size=0.098 GB, outvar_size=0.419 GB, temp_buffer_size=0.598 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.140, peak_memory=1.312 GB, invar_size=0.056 GB, outvar_size=0.538 GB, temp_buffer_size=0.718 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.147, peak_memory=2.049 GB, invar_size=0.845 GB, outvar_size=0.303 GB, temp_buffer_size=1.085 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.965 GB, invar_size=0.486 GB, outvar_size=0.239 GB, temp_buffer_size=0.239 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=2.837 GB, invar_size=1.404 GB, outvar_size=0.642 GB, temp_buffer_size=1.194 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.184, peak_memory=2.881 GB, invar_size=1.121 GB, outvar_size=0.441 GB, temp_buffer_size=1.521 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.006, peak_memory=2.796 GB, invar_size=1.129 GB, outvar_size=0.505 GB, temp_buffer_size=1.427 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.965 GB, invar_size=0.486 GB, outvar_size=0.239 GB, temp_buffer_size=0.239 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.985 GB, invar_size=1.182 GB, outvar_size=0.180 GB, temp_buffer_size=0.623 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=2.717 GB, invar_size=1.284 GB, outvar_size=0.642 GB, temp_buffer_size=1.194 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.049, peak_memory=1.021 GB, invar_size=0.423 GB, outvar_size=0.239 GB, temp_buffer_size=0.359 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.095, peak_memory=1.640 GB, invar_size=0.862 GB, outvar_size=0.299 GB, temp_buffer_size=0.479 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.475 GB, invar_size=1.732 GB, outvar_size=0.120 GB, temp_buffer_size=0.623 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.270, peak_memory=3.632 GB, invar_size=1.342 GB, outvar_size=0.372 GB, temp_buffer_size=2.051 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.007, peak_memory=2.052 GB, invar_size=1.092 GB, outvar_size=0.486 GB, temp_buffer_size=0.841 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.006, peak_memory=2.916 GB, invar_size=1.249 GB, outvar_size=0.505 GB, temp_buffer_size=1.427 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=2.898 GB, invar_size=0.878 GB, outvar_size=0.289 GB, temp_buffer_size=1.840 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=3.458 GB, invar_size=0.849 GB, outvar_size=0.094 GB, temp_buffer_size=2.608 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.103, peak_memory=1.548 GB, invar_size=0.771 GB, outvar_size=0.299 GB, temp_buffer_size=0.479 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=2.898 GB, invar_size=0.878 GB, outvar_size=0.289 GB, temp_buffer_size=1.840 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=2.612 GB, invar_size=0.610 GB, outvar_size=0.094 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.688 GB, invar_size=1.045 GB, outvar_size=0.120 GB, temp_buffer_size=0.523 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.292, peak_memory=3.299 GB, invar_size=0.641 GB, outvar_size=0.047 GB, temp_buffer_size=2.658 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.007, peak_memory=2.053 GB, invar_size=1.092 GB, outvar_size=0.486 GB, temp_buffer_size=0.841 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.374, peak_memory=3.599 GB, invar_size=0.947 GB, outvar_size=0.414 GB, temp_buffer_size=2.293 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.219 GB, invar_size=1.525 GB, outvar_size=0.120 GB, temp_buffer_size=0.574 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.007, peak_memory=2.053 GB, invar_size=1.092 GB, outvar_size=0.486 GB, temp_buffer_size=0.841 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.386 GB, invar_size=0.853 GB, outvar_size=0.120 GB, temp_buffer_size=0.414 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.020, peak_memory=4.289 GB, invar_size=2.424 GB, outvar_size=1.182 GB, temp_buffer_size=1.746 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.688 GB, invar_size=1.045 GB, outvar_size=0.120 GB, temp_buffer_size=0.523 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.144 GB, invar_size=1.525 GB, outvar_size=0.120 GB, temp_buffer_size=0.499 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.147, peak_memory=2.049 GB, invar_size=0.845 GB, outvar_size=0.303 GB, temp_buffer_size=1.085 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.386 GB, invar_size=0.853 GB, outvar_size=0.120 GB, temp_buffer_size=0.414 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.144 GB, invar_size=1.525 GB, outvar_size=0.120 GB, temp_buffer_size=0.499 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.371 GB, invar_size=0.853 GB, outvar_size=0.120 GB, temp_buffer_size=0.399 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.371 GB, invar_size=0.853 GB, outvar_size=0.120 GB, temp_buffer_size=0.399 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.072, peak_memory=2.845 GB, invar_size=1.784 GB, outvar_size=0.742 GB, temp_buffer_size=0.942 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.146, peak_memory=2.785 GB, invar_size=1.601 GB, outvar_size=0.651 GB, temp_buffer_size=1.064 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.371 GB, invar_size=0.853 GB, outvar_size=0.120 GB, temp_buffer_size=0.399 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=5.975 GB, invar_size=3.462 GB, outvar_size=1.731 GB, temp_buffer_size=2.393 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.028, peak_memory=5.367 GB, invar_size=3.110 GB, outvar_size=1.525 GB, temp_buffer_size=2.198 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.371 GB, invar_size=0.853 GB, outvar_size=0.120 GB, temp_buffer_size=0.399 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.144 GB, invar_size=1.525 GB, outvar_size=0.120 GB, temp_buffer_size=0.499 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.371 GB, invar_size=0.853 GB, outvar_size=0.120 GB, temp_buffer_size=0.399 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.028, peak_memory=5.367 GB, invar_size=3.110 GB, outvar_size=1.525 GB, temp_buffer_size=2.198 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=3.215 GB, invar_size=1.971 GB, outvar_size=0.926 GB, temp_buffer_size=1.125 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.633 GB, invar_size=1.704 GB, outvar_size=0.792 GB, temp_buffer_size=0.868 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.028, peak_memory=5.367 GB, invar_size=3.110 GB, outvar_size=1.525 GB, temp_buffer_size=2.198 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.251 GB, invar_size=4.309 GB, outvar_size=0.090 GB, temp_buffer_size=1.852 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.371 GB, invar_size=0.853 GB, outvar_size=0.120 GB, temp_buffer_size=0.399 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.633 GB, invar_size=1.704 GB, outvar_size=0.792 GB, temp_buffer_size=0.868 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=3.215 GB, invar_size=1.971 GB, outvar_size=0.926 GB, temp_buffer_size=1.125 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.640 GB, invar_size=1.704 GB, outvar_size=0.792 GB, temp_buffer_size=0.876 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=3.308 GB, invar_size=2.245 GB, outvar_size=0.090 GB, temp_buffer_size=0.973 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.640 GB, invar_size=1.704 GB, outvar_size=0.792 GB, temp_buffer_size=0.876 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=3.308 GB, invar_size=2.245 GB, outvar_size=0.090 GB, temp_buffer_size=0.973 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.418 GB, invar_size=6.507 GB, outvar_size=0.060 GB, temp_buffer_size=1.852 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.520 GB, invar_size=1.704 GB, outvar_size=0.792 GB, temp_buffer_size=0.756 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=4.436 GB, invar_size=3.343 GB, outvar_size=0.060 GB, temp_buffer_size=1.033 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.520 GB, invar_size=1.704 GB, outvar_size=0.792 GB, temp_buffer_size=0.756 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.028, peak_memory=5.367 GB, invar_size=3.110 GB, outvar_size=1.525 GB, temp_buffer_size=2.198 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.023, peak_memory=4.436 GB, invar_size=3.343 GB, outvar_size=0.060 GB, temp_buffer_size=1.033 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.809 GB, invar_size=5.968 GB, outvar_size=0.030 GB, temp_buffer_size=1.810 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.520 GB, invar_size=1.704 GB, outvar_size=0.792 GB, temp_buffer_size=0.756 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=2.520 GB, invar_size=1.704 GB, outvar_size=0.792 GB, temp_buffer_size=0.756 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.080, peak_memory=16.226 GB, invar_size=8.647 GB, outvar_size=4.308 GB, temp_buffer_size=7.520 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=3.976 GB, invar_size=3.000 GB, outvar_size=0.030 GB, temp_buffer_size=0.946 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=3.976 GB, invar_size=3.000 GB, outvar_size=0.030 GB, temp_buffer_size=0.946 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=22.447 GB, invar_size=13.011 GB, outvar_size=6.506 GB, temp_buffer_size=9.376 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.103, peak_memory=6.512 GB, invar_size=4.488 GB, outvar_size=2.184 GB, temp_buffer_size=1.964 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.103, peak_memory=6.512 GB, invar_size=4.488 GB, outvar_size=2.184 GB, temp_buffer_size=1.964 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.077, peak_memory=8.853 GB, invar_size=6.626 GB, outvar_size=3.283 GB, temp_buffer_size=2.167 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.111, peak_memory=20.834 GB, invar_size=11.936 GB, outvar_size=5.968 GB, temp_buffer_size=8.868 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.077, peak_memory=8.853 GB, invar_size=6.626 GB, outvar_size=3.283 GB, temp_buffer_size=2.167 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.048, peak_memory=7.569 GB, invar_size=5.998 GB, outvar_size=2.999 GB, temp_buffer_size=1.541 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.048, peak_memory=7.569 GB, invar_size=5.998 GB, outvar_size=2.999 GB, temp_buffer_size=1.541 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 14.95 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.199 GB, invar_size=0.524 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.187 GB, invar_size=1.049 GB, outvar_size=0.524 GB, temp_buffer_size=2.660 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.260 GB, invar_size=0.423 GB, outvar_size=0.239 GB, temp_buffer_size=0.598 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.997 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.173 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.260 GB, invar_size=0.423 GB, outvar_size=0.239 GB, temp_buffer_size=0.598 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.260 GB, invar_size=0.423 GB, outvar_size=0.239 GB, temp_buffer_size=0.598 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.260 GB, invar_size=0.423 GB, outvar_size=0.239 GB, temp_buffer_size=0.598 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.260 GB, invar_size=0.423 GB, outvar_size=0.239 GB, temp_buffer_size=0.598 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.997 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.173 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.199 GB, invar_size=0.524 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.260 GB, invar_size=0.423 GB, outvar_size=0.239 GB, temp_buffer_size=0.598 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.997 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.173 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.271 GB, invar_size=0.845 GB, outvar_size=0.422 GB, temp_buffer_size=1.187 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.510 GB, invar_size=0.845 GB, outvar_size=0.422 GB, temp_buffer_size=1.426 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.271 GB, invar_size=0.845 GB, outvar_size=0.422 GB, temp_buffer_size=1.187 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.510 GB, invar_size=0.845 GB, outvar_size=0.422 GB, temp_buffer_size=1.426 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.187 GB, invar_size=1.049 GB, outvar_size=0.524 GB, temp_buffer_size=2.660 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.510 GB, invar_size=0.845 GB, outvar_size=0.422 GB, temp_buffer_size=1.426 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.997 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.173 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.561 GB, invar_size=0.852 GB, outvar_size=0.120 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.510 GB, invar_size=0.845 GB, outvar_size=0.422 GB, temp_buffer_size=1.426 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.878 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.054 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.883 GB, invar_size=2.990 GB, outvar_size=0.060 GB, temp_buffer_size=1.833 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.883 GB, invar_size=2.990 GB, outvar_size=0.060 GB, temp_buffer_size=1.833 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.878 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.054 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.878 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.054 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.878 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.054 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.878 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.054 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.931 GB, invar_size=3.068 GB, outvar_size=0.000 GB, temp_buffer_size=1.862 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.878 GB, invar_size=1.704 GB, outvar_size=0.852 GB, temp_buffer_size=1.054 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.931 GB, invar_size=3.068 GB, outvar_size=0.000 GB, temp_buffer_size=1.862 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.848 GB, invar_size=5.980 GB, outvar_size=2.990 GB, temp_buffer_size=2.808 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.848 GB, invar_size=5.980 GB, outvar_size=2.990 GB, temp_buffer_size=2.808 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.825 GB, invar_size=6.076 GB, outvar_size=3.068 GB, temp_buffer_size=2.689 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.825 GB, invar_size=6.076 GB, outvar_size=3.068 GB, temp_buffer_size=2.689 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 8.37 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 3, 2, 0) has been pruned...
[TMP] Stage (1, 3, 2, 1) has been pruned...
[TMP] Stage (1, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 6, 3, 0) has been pruned...
[TMP] Stage (1, 6, 3, 1) has been pruned...
[TMP] Stage (1, 6, 3, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 4, 2, 0) has been pruned...
[TMP] Stage (2, 4, 2, 1) has been pruned...
[TMP] Stage (2, 4, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 7, 3, 0) has been pruned...
[TMP] Stage (2, 7, 3, 1) has been pruned...
[TMP] Stage (2, 7, 3, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (3, 5, 2, 0) has been pruned...
[TMP] Stage (3, 5, 2, 1) has been pruned...
[TMP] Stage (3, 5, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 8, 3, 0) has been pruned...
[TMP] Stage (3, 8, 3, 1) has been pruned...
[TMP] Stage (3, 8, 3, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (5, 7, 2, 0) has been pruned...
[TMP] Stage (5, 7, 2, 1) has been pruned...
[TMP] Stage (5, 7, 2, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4], [5], [6, 7], [8], [9], [10], [11], [12, 13], [14], [15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1)]
Result autosharding_option_dicts: [{}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO comm 0x442b670 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO comm 0x3ec1390 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO comm 0x642c620 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO comm 0x5f542c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO comm 0x9ce6aa0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO comm 0x4b478a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO comm 0x9dc4650 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO comm 0x6b70680 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO comm 0x755aeb0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO comm 0x3b0c950 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO comm 0x9076e70 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO comm 0x40e7c40 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO comm 0x6e66320 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO comm 0x613a310 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO comm 0x3d500d0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO comm 0x9ed35e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO comm 0x9fb2aa0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO comm 0x6865440 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO comm 0x3b44a00 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO comm 0x6047270 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO comm 0x51ad200 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO comm 0x90af060 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO comm 0xa701c20 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO comm 0x45d9980 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO comm 0x73ca580 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO comm 0x3648a50 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO comm 0x727aab0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO comm 0x69be930 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4053450)[0m 
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4053450)[0m 
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4053450)[0m 
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO comm 0x50dc290 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO comm 0x9a032b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4053450)[0m 
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO comm 0xad0a440 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4053450)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4053449)[0m 
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO comm 0x999a170 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4053449)[0m 
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4053449)[0m 
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4053449)[0m gpu37:4053449:4053449 [0] NCCL INFO comm 0x444b860 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4053450)[0m 
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO comm 0x82500a0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
 - Compile (driver): 45.72 s
compilation time breakdown: {'stage-construction': '25.38', 'stage-construction-dp': '1.23', 'stage-construction-compilation': '5.22', 'stage-construction-profiling': '9.32'}
 - Compile (worker): 3.15 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO comm 0x7f94a0606500 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948319 [1] NCCL INFO comm 0x7f948414aa80 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948317 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1948238, ip=192.168.0.56)[0m gpu26:1948238:1948238 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392468 [1] NCCL INFO comm 0x7fced0a26d00 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO comm 0x7fcee000aaa0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392466 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2392394, ip=192.168.0.57)[0m gpu27:2392394:2392394 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2707937, ip=192.168.0.60)[0m gpu30:2707937:2707937 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2707938, ip=192.168.0.60)[0m gpu30:2707938:2707938 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257714 [1] NCCL INFO comm 0x7f355e73a0c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO comm 0x7f3582df2910 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257712 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3257638, ip=192.168.0.58)[0m gpu28:3257638:3257638 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3085757, ip=192.168.0.72)[0m gpu42:3085757:3085757 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3085758, ip=192.168.0.72)[0m gpu42:3085758:3085758 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3262612, ip=192.168.0.59)[0m gpu29:3262612:3262612 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3262633, ip=192.168.0.59)[0m gpu29:3262633:3262633 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342566 [1] NCCL INFO comm 0x7f457f401820 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO comm 0x7f45d3bd8590 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342564 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2342503, ip=192.168.0.55)[0m gpu25:2342503:2342503 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4053450)[0m gpu37:4053450:4053450 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 230.23 s

[43.658278465270996, 30.507136583328247, 30.349188089370728, 30.309085369110107, 30.42216467857361, 30.510955333709717, 30.593790769577026]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 155.066 s.
 - Average e2e iteration time: 31.013002395629883 s.
 - Total local training time: 152.1850128173828 s.
 - Average local iteration time: 30.437002182006836 s.
 - Max allocated memory among devices: 12.856 GB.
 - Compilation times:  {'stage-construction': 25.384884357452393, 'stage-construction-dp': 1.2287893295288086, 'stage-construction-compilation': 5.2159833908081055, 'stage-construction-profiling': 9.320825815200806}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 30.437036514282227
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_4B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling wide_resnet_4B with batch size: 512...
------------------------------------------------------------------
[TMP] Profiling results not found in `./jaxpr/prof_log/optimal/wide_resnet_4B_512.pkl`, creating it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 640
    width_factor = 2
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (512, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.756 GB, invar_size=0.606 GB, outvar_size=0.479 GB, temp_buffer_size=0.671 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.092, peak_memory=1.950 GB, invar_size=0.662 GB, outvar_size=0.479 GB, temp_buffer_size=0.809 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.198 GB, invar_size=0.882 GB, outvar_size=0.479 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.198 GB, invar_size=0.882 GB, outvar_size=0.479 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.128, peak_memory=3.073 GB, invar_size=1.159 GB, outvar_size=0.479 GB, temp_buffer_size=1.436 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.419 GB, invar_size=0.744 GB, outvar_size=0.718 GB, temp_buffer_size=0.957 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.379, peak_memory=4.200 GB, invar_size=1.090 GB, outvar_size=1.196 GB, temp_buffer_size=1.914 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.419 GB, invar_size=0.744 GB, outvar_size=0.718 GB, temp_buffer_size=0.957 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.756 GB, invar_size=0.606 GB, outvar_size=0.479 GB, temp_buffer_size=0.671 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.635 GB, invar_size=0.469 GB, outvar_size=0.957 GB, temp_buffer_size=1.209 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.136 GB, invar_size=0.103 GB, outvar_size=0.837 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.136 GB, invar_size=0.103 GB, outvar_size=0.837 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.277, peak_memory=2.577 GB, invar_size=0.065 GB, outvar_size=1.077 GB, temp_buffer_size=1.436 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.290, peak_memory=3.664 GB, invar_size=1.323 GB, outvar_size=0.422 GB, temp_buffer_size=2.102 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.225, peak_memory=3.172 GB, invar_size=0.773 GB, outvar_size=0.957 GB, temp_buffer_size=1.442 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.635 GB, invar_size=0.469 GB, outvar_size=0.957 GB, temp_buffer_size=1.209 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.007, peak_memory=3.190 GB, invar_size=1.450 GB, outvar_size=0.606 GB, temp_buffer_size=1.500 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.363, peak_memory=5.274 GB, invar_size=1.839 GB, outvar_size=0.680 GB, temp_buffer_size=2.957 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.563 GB, invar_size=0.606 GB, outvar_size=0.479 GB, temp_buffer_size=0.479 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.563 GB, invar_size=0.606 GB, outvar_size=0.479 GB, temp_buffer_size=0.479 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.092, peak_memory=1.858 GB, invar_size=0.662 GB, outvar_size=0.479 GB, temp_buffer_size=0.718 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.534, peak_memory=6.982 GB, invar_size=2.419 GB, outvar_size=0.611 GB, temp_buffer_size=4.084 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=4.397 GB, invar_size=1.763 GB, outvar_size=0.882 GB, temp_buffer_size=2.155 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.006, peak_memory=5.009 GB, invar_size=1.728 GB, outvar_size=0.744 GB, temp_buffer_size=2.803 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.746, peak_memory=7.069 GB, invar_size=1.785 GB, outvar_size=0.773 GB, temp_buffer_size=4.566 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.006, peak_memory=5.249 GB, invar_size=1.967 GB, outvar_size=0.744 GB, temp_buffer_size=2.803 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.008, peak_memory=4.636 GB, invar_size=2.002 GB, outvar_size=0.882 GB, temp_buffer_size=2.155 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.468 GB, invar_size=1.302 GB, outvar_size=0.359 GB, temp_buffer_size=0.807 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.583, peak_memory=6.478 GB, invar_size=1.188 GB, outvar_size=0.047 GB, temp_buffer_size=5.290 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=2.565 GB, invar_size=1.010 GB, outvar_size=0.598 GB, temp_buffer_size=0.957 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.468 GB, invar_size=1.302 GB, outvar_size=0.359 GB, temp_buffer_size=0.807 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.898 GB, invar_size=1.851 GB, outvar_size=0.239 GB, temp_buffer_size=0.807 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=5.530 GB, invar_size=1.536 GB, outvar_size=0.469 GB, temp_buffer_size=3.635 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=5.530 GB, invar_size=1.536 GB, outvar_size=0.469 GB, temp_buffer_size=3.635 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=2.351 GB, invar_size=1.285 GB, outvar_size=0.239 GB, temp_buffer_size=0.827 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=6.701 GB, invar_size=1.512 GB, outvar_size=0.094 GB, temp_buffer_size=5.189 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.007, peak_memory=3.190 GB, invar_size=1.450 GB, outvar_size=0.606 GB, temp_buffer_size=1.500 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.290, peak_memory=3.664 GB, invar_size=1.323 GB, outvar_size=0.422 GB, temp_buffer_size=2.102 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.007, peak_memory=3.190 GB, invar_size=1.450 GB, outvar_size=0.606 GB, temp_buffer_size=1.500 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=5.009 GB, invar_size=1.033 GB, outvar_size=0.094 GB, temp_buffer_size=3.975 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.533 GB, invar_size=1.585 GB, outvar_size=0.239 GB, temp_buffer_size=0.709 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.850 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.639 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.007, peak_memory=3.190 GB, invar_size=1.450 GB, outvar_size=0.606 GB, temp_buffer_size=1.500 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=2.351 GB, invar_size=1.285 GB, outvar_size=0.239 GB, temp_buffer_size=0.827 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.850 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.639 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.413 GB, invar_size=1.585 GB, outvar_size=0.239 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.700 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.489 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.279, peak_memory=4.025 GB, invar_size=2.139 GB, outvar_size=0.770 GB, temp_buffer_size=1.647 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.020, peak_memory=4.887 GB, invar_size=2.723 GB, outvar_size=1.302 GB, temp_buffer_size=1.926 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.700 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.489 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=6.285 GB, invar_size=3.702 GB, outvar_size=1.851 GB, temp_buffer_size=2.344 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.413 GB, invar_size=1.585 GB, outvar_size=0.239 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.020, peak_memory=4.916 GB, invar_size=2.842 GB, outvar_size=1.302 GB, temp_buffer_size=1.835 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.700 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.489 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.200, peak_memory=4.256 GB, invar_size=2.329 GB, outvar_size=1.045 GB, temp_buffer_size=1.687 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.350 GB, invar_size=1.944 GB, outvar_size=0.852 GB, temp_buffer_size=1.287 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.028, peak_memory=5.606 GB, invar_size=3.289 GB, outvar_size=1.585 GB, temp_buffer_size=2.198 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.413 GB, invar_size=1.585 GB, outvar_size=0.239 GB, temp_buffer_size=0.589 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.700 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.489 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.350 GB, invar_size=1.944 GB, outvar_size=0.852 GB, temp_buffer_size=1.287 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.700 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.489 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.700 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.489 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.192, peak_memory=4.134 GB, invar_size=2.329 GB, outvar_size=1.045 GB, temp_buffer_size=1.565 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.028, peak_memory=5.606 GB, invar_size=3.289 GB, outvar_size=1.585 GB, temp_buffer_size=2.198 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.350 GB, invar_size=1.944 GB, outvar_size=0.852 GB, temp_buffer_size=1.287 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.494 GB, invar_size=4.369 GB, outvar_size=0.180 GB, temp_buffer_size=1.946 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.350 GB, invar_size=1.944 GB, outvar_size=0.852 GB, temp_buffer_size=1.287 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.126, peak_memory=3.611 GB, invar_size=2.364 GB, outvar_size=0.180 GB, temp_buffer_size=1.067 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.126, peak_memory=3.611 GB, invar_size=2.364 GB, outvar_size=0.180 GB, temp_buffer_size=1.067 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.028, peak_memory=5.606 GB, invar_size=3.289 GB, outvar_size=1.585 GB, temp_buffer_size=2.198 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.197 GB, invar_size=1.944 GB, outvar_size=0.852 GB, temp_buffer_size=1.134 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.197 GB, invar_size=1.944 GB, outvar_size=0.852 GB, temp_buffer_size=1.134 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.197 GB, invar_size=1.944 GB, outvar_size=0.852 GB, temp_buffer_size=1.134 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.632 GB, invar_size=6.566 GB, outvar_size=0.120 GB, temp_buffer_size=1.946 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.028, peak_memory=5.606 GB, invar_size=3.289 GB, outvar_size=1.585 GB, temp_buffer_size=2.198 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.197 GB, invar_size=1.944 GB, outvar_size=0.852 GB, temp_buffer_size=1.134 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=4.821 GB, invar_size=3.463 GB, outvar_size=0.120 GB, temp_buffer_size=1.238 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=4.821 GB, invar_size=3.463 GB, outvar_size=0.120 GB, temp_buffer_size=1.238 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.054, peak_memory=4.103 GB, invar_size=3.029 GB, outvar_size=0.060 GB, temp_buffer_size=1.014 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=7.921 GB, invar_size=5.998 GB, outvar_size=0.060 GB, temp_buffer_size=1.863 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.054, peak_memory=4.103 GB, invar_size=3.029 GB, outvar_size=0.060 GB, temp_buffer_size=1.014 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.200, peak_memory=7.115 GB, invar_size=4.727 GB, outvar_size=2.244 GB, temp_buffer_size=2.268 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.080, peak_memory=16.436 GB, invar_size=8.796 GB, outvar_size=4.368 GB, temp_buffer_size=7.520 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.200, peak_memory=7.115 GB, invar_size=4.727 GB, outvar_size=2.244 GB, temp_buffer_size=2.268 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.144, peak_memory=9.599 GB, invar_size=6.805 GB, outvar_size=3.343 GB, temp_buffer_size=2.674 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.144, peak_memory=9.599 GB, invar_size=6.805 GB, outvar_size=3.343 GB, temp_buffer_size=2.674 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=22.626 GB, invar_size=13.131 GB, outvar_size=6.566 GB, temp_buffer_size=9.376 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.096, peak_memory=8.020 GB, invar_size=6.058 GB, outvar_size=3.029 GB, temp_buffer_size=1.902 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.111, peak_memory=20.924 GB, invar_size=11.996 GB, outvar_size=5.998 GB, temp_buffer_size=8.868 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.096, peak_memory=8.020 GB, invar_size=6.058 GB, outvar_size=3.029 GB, temp_buffer_size=1.902 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 14.90 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.353 GB, invar_size=1.003 GB, outvar_size=0.957 GB, temp_buffer_size=2.393 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.337 GB, invar_size=0.662 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.939 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.756 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.337 GB, invar_size=0.662 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.353 GB, invar_size=1.003 GB, outvar_size=0.957 GB, temp_buffer_size=2.393 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.337 GB, invar_size=0.662 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.337 GB, invar_size=0.662 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.337 GB, invar_size=0.662 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.254 GB, invar_size=2.006 GB, outvar_size=1.003 GB, temp_buffer_size=5.292 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.337 GB, invar_size=0.662 GB, outvar_size=0.479 GB, temp_buffer_size=1.196 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.940 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.757 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.939 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.756 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.544 GB, invar_size=1.323 GB, outvar_size=0.662 GB, temp_buffer_size=2.742 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.544 GB, invar_size=1.323 GB, outvar_size=0.662 GB, temp_buffer_size=2.742 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.066 GB, invar_size=1.323 GB, outvar_size=0.662 GB, temp_buffer_size=2.264 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.066 GB, invar_size=1.323 GB, outvar_size=0.662 GB, temp_buffer_size=2.264 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.544 GB, invar_size=1.323 GB, outvar_size=0.662 GB, temp_buffer_size=2.742 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.544 GB, invar_size=1.323 GB, outvar_size=0.662 GB, temp_buffer_size=2.742 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.254 GB, invar_size=2.006 GB, outvar_size=1.003 GB, temp_buffer_size=5.292 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.950 GB, invar_size=0.972 GB, outvar_size=0.239 GB, temp_buffer_size=0.739 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.940 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.757 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.077 GB, invar_size=3.050 GB, outvar_size=0.120 GB, temp_buffer_size=1.907 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.700 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.518 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.700 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.518 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.700 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.518 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.700 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.518 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.077 GB, invar_size=3.050 GB, outvar_size=0.120 GB, temp_buffer_size=1.907 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.700 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.518 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.700 GB, invar_size=1.944 GB, outvar_size=0.972 GB, temp_buffer_size=1.518 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.296 GB, invar_size=6.099 GB, outvar_size=3.050 GB, temp_buffer_size=3.078 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.095 GB, invar_size=3.128 GB, outvar_size=0.000 GB, temp_buffer_size=1.967 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.095 GB, invar_size=3.128 GB, outvar_size=0.000 GB, temp_buffer_size=1.967 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.296 GB, invar_size=6.099 GB, outvar_size=3.050 GB, temp_buffer_size=3.078 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.094 GB, invar_size=6.136 GB, outvar_size=3.128 GB, temp_buffer_size=2.838 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=9.094 GB, invar_size=6.136 GB, outvar_size=3.128 GB, temp_buffer_size=2.838 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 8.33 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 3, 2, 0) has been pruned...
[TMP] Stage (1, 3, 2, 1) has been pruned...
[TMP] Stage (1, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 6, 3, 0) has been pruned...
[TMP] Stage (1, 6, 3, 1) has been pruned...
[TMP] Stage (1, 6, 3, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 4, 2, 0) has been pruned...
[TMP] Stage (2, 4, 2, 1) has been pruned...
[TMP] Stage (2, 4, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 7, 3, 0) has been pruned...
[TMP] Stage (2, 7, 3, 1) has been pruned...
[TMP] Stage (2, 7, 3, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (3, 5, 2, 0) has been pruned...
[TMP] Stage (3, 5, 2, 1) has been pruned...
[TMP] Stage (3, 5, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 8, 3, 0) has been pruned...
[TMP] Stage (3, 8, 3, 1) has been pruned...
[TMP] Stage (3, 8, 3, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (5, 7, 2, 0) has been pruned...
[TMP] Stage (5, 7, 2, 1) has been pruned...
[TMP] Stage (5, 7, 2, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4], [5], [6, 7], [8, 9], [10], [11], [12, 13], [14], [15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 1), (1, 1), (1, 2), (1, 2), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (1, 1), (1, 1), (2, 1), (2, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1)]
Result autosharding_option_dicts: [{}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO comm 0x5212a80 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO comm 0x471c0b0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO comm 0x9b1ea20 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO comm 0x754eca0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4061591)[0m 
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4061591)[0m 
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4061591)[0m 
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO comm 0xa9e1e40 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO comm 0x4804100 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4061591)[0m 
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO comm 0xaa4af80 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4061589)[0m 
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4061589)[0m 
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4061589)[0m 
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO comm 0xa4324d0 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4061591)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4061591)[0m 
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO comm 0x53c1d90 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4061589)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO comm 0x79782b0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4061589)[0m 
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO comm 0x881d340 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO comm 0x50547a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4061589)[0m 
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO comm 0x7f74510 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO comm 0x843b300 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO comm 0xb490550 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO comm 0x48b8980 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO comm 0x6ac1c40 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO comm 0xb427410 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO comm 0xa911ef0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO comm 0x534a500 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO comm 0xa8a8db0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO comm 0xa89f1d0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO comm 0xa6f1d30 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO comm 0x52d1370 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO comm 0x80cdc00 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO comm 0x41166c0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO comm 0x611b810 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO comm 0x7f7e130 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO comm 0x4309170 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [0] NCCL INFO comm 0x9eb1310 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO comm 0x985e070 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088171 [1] NCCL INFO comm 0xa1080e0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262155, ip=192.168.0.58)[0m gpu28:3262155:3262155 [0] NCCL INFO comm 0x96b0a20 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3262154, ip=192.168.0.58)[0m gpu28:3262154:3262154 [0] NCCL INFO comm 0x4a97c60 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
 - Compile (driver): 45.62 s
compilation time breakdown: {'stage-construction': '25.28', 'stage-construction-dp': '1.22', 'stage-construction-compilation': '5.21', 'stage-construction-profiling': '9.28'}
 - Compile (worker): 3.17 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO comm 0x7f566762a990 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396490 [1] NCCL INFO comm 0x7f5640494d70 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396488 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2396427, ip=192.168.0.57)[0m gpu27:2396427:2396427 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO comm 0x7f6736ad79a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346072 [1] NCCL INFO comm 0x7f671501c190 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2346070 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2345965, ip=192.168.0.55)[0m gpu25:2345965:2345965 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4061591)[0m gpu37:4061591:4061591 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4061589)[0m gpu37:4061589:4061589 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO comm 0x7f5ef235b020 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711261 [1] NCCL INFO comm 0x7f5ed0707530 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711259 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2711198, ip=192.168.0.60)[0m gpu30:2711198:2711198 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267995 [1] NCCL INFO comm 0x7f66bca57020 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO comm 0x7f66cc0c5f30 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267993 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3267877, ip=192.168.0.59)[0m gpu29:3267877:3267877 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1952476, ip=192.168.0.56)[0m gpu26:1952476:1952476 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1952477, ip=192.168.0.56)[0m gpu26:1952477:1952477 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088278 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3088171, ip=192.168.0.72)[0m gpu42:3088171:3088280 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
