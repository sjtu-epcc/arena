
------------------------------------------------------------------
- (1/3) Profiling bert_6.7B with batch size: 128...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_6.7B_128.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7fd7b41667c0>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.100, peak_memory=11.280 GB, invar_size=11.022 GB, outvar_size=0.055 GB, temp_buffer_size=0.203 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.240, peak_memory=5.719 GB, invar_size=5.512 GB, outvar_size=0.109 GB, temp_buffer_size=0.098 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=45.610, peak_memory=1.942 GB, invar_size=1.379 GB, outvar_size=0.438 GB, temp_buffer_size=0.125 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=10.403, peak_memory=38.515 GB, invar_size=25.694 GB, outvar_size=12.820 GB, temp_buffer_size=12.821 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=4.987, peak_memory=19.341 GB, invar_size=12.931 GB, outvar_size=6.411 GB, temp_buffer_size=6.411 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=100.811, peak_memory=6.289 GB, invar_size=3.645 GB, outvar_size=1.604 GB, temp_buffer_size=2.644 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 191.19 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.258, peak_memory=2.094 GB, invar_size=1.626 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.259, peak_memory=2.094 GB, invar_size=1.626 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.259, peak_memory=2.094 GB, invar_size=1.626 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.104, peak_memory=3.563 GB, invar_size=3.157 GB, outvar_size=0.062 GB, temp_buffer_size=0.344 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.112, peak_memory=3.849 GB, invar_size=3.395 GB, outvar_size=0.062 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.273, peak_memory=2.214 GB, invar_size=1.698 GB, outvar_size=0.125 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.273, peak_memory=2.214 GB, invar_size=1.698 GB, outvar_size=0.125 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.104, peak_memory=3.563 GB, invar_size=3.157 GB, outvar_size=0.062 GB, temp_buffer_size=0.344 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=3.438 GB, invar_size=3.032 GB, outvar_size=0.062 GB, temp_buffer_size=0.344 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.251, peak_memory=2.063 GB, invar_size=1.563 GB, outvar_size=0.125 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.251, peak_memory=2.063 GB, invar_size=1.563 GB, outvar_size=0.125 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.258, peak_memory=2.094 GB, invar_size=1.626 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=3.438 GB, invar_size=3.032 GB, outvar_size=0.062 GB, temp_buffer_size=0.344 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.245, peak_memory=2.032 GB, invar_size=1.563 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.244, peak_memory=2.032 GB, invar_size=1.563 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=3.438 GB, invar_size=3.032 GB, outvar_size=0.062 GB, temp_buffer_size=0.344 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.340, peak_memory=11.099 GB, invar_size=6.345 GB, outvar_size=3.157 GB, temp_buffer_size=4.722 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.624, peak_memory=8.778 GB, invar_size=3.314 GB, outvar_size=1.626 GB, temp_buffer_size=5.401 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.341, peak_memory=11.067 GB, invar_size=6.345 GB, outvar_size=3.157 GB, temp_buffer_size=4.691 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.245, peak_memory=2.032 GB, invar_size=1.563 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.351, peak_memory=11.439 GB, invar_size=6.853 GB, outvar_size=3.395 GB, temp_buffer_size=4.586 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.622, peak_memory=9.505 GB, invar_size=3.521 GB, outvar_size=1.698 GB, temp_buffer_size=5.984 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.624, peak_memory=8.901 GB, invar_size=3.314 GB, outvar_size=1.626 GB, temp_buffer_size=5.524 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.244, peak_memory=2.032 GB, invar_size=1.563 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.050, peak_memory=1.907 GB, invar_size=1.532 GB, outvar_size=0.031 GB, temp_buffer_size=0.344 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.327, peak_memory=10.255 GB, invar_size=6.095 GB, outvar_size=3.032 GB, temp_buffer_size=4.129 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.125, peak_memory=1.250 GB, invar_size=0.813 GB, outvar_size=0.062 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.601, peak_memory=8.778 GB, invar_size=3.189 GB, outvar_size=1.563 GB, temp_buffer_size=5.527 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.622, peak_memory=9.505 GB, invar_size=3.521 GB, outvar_size=1.698 GB, temp_buffer_size=5.984 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.125, peak_memory=1.250 GB, invar_size=0.813 GB, outvar_size=0.062 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.601, peak_memory=8.778 GB, invar_size=3.189 GB, outvar_size=1.563 GB, temp_buffer_size=5.527 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.613, peak_memory=9.462 GB, invar_size=3.314 GB, outvar_size=1.626 GB, temp_buffer_size=6.085 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.326, peak_memory=10.192 GB, invar_size=6.095 GB, outvar_size=3.032 GB, temp_buffer_size=4.066 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.613, peak_memory=9.337 GB, invar_size=3.314 GB, outvar_size=1.626 GB, temp_buffer_size=5.961 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=8.651 GB, invar_size=3.189 GB, outvar_size=1.563 GB, temp_buffer_size=5.400 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=8.653 GB, invar_size=3.189 GB, outvar_size=1.563 GB, temp_buffer_size=5.401 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.327, peak_memory=10.193 GB, invar_size=6.095 GB, outvar_size=3.032 GB, temp_buffer_size=4.066 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.601, peak_memory=8.715 GB, invar_size=3.189 GB, outvar_size=1.563 GB, temp_buffer_size=5.463 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.356, peak_memory=10.817 GB, invar_size=6.658 GB, outvar_size=3.329 GB, temp_buffer_size=4.127 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.601, peak_memory=8.716 GB, invar_size=3.189 GB, outvar_size=1.563 GB, temp_buffer_size=5.465 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.631, peak_memory=8.852 GB, invar_size=3.423 GB, outvar_size=1.712 GB, temp_buffer_size=5.367 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.631, peak_memory=8.852 GB, invar_size=3.423 GB, outvar_size=1.712 GB, temp_buffer_size=5.367 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 41.64 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.108, peak_memory=2.438 GB, invar_size=1.688 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.108, peak_memory=2.438 GB, invar_size=1.688 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.124, peak_memory=2.747 GB, invar_size=1.895 GB, outvar_size=0.062 GB, temp_buffer_size=0.789 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.124, peak_memory=2.747 GB, invar_size=1.895 GB, outvar_size=0.062 GB, temp_buffer_size=0.789 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.321, peak_memory=12.759 GB, invar_size=3.376 GB, outvar_size=1.688 GB, temp_buffer_size=9.320 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.338, peak_memory=12.960 GB, invar_size=3.852 GB, outvar_size=1.895 GB, temp_buffer_size=9.108 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.338, peak_memory=12.960 GB, invar_size=3.852 GB, outvar_size=1.895 GB, temp_buffer_size=9.108 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.321, peak_memory=12.759 GB, invar_size=3.376 GB, outvar_size=1.688 GB, temp_buffer_size=9.320 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.296, peak_memory=11.385 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.197 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.296, peak_memory=11.385 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.197 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.294, peak_memory=11.195 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.006 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.296, peak_memory=11.510 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.322 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.296, peak_memory=11.510 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.322 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.294, peak_memory=11.195 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.006 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.296, peak_memory=11.320 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.131 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.296, peak_memory=11.320 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.131 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.296, peak_memory=11.197 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.009 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.296, peak_memory=11.197 GB, invar_size=3.126 GB, outvar_size=1.563 GB, temp_buffer_size=8.009 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.349, peak_memory=11.975 GB, invar_size=3.657 GB, outvar_size=1.860 GB, temp_buffer_size=8.255 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.349, peak_memory=11.975 GB, invar_size=3.657 GB, outvar_size=1.860 GB, temp_buffer_size=8.255 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 20.78 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0], [1, 2], [3, 4], [5, 6], [7]]
Result mesh_shapes: [(1, 1), (1, 2), (1, 2), (1, 2), (1, 1)]
Result logical_mesh_shapes: [(1, 1), (2, 1), (2, 1), (2, 1), (1, 1)]
Result autosharding_option_dicts: [{}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}]
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO comm 0x439eb60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO comm 0x4e69910 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO comm 0x6d70b20 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 00 : 0[31000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 01 : 0[31000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO comm 0x70688d0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO comm 0x44f6f50 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO comm 0xaeba030 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO comm 0xae50ef0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO comm 0x629cec0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2633155)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO comm 0x48f8910 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO comm 0xa271300 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO comm 0x6c99910 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO comm 0x7c969d0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO comm 0x3fb6180 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO comm 0xacdead0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO comm 0xac75990 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1886429, ip=192.168.0.35)[0m gpu20:1886429:1886429 [0] NCCL INFO comm 0x6db2c20 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
 - Compile (driver): 306.04 s
compilation time breakdown: {'stage-construction': '258.14', 'stage-construction-dp': '1.41', 'stage-construction-compilation': '177.91', 'stage-construction-profiling': '36.84'}
 - Compile (worker): 7.18 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1886428, ip=192.168.0.35)[0m gpu20:1886428:1886428 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107861 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633155 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834076 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834228 [1] NCCL INFO comm 0x7fac89f57960 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO comm 0x7fac91c99d70 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2633155)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2633155)[0m 
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO comm 0x7f49160e3980 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633226 [1] NCCL INFO comm 0x7f491038e7f0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107967 [1] NCCL INFO comm 0x7f1a768067d0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO comm 0x7f1a7213ba40 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1834076, ip=192.168.0.34)[0m gpu19:1834076:1834226 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2633155)[0m gpu16:2633155:2633224 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3107861, ip=192.168.0.39)[0m gpu24:3107861:3107965 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 308.82 s

[76.62879419326782, 20.69278645515442, 20.269023418426514, 20.292076349258423, 20.688398838043213, 20.85498046875, 21.145963668823242]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 107.057 s.
 - Average e2e iteration time: 21.411001205444336 s.
 - Total local training time: 103.25000762939453 s.
 - Average local iteration time: 20.650001525878906 s.
 - Max allocated memory among devices: 24.394 GB.
 - Compilation times:  {'stage-construction': 258.14474272727966, 'stage-construction-dp': 1.4082777500152588, 'stage-construction-compilation': 177.90989422798157, 'stage-construction-profiling': 36.843679904937744}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 20.650089263916016
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_6.7B_128.pkl`...

------------------------------------------------------------------
- (2/3) Profiling bert_6.7B with batch size: 256...
------------------------------------------------------------------
[TMP] Profiling results not found in `./jaxpr/prof_log/optimal/bert_6.7B_256.pkl`, creating it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7efd5857e850>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.192, peak_memory=11.327 GB, invar_size=11.022 GB, outvar_size=0.109 GB, temp_buffer_size=0.195 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.469, peak_memory=5.926 GB, invar_size=5.512 GB, outvar_size=0.219 GB, temp_buffer_size=0.195 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=1.761, peak_memory=11.107 GB, invar_size=10.677 GB, outvar_size=0.109 GB, temp_buffer_size=0.320 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=10.718, peak_memory=38.570 GB, invar_size=25.749 GB, outvar_size=12.820 GB, temp_buffer_size=12.821 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=5.605, peak_memory=19.451 GB, invar_size=13.040 GB, outvar_size=6.411 GB, temp_buffer_size=6.411 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=13.343, peak_memory=36.622 GB, invar_size=24.375 GB, outvar_size=12.133 GB, temp_buffer_size=12.248 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 174.45 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.206, peak_memory=4.001 GB, invar_size=3.188 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.515, peak_memory=2.626 GB, invar_size=1.688 GB, outvar_size=0.188 GB, temp_buffer_size=0.750 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.876 GB, invar_size=3.063 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.206, peak_memory=4.001 GB, invar_size=3.188 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.515, peak_memory=2.626 GB, invar_size=1.688 GB, outvar_size=0.188 GB, temp_buffer_size=0.750 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.241, peak_memory=4.229 GB, invar_size=3.198 GB, outvar_size=0.125 GB, temp_buffer_size=0.906 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.222, peak_memory=4.302 GB, invar_size=3.395 GB, outvar_size=0.125 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.500, peak_memory=2.626 GB, invar_size=1.626 GB, outvar_size=0.250 GB, temp_buffer_size=0.750 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.543, peak_memory=2.729 GB, invar_size=1.698 GB, outvar_size=0.250 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.206, peak_memory=4.001 GB, invar_size=3.188 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.876 GB, invar_size=3.063 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.206, peak_memory=4.001 GB, invar_size=3.188 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.876 GB, invar_size=3.063 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.876 GB, invar_size=3.063 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.487, peak_memory=2.563 GB, invar_size=1.626 GB, outvar_size=0.188 GB, temp_buffer_size=0.750 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.876 GB, invar_size=3.063 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.487, peak_memory=2.563 GB, invar_size=1.626 GB, outvar_size=0.188 GB, temp_buffer_size=0.750 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=1.196, peak_memory=14.542 GB, invar_size=3.376 GB, outvar_size=1.626 GB, temp_buffer_size=11.040 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=1.240, peak_memory=14.663 GB, invar_size=3.501 GB, outvar_size=1.688 GB, temp_buffer_size=11.036 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.876 GB, invar_size=3.063 GB, outvar_size=0.125 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.645, peak_memory=15.946 GB, invar_size=6.439 GB, outvar_size=3.188 GB, temp_buffer_size=9.444 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.647, peak_memory=16.008 GB, invar_size=6.502 GB, outvar_size=3.188 GB, temp_buffer_size=9.444 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.647, peak_memory=15.883 GB, invar_size=6.439 GB, outvar_size=3.188 GB, temp_buffer_size=9.381 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.621, peak_memory=14.509 GB, invar_size=6.189 GB, outvar_size=3.063 GB, temp_buffer_size=8.257 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.099, peak_memory=2.313 GB, invar_size=1.563 GB, outvar_size=0.062 GB, temp_buffer_size=0.688 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.621, peak_memory=14.509 GB, invar_size=6.189 GB, outvar_size=3.063 GB, temp_buffer_size=8.257 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.250, peak_memory=1.750 GB, invar_size=0.875 GB, outvar_size=0.125 GB, temp_buffer_size=0.750 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.687, peak_memory=15.754 GB, invar_size=6.521 GB, outvar_size=3.198 GB, temp_buffer_size=9.233 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=1.238, peak_memory=15.600 GB, invar_size=3.646 GB, outvar_size=1.698 GB, temp_buffer_size=11.954 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.666, peak_memory=16.087 GB, invar_size=6.916 GB, outvar_size=3.395 GB, temp_buffer_size=9.171 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=1.219, peak_memory=15.786 GB, invar_size=3.501 GB, outvar_size=1.688 GB, temp_buffer_size=12.159 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.618, peak_memory=14.382 GB, invar_size=6.189 GB, outvar_size=3.063 GB, temp_buffer_size=8.130 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.645, peak_memory=16.009 GB, invar_size=6.502 GB, outvar_size=3.188 GB, temp_buffer_size=9.444 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.621, peak_memory=14.382 GB, invar_size=6.189 GB, outvar_size=3.063 GB, temp_buffer_size=8.131 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=1.176, peak_memory=14.288 GB, invar_size=3.376 GB, outvar_size=1.626 GB, temp_buffer_size=10.787 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.618, peak_memory=14.382 GB, invar_size=6.189 GB, outvar_size=3.063 GB, temp_buffer_size=8.130 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=1.196, peak_memory=14.415 GB, invar_size=3.376 GB, outvar_size=1.626 GB, temp_buffer_size=10.913 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.621, peak_memory=14.382 GB, invar_size=6.189 GB, outvar_size=3.063 GB, temp_buffer_size=8.131 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=1.255, peak_memory=14.395 GB, invar_size=3.548 GB, outvar_size=1.774 GB, temp_buffer_size=10.722 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.676, peak_memory=15.038 GB, invar_size=6.721 GB, outvar_size=3.360 GB, temp_buffer_size=8.255 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.697, peak_memory=14.710 GB, invar_size=6.330 GB, outvar_size=3.165 GB, temp_buffer_size=8.318 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 44.50 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.215, peak_memory=3.251 GB, invar_size=1.750 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.215, peak_memory=3.251 GB, invar_size=1.750 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.125 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.125 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.247, peak_memory=3.598 GB, invar_size=1.895 GB, outvar_size=0.125 GB, temp_buffer_size=1.578 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.247, peak_memory=3.598 GB, invar_size=1.895 GB, outvar_size=0.125 GB, temp_buffer_size=1.578 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.126 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.126 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.125 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.125 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.126 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=19.767 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.392 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=19.767 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.392 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.674, peak_memory=22.131 GB, invar_size=3.915 GB, outvar_size=1.895 GB, temp_buffer_size=18.216 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.674, peak_memory=22.131 GB, invar_size=3.915 GB, outvar_size=1.895 GB, temp_buffer_size=18.216 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.640, peak_memory=22.267 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=18.641 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.640, peak_memory=22.267 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=18.641 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.126 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=20.018 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.642 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.125 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=20.018 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.642 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.125 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.587, peak_memory=19.389 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.013 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.587, peak_memory=19.389 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.013 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=19.639 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.263 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=19.639 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.263 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=19.392 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.017 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.591, peak_memory=19.392 GB, invar_size=3.251 GB, outvar_size=1.625 GB, temp_buffer_size=16.017 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.697, peak_memory=20.355 GB, invar_size=3.720 GB, outvar_size=1.922 GB, temp_buffer_size=16.510 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.697, peak_memory=20.355 GB, invar_size=3.720 GB, outvar_size=1.922 GB, temp_buffer_size=16.510 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 20.99 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0], [1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 1), (1, 1), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(1, 1), (1, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.38<0>
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO comm 0x3a7b260 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO comm 0x387a0d0 rank 1 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO comm 0x8dda6a0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 00 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 01 : 0[98000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 00 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 01 : 1[31000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO comm 0x431b680 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m 
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO comm 0x8c4a9a0 rank 0 nranks 2 cudaDev 0 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO comm 0x444b4c0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2648134)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO comm 0x49f3a20 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO comm 0x9ef6020 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO comm 0xa66f3b0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO comm 0x9df1690 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO comm 0xacb88b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [0] NCCL INFO comm 0x35be960 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889306 [1] NCCL INFO comm 0x5479f30 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO comm 0xad219f0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 298.30 s
compilation time breakdown: {'stage-construction': '244.60', 'stage-construction-dp': '1.38', 'stage-construction-compilation': '159.23', 'stage-construction-profiling': '39.11'}
 - Compile (worker): 7.50 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=3112965, ip=192.168.0.39)[0m gpu24:3112965:3112965 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3112966, ip=192.168.0.39)[0m gpu24:3112966:3112966 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648134 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841415 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.30<0>
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2648134)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.34<0>
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m 
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889412 [1] NCCL INFO comm 0x7eec662e1cc0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO comm 0x7eec61a4fa70 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1889306, ip=192.168.0.35)[0m gpu20:1889306:1889410 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.33<0>
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m 
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO comm 0x7f8134431a60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841521 [1] NCCL INFO comm 0x7f8130ca26a0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2648134)[0m 
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648245 [1] NCCL INFO comm 0x7f7cb4605e80 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO comm 0x7f7cbf4bc3c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2648134)[0m gpu16:2648134:2648243 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1841415, ip=192.168.0.34)[0m gpu19:1841415:1841519 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 572.44 s

[227.77652955055237, 52.73806405067444, 52.64373588562012, 52.58751082420349, 52.67676329612732, 52.678688287734985, 52.64509677886963]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 270.357 s.
 - Average e2e iteration time: 54.07100296020508 s.
 - Total local training time: 263.2320251464844 s.
 - Average local iteration time: 52.64600372314453 s.
 - Max allocated memory among devices: 33.628 GB.
 - Compilation times:  {'stage-construction': 244.60125970840454, 'stage-construction-dp': 1.3789594173431396, 'stage-construction-compilation': 159.2270495891571, 'stage-construction-profiling': 39.1097252368927}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 52.646358489990234
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_6.7B_256.pkl`...

------------------------------------------------------------------
- (3/3) Profiling bert_6.7B with batch size: 512...
------------------------------------------------------------------
[TMP] Profiling results not found in `./jaxpr/prof_log/optimal/bert_6.7B_512.pkl`, creating it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7ff7b2d58610>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.878, peak_memory=6.324 GB, invar_size=5.512 GB, outvar_size=0.406 GB, temp_buffer_size=0.406 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.365, peak_memory=11.632 GB, invar_size=11.022 GB, outvar_size=0.219 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.365, peak_memory=11.632 GB, invar_size=11.022 GB, outvar_size=0.219 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=11.312, peak_memory=38.679 GB, invar_size=25.858 GB, outvar_size=12.820 GB, temp_buffer_size=12.821 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=11.312, peak_memory=38.679 GB, invar_size=25.858 GB, outvar_size=12.820 GB, temp_buffer_size=12.821 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=6.815, peak_memory=19.638 GB, invar_size=13.228 GB, outvar_size=6.411 GB, temp_buffer_size=6.411 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 191.76 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.412, peak_memory=4.876 GB, invar_size=3.251 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.444, peak_memory=5.208 GB, invar_size=3.396 GB, outvar_size=0.250 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=1.084, peak_memory=3.761 GB, invar_size=1.698 GB, outvar_size=0.500 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.444, peak_memory=5.208 GB, invar_size=3.396 GB, outvar_size=0.250 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=3.126 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.997, peak_memory=3.751 GB, invar_size=1.751 GB, outvar_size=0.500 GB, temp_buffer_size=1.500 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=3.126 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=1.026, peak_memory=3.688 GB, invar_size=1.813 GB, outvar_size=0.375 GB, temp_buffer_size=1.500 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.412, peak_memory=4.876 GB, invar_size=3.251 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=1.026, peak_memory=3.688 GB, invar_size=1.813 GB, outvar_size=0.375 GB, temp_buffer_size=1.500 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.412, peak_memory=4.876 GB, invar_size=3.251 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.412, peak_memory=4.876 GB, invar_size=3.251 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=3.126 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.971, peak_memory=3.626 GB, invar_size=1.751 GB, outvar_size=0.375 GB, temp_buffer_size=1.500 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=3.126 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=3.126 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.125 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.971, peak_memory=3.626 GB, invar_size=1.751 GB, outvar_size=0.375 GB, temp_buffer_size=1.500 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=2.388, peak_memory=26.063 GB, invar_size=3.751 GB, outvar_size=1.751 GB, temp_buffer_size=22.061 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=1.210, peak_memory=23.015 GB, invar_size=6.377 GB, outvar_size=3.126 GB, temp_buffer_size=16.513 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=1.297, peak_memory=25.382 GB, invar_size=7.041 GB, outvar_size=3.395 GB, temp_buffer_size=18.341 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=1.210, peak_memory=23.015 GB, invar_size=6.377 GB, outvar_size=3.126 GB, temp_buffer_size=16.513 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=3.126 GB, outvar_size=0.250 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=2.472, peak_memory=27.785 GB, invar_size=3.896 GB, outvar_size=1.698 GB, temp_buffer_size=23.889 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=1.257, peak_memory=25.640 GB, invar_size=6.627 GB, outvar_size=3.251 GB, temp_buffer_size=18.888 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=2.475, peak_memory=26.182 GB, invar_size=3.876 GB, outvar_size=1.813 GB, temp_buffer_size=22.055 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=1.297, peak_memory=25.382 GB, invar_size=7.041 GB, outvar_size=3.395 GB, temp_buffer_size=18.341 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=1.261, peak_memory=25.514 GB, invar_size=6.627 GB, outvar_size=3.251 GB, temp_buffer_size=18.763 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=1.261, peak_memory=25.764 GB, invar_size=6.752 GB, outvar_size=3.251 GB, temp_buffer_size=18.888 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.499, peak_memory=2.750 GB, invar_size=1.000 GB, outvar_size=0.250 GB, temp_buffer_size=1.500 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.197, peak_memory=3.125 GB, invar_size=1.625 GB, outvar_size=0.125 GB, temp_buffer_size=1.375 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=2.434, peak_memory=28.429 GB, invar_size=3.876 GB, outvar_size=1.813 GB, temp_buffer_size=24.303 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=2.347, peak_memory=25.557 GB, invar_size=3.751 GB, outvar_size=1.751 GB, temp_buffer_size=21.555 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=1.206, peak_memory=22.762 GB, invar_size=6.377 GB, outvar_size=3.126 GB, temp_buffer_size=16.260 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=1.210, peak_memory=22.762 GB, invar_size=6.377 GB, outvar_size=3.126 GB, temp_buffer_size=16.261 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=1.206, peak_memory=22.762 GB, invar_size=6.377 GB, outvar_size=3.126 GB, temp_buffer_size=16.260 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=1.257, peak_memory=25.765 GB, invar_size=6.752 GB, outvar_size=3.251 GB, temp_buffer_size=18.888 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=1.210, peak_memory=22.762 GB, invar_size=6.377 GB, outvar_size=3.126 GB, temp_buffer_size=16.261 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=2.388, peak_memory=25.810 GB, invar_size=3.751 GB, outvar_size=1.751 GB, temp_buffer_size=21.809 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=1.319, peak_memory=23.480 GB, invar_size=6.846 GB, outvar_size=3.423 GB, temp_buffer_size=16.510 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=2.505, peak_memory=25.476 GB, invar_size=3.798 GB, outvar_size=1.899 GB, temp_buffer_size=21.428 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=1.363, peak_memory=23.215 GB, invar_size=6.455 GB, outvar_size=3.227 GB, temp_buffer_size=16.635 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 41.64 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.429, peak_memory=4.876 GB, invar_size=1.876 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.429, peak_memory=4.876 GB, invar_size=1.876 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.493, peak_memory=5.302 GB, invar_size=1.895 GB, outvar_size=0.250 GB, temp_buffer_size=3.156 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.493, peak_memory=5.302 GB, invar_size=1.895 GB, outvar_size=0.250 GB, temp_buffer_size=3.156 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=1.181, peak_memory=36.532 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=32.781 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=1.181, peak_memory=36.532 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=32.781 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=1.279, peak_memory=41.282 GB, invar_size=3.751 GB, outvar_size=1.875 GB, temp_buffer_size=37.281 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=1.279, peak_memory=41.282 GB, invar_size=3.751 GB, outvar_size=1.875 GB, temp_buffer_size=37.281 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=1.348, peak_memory=40.472 GB, invar_size=4.040 GB, outvar_size=1.895 GB, temp_buffer_size=36.432 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=1.181, peak_memory=37.032 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=33.281 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=1.348, peak_memory=40.472 GB, invar_size=4.040 GB, outvar_size=1.895 GB, temp_buffer_size=36.432 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=1.173, peak_memory=35.776 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=32.025 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.394, peak_memory=4.751 GB, invar_size=1.751 GB, outvar_size=0.250 GB, temp_buffer_size=2.750 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=1.181, peak_memory=37.032 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=33.281 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=1.173, peak_memory=35.776 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=32.025 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=1.181, peak_memory=36.277 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=32.526 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=1.181, peak_memory=35.782 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=32.031 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=1.181, peak_memory=36.277 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=32.526 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=1.181, peak_memory=35.782 GB, invar_size=3.501 GB, outvar_size=1.750 GB, temp_buffer_size=32.031 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=1.393, peak_memory=37.115 GB, invar_size=3.845 GB, outvar_size=2.047 GB, temp_buffer_size=33.020 GB, available_memory=35.242 GB)
