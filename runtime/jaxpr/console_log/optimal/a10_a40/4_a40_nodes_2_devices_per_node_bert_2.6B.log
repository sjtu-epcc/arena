
------------------------------------------------------------------
- (1/3) Profiling bert_2.6B with batch size: 128...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_2.6B_128.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f2747b4d910>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=4.630 GB, invar_size=4.399 GB, outvar_size=0.034 GB, temp_buffer_size=0.197 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.133, peak_memory=2.366 GB, invar_size=2.200 GB, outvar_size=0.068 GB, temp_buffer_size=0.098 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.536, peak_memory=4.415 GB, invar_size=4.183 GB, outvar_size=0.034 GB, temp_buffer_size=0.197 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=4.229, peak_memory=15.612 GB, invar_size=10.419 GB, outvar_size=5.193 GB, temp_buffer_size=5.193 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=2.106, peak_memory=7.859 GB, invar_size=5.262 GB, outvar_size=2.597 GB, temp_buffer_size=2.597 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=4.878, peak_memory=14.366 GB, invar_size=9.560 GB, outvar_size=4.763 GB, temp_buffer_size=4.805 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 172.45 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.588 GB, invar_size=1.241 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.588 GB, invar_size=1.241 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.141, peak_memory=1.037 GB, invar_size=0.650 GB, outvar_size=0.059 GB, temp_buffer_size=0.328 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.050, peak_memory=1.849 GB, invar_size=1.419 GB, outvar_size=0.039 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.588 GB, invar_size=1.241 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.151, peak_memory=1.178 GB, invar_size=0.710 GB, outvar_size=0.078 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.141, peak_memory=1.037 GB, invar_size=0.650 GB, outvar_size=0.059 GB, temp_buffer_size=0.328 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.056, peak_memory=1.765 GB, invar_size=1.296 GB, outvar_size=0.039 GB, temp_buffer_size=0.430 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=1.540 GB, invar_size=1.192 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=1.540 GB, invar_size=1.192 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.137, peak_memory=1.032 GB, invar_size=0.625 GB, outvar_size=0.078 GB, temp_buffer_size=0.328 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.588 GB, invar_size=1.241 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=1.540 GB, invar_size=1.192 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.133, peak_memory=1.012 GB, invar_size=0.625 GB, outvar_size=0.059 GB, temp_buffer_size=0.328 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=1.540 GB, invar_size=1.192 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=1.540 GB, invar_size=1.192 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.315, peak_memory=5.535 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=4.206 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.133, peak_memory=1.012 GB, invar_size=0.625 GB, outvar_size=0.059 GB, temp_buffer_size=0.328 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=5.755 GB, invar_size=2.403 GB, outvar_size=1.192 GB, temp_buffer_size=3.332 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.143, peak_memory=6.391 GB, invar_size=2.501 GB, outvar_size=1.241 GB, temp_buffer_size=3.870 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=0.934 GB, invar_size=0.606 GB, outvar_size=0.020 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.153, peak_memory=6.642 GB, invar_size=2.877 GB, outvar_size=1.419 GB, temp_buffer_size=3.765 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.142, peak_memory=6.411 GB, invar_size=2.501 GB, outvar_size=1.241 GB, temp_buffer_size=3.890 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.143, peak_memory=6.430 GB, invar_size=2.521 GB, outvar_size=1.241 GB, temp_buffer_size=3.890 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=1.540 GB, invar_size=1.192 GB, outvar_size=0.039 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.329, peak_memory=6.139 GB, invar_size=1.497 GB, outvar_size=0.710 GB, temp_buffer_size=4.642 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=5.755 GB, invar_size=2.403 GB, outvar_size=1.192 GB, temp_buffer_size=3.332 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=0.699 GB, invar_size=0.332 GB, outvar_size=0.039 GB, temp_buffer_size=0.328 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.327, peak_memory=5.587 GB, invar_size=1.339 GB, outvar_size=0.650 GB, temp_buffer_size=4.209 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=0.934 GB, invar_size=0.606 GB, outvar_size=0.020 GB, temp_buffer_size=0.309 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=6.428 GB, invar_size=2.630 GB, outvar_size=1.296 GB, temp_buffer_size=3.797 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.321, peak_memory=6.120 GB, invar_size=1.339 GB, outvar_size=0.650 GB, temp_buffer_size=4.742 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=5.715 GB, invar_size=2.403 GB, outvar_size=1.192 GB, temp_buffer_size=3.292 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.142, peak_memory=6.430 GB, invar_size=2.521 GB, outvar_size=1.241 GB, temp_buffer_size=3.890 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=5.715 GB, invar_size=2.403 GB, outvar_size=1.192 GB, temp_buffer_size=3.292 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=5.715 GB, invar_size=2.403 GB, outvar_size=1.192 GB, temp_buffer_size=3.292 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.309, peak_memory=5.455 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=4.126 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=5.715 GB, invar_size=2.403 GB, outvar_size=1.192 GB, temp_buffer_size=3.292 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.157, peak_memory=6.255 GB, invar_size=2.799 GB, outvar_size=1.400 GB, temp_buffer_size=3.436 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.315, peak_memory=5.495 GB, invar_size=1.290 GB, outvar_size=0.625 GB, temp_buffer_size=4.166 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.336, peak_memory=5.603 GB, invar_size=1.458 GB, outvar_size=0.729 GB, temp_buffer_size=4.106 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.162, peak_memory=6.030 GB, invar_size=2.555 GB, outvar_size=1.277 GB, temp_buffer_size=3.456 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 43.06 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.330 GB, invar_size=0.674 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.330 GB, invar_size=0.674 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.056, peak_memory=1.661 GB, invar_size=0.833 GB, outvar_size=0.039 GB, temp_buffer_size=0.789 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.056, peak_memory=1.661 GB, invar_size=0.833 GB, outvar_size=0.039 GB, temp_buffer_size=0.789 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.915 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.625 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.132, peak_memory=9.128 GB, invar_size=1.348 GB, outvar_size=0.674 GB, temp_buffer_size=7.741 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.915 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.625 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.991 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.702 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.991 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.702 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.132, peak_memory=9.128 GB, invar_size=1.348 GB, outvar_size=0.674 GB, temp_buffer_size=7.741 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.149, peak_memory=9.195 GB, invar_size=1.705 GB, outvar_size=0.833 GB, temp_buffer_size=7.491 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.149, peak_memory=9.195 GB, invar_size=1.705 GB, outvar_size=0.833 GB, temp_buffer_size=7.491 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.834 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.544 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.834 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.544 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.874 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.585 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.874 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.585 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.798 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.508 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=7.798 GB, invar_size=1.251 GB, outvar_size=0.625 GB, temp_buffer_size=6.508 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=8.538 GB, invar_size=1.627 GB, outvar_size=0.833 GB, temp_buffer_size=6.872 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=8.538 GB, invar_size=1.627 GB, outvar_size=0.833 GB, temp_buffer_size=6.872 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 20.92 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO comm 0x49b3790 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO comm 0x38f0db0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO comm 0x8d1ca40 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO comm 0x9db6250 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4019258)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO comm 0x4a21770 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO comm 0x948bcd0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO comm 0x60bcc00 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO comm 0x68d9650 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO comm 0xad72610 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [0] NCCL INFO comm 0x4448030 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO comm 0xad7af40 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142301 [1] NCCL INFO comm 0x6495820 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 293.12 s
compilation time breakdown: {'stage-construction': '240.64', 'stage-construction-dp': '1.40', 'stage-construction-compilation': '159.83', 'stage-construction-profiling': '37.03'}
 - Compile (worker): 6.86 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517007 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019258 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400008 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4019258)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO comm 0x7f567e7e71a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142407 [1] NCCL INFO comm 0x7f568427b570 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2142301, ip=192.168.0.33)[0m gpu18:2142301:2142405 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO comm 0x7f2e06b59a20 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400156 [1] NCCL INFO comm 0x7f2dff666d30 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4019258)[0m 
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019328 [1] NCCL INFO comm 0x7f97ef452840 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO comm 0x7f97e45d47c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4019258)[0m gpu2:4019258:4019326 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517116 [1] NCCL INFO comm 0x7f3b6a2a3ee0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO comm 0x7f3b7437daf0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=400008, ip=192.168.0.26)[0m gpu11:400008:400154 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1517007, ip=192.168.0.18)[0m gpu3:1517007:1517114 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 79.78 s

[25.50240707397461, 7.501437187194824, 7.547459363937378, 7.432059049606323, 7.712479591369629, 7.411576986312866, 7.698152303695679]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 40.277 s.
 - Average e2e iteration time: 8.055000305175781 s.
 - Total local training time: 37.802001953125 s.
 - Average local iteration time: 7.560000419616699 s.
 - Max allocated memory among devices: 11.212 GB.
 - Compilation times:  {'stage-construction': 240.63587760925293, 'stage-construction-dp': 1.3955810070037842, 'stage-construction-compilation': 159.82767391204834, 'stage-construction-profiling': 37.02959656715393}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 7.560345649719238
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_2.6B_128.pkl`...

------------------------------------------------------------------
- (2/3) Profiling bert_2.6B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_2.6B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f6099abea00>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.082, peak_memory=4.662 GB, invar_size=4.399 GB, outvar_size=0.068 GB, temp_buffer_size=0.195 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.251, peak_memory=2.522 GB, invar_size=2.200 GB, outvar_size=0.127 GB, temp_buffer_size=0.195 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=1.063, peak_memory=4.525 GB, invar_size=4.183 GB, outvar_size=0.068 GB, temp_buffer_size=0.273 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=4.359, peak_memory=15.647 GB, invar_size=10.453 GB, outvar_size=5.193 GB, temp_buffer_size=5.193 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=2.428, peak_memory=7.917 GB, invar_size=5.320 GB, outvar_size=2.597 GB, temp_buffer_size=2.597 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=6.001, peak_memory=14.503 GB, invar_size=9.595 GB, outvar_size=4.763 GB, temp_buffer_size=4.909 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 178.29 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=1.956 GB, invar_size=1.260 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.297, peak_memory=1.647 GB, invar_size=0.710 GB, outvar_size=0.156 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.097, peak_memory=2.278 GB, invar_size=1.419 GB, outvar_size=0.078 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.108, peak_memory=2.233 GB, invar_size=1.296 GB, outvar_size=0.078 GB, temp_buffer_size=0.859 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.278, peak_memory=1.462 GB, invar_size=0.689 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=1.956 GB, invar_size=1.260 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=1.907 GB, invar_size=1.211 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=1.907 GB, invar_size=1.211 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.270, peak_memory=1.477 GB, invar_size=0.664 GB, outvar_size=0.156 GB, temp_buffer_size=0.656 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.278, peak_memory=1.462 GB, invar_size=0.689 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=1.956 GB, invar_size=1.260 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=1.956 GB, invar_size=1.260 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=1.907 GB, invar_size=1.211 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.262, peak_memory=1.438 GB, invar_size=0.664 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=1.907 GB, invar_size=1.211 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=1.907 GB, invar_size=1.211 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.644, peak_memory=9.947 GB, invar_size=1.456 GB, outvar_size=0.689 GB, temp_buffer_size=8.413 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.262, peak_memory=1.438 GB, invar_size=0.664 GB, outvar_size=0.117 GB, temp_buffer_size=0.656 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.649, peak_memory=10.849 GB, invar_size=1.576 GB, outvar_size=0.710 GB, temp_buffer_size=9.273 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.284, peak_memory=10.446 GB, invar_size=2.916 GB, outvar_size=1.419 GB, temp_buffer_size=7.530 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=1.907 GB, invar_size=1.211 GB, outvar_size=0.078 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.254, peak_memory=9.164 GB, invar_size=2.462 GB, outvar_size=1.211 GB, temp_buffer_size=6.663 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.254, peak_memory=9.164 GB, invar_size=2.462 GB, outvar_size=1.211 GB, temp_buffer_size=6.663 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.621, peak_memory=9.888 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=8.403 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=10.379 GB, invar_size=2.560 GB, outvar_size=1.260 GB, temp_buffer_size=7.780 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.135, peak_memory=1.106 GB, invar_size=0.371 GB, outvar_size=0.078 GB, temp_buffer_size=0.656 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=10.418 GB, invar_size=2.599 GB, outvar_size=1.260 GB, temp_buffer_size=7.780 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=10.339 GB, invar_size=2.560 GB, outvar_size=1.260 GB, temp_buffer_size=7.741 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.297, peak_memory=10.248 GB, invar_size=2.670 GB, outvar_size=1.296 GB, temp_buffer_size=7.579 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.282 GB, invar_size=0.625 GB, outvar_size=0.039 GB, temp_buffer_size=0.617 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=10.418 GB, invar_size=2.599 GB, outvar_size=1.260 GB, temp_buffer_size=7.780 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.631, peak_memory=11.011 GB, invar_size=1.456 GB, outvar_size=0.689 GB, temp_buffer_size=9.477 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.609, peak_memory=9.729 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=8.244 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=9.084 GB, invar_size=2.462 GB, outvar_size=1.211 GB, temp_buffer_size=6.583 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=9.084 GB, invar_size=2.462 GB, outvar_size=1.211 GB, temp_buffer_size=6.583 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.254, peak_memory=9.085 GB, invar_size=2.462 GB, outvar_size=1.211 GB, temp_buffer_size=6.583 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.621, peak_memory=9.809 GB, invar_size=1.407 GB, outvar_size=0.664 GB, temp_buffer_size=8.324 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.254, peak_memory=9.085 GB, invar_size=2.462 GB, outvar_size=1.211 GB, temp_buffer_size=6.583 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.293, peak_memory=9.749 GB, invar_size=2.838 GB, outvar_size=1.419 GB, temp_buffer_size=6.872 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.662, peak_memory=9.820 GB, invar_size=1.537 GB, outvar_size=0.768 GB, temp_buffer_size=8.206 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.306, peak_memory=9.544 GB, invar_size=2.594 GB, outvar_size=1.297 GB, temp_buffer_size=6.911 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 38.88 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=2.026 GB, invar_size=0.713 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=2.026 GB, invar_size=0.713 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.110, peak_memory=2.489 GB, invar_size=0.833 GB, outvar_size=0.078 GB, temp_buffer_size=1.578 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.110, peak_memory=2.489 GB, invar_size=0.833 GB, outvar_size=0.078 GB, temp_buffer_size=1.578 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=14.656 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.249 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=14.656 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.249 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=14.810 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.403 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.258, peak_memory=16.986 GB, invar_size=1.426 GB, outvar_size=0.713 GB, temp_buffer_size=15.481 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.258, peak_memory=16.986 GB, invar_size=1.426 GB, outvar_size=0.713 GB, temp_buffer_size=15.481 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=14.810 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.403 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.236, peak_memory=14.495 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.088 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.293, peak_memory=16.725 GB, invar_size=1.744 GB, outvar_size=0.833 GB, temp_buffer_size=14.981 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.293, peak_memory=16.725 GB, invar_size=1.744 GB, outvar_size=0.833 GB, temp_buffer_size=14.981 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.236, peak_memory=14.495 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.088 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=14.576 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.169 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=14.576 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.169 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=14.422 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.015 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=14.422 GB, invar_size=1.329 GB, outvar_size=0.664 GB, temp_buffer_size=13.015 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.312, peak_memory=15.488 GB, invar_size=1.666 GB, outvar_size=0.872 GB, temp_buffer_size=13.744 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.312, peak_memory=15.488 GB, invar_size=1.666 GB, outvar_size=0.872 GB, temp_buffer_size=13.744 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 20.40 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO comm 0x4f1d5d0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO comm 0x429bd50 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO comm 0x7690050 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO comm 0xa31fce0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO comm 0xa6e5230 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO comm 0x4d4c510 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO comm 0x6f4b9d0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO comm 0xa67c0f0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [0] NCCL INFO comm 0x54d0390 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO comm 0xad956a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034458 [1] NCCL INFO comm 0x8649210 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO comm 0xad2c560 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 293.22 s
compilation time breakdown: {'stage-construction': '242.06', 'stage-construction-dp': '1.40', 'stage-construction-compilation': '160.77', 'stage-construction-profiling': '39.10'}
 - Compile (worker): 6.93 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148345 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519688 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404891 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4034458)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4034458)[0m 
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO comm 0x7fd432dffca0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034612 [1] NCCL INFO comm 0x7fd42ca760b0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4034458)[0m gpu2:4034458:4034610 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO comm 0x7f2a2600ad60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404955 [1] NCCL INFO comm 0x7f2a29c11290 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO comm 0x7f38c85645a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519852 [1] NCCL INFO comm 0x7f38db093540 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1519688, ip=192.168.0.18)[0m gpu3:1519688:1519850 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO comm 0x7f57cef0dfc0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148409 [1] NCCL INFO comm 0x7f43895a5bb0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=404891, ip=192.168.0.26)[0m gpu11:404891:404953 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2148345, ip=192.168.0.33)[0m gpu18:2148345:2148407 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 116.93 s

[23.26140832901001, 14.510406255722046, 14.21257209777832, 14.230054140090942, 14.324399709701538, 14.2699134349823, 14.323755502700806]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 75.134 s.
 - Average e2e iteration time: 15.027000427246094 s.
 - Total local training time: 71.36100006103516 s.
 - Average local iteration time: 14.272000312805176 s.
 - Max allocated memory among devices: 15.33 GB.
 - Compilation times:  {'stage-construction': 242.0577187538147, 'stage-construction-dp': 1.3958909511566162, 'stage-construction-compilation': 160.76609420776367, 'stage-construction-profiling': 39.09984517097473}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 14.272139549255371
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_2.6B_256.pkl`...

------------------------------------------------------------------
- (3/3) Profiling bert_2.6B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_2.6B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 4
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7fbad7e246d0>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 3, 0), 0] = ModuleProfileResult(compute_cost=0.156, peak_memory=4.926 GB, invar_size=4.399 GB, outvar_size=0.137 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 0] = ModuleProfileResult(compute_cost=0.471, peak_memory=2.844 GB, invar_size=2.200 GB, outvar_size=0.254 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 0] = ModuleProfileResult(compute_cost=0.156, peak_memory=4.926 GB, invar_size=4.399 GB, outvar_size=0.137 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 7, 3, 0), 1] = ModuleProfileResult(compute_cost=4.614, peak_memory=15.715 GB, invar_size=10.522 GB, outvar_size=5.193 GB, temp_buffer_size=5.193 GB, available_memory=35.242 GB)
result[(0, 7, 3, 2), 1] = ModuleProfileResult(compute_cost=4.613, peak_memory=15.715 GB, invar_size=10.522 GB, outvar_size=5.193 GB, temp_buffer_size=5.193 GB, available_memory=35.242 GB)
result[(0, 7, 3, 1), 1] = ModuleProfileResult(compute_cost=3.063, peak_memory=9.670 GB, invar_size=5.447 GB, outvar_size=2.597 GB, temp_buffer_size=4.222 GB, available_memory=35.242 GB)
Profiling for submesh 3 (4, 2) takes 188.05 seconds
--------------------------------------------------
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.166, peak_memory=2.690 GB, invar_size=1.299 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.550, peak_memory=2.314 GB, invar_size=0.767 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.166, peak_memory=2.690 GB, invar_size=1.299 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=2.641 GB, invar_size=1.251 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.166, peak_memory=2.690 GB, invar_size=1.299 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=2.641 GB, invar_size=1.251 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.550, peak_memory=2.314 GB, invar_size=0.767 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.536, peak_memory=2.368 GB, invar_size=0.743 GB, outvar_size=0.312 GB, temp_buffer_size=1.313 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.189, peak_memory=3.138 GB, invar_size=1.419 GB, outvar_size=0.156 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.590, peak_memory=2.585 GB, invar_size=0.710 GB, outvar_size=0.312 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.189, peak_memory=3.138 GB, invar_size=1.419 GB, outvar_size=0.156 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.166, peak_memory=2.690 GB, invar_size=1.299 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=2.641 GB, invar_size=1.251 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.519, peak_memory=2.290 GB, invar_size=0.743 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=2.641 GB, invar_size=1.251 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=2.641 GB, invar_size=1.251 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.519, peak_memory=2.290 GB, invar_size=0.743 GB, outvar_size=0.234 GB, temp_buffer_size=1.313 GB, available_memory=35.242 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=1.274, peak_memory=18.663 GB, invar_size=1.690 GB, outvar_size=0.767 GB, temp_buffer_size=16.817 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=2.641 GB, invar_size=1.251 GB, outvar_size=0.156 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=1.285, peak_memory=20.264 GB, invar_size=1.732 GB, outvar_size=0.710 GB, temp_buffer_size=18.532 GB, available_memory=35.242 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.486, peak_memory=15.983 GB, invar_size=2.579 GB, outvar_size=1.251 GB, temp_buffer_size=13.326 GB, available_memory=35.242 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=1.229, peak_memory=18.591 GB, invar_size=1.641 GB, outvar_size=0.743 GB, temp_buffer_size=16.794 GB, available_memory=35.242 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.505, peak_memory=18.315 GB, invar_size=2.677 GB, outvar_size=1.299 GB, temp_buffer_size=15.560 GB, available_memory=35.242 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.507, peak_memory=18.236 GB, invar_size=2.677 GB, outvar_size=1.299 GB, temp_buffer_size=15.481 GB, available_memory=35.242 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.544, peak_memory=18.054 GB, invar_size=2.994 GB, outvar_size=1.419 GB, temp_buffer_size=15.060 GB, available_memory=35.242 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.507, peak_memory=18.393 GB, invar_size=2.755 GB, outvar_size=1.299 GB, temp_buffer_size=15.560 GB, available_memory=35.242 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.544, peak_memory=18.054 GB, invar_size=2.994 GB, outvar_size=1.419 GB, temp_buffer_size=15.060 GB, available_memory=35.242 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.486, peak_memory=15.983 GB, invar_size=2.579 GB, outvar_size=1.251 GB, temp_buffer_size=13.326 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.268, peak_memory=1.918 GB, invar_size=0.450 GB, outvar_size=0.156 GB, temp_buffer_size=1.313 GB, available_memory=35.242 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=1.249, peak_memory=20.791 GB, invar_size=1.690 GB, outvar_size=0.767 GB, temp_buffer_size=18.944 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.977 GB, invar_size=0.664 GB, outvar_size=0.078 GB, temp_buffer_size=1.234 GB, available_memory=35.242 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=1.204, peak_memory=18.274 GB, invar_size=1.641 GB, outvar_size=0.743 GB, temp_buffer_size=16.476 GB, available_memory=35.242 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.505, peak_memory=18.393 GB, invar_size=2.755 GB, outvar_size=1.299 GB, temp_buffer_size=15.560 GB, available_memory=35.242 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.484, peak_memory=15.824 GB, invar_size=2.579 GB, outvar_size=1.251 GB, temp_buffer_size=13.166 GB, available_memory=35.242 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.486, peak_memory=15.824 GB, invar_size=2.579 GB, outvar_size=1.251 GB, temp_buffer_size=13.167 GB, available_memory=35.242 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.484, peak_memory=15.824 GB, invar_size=2.579 GB, outvar_size=1.251 GB, temp_buffer_size=13.166 GB, available_memory=35.242 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=1.229, peak_memory=18.434 GB, invar_size=1.641 GB, outvar_size=0.743 GB, temp_buffer_size=16.636 GB, available_memory=35.242 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.486, peak_memory=15.824 GB, invar_size=2.579 GB, outvar_size=1.251 GB, temp_buffer_size=13.167 GB, available_memory=35.242 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.562, peak_memory=16.739 GB, invar_size=2.916 GB, outvar_size=1.458 GB, temp_buffer_size=13.744 GB, available_memory=35.242 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=1.311, peak_memory=18.251 GB, invar_size=1.693 GB, outvar_size=0.846 GB, temp_buffer_size=16.402 GB, available_memory=35.242 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.590, peak_memory=16.573 GB, invar_size=2.672 GB, outvar_size=1.336 GB, temp_buffer_size=13.823 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 40.49 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.173, peak_memory=3.416 GB, invar_size=0.791 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.173, peak_memory=3.416 GB, invar_size=0.791 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.220, peak_memory=4.146 GB, invar_size=0.833 GB, outvar_size=0.156 GB, temp_buffer_size=3.156 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.220, peak_memory=4.146 GB, invar_size=0.833 GB, outvar_size=0.156 GB, temp_buffer_size=3.156 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.515, peak_memory=32.702 GB, invar_size=1.583 GB, outvar_size=0.791 GB, temp_buffer_size=30.963 GB, available_memory=35.242 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.473, peak_memory=28.139 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.497 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.515, peak_memory=32.702 GB, invar_size=1.583 GB, outvar_size=0.791 GB, temp_buffer_size=30.963 GB, available_memory=35.242 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.473, peak_memory=28.139 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.497 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=35.242 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.473, peak_memory=28.448 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.807 GB, available_memory=35.242 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.473, peak_memory=28.448 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.807 GB, available_memory=35.242 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.585, peak_memory=31.785 GB, invar_size=1.822 GB, outvar_size=0.833 GB, temp_buffer_size=29.963 GB, available_memory=35.242 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.585, peak_memory=31.785 GB, invar_size=1.822 GB, outvar_size=0.833 GB, temp_buffer_size=29.963 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.368 GB, invar_size=0.743 GB, outvar_size=0.156 GB, temp_buffer_size=2.469 GB, available_memory=35.242 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.470, peak_memory=27.817 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.176 GB, available_memory=35.242 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.470, peak_memory=27.817 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.176 GB, available_memory=35.242 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.473, peak_memory=27.979 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.338 GB, available_memory=35.242 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.473, peak_memory=27.979 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.338 GB, available_memory=35.242 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.473, peak_memory=27.670 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.029 GB, available_memory=35.242 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.473, peak_memory=27.670 GB, invar_size=1.485 GB, outvar_size=0.742 GB, temp_buffer_size=26.029 GB, available_memory=35.242 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.622, peak_memory=29.389 GB, invar_size=1.744 GB, outvar_size=0.950 GB, temp_buffer_size=27.489 GB, available_memory=35.242 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.622, peak_memory=29.389 GB, invar_size=1.744 GB, outvar_size=0.950 GB, temp_buffer_size=27.489 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 21.14 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 5, 2, 0) has been pruned...
[TMP] Stage (1, 5, 2, 1) has been pruned...
[TMP] Stage (1, 5, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 6, 2, 0) has been pruned...
[TMP] Stage (2, 6, 2, 1) has been pruned...
[TMP] Stage (2, 6, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO comm 0x3f422a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO comm 0x4825940 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO comm 0x7eb1470 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO comm 0x686d820 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4049544)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO comm 0x549a3f0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO comm 0xb7d0d00 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO comm 0x77abc20 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO comm 0xb8f7db0 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO comm 0xcb98750 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [0] NCCL INFO comm 0x4cdffa0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO Channel 00 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 00 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Channel 01 : 0[98000] -> 1[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO Channel 01 : 1[98000] -> 0[98000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522725 [1] NCCL INFO comm 0xa0e2e70 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO comm 0xca42e70 rank 0 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
 - Compile (driver): 307.60 s
compilation time breakdown: {'stage-construction': '254.22', 'stage-construction-dp': '1.40', 'stage-construction-compilation': '171.72', 'stage-construction-profiling': '38.35'}
 - Compile (worker): 6.93 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409732 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049544 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154436 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4049544)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522793 [1] NCCL INFO comm 0x7f2f3424e7c0 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO comm 0x7f2f3bf71fc0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1522725, ip=192.168.0.18)[0m gpu3:1522725:1522791 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.32<0>
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m 
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO comm 0x7ef79a6f7f60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154584 [1] NCCL INFO comm 0x7ef7a3b6f930 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4049544)[0m 
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO comm 0x7f3db74c9940 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049615 [1] NCCL INFO comm 0x7f3dadf94800 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4049544)[0m gpu2:4049544:4049613 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.25<0>
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m 
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Channel 00 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Channel 01 : 0[31000] -> 1[98000] via direct shared memory
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO Channel 00 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO Channel 01 : 1[98000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409880 [1] NCCL INFO comm 0x7f6607a8a040 rank 1 nranks 2 cudaDev 1 busId 98000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO comm 0x7f65f60bfdf0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2154436, ip=192.168.0.33)[0m gpu18:2154436:2154582 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=409732, ip=192.168.0.26)[0m gpu11:409732:409878 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 226.18 s

[38.63629651069641, 29.293193101882935, 29.465897798538208, 29.325095176696777, 29.160481929779053, 29.23638391494751, 29.389742374420166]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 153.359 s.
 - Average e2e iteration time: 30.672000885009766 s.
 - Total local training time: 146.5780029296875 s.
 - Average local iteration time: 29.316001892089844 s.
 - Max allocated memory among devices: 24.479 GB.
 - Compilation times:  {'stage-construction': 254.2202489376068, 'stage-construction-dp': 1.4026596546173096, 'stage-construction-compilation': 171.7241129875183, 'stage-construction-profiling': 38.35187530517578}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `4_a40_4_n_2_d`: 29.315521240234375
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_2.6B_512.pkl`...
