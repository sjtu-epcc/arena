
------------------------------------------------------------------
- (1/3) Profiling moe_2.4B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_2.4B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7fe3960747f0>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.110 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.110 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.094 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.018, peak_memory=1.251 GB, invar_size=0.594 GB, outvar_size=0.156 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=1.243 GB, invar_size=0.711 GB, outvar_size=0.031 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=0.985 GB, invar_size=0.297 GB, outvar_size=0.172 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=0.860 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.020, peak_memory=0.993 GB, invar_size=0.461 GB, outvar_size=0.031 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=0.891 GB, invar_size=0.328 GB, outvar_size=0.031 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.022, peak_memory=1.001 GB, invar_size=0.344 GB, outvar_size=0.156 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=0.989 GB, invar_size=0.442 GB, outvar_size=0.047 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=2.206 GB, invar_size=0.641 GB, outvar_size=0.305 GB, temp_buffer_size=1.534 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.642 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.626 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.470 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.657 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.501 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.069, peak_memory=2.173 GB, invar_size=0.641 GB, outvar_size=0.289 GB, temp_buffer_size=1.517 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.082, peak_memory=2.472 GB, invar_size=0.782 GB, outvar_size=0.297 GB, temp_buffer_size=1.690 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.054, peak_memory=2.893 GB, invar_size=1.345 GB, outvar_size=0.594 GB, temp_buffer_size=1.548 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.047, peak_memory=2.157 GB, invar_size=0.641 GB, outvar_size=0.313 GB, temp_buffer_size=1.501 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.055, peak_memory=2.424 GB, invar_size=0.845 GB, outvar_size=0.344 GB, temp_buffer_size=1.580 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=2.238 GB, invar_size=0.641 GB, outvar_size=0.305 GB, temp_buffer_size=1.566 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=0.860 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=2.605 GB, invar_size=0.789 GB, outvar_size=0.441 GB, temp_buffer_size=1.660 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.173 GB, invar_size=0.672 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.094 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.054, peak_memory=2.955 GB, invar_size=1.313 GB, outvar_size=0.711 GB, temp_buffer_size=1.501 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.110 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=0.891 GB, invar_size=0.328 GB, outvar_size=0.031 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.054, peak_memory=2.502 GB, invar_size=0.828 GB, outvar_size=0.461 GB, temp_buffer_size=1.533 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=0.860 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.094 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.047, peak_memory=2.142 GB, invar_size=0.641 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=0.860 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.626 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.470 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=2.206 GB, invar_size=0.641 GB, outvar_size=0.305 GB, temp_buffer_size=1.534 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.069, peak_memory=2.173 GB, invar_size=0.641 GB, outvar_size=0.289 GB, temp_buffer_size=1.517 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.110 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=0.891 GB, invar_size=0.328 GB, outvar_size=0.031 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.642 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.047, peak_memory=2.142 GB, invar_size=0.641 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.094 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.173 GB, invar_size=0.672 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=0.891 GB, invar_size=0.328 GB, outvar_size=0.031 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.110 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.626 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.470 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.069, peak_memory=2.173 GB, invar_size=0.641 GB, outvar_size=0.289 GB, temp_buffer_size=1.517 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=2.206 GB, invar_size=0.641 GB, outvar_size=0.305 GB, temp_buffer_size=1.534 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.094 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.047, peak_memory=2.142 GB, invar_size=0.641 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.642 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.626 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.470 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.173 GB, invar_size=0.672 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=2.206 GB, invar_size=0.641 GB, outvar_size=0.305 GB, temp_buffer_size=1.534 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=0.860 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.069, peak_memory=2.173 GB, invar_size=0.641 GB, outvar_size=0.289 GB, temp_buffer_size=1.517 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.110 GB, invar_size=0.563 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=0.891 GB, invar_size=0.328 GB, outvar_size=0.031 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.008, peak_memory=1.047 GB, invar_size=0.516 GB, outvar_size=0.016 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.010, peak_memory=0.829 GB, invar_size=0.281 GB, outvar_size=0.016 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.642 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.017, peak_memory=0.860 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=0.516 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.173 GB, invar_size=0.672 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.883 GB, invar_size=0.305 GB, outvar_size=0.047 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.010, peak_memory=0.829 GB, invar_size=0.281 GB, outvar_size=0.016 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.047, peak_memory=2.142 GB, invar_size=0.641 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.626 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.470 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.069, peak_memory=2.173 GB, invar_size=0.641 GB, outvar_size=0.289 GB, temp_buffer_size=1.517 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.074, peak_memory=2.206 GB, invar_size=0.641 GB, outvar_size=0.305 GB, temp_buffer_size=1.534 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=3.084 GB, invar_size=1.232 GB, outvar_size=0.616 GB, temp_buffer_size=1.837 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.642 GB, invar_size=1.141 GB, outvar_size=0.563 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.047, peak_memory=2.142 GB, invar_size=0.641 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.085, peak_memory=2.610 GB, invar_size=0.647 GB, outvar_size=0.316 GB, temp_buffer_size=1.947 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.173 GB, invar_size=0.672 GB, outvar_size=0.313 GB, temp_buffer_size=1.485 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.066, peak_memory=2.554 GB, invar_size=0.686 GB, outvar_size=0.335 GB, temp_buffer_size=1.853 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 24.52 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.165 GB, invar_size=0.071 GB, outvar_size=0.031 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=1.165 GB, invar_size=0.071 GB, outvar_size=0.031 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=2.495 GB, invar_size=0.173 GB, outvar_size=0.071 GB, temp_buffer_size=2.322 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.031, peak_memory=2.495 GB, invar_size=0.173 GB, outvar_size=0.071 GB, temp_buffer_size=2.322 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=3.937 GB, invar_size=0.232 GB, outvar_size=0.131 GB, temp_buffer_size=3.674 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=3.937 GB, invar_size=0.232 GB, outvar_size=0.131 GB, temp_buffer_size=3.674 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.045, peak_memory=3.033 GB, invar_size=1.063 GB, outvar_size=0.531 GB, temp_buffer_size=1.939 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 9.39 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 2, 2, 0) has been pruned...
[TMP] Stage (0, 2, 2, 1) has been pruned...
[TMP] Stage (0, 2, 2, 2) has been pruned...
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 3, 2, 0) has been pruned...
[TMP] Stage (1, 3, 2, 1) has been pruned...
[TMP] Stage (1, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 6, 3, 0) has been pruned...
[TMP] Stage (1, 6, 3, 1) has been pruned...
[TMP] Stage (1, 6, 3, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 4, 2, 0) has been pruned...
[TMP] Stage (2, 4, 2, 1) has been pruned...
[TMP] Stage (2, 4, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (2, 11, 3, 0) has been pruned...
[TMP] Stage (2, 11, 3, 1) has been pruned...
[TMP] Stage (2, 11, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (3, 12, 3, 0) has been pruned...
[TMP] Stage (3, 12, 3, 1) has been pruned...
[TMP] Stage (3, 12, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 8, 2, 0) has been pruned...
[TMP] Stage (4, 8, 2, 1) has been pruned...
[TMP] Stage (4, 8, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (4, 13, 3, 0) has been pruned...
[TMP] Stage (4, 13, 3, 1) has been pruned...
[TMP] Stage (4, 13, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 9, 2, 0) has been pruned...
[TMP] Stage (5, 9, 2, 1) has been pruned...
[TMP] Stage (5, 9, 2, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 10, 2, 0) has been pruned...
[TMP] Stage (6, 10, 2, 1) has been pruned...
[TMP] Stage (6, 10, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO comm 0x4eb4750 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO comm 0x3aba580 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO comm 0xa2b79c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO comm 0x5b02fa0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO comm 0xb17f150 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO comm 0x52b7cd0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO comm 0xb1e8290 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO comm 0x8655e00 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO comm 0xb6ad840 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO comm 0x526a030 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO comm 0x7e0e510 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO comm 0xb644700 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4030789)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO comm 0xb102370 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO comm 0x46e4da0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO comm 0xb228a80 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO comm 0x67337c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO comm 0x3c34950 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO comm 0xa4c2930 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO comm 0x5e34230 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO comm 0xa720cf0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO comm 0x9c84a00 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO comm 0x46e6540 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO comm 0x672dea0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO comm 0x9c1b8c0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [0] NCCL INFO comm 0x3a490e0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO comm 0xbc52a90 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246409 [1] NCCL INFO comm 0x5a756d0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO comm 0xa5716c0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
 - Compile (driver): 72.98 s
compilation time breakdown: {'stage-construction': '37.36', 'stage-construction-dp': '1.22', 'stage-construction-compilation': '8.57', 'stage-construction-profiling': '9.91'}
 - Compile (worker): 5.23 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699276 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079821 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251461 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030789 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936518 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2381887 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332765 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO comm 0x7f31977697d0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246557 [1] NCCL INFO comm 0x7f319a29e3d0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3246409, ip=192.168.0.58)[0m gpu28:3246409:3246555 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332871 [1] NCCL INFO comm 0x7fcfc7c6c750 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO comm 0x7fcfc0010ec0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382035 [1] NCCL INFO comm 0x7f7cf346b250 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO comm 0x7f7ce4cced60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936623 [1] NCCL INFO comm 0x7ef56fc03650 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO comm 0x7ef56ae984c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4030789)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4030789)[0m 
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030910 [1] NCCL INFO comm 0x7f1827f20890 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO comm 0x7f1830896680 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO comm 0x7f7104e18b20 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251526 [1] NCCL INFO comm 0x7f70f59b1550 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079889 [1] NCCL INFO comm 0x7fddda48bdf0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO comm 0x7fddcf4dd940 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO comm 0x7f818a984d90 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699381 [1] NCCL INFO comm 0x7f8197105b70 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2332765, ip=192.168.0.55)[0m gpu25:2332765:2332869 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2381887, ip=192.168.0.57)[0m gpu27:2381887:2382033 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1936518, ip=192.168.0.56)[0m gpu26:1936518:1936621 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=4030789)[0m gpu37:4030789:4030908 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3251461, ip=192.168.0.59)[0m gpu29:3251461:3251524 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3079821, ip=192.168.0.72)[0m gpu42:3079821:3079887 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2699276, ip=192.168.0.60)[0m gpu30:2699276:2699379 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 45.66 s

[14.398433923721313, 4.770254850387573, 4.783102989196777, 4.7895402908325195, 4.745432376861572, 4.805174350738525, 4.82927393913269]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 25.111 s.
 - Average e2e iteration time: 5.022000312805176 s.
 - Total local training time: 23.953001022338867 s.
 - Average local iteration time: 4.7910003662109375 s.
 - Max allocated memory among devices: 5.886 GB.
 - Compilation times:  {'stage-construction': 37.356658697128296, 'stage-construction-dp': 1.2180466651916504, 'stage-construction-compilation': 8.565504312515259, 'stage-construction-profiling': 9.906390905380249}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 4.7905049324035645
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_2.4B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling moe_2.4B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_2.4B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f3814ccc640>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.673 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.035, peak_memory=1.907 GB, invar_size=0.594 GB, outvar_size=0.312 GB, temp_buffer_size=1.000 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.673 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.485 GB, invar_size=0.359 GB, outvar_size=0.062 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.066, peak_memory=1.674 GB, invar_size=0.298 GB, outvar_size=0.344 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.000 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=1.915 GB, invar_size=0.852 GB, outvar_size=0.062 GB, temp_buffer_size=1.000 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=1.423 GB, invar_size=0.328 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.038, peak_memory=1.789 GB, invar_size=0.602 GB, outvar_size=0.062 GB, temp_buffer_size=1.125 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.041, peak_memory=1.657 GB, invar_size=0.344 GB, outvar_size=0.312 GB, temp_buffer_size=1.000 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.693 GB, invar_size=0.598 GB, outvar_size=0.094 GB, temp_buffer_size=1.001 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.144, peak_memory=3.864 GB, invar_size=0.735 GB, outvar_size=0.336 GB, temp_buffer_size=3.067 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.189 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.135, peak_memory=3.799 GB, invar_size=0.735 GB, outvar_size=0.305 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.158, peak_memory=4.349 GB, invar_size=0.970 GB, outvar_size=0.297 GB, temp_buffer_size=3.379 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.221 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=3.002 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.598 GB, invar_size=1.501 GB, outvar_size=0.594 GB, temp_buffer_size=3.097 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.158 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.939 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.144, peak_memory=3.927 GB, invar_size=0.735 GB, outvar_size=0.336 GB, temp_buffer_size=3.130 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.106, peak_memory=4.160 GB, invar_size=1.001 GB, outvar_size=0.344 GB, temp_buffer_size=3.159 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.088, peak_memory=3.752 GB, invar_size=0.750 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=1.423 GB, invar_size=0.328 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=3.721 GB, invar_size=0.688 GB, outvar_size=0.328 GB, temp_buffer_size=3.002 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.181, peak_memory=4.639 GB, invar_size=1.008 GB, outvar_size=0.598 GB, temp_buffer_size=3.318 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.000 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.769 GB, invar_size=1.485 GB, outvar_size=0.852 GB, temp_buffer_size=3.003 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.673 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.485 GB, invar_size=0.359 GB, outvar_size=0.062 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.102, peak_memory=4.363 GB, invar_size=1.016 GB, outvar_size=0.602 GB, temp_buffer_size=3.066 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=1.423 GB, invar_size=0.328 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.000 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=3.689 GB, invar_size=0.688 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.158 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.939 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=1.423 GB, invar_size=0.328 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.135, peak_memory=3.799 GB, invar_size=0.735 GB, outvar_size=0.305 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.673 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.485 GB, invar_size=0.359 GB, outvar_size=0.062 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.189 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.144, peak_memory=3.864 GB, invar_size=0.735 GB, outvar_size=0.336 GB, temp_buffer_size=3.067 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.000 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.088, peak_memory=3.752 GB, invar_size=0.750 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=3.689 GB, invar_size=0.688 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.485 GB, invar_size=0.359 GB, outvar_size=0.062 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.158 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.939 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.673 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.135, peak_memory=3.799 GB, invar_size=0.735 GB, outvar_size=0.305 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.144, peak_memory=3.864 GB, invar_size=0.735 GB, outvar_size=0.336 GB, temp_buffer_size=3.067 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.189 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=3.689 GB, invar_size=0.688 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.088, peak_memory=3.752 GB, invar_size=0.750 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.158 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.939 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=1.423 GB, invar_size=0.328 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.641 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.000 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=1.485 GB, invar_size=0.359 GB, outvar_size=0.062 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.144, peak_memory=3.864 GB, invar_size=0.735 GB, outvar_size=0.336 GB, temp_buffer_size=3.067 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.135, peak_memory=3.799 GB, invar_size=0.735 GB, outvar_size=0.305 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.027, peak_memory=1.673 GB, invar_size=0.578 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=1.594 GB, invar_size=0.531 GB, outvar_size=0.031 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.189 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=1.423 GB, invar_size=0.328 GB, outvar_size=0.062 GB, temp_buffer_size=1.032 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=1.493 GB, invar_size=0.336 GB, outvar_size=0.094 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.088, peak_memory=3.752 GB, invar_size=0.750 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.019, peak_memory=1.407 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.135, peak_memory=3.799 GB, invar_size=0.735 GB, outvar_size=0.305 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=3.689 GB, invar_size=0.688 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.019, peak_memory=1.407 GB, invar_size=0.313 GB, outvar_size=0.031 GB, temp_buffer_size=1.063 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.158 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.939 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.144, peak_memory=3.864 GB, invar_size=0.735 GB, outvar_size=0.336 GB, temp_buffer_size=3.067 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.083, peak_memory=4.189 GB, invar_size=1.188 GB, outvar_size=0.578 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.111, peak_memory=4.968 GB, invar_size=1.263 GB, outvar_size=0.631 GB, temp_buffer_size=3.674 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.088, peak_memory=3.752 GB, invar_size=0.750 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.091, peak_memory=3.689 GB, invar_size=0.688 GB, outvar_size=0.328 GB, temp_buffer_size=2.970 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.166, peak_memory=4.619 GB, invar_size=0.694 GB, outvar_size=0.331 GB, temp_buffer_size=3.894 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.116, peak_memory=4.499 GB, invar_size=0.794 GB, outvar_size=0.381 GB, temp_buffer_size=3.674 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 24.53 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=2.260 GB, invar_size=0.071 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=2.260 GB, invar_size=0.071 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.061, peak_memory=4.849 GB, invar_size=0.204 GB, outvar_size=0.071 GB, temp_buffer_size=4.644 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.061, peak_memory=4.849 GB, invar_size=0.204 GB, outvar_size=0.071 GB, temp_buffer_size=4.644 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.120, peak_memory=7.673 GB, invar_size=0.263 GB, outvar_size=0.163 GB, temp_buffer_size=7.347 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.120, peak_memory=7.673 GB, invar_size=0.263 GB, outvar_size=0.163 GB, temp_buffer_size=7.347 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.086, peak_memory=5.066 GB, invar_size=1.125 GB, outvar_size=0.563 GB, temp_buffer_size=3.878 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 9.43 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 2, 2, 0) has been pruned...
[TMP] Stage (0, 2, 2, 1) has been pruned...
[TMP] Stage (0, 2, 2, 2) has been pruned...
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 3, 2, 0) has been pruned...
[TMP] Stage (1, 3, 2, 1) has been pruned...
[TMP] Stage (1, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 6, 3, 0) has been pruned...
[TMP] Stage (1, 6, 3, 1) has been pruned...
[TMP] Stage (1, 6, 3, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 4, 2, 0) has been pruned...
[TMP] Stage (2, 4, 2, 1) has been pruned...
[TMP] Stage (2, 4, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (2, 11, 3, 0) has been pruned...
[TMP] Stage (2, 11, 3, 1) has been pruned...
[TMP] Stage (2, 11, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (3, 12, 3, 0) has been pruned...
[TMP] Stage (3, 12, 3, 1) has been pruned...
[TMP] Stage (3, 12, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 8, 2, 0) has been pruned...
[TMP] Stage (4, 8, 2, 1) has been pruned...
[TMP] Stage (4, 8, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (4, 13, 3, 0) has been pruned...
[TMP] Stage (4, 13, 3, 1) has been pruned...
[TMP] Stage (4, 13, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 9, 2, 0) has been pruned...
[TMP] Stage (5, 9, 2, 1) has been pruned...
[TMP] Stage (5, 9, 2, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 10, 2, 0) has been pruned...
[TMP] Stage (6, 10, 2, 1) has been pruned...
[TMP] Stage (6, 10, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO comm 0x3a83900 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO comm 0x40ff600 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO comm 0x6628650 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO comm 0x614e880 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4038093)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO comm 0x4828040 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO comm 0x990ae40 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO comm 0x9a317d0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO comm 0x6870dc0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO comm 0x4b279b0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO comm 0xa600e00 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO comm 0xa85e1b0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO comm 0x7ec52c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO comm 0xaf1d8f0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO comm 0x4e8cd90 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO comm 0xaeb47b0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO comm 0x822a730 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO comm 0x3703ff0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO comm 0xb283530 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO comm 0x8b062c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO comm 0xb21a3f0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO comm 0x99cd780 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO comm 0x53009d0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO comm 0x869e340 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO comm 0x9a368c0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO comm 0xb6f6e90 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [0] NCCL INFO comm 0x3c116d0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO comm 0xb68dd50 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2335953 [1] NCCL INFO comm 0x5c3de00 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
 - Compile (driver): 72.73 s
compilation time breakdown: {'stage-construction': '37.40', 'stage-construction-dp': '1.21', 'stage-construction-compilation': '8.81', 'stage-construction-profiling': '9.96'}
 - Compile (worker): 5.30 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385202 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038093 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940215 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254868 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081841 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702159 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249847 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO comm 0x7efd7efca3e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336102 [1] NCCL INFO comm 0x7f088e8b2490 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2335953, ip=192.168.0.55)[0m gpu25:2335953:2336100 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249911 [1] NCCL INFO comm 0x7f81fac9ced0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO comm 0x7f8200ab9b30 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO comm 0x7fe049c62aa0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702319 [1] NCCL INFO comm 0x7fe04f44d0a0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO comm 0x7faa7ba7e780 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081993 [1] NCCL INFO comm 0x7faa7e6f3490 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO comm 0x7f1c8102efb0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254932 [1] NCCL INFO comm 0x7f1c74229570 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940278 [1] NCCL INFO comm 0x7fc24b1c5820 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO comm 0x7fc22d9b1550 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4038093)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4038093)[0m 
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038172 [1] NCCL INFO comm 0x7eec94595e20 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO comm 0x7eec9d6c71a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385349 [1] NCCL INFO comm 0x7f02b4e77ba0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO comm 0x7f02ab45f070 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3249847, ip=192.168.0.58)[0m gpu28:3249847:3249909 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2702159, ip=192.168.0.60)[0m gpu30:2702159:2702317 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3081841, ip=192.168.0.72)[0m gpu42:3081841:3081991 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3254868, ip=192.168.0.59)[0m gpu29:3254868:3254930 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1940215, ip=192.168.0.56)[0m gpu26:1940215:1940276 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=4038093)[0m gpu37:4038093:4038170 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2385202, ip=192.168.0.57)[0m gpu27:2385202:2385347 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 76.48 s

[18.015857934951782, 9.184807300567627, 9.225829362869263, 9.14868950843811, 9.124721050262451, 9.25605821609497, 9.178009271621704]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 47.684 s.
 - Average e2e iteration time: 9.53700065612793 s.
 - Total local training time: 45.93300247192383 s.
 - Average local iteration time: 9.187000274658203 s.
 - Max allocated memory among devices: 10.06 GB.
 - Compilation times:  {'stage-construction': 37.39815306663513, 'stage-construction-dp': 1.2097587585449219, 'stage-construction-compilation': 8.81283164024353, 'stage-construction-profiling': 9.962677955627441}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 9.186661720275879
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_2.4B_512.pkl`...

------------------------------------------------------------------
- (3/3) Profiling moe_2.4B with batch size: 1024...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_2.4B_1024.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f4d0daba910>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.798 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.798 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.058, peak_memory=2.674 GB, invar_size=0.422 GB, outvar_size=0.125 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.069, peak_memory=3.221 GB, invar_size=0.595 GB, outvar_size=0.625 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=3.259 GB, invar_size=1.133 GB, outvar_size=0.125 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.548 GB, invar_size=0.360 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.074, peak_memory=3.010 GB, invar_size=0.883 GB, outvar_size=0.125 GB, temp_buffer_size=2.002 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.164, peak_memory=3.100 GB, invar_size=0.910 GB, outvar_size=0.188 GB, temp_buffer_size=2.002 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.130, peak_memory=3.050 GB, invar_size=0.298 GB, outvar_size=0.688 GB, temp_buffer_size=2.064 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=2.971 GB, invar_size=0.345 GB, outvar_size=0.625 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.283, peak_memory=7.180 GB, invar_size=0.922 GB, outvar_size=0.398 GB, temp_buffer_size=6.133 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.285 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=7.051 GB, invar_size=0.922 GB, outvar_size=0.336 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.205, peak_memory=7.632 GB, invar_size=1.314 GB, outvar_size=0.344 GB, temp_buffer_size=6.318 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.348 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=6.004 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.222 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.878 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.311, peak_memory=8.103 GB, invar_size=1.345 GB, outvar_size=0.297 GB, temp_buffer_size=6.758 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.007 GB, invar_size=1.814 GB, outvar_size=0.594 GB, temp_buffer_size=6.193 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=6.910 GB, invar_size=0.906 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.548 GB, invar_size=0.360 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.283, peak_memory=7.306 GB, invar_size=0.922 GB, outvar_size=0.398 GB, temp_buffer_size=6.258 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.175, peak_memory=6.848 GB, invar_size=0.782 GB, outvar_size=0.359 GB, temp_buffer_size=6.004 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.355, peak_memory=8.706 GB, invar_size=1.446 GB, outvar_size=0.910 GB, temp_buffer_size=6.636 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.396 GB, invar_size=1.828 GB, outvar_size=1.133 GB, temp_buffer_size=6.006 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.798 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.198, peak_memory=8.086 GB, invar_size=1.391 GB, outvar_size=0.883 GB, temp_buffer_size=6.133 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.058, peak_memory=2.674 GB, invar_size=0.422 GB, outvar_size=0.125 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.548 GB, invar_size=0.360 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.175, peak_memory=6.785 GB, invar_size=0.782 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.222 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.878 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.798 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.283, peak_memory=7.180 GB, invar_size=0.922 GB, outvar_size=0.398 GB, temp_buffer_size=6.133 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=7.051 GB, invar_size=0.922 GB, outvar_size=0.336 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.058, peak_memory=2.674 GB, invar_size=0.422 GB, outvar_size=0.125 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.285 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.175, peak_memory=6.785 GB, invar_size=0.782 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.548 GB, invar_size=0.360 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=6.910 GB, invar_size=0.906 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.798 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.058, peak_memory=2.674 GB, invar_size=0.422 GB, outvar_size=0.125 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.222 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.878 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=7.051 GB, invar_size=0.922 GB, outvar_size=0.336 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.283, peak_memory=7.180 GB, invar_size=0.922 GB, outvar_size=0.398 GB, temp_buffer_size=6.133 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.175, peak_memory=6.785 GB, invar_size=0.782 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.285 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=6.910 GB, invar_size=0.906 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.548 GB, invar_size=0.360 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.058, peak_memory=2.674 GB, invar_size=0.422 GB, outvar_size=0.125 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.222 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.878 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.283, peak_memory=7.180 GB, invar_size=0.922 GB, outvar_size=0.398 GB, temp_buffer_size=6.133 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.736 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.001 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=7.051 GB, invar_size=0.922 GB, outvar_size=0.336 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.051, peak_memory=2.798 GB, invar_size=0.610 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=2.689 GB, invar_size=0.563 GB, outvar_size=0.062 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.285 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=6.910 GB, invar_size=0.906 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.548 GB, invar_size=0.360 GB, outvar_size=0.125 GB, temp_buffer_size=2.063 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.115, peak_memory=2.713 GB, invar_size=0.399 GB, outvar_size=0.188 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.036, peak_memory=2.564 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.265, peak_memory=7.051 GB, invar_size=0.922 GB, outvar_size=0.336 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.036, peak_memory=2.564 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=2.127 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.175, peak_memory=6.785 GB, invar_size=0.782 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.222 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.878 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.283, peak_memory=7.180 GB, invar_size=0.922 GB, outvar_size=0.398 GB, temp_buffer_size=6.133 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.155, peak_memory=7.285 GB, invar_size=1.282 GB, outvar_size=0.609 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=6.910 GB, invar_size=0.906 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.175, peak_memory=6.785 GB, invar_size=0.782 GB, outvar_size=0.359 GB, temp_buffer_size=5.941 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.211, peak_memory=8.736 GB, invar_size=1.326 GB, outvar_size=0.663 GB, temp_buffer_size=7.347 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.325, peak_memory=8.638 GB, invar_size=0.788 GB, outvar_size=0.363 GB, temp_buffer_size=7.787 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.225, peak_memory=8.298 GB, invar_size=0.888 GB, outvar_size=0.413 GB, temp_buffer_size=7.347 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 24.04 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.056, peak_memory=4.449 GB, invar_size=0.072 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.056, peak_memory=4.449 GB, invar_size=0.072 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.122, peak_memory=9.555 GB, invar_size=0.267 GB, outvar_size=0.071 GB, temp_buffer_size=9.288 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.122, peak_memory=9.555 GB, invar_size=0.267 GB, outvar_size=0.071 GB, temp_buffer_size=9.288 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.235, peak_memory=15.146 GB, invar_size=0.326 GB, outvar_size=0.225 GB, temp_buffer_size=14.695 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.235, peak_memory=15.146 GB, invar_size=0.326 GB, outvar_size=0.225 GB, temp_buffer_size=14.695 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.059, peak_memory=4.877 GB, invar_size=0.625 GB, outvar_size=0.125 GB, temp_buffer_size=4.127 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=9.132 GB, invar_size=1.250 GB, outvar_size=0.625 GB, temp_buffer_size=7.757 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 9.27 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 2, 2, 0) has been pruned...
[TMP] Stage (0, 2, 2, 1) has been pruned...
[TMP] Stage (0, 2, 2, 2) has been pruned...
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 3, 2, 0) has been pruned...
[TMP] Stage (1, 3, 2, 1) has been pruned...
[TMP] Stage (1, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 6, 3, 0) has been pruned...
[TMP] Stage (1, 6, 3, 1) has been pruned...
[TMP] Stage (1, 6, 3, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 4, 2, 0) has been pruned...
[TMP] Stage (2, 4, 2, 1) has been pruned...
[TMP] Stage (2, 4, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (2, 11, 3, 0) has been pruned...
[TMP] Stage (2, 11, 3, 1) has been pruned...
[TMP] Stage (2, 11, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (3, 12, 3, 0) has been pruned...
[TMP] Stage (3, 12, 3, 1) has been pruned...
[TMP] Stage (3, 12, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 8, 2, 0) has been pruned...
[TMP] Stage (4, 8, 2, 1) has been pruned...
[TMP] Stage (4, 8, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (4, 13, 3, 0) has been pruned...
[TMP] Stage (4, 13, 3, 1) has been pruned...
[TMP] Stage (4, 13, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 9, 2, 0) has been pruned...
[TMP] Stage (5, 9, 2, 1) has been pruned...
[TMP] Stage (5, 9, 2, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 10, 2, 0) has been pruned...
[TMP] Stage (6, 10, 2, 1) has been pruned...
[TMP] Stage (6, 10, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO comm 0x3f21c30 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO comm 0x361aa00 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO comm 0x6126110 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO comm 0x5943670 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=4045472)[0m 
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4045472)[0m 
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=4045472)[0m 
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO comm 0x4696180 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO comm 0x9f79890 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4045472)[0m 
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO comm 0x9f10750 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO comm 0x7044420 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4045472)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=4045472)[0m 
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO comm 0xa52c490 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO comm 0x51c96e0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=4045472)[0m 
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO comm 0xa652610 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO comm 0x7210820 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO comm 0x4dcacf0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO comm 0xb2c26f0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO comm 0xb61f650 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO comm 0xa1c1c60 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO comm 0xb0864b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO comm 0x3740e80 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO comm 0xb0ef5f0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO comm 0x5944520 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO comm 0x97979a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO comm 0x38de590 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO comm 0x972e860 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO comm 0x5beb040 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO comm 0xafd4c50 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [0] NCCL INFO comm 0x4b649b0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705309 [1] NCCL INFO comm 0x9f66f10 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO comm 0xafdfb80 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
 - Compile (driver): 71.82 s
compilation time breakdown: {'stage-construction': '36.66', 'stage-construction-dp': '1.20', 'stage-construction-compilation': '8.47', 'stage-construction-profiling': '9.88'}
 - Compile (worker): 5.29 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3253399, ip=192.168.0.58)[0m gpu28:3253399:3253399 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2388410, ip=192.168.0.57)[0m gpu27:2388410:2388410 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=4045472)[0m gpu37:4045472:4045472 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944006 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258298 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084037 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339075 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705414 [1] NCCL INFO comm 0x7f938f5d6d20 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO comm 0x7f939943cb40 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2705309, ip=192.168.0.60)[0m gpu30:2705309:2705412 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339264 [0] NCCL INFO comm 0x7f6767aa4ea0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2339075, ip=192.168.0.55)[0m gpu25:2339075:2339266 [1] NCCL INFO comm 0x7f6769415730 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084187 [0] NCCL INFO comm 0x7f1f4d381800 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3084037, ip=192.168.0.72)[0m gpu42:3084037:3084189 [1] NCCL INFO comm 0x7f1f596a0dd0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258360 [0] NCCL INFO comm 0x7f37b32fc8d0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3258298, ip=192.168.0.59)[0m gpu29:3258298:3258362 [1] NCCL INFO comm 0x7f37ac9508d0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944109 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1944006, ip=192.168.0.56)[0m gpu26:1944006:1944111 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
