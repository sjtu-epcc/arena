
------------------------------------------------------------------
- (1/3) Profiling bert_1.3B with batch size: 128...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_128.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f4f34ecddf0>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2))
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.279, peak_memory=1.599 GB, invar_size=1.053 GB, outvar_size=0.156 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.080, peak_memory=2.573 GB, invar_size=2.105 GB, outvar_size=0.078 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.084, peak_memory=2.506 GB, invar_size=2.006 GB, outvar_size=0.078 GB, temp_buffer_size=0.422 GB, available_memory=35.242 GB)
result[(0, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.314, peak_memory=9.011 GB, invar_size=5.382 GB, outvar_size=2.652 GB, temp_buffer_size=3.629 GB, available_memory=35.242 GB)
result[(0, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.752, peak_memory=7.477 GB, invar_size=2.809 GB, outvar_size=1.326 GB, temp_buffer_size=4.668 GB, available_memory=35.242 GB)
result[(0, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.323, peak_memory=8.617 GB, invar_size=4.989 GB, outvar_size=2.455 GB, temp_buffer_size=3.628 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 49.44 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.095, peak_memory=2.229 GB, invar_size=1.354 GB, outvar_size=0.094 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(1, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.876 GB, invar_size=1.188 GB, outvar_size=0.094 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(0, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.095, peak_memory=2.229 GB, invar_size=1.354 GB, outvar_size=0.094 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(1, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.876 GB, invar_size=1.188 GB, outvar_size=0.094 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(2, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.876 GB, invar_size=1.188 GB, outvar_size=0.094 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(2, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.083, peak_memory=1.876 GB, invar_size=1.188 GB, outvar_size=0.094 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(3, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.054, peak_memory=1.438 GB, invar_size=0.782 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(0, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.271, peak_memory=11.014 GB, invar_size=2.802 GB, outvar_size=1.354 GB, temp_buffer_size=8.212 GB, available_memory=35.242 GB)
result[(0, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.271, peak_memory=11.014 GB, invar_size=2.802 GB, outvar_size=1.354 GB, temp_buffer_size=8.212 GB, available_memory=35.242 GB)
result[(1, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.248, peak_memory=10.922 GB, invar_size=2.439 GB, outvar_size=1.188 GB, temp_buffer_size=8.452 GB, available_memory=35.242 GB)
result[(3, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.054, peak_memory=1.438 GB, invar_size=0.782 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=35.242 GB)
result[(1, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.248, peak_memory=10.922 GB, invar_size=2.439 GB, outvar_size=1.188 GB, temp_buffer_size=8.452 GB, available_memory=35.242 GB)
result[(2, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.248, peak_memory=11.611 GB, invar_size=2.439 GB, outvar_size=1.188 GB, temp_buffer_size=9.141 GB, available_memory=35.242 GB)
result[(2, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.248, peak_memory=11.611 GB, invar_size=2.439 GB, outvar_size=1.188 GB, temp_buffer_size=9.141 GB, available_memory=35.242 GB)
result[(3, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.271, peak_memory=9.830 GB, invar_size=2.689 GB, outvar_size=1.329 GB, temp_buffer_size=7.110 GB, available_memory=35.242 GB)
result[(3, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.271, peak_memory=9.830 GB, invar_size=2.689 GB, outvar_size=1.329 GB, temp_buffer_size=7.110 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 32.31 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-15-39-02.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2], [3, 4, 5]]
Result mesh_shapes: [(1, 1), (1, 1)]
Result logical_mesh_shapes: [(1, 1), (1, 1)]
Result autosharding_option_dicts: [{}, {'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 116.75 s
compilation time breakdown: {'stage-construction': '85.47', 'stage-construction-dp': '1.35', 'stage-construction-compilation': '29.82', 'stage-construction-profiling': '29.07'}
 - Compile (worker): 9.43 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 98.79 s

[16.05735182762146, 12.758176565170288, 12.749069452285767, 12.752673864364624, 12.754915475845337, 12.750397443771362, 12.745187520980835]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 66.929 s.
 - Average e2e iteration time: 13.386000633239746 s.
 - Total local training time: 63.75200271606445 s.
 - Average local iteration time: 12.750000953674316 s.
 - Max allocated memory among devices: 20.109 GB.
 - Compilation times:  {'stage-construction': 85.47012877464294, 'stage-construction-dp': 1.348153829574585, 'stage-construction-compilation': 29.821616888046265, 'stage-construction-profiling': 29.06905484199524}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_2_d`: 12.750449180603027
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_128.pkl`...

------------------------------------------------------------------
- (2/3) Profiling bert_1.3B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f12ce15ecd0>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2))
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.149, peak_memory=3.042 GB, invar_size=2.105 GB, outvar_size=0.156 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.546, peak_memory=2.146 GB, invar_size=1.053 GB, outvar_size=0.312 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.158, peak_memory=3.006 GB, invar_size=2.006 GB, outvar_size=0.156 GB, temp_buffer_size=0.844 GB, available_memory=35.242 GB)
result[(0, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.567, peak_memory=12.717 GB, invar_size=5.460 GB, outvar_size=2.652 GB, temp_buffer_size=7.257 GB, available_memory=35.242 GB)
result[(0, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=1.463, peak_memory=12.287 GB, invar_size=2.965 GB, outvar_size=1.326 GB, temp_buffer_size=9.322 GB, available_memory=35.242 GB)
result[(0, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.587, peak_memory=12.324 GB, invar_size=5.067 GB, outvar_size=2.455 GB, temp_buffer_size=7.256 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 50.41 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.184, peak_memory=3.104 GB, invar_size=1.354 GB, outvar_size=0.188 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(1, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.159, peak_memory=2.594 GB, invar_size=1.219 GB, outvar_size=0.188 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(0, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.184, peak_memory=3.104 GB, invar_size=1.354 GB, outvar_size=0.188 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(1, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.159, peak_memory=2.594 GB, invar_size=1.219 GB, outvar_size=0.188 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(2, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.159, peak_memory=2.594 GB, invar_size=1.219 GB, outvar_size=0.188 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(2, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.159, peak_memory=2.594 GB, invar_size=1.219 GB, outvar_size=0.188 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(3, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.103, peak_memory=2.125 GB, invar_size=0.813 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(1, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.476, peak_memory=19.525 GB, invar_size=2.564 GB, outvar_size=1.219 GB, temp_buffer_size=16.899 GB, available_memory=35.242 GB)
result[(0, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.522, peak_memory=19.313 GB, invar_size=2.896 GB, outvar_size=1.354 GB, temp_buffer_size=16.417 GB, available_memory=35.242 GB)
result[(0, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.522, peak_memory=19.313 GB, invar_size=2.896 GB, outvar_size=1.354 GB, temp_buffer_size=16.417 GB, available_memory=35.242 GB)
result[(3, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.103, peak_memory=2.125 GB, invar_size=0.813 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=35.242 GB)
result[(2, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.476, peak_memory=20.903 GB, invar_size=2.564 GB, outvar_size=1.219 GB, temp_buffer_size=18.277 GB, available_memory=35.242 GB)
result[(1, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.476, peak_memory=19.525 GB, invar_size=2.564 GB, outvar_size=1.219 GB, temp_buffer_size=16.899 GB, available_memory=35.242 GB)
result[(2, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.476, peak_memory=20.903 GB, invar_size=2.564 GB, outvar_size=1.219 GB, temp_buffer_size=18.277 GB, available_memory=35.242 GB)
result[(3, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.523, peak_memory=17.058 GB, invar_size=2.783 GB, outvar_size=1.360 GB, temp_buffer_size=14.213 GB, available_memory=35.242 GB)
result[(3, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.523, peak_memory=17.058 GB, invar_size=2.783 GB, outvar_size=1.360 GB, temp_buffer_size=14.213 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 31.32 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-15-42-58.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5]]
Result mesh_shapes: [(1, 2)]
Result logical_mesh_shapes: [(2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 127.04 s
compilation time breakdown: {'stage-construction': '85.22', 'stage-construction-dp': '1.34', 'stage-construction-compilation': '30.46', 'stage-construction-profiling': '28.75'}
 - Compile (worker): 18.92 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 176.88 s

[26.126418828964233, 23.590519905090332, 23.571733713150024, 23.57567000389099, 23.67132592201233, 23.573177576065063, 23.570866584777832]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 122.148 s.
 - Average e2e iteration time: 24.43000030517578 s.
 - Total local training time: 117.96300506591797 s.
 - Average local iteration time: 23.593000411987305 s.
 - Max allocated memory among devices: 23.018 GB.
 - Compilation times:  {'stage-construction': 85.22470569610596, 'stage-construction-dp': 1.342752456665039, 'stage-construction-compilation': 30.46473526954651, 'stage-construction-profiling': 28.74994683265686}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_2_d`: 23.59255599975586
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_256.pkl`...

------------------------------------------------------------------
- (3/3) Profiling bert_1.3B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f02a8eefc70>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2))
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=1.079, peak_memory=3.240 GB, invar_size=1.053 GB, outvar_size=0.625 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.286, peak_memory=3.980 GB, invar_size=2.105 GB, outvar_size=0.312 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.286, peak_memory=3.980 GB, invar_size=2.105 GB, outvar_size=0.312 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=1.069, peak_memory=20.130 GB, invar_size=5.616 GB, outvar_size=2.652 GB, temp_buffer_size=14.514 GB, available_memory=35.242 GB)
result[(0, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=2.880, peak_memory=21.901 GB, invar_size=3.278 GB, outvar_size=1.326 GB, temp_buffer_size=18.624 GB, available_memory=35.242 GB)
result[(0, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=1.069, peak_memory=20.130 GB, invar_size=5.616 GB, outvar_size=2.652 GB, temp_buffer_size=14.514 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 48.69 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.364, peak_memory=4.855 GB, invar_size=1.354 GB, outvar_size=0.375 GB, temp_buffer_size=3.125 GB, available_memory=35.242 GB)
result[(1, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.315, peak_memory=4.032 GB, invar_size=1.282 GB, outvar_size=0.375 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(0, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.364, peak_memory=4.855 GB, invar_size=1.354 GB, outvar_size=0.375 GB, temp_buffer_size=3.125 GB, available_memory=35.242 GB)
result[(1, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.315, peak_memory=4.032 GB, invar_size=1.282 GB, outvar_size=0.375 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(2, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.315, peak_memory=4.032 GB, invar_size=1.282 GB, outvar_size=0.375 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(2, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.315, peak_memory=4.032 GB, invar_size=1.282 GB, outvar_size=0.375 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(0, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=1.035, peak_memory=35.910 GB, invar_size=3.084 GB, outvar_size=1.354 GB, temp_buffer_size=32.827 GB, available_memory=35.242 GB)
result[(3, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.204, peak_memory=3.501 GB, invar_size=0.876 GB, outvar_size=0.250 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(0, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=1.035, peak_memory=35.910 GB, invar_size=3.084 GB, outvar_size=1.354 GB, temp_buffer_size=32.827 GB, available_memory=35.242 GB)
result[(1, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.944, peak_memory=36.730 GB, invar_size=2.814 GB, outvar_size=1.282 GB, temp_buffer_size=33.791 GB, available_memory=35.242 GB)
result[(3, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.204, peak_memory=3.501 GB, invar_size=0.876 GB, outvar_size=0.250 GB, temp_buffer_size=2.375 GB, available_memory=35.242 GB)
result[(1, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.944, peak_memory=36.730 GB, invar_size=2.814 GB, outvar_size=1.282 GB, temp_buffer_size=33.791 GB, available_memory=35.242 GB)
result[(2, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.944, peak_memory=39.484 GB, invar_size=2.814 GB, outvar_size=1.282 GB, temp_buffer_size=36.545 GB, available_memory=35.242 GB)
result[(2, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.944, peak_memory=39.484 GB, invar_size=2.814 GB, outvar_size=1.282 GB, temp_buffer_size=36.545 GB, available_memory=35.242 GB)
result[(3, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=1.038, peak_memory=31.512 GB, invar_size=2.970 GB, outvar_size=1.423 GB, temp_buffer_size=28.417 GB, available_memory=35.242 GB)
result[(3, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=1.038, peak_memory=31.512 GB, invar_size=2.970 GB, outvar_size=1.423 GB, temp_buffer_size=28.417 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 30.59 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-15-48-30.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5]]
Result mesh_shapes: [(1, 2)]
Result logical_mesh_shapes: [(2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 123.64 s
compilation time breakdown: {'stage-construction': '82.82', 'stage-construction-dp': '1.34', 'stage-construction-compilation': '29.20', 'stage-construction-profiling': '28.08'}
 - Compile (worker): 19.52 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 336.72 s

[48.95266914367676, 46.007988929748535, 45.98175573348999, 45.993614196777344, 45.99258208274841, 45.994924545288086, 45.96769690513611]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 236.293 s.
 - Average e2e iteration time: 47.259002685546875 s.
 - Total local training time: 229.93101501464844 s.
 - Average local iteration time: 45.98600387573242 s.
 - Max allocated memory among devices: 32.776 GB.
 - Compilation times:  {'stage-construction': 82.82156372070312, 'stage-construction-dp': 1.343367576599121, 'stage-construction-compilation': 29.201287269592285, 'stage-construction-profiling': 28.07974624633789}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_2_d`: 45.986114501953125
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_512.pkl`...
