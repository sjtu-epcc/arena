
------------------------------------------------------------------
- (1/3) Profiling wide_resnet_2B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_2B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 448
    width_factor = 2
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (256, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=0.721 GB, invar_size=0.257 GB, outvar_size=0.168 GB, temp_buffer_size=0.296 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.706 GB, invar_size=0.263 GB, outvar_size=0.168 GB, temp_buffer_size=0.275 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.023 GB, invar_size=0.434 GB, outvar_size=0.168 GB, temp_buffer_size=0.422 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.884 GB, invar_size=0.298 GB, outvar_size=0.251 GB, temp_buffer_size=0.335 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.808 GB, invar_size=0.365 GB, outvar_size=0.168 GB, temp_buffer_size=0.275 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.119 GB, invar_size=0.278 GB, outvar_size=0.335 GB, temp_buffer_size=0.505 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.762 GB, invar_size=0.050 GB, outvar_size=0.293 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.884 GB, invar_size=0.298 GB, outvar_size=0.251 GB, temp_buffer_size=0.335 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.939 GB, invar_size=0.180 GB, outvar_size=0.335 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.808 GB, invar_size=0.365 GB, outvar_size=0.168 GB, temp_buffer_size=0.275 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.098, peak_memory=0.911 GB, invar_size=0.032 GB, outvar_size=0.377 GB, temp_buffer_size=0.502 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.134, peak_memory=1.489 GB, invar_size=0.400 GB, outvar_size=0.419 GB, temp_buffer_size=0.670 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.762 GB, invar_size=0.050 GB, outvar_size=0.293 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.939 GB, invar_size=0.180 GB, outvar_size=0.335 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=1.244 GB, invar_size=0.610 GB, outvar_size=0.263 GB, temp_buffer_size=0.550 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.706 GB, invar_size=0.263 GB, outvar_size=0.168 GB, temp_buffer_size=0.275 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.102, peak_memory=1.343 GB, invar_size=0.515 GB, outvar_size=0.174 GB, temp_buffer_size=0.745 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.598 GB, invar_size=0.263 GB, outvar_size=0.168 GB, temp_buffer_size=0.168 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=1.973 GB, invar_size=0.568 GB, outvar_size=0.180 GB, temp_buffer_size=1.279 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=1.810 GB, invar_size=0.679 GB, outvar_size=0.298 GB, temp_buffer_size=0.963 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.128, peak_memory=1.915 GB, invar_size=0.700 GB, outvar_size=0.266 GB, temp_buffer_size=1.047 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.598 GB, invar_size=0.263 GB, outvar_size=0.168 GB, temp_buffer_size=0.168 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=1.684 GB, invar_size=0.730 GB, outvar_size=0.365 GB, temp_buffer_size=0.787 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=1.768 GB, invar_size=0.814 GB, outvar_size=0.365 GB, temp_buffer_size=0.787 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=1.893 GB, invar_size=0.763 GB, outvar_size=0.298 GB, temp_buffer_size=0.963 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=0.676 GB, invar_size=0.257 GB, outvar_size=0.168 GB, temp_buffer_size=0.251 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.074 GB, invar_size=0.605 GB, outvar_size=0.126 GB, temp_buffer_size=0.344 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.188, peak_memory=2.483 GB, invar_size=0.884 GB, outvar_size=0.233 GB, temp_buffer_size=1.432 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.001, peak_memory=1.785 GB, invar_size=0.389 GB, outvar_size=0.046 GB, temp_buffer_size=1.395 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.021, peak_memory=0.811 GB, invar_size=0.449 GB, outvar_size=0.126 GB, temp_buffer_size=0.236 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.070, peak_memory=0.972 GB, invar_size=0.428 GB, outvar_size=0.209 GB, temp_buffer_size=0.335 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.205, peak_memory=2.287 GB, invar_size=0.432 GB, outvar_size=0.023 GB, temp_buffer_size=1.855 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.302 GB, invar_size=0.874 GB, outvar_size=0.084 GB, temp_buffer_size=0.344 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=1.973 GB, invar_size=0.568 GB, outvar_size=0.180 GB, temp_buffer_size=1.279 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.262, peak_memory=2.492 GB, invar_size=0.640 GB, outvar_size=0.278 GB, temp_buffer_size=1.601 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=1.244 GB, invar_size=0.610 GB, outvar_size=0.263 GB, temp_buffer_size=0.550 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.001, peak_memory=2.377 GB, invar_size=0.557 GB, outvar_size=0.046 GB, temp_buffer_size=1.820 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.966 GB, invar_size=0.563 GB, outvar_size=0.084 GB, temp_buffer_size=0.320 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=1.245 GB, invar_size=0.610 GB, outvar_size=0.263 GB, temp_buffer_size=0.550 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.153 GB, invar_size=0.760 GB, outvar_size=0.084 GB, temp_buffer_size=0.310 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=1.245 GB, invar_size=0.610 GB, outvar_size=0.263 GB, temp_buffer_size=0.550 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.010, peak_memory=2.244 GB, invar_size=1.250 GB, outvar_size=0.604 GB, temp_buffer_size=0.909 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.102, peak_memory=1.343 GB, invar_size=0.515 GB, outvar_size=0.174 GB, temp_buffer_size=0.745 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.966 GB, invar_size=0.563 GB, outvar_size=0.084 GB, temp_buffer_size=0.320 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.784 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.257 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.101 GB, invar_size=0.760 GB, outvar_size=0.084 GB, temp_buffer_size=0.257 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.784 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.257 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.760 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.233 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.101 GB, invar_size=0.760 GB, outvar_size=0.084 GB, temp_buffer_size=0.257 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.760 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.233 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.760 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.233 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.100, peak_memory=1.654 GB, invar_size=0.897 GB, outvar_size=0.344 GB, temp_buffer_size=0.673 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=2.680 GB, invar_size=1.562 GB, outvar_size=0.760 GB, temp_buffer_size=1.077 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.760 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.233 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.015, peak_memory=3.003 GB, invar_size=1.747 GB, outvar_size=0.874 GB, temp_buffer_size=1.173 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.048, peak_memory=1.798 GB, invar_size=0.981 GB, outvar_size=0.449 GB, temp_buffer_size=0.733 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.101 GB, invar_size=0.760 GB, outvar_size=0.084 GB, temp_buffer_size=0.257 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=2.680 GB, invar_size=1.562 GB, outvar_size=0.760 GB, temp_buffer_size=1.077 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.760 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.233 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.079, peak_memory=1.840 GB, invar_size=1.041 GB, outvar_size=0.479 GB, temp_buffer_size=0.715 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.114 GB, invar_size=2.124 GB, outvar_size=0.063 GB, temp_buffer_size=0.927 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=0.760 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.233 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.427 GB, invar_size=0.885 GB, outvar_size=0.401 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.427 GB, invar_size=0.885 GB, outvar_size=0.401 GB, temp_buffer_size=0.500 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.077, peak_memory=1.780 GB, invar_size=1.041 GB, outvar_size=0.479 GB, temp_buffer_size=0.656 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=2.680 GB, invar_size=1.562 GB, outvar_size=0.760 GB, temp_buffer_size=1.077 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.445 GB, invar_size=0.886 GB, outvar_size=0.401 GB, temp_buffer_size=0.518 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.685 GB, invar_size=1.125 GB, outvar_size=0.063 GB, temp_buffer_size=0.497 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.445 GB, invar_size=0.886 GB, outvar_size=0.401 GB, temp_buffer_size=0.518 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.362 GB, invar_size=0.886 GB, outvar_size=0.401 GB, temp_buffer_size=0.434 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.044, peak_memory=1.685 GB, invar_size=1.125 GB, outvar_size=0.063 GB, temp_buffer_size=0.497 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.170 GB, invar_size=3.201 GB, outvar_size=0.042 GB, temp_buffer_size=0.927 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.362 GB, invar_size=0.886 GB, outvar_size=0.401 GB, temp_buffer_size=0.434 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=2.680 GB, invar_size=1.562 GB, outvar_size=0.760 GB, temp_buffer_size=1.077 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=2.244 GB, invar_size=1.664 GB, outvar_size=0.042 GB, temp_buffer_size=0.538 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.016, peak_memory=2.244 GB, invar_size=1.664 GB, outvar_size=0.042 GB, temp_buffer_size=0.538 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.362 GB, invar_size=0.886 GB, outvar_size=0.401 GB, temp_buffer_size=0.434 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.867 GB, invar_size=2.947 GB, outvar_size=0.021 GB, temp_buffer_size=0.898 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.039, peak_memory=7.995 GB, invar_size=4.268 GB, outvar_size=2.124 GB, temp_buffer_size=3.685 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.362 GB, invar_size=0.886 GB, outvar_size=0.401 GB, temp_buffer_size=0.434 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.019, peak_memory=1.983 GB, invar_size=1.484 GB, outvar_size=0.021 GB, temp_buffer_size=0.478 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.019, peak_memory=1.983 GB, invar_size=1.484 GB, outvar_size=0.021 GB, temp_buffer_size=0.478 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=11.037 GB, invar_size=6.401 GB, outvar_size=3.201 GB, temp_buffer_size=4.594 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.071, peak_memory=3.318 GB, invar_size=2.250 GB, outvar_size=1.083 GB, temp_buffer_size=1.026 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.071, peak_memory=3.318 GB, invar_size=2.250 GB, outvar_size=1.083 GB, temp_buffer_size=1.026 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.055, peak_memory=10.277 GB, invar_size=5.894 GB, outvar_size=2.947 GB, temp_buffer_size=4.362 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.052, peak_memory=4.474 GB, invar_size=3.284 GB, outvar_size=1.621 GB, temp_buffer_size=1.147 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.034, peak_memory=3.801 GB, invar_size=2.968 GB, outvar_size=1.484 GB, temp_buffer_size=0.812 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.052, peak_memory=4.474 GB, invar_size=3.284 GB, outvar_size=1.621 GB, temp_buffer_size=1.147 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.034, peak_memory=3.801 GB, invar_size=2.968 GB, outvar_size=1.484 GB, temp_buffer_size=0.812 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 15.02 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.530 GB, invar_size=0.357 GB, outvar_size=0.335 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.906 GB, invar_size=0.715 GB, outvar_size=0.357 GB, temp_buffer_size=1.856 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.844 GB, invar_size=0.257 GB, outvar_size=0.168 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.844 GB, invar_size=0.257 GB, outvar_size=0.168 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.530 GB, invar_size=0.357 GB, outvar_size=0.335 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.844 GB, invar_size=0.257 GB, outvar_size=0.168 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.844 GB, invar_size=0.257 GB, outvar_size=0.168 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.844 GB, invar_size=0.257 GB, outvar_size=0.168 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.844 GB, invar_size=0.257 GB, outvar_size=0.168 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.657 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.688 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.657 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.688 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.657 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.688 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.490 GB, invar_size=0.514 GB, outvar_size=0.257 GB, temp_buffer_size=0.808 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.906 GB, invar_size=0.715 GB, outvar_size=0.357 GB, temp_buffer_size=1.856 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.490 GB, invar_size=0.514 GB, outvar_size=0.257 GB, temp_buffer_size=0.808 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.657 GB, invar_size=0.514 GB, outvar_size=0.257 GB, temp_buffer_size=0.975 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.657 GB, invar_size=0.514 GB, outvar_size=0.257 GB, temp_buffer_size=0.975 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.657 GB, invar_size=0.514 GB, outvar_size=0.257 GB, temp_buffer_size=0.975 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.657 GB, invar_size=0.514 GB, outvar_size=0.257 GB, temp_buffer_size=0.975 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.657 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.688 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.868 GB, invar_size=0.443 GB, outvar_size=0.084 GB, temp_buffer_size=0.341 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.573 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.604 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.434 GB, invar_size=1.478 GB, outvar_size=0.042 GB, temp_buffer_size=0.914 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.573 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.604 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.434 GB, invar_size=1.478 GB, outvar_size=0.042 GB, temp_buffer_size=0.914 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.573 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.604 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.573 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.604 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.573 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.604 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.573 GB, invar_size=0.885 GB, outvar_size=0.443 GB, temp_buffer_size=0.604 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.467 GB, invar_size=1.533 GB, outvar_size=0.000 GB, temp_buffer_size=0.935 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.467 GB, invar_size=1.533 GB, outvar_size=0.000 GB, temp_buffer_size=0.935 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.430 GB, invar_size=2.955 GB, outvar_size=1.478 GB, temp_buffer_size=1.433 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.430 GB, invar_size=2.955 GB, outvar_size=1.478 GB, temp_buffer_size=1.433 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.414 GB, invar_size=3.023 GB, outvar_size=1.532 GB, temp_buffer_size=1.349 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.414 GB, invar_size=3.023 GB, outvar_size=1.532 GB, temp_buffer_size=1.349 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 8.35 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 3, 2, 0) has been pruned...
[TMP] Stage (1, 3, 2, 1) has been pruned...
[TMP] Stage (1, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 6, 3, 0) has been pruned...
[TMP] Stage (1, 6, 3, 1) has been pruned...
[TMP] Stage (1, 6, 3, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 4, 2, 0) has been pruned...
[TMP] Stage (2, 4, 2, 1) has been pruned...
[TMP] Stage (2, 4, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 7, 3, 0) has been pruned...
[TMP] Stage (2, 7, 3, 1) has been pruned...
[TMP] Stage (2, 7, 3, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (3, 5, 2, 0) has been pruned...
[TMP] Stage (3, 5, 2, 1) has been pruned...
[TMP] Stage (3, 5, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (5, 7, 2, 0) has been pruned...
[TMP] Stage (5, 7, 2, 1) has been pruned...
[TMP] Stage (5, 7, 2, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4], [5], [6, 7], [8], [9], [10], [11], [12, 13], [14], [15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1)]
Result autosharding_option_dicts: [{}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}]
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO comm 0x390fd50 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO comm 0x47bcdf0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO comm 0x6cdfeb0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO comm 0x67be430 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO comm 0x4e908c0 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO comm 0xa5588e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO comm 0xa3e0860 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO comm 0xa7af6b0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO comm 0x4ff46f0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO comm 0xa22bde0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO comm 0x43c4fc0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO comm 0x7b15290 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO comm 0x65c45d0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO comm 0x72c6400 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO comm 0xa40e420 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO comm 0x514ddc0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO comm 0xa3a52e0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO comm 0x7f45250 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO comm 0x7db9f30 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO comm 0x4694710 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3957164)[0m 
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3957164)[0m 
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3957164)[0m 
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO comm 0x3b40af0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO comm 0x9dbaff0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3957164)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3957165)[0m 
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3957164)[0m 
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO comm 0x8f4d290 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3957165)[0m 
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3957165)[0m 
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO comm 0x4cf6570 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3957165)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3957165)[0m 
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO comm 0x7d4e4a0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO comm 0x51a5d40 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3957165)[0m 
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO comm 0x8174ca0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO comm 0x8547ff0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO comm 0xb590740 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO comm 0x445c400 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO comm 0xb527600 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO comm 0x99b1750 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO comm 0x9804530 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1904924, ip=192.168.0.56)[0m gpu26:1904924:1904924 [0] NCCL INFO comm 0x5363140 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
 - Compile (driver): 45.45 s
compilation time breakdown: {'stage-construction': '25.39', 'stage-construction-dp': '1.18', 'stage-construction-compilation': '5.32', 'stage-construction-profiling': '9.23'}
 - Compile (worker): 3.12 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO comm 0x7f9ed2c8c480 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221995 [1] NCCL INFO comm 0x7f9eb60bb630 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221993 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3221886, ip=192.168.0.59)[0m gpu29:3221886:3221886 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065819 [1] NCCL INFO comm 0x7fd79d3d6ed0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO comm 0x7fd7d0000030 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065817 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3065745, ip=192.168.0.72)[0m gpu42:3065745:3065745 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3215541, ip=192.168.0.58)[0m gpu28:3215541:3215541 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3215540, ip=192.168.0.58)[0m gpu28:3215540:3215540 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306439 [1] NCCL INFO comm 0x7f5542078610 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO comm 0x7f556f3bd370 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306437 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2306291, ip=192.168.0.55)[0m gpu25:2306291:2306291 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2354299, ip=192.168.0.57)[0m gpu27:2354299:2354299 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2354300, ip=192.168.0.57)[0m gpu27:2354300:2354300 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3957164)[0m gpu37:3957164:3957164 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3957165)[0m gpu37:3957165:3957165 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673974 [1] NCCL INFO comm 0x7f04c466eb60 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO comm 0x7f04d8b088c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673972 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2673826, ip=192.168.0.60)[0m gpu30:2673826:2673826 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1904923, ip=192.168.0.56)[0m gpu26:1904923:1904923 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 158.42 s

[32.97942495346069, 20.36126685142517, 20.354384183883667, 20.49675750732422, 20.57005476951599, 20.610867738723755, 20.64337992668152]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 104.377 s.
 - Average e2e iteration time: 20.875001907348633 s.
 - Total local training time: 102.67500305175781 s.
 - Average local iteration time: 20.535001754760742 s.
 - Max allocated memory among devices: 10.383 GB.
 - Compilation times:  {'stage-construction': 25.385125160217285, 'stage-construction-dp': 1.176788568496704, 'stage-construction-compilation': 5.318131446838379, 'stage-construction-profiling': 9.234772205352783}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 20.53508949279785
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_2B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling wide_resnet_2B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_2B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 448
    width_factor = 2
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (512, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.307 GB, invar_size=0.425 GB, outvar_size=0.335 GB, temp_buffer_size=0.547 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.137 GB, invar_size=0.347 GB, outvar_size=0.335 GB, temp_buffer_size=0.455 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.265, peak_memory=2.912 GB, invar_size=0.735 GB, outvar_size=0.837 GB, temp_buffer_size=1.340 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.638 GB, invar_size=0.465 GB, outvar_size=0.502 GB, temp_buffer_size=0.670 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.638 GB, invar_size=0.465 GB, outvar_size=0.502 GB, temp_buffer_size=0.670 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.454 GB, invar_size=0.533 GB, outvar_size=0.335 GB, temp_buffer_size=0.586 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.454 GB, invar_size=0.533 GB, outvar_size=0.335 GB, temp_buffer_size=0.586 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=2.109 GB, invar_size=0.769 GB, outvar_size=0.335 GB, temp_buffer_size=1.005 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.479 GB, invar_size=0.055 GB, outvar_size=0.586 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.157, peak_memory=2.207 GB, invar_size=0.529 GB, outvar_size=0.670 GB, temp_buffer_size=1.008 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.202, peak_memory=2.474 GB, invar_size=0.849 GB, outvar_size=0.257 GB, temp_buffer_size=1.457 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.194, peak_memory=1.800 GB, invar_size=0.041 GB, outvar_size=0.754 GB, temp_buffer_size=1.005 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.819 GB, invar_size=0.305 GB, outvar_size=0.670 GB, temp_buffer_size=0.843 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.479 GB, invar_size=0.055 GB, outvar_size=0.586 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.819 GB, invar_size=0.305 GB, outvar_size=0.670 GB, temp_buffer_size=0.843 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.041 GB, invar_size=0.862 GB, outvar_size=0.347 GB, temp_buffer_size=1.012 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.137 GB, invar_size=0.347 GB, outvar_size=0.335 GB, temp_buffer_size=0.455 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.017 GB, invar_size=0.347 GB, outvar_size=0.335 GB, temp_buffer_size=0.335 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=3.589 GB, invar_size=1.202 GB, outvar_size=0.434 GB, temp_buffer_size=2.052 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.017 GB, invar_size=0.347 GB, outvar_size=0.335 GB, temp_buffer_size=0.335 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.374, peak_memory=4.828 GB, invar_size=1.638 GB, outvar_size=0.400 GB, temp_buffer_size=2.856 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=3.359 GB, invar_size=1.098 GB, outvar_size=0.465 GB, temp_buffer_size=1.926 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=1.262 GB, invar_size=0.425 GB, outvar_size=0.335 GB, temp_buffer_size=0.502 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.860 GB, invar_size=1.065 GB, outvar_size=0.532 GB, temp_buffer_size=1.460 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=3.527 GB, invar_size=1.265 GB, outvar_size=0.465 GB, temp_buffer_size=1.926 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.408, peak_memory=4.515 GB, invar_size=0.818 GB, outvar_size=0.023 GB, temp_buffer_size=3.697 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.522, peak_memory=4.921 GB, invar_size=1.226 GB, outvar_size=0.529 GB, temp_buffer_size=3.192 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.412 GB, invar_size=0.688 GB, outvar_size=0.251 GB, temp_buffer_size=0.473 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=3.027 GB, invar_size=1.232 GB, outvar_size=0.532 GB, temp_buffer_size=1.460 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.412 GB, invar_size=0.688 GB, outvar_size=0.251 GB, temp_buffer_size=0.473 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.136, peak_memory=1.684 GB, invar_size=0.595 GB, outvar_size=0.419 GB, temp_buffer_size=0.670 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=3.815 GB, invar_size=1.029 GB, outvar_size=0.305 GB, temp_buffer_size=2.535 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.598 GB, invar_size=0.958 GB, outvar_size=0.168 GB, temp_buffer_size=0.473 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=3.815 GB, invar_size=1.029 GB, outvar_size=0.305 GB, temp_buffer_size=2.535 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.041 GB, invar_size=0.862 GB, outvar_size=0.347 GB, temp_buffer_size=1.012 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.001, peak_memory=4.657 GB, invar_size=1.022 GB, outvar_size=0.046 GB, temp_buffer_size=3.636 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.001, peak_memory=3.464 GB, invar_size=0.687 GB, outvar_size=0.046 GB, temp_buffer_size=2.777 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.430 GB, invar_size=0.730 GB, outvar_size=0.168 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.041 GB, invar_size=0.862 GB, outvar_size=0.347 GB, temp_buffer_size=1.012 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.202, peak_memory=2.474 GB, invar_size=0.849 GB, outvar_size=0.257 GB, temp_buffer_size=1.457 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.113 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.394 GB, invar_size=0.802 GB, outvar_size=0.168 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=2.041 GB, invar_size=0.862 GB, outvar_size=0.347 GB, temp_buffer_size=1.012 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.113 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.419 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=1.430 GB, invar_size=0.730 GB, outvar_size=0.168 GB, temp_buffer_size=0.532 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.289 GB, invar_size=0.802 GB, outvar_size=0.168 GB, temp_buffer_size=0.320 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=0.990 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.296 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.193, peak_memory=2.567 GB, invar_size=1.274 GB, outvar_size=0.428 GB, temp_buffer_size=1.125 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.010, peak_memory=2.668 GB, invar_size=1.460 GB, outvar_size=0.688 GB, temp_buffer_size=1.041 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=0.990 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.296 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.289 GB, invar_size=0.802 GB, outvar_size=0.168 GB, temp_buffer_size=0.320 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.015, peak_memory=3.231 GB, invar_size=1.914 GB, outvar_size=0.957 GB, temp_buffer_size=1.149 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.136, peak_memory=2.615 GB, invar_size=1.292 GB, outvar_size=0.562 GB, temp_buffer_size=1.155 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=0.990 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.296 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=1.981 GB, invar_size=1.053 GB, outvar_size=0.443 GB, temp_buffer_size=0.844 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=0.990 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.296 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.010, peak_memory=2.794 GB, invar_size=1.544 GB, outvar_size=0.688 GB, temp_buffer_size=1.083 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.289 GB, invar_size=0.802 GB, outvar_size=0.168 GB, temp_buffer_size=0.320 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=2.848 GB, invar_size=1.687 GB, outvar_size=0.802 GB, temp_buffer_size=1.078 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=1.981 GB, invar_size=1.053 GB, outvar_size=0.443 GB, temp_buffer_size=0.844 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=0.990 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.296 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.128, peak_memory=2.555 GB, invar_size=1.292 GB, outvar_size=0.562 GB, temp_buffer_size=1.095 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=1.981 GB, invar_size=1.053 GB, outvar_size=0.443 GB, temp_buffer_size=0.844 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=0.990 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.296 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=2.848 GB, invar_size=1.687 GB, outvar_size=0.802 GB, temp_buffer_size=1.077 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=1.981 GB, invar_size=1.053 GB, outvar_size=0.443 GB, temp_buffer_size=0.844 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.285 GB, invar_size=2.166 GB, outvar_size=0.126 GB, temp_buffer_size=0.993 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=1.837 GB, invar_size=1.053 GB, outvar_size=0.443 GB, temp_buffer_size=0.700 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=2.848 GB, invar_size=1.687 GB, outvar_size=0.802 GB, temp_buffer_size=1.077 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.082, peak_memory=2.065 GB, invar_size=1.209 GB, outvar_size=0.210 GB, temp_buffer_size=0.646 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=1.837 GB, invar_size=1.053 GB, outvar_size=0.443 GB, temp_buffer_size=0.700 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.082, peak_memory=2.065 GB, invar_size=1.209 GB, outvar_size=0.210 GB, temp_buffer_size=0.646 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.320 GB, invar_size=3.243 GB, outvar_size=0.084 GB, temp_buffer_size=0.993 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=1.837 GB, invar_size=1.053 GB, outvar_size=0.443 GB, temp_buffer_size=0.700 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=2.848 GB, invar_size=1.687 GB, outvar_size=0.802 GB, temp_buffer_size=1.077 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.108, peak_memory=1.837 GB, invar_size=1.053 GB, outvar_size=0.443 GB, temp_buffer_size=0.700 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=2.513 GB, invar_size=1.747 GB, outvar_size=0.084 GB, temp_buffer_size=0.682 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=2.513 GB, invar_size=1.747 GB, outvar_size=0.084 GB, temp_buffer_size=0.682 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=2.146 GB, invar_size=1.547 GB, outvar_size=0.042 GB, temp_buffer_size=0.556 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.945 GB, invar_size=2.968 GB, outvar_size=0.042 GB, temp_buffer_size=0.935 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.032, peak_memory=2.146 GB, invar_size=1.547 GB, outvar_size=0.042 GB, temp_buffer_size=0.556 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.039, peak_memory=8.142 GB, invar_size=4.373 GB, outvar_size=2.166 GB, temp_buffer_size=3.685 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=3.705 GB, invar_size=2.459 GB, outvar_size=1.125 GB, temp_buffer_size=1.163 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=3.705 GB, invar_size=2.459 GB, outvar_size=1.125 GB, temp_buffer_size=1.163 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=4.232 GB, invar_size=3.052 GB, outvar_size=1.505 GB, temp_buffer_size=1.138 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.096, peak_memory=4.742 GB, invar_size=3.410 GB, outvar_size=1.663 GB, temp_buffer_size=1.248 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.096, peak_memory=4.742 GB, invar_size=3.410 GB, outvar_size=1.663 GB, temp_buffer_size=1.248 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.055, peak_memory=10.340 GB, invar_size=5.936 GB, outvar_size=2.968 GB, temp_buffer_size=4.362 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=11.163 GB, invar_size=6.485 GB, outvar_size=3.242 GB, temp_buffer_size=4.594 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.070, peak_memory=4.232 GB, invar_size=3.052 GB, outvar_size=1.505 GB, temp_buffer_size=1.138 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 14.93 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.037 GB, invar_size=0.692 GB, outvar_size=0.670 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.597 GB, invar_size=0.425 GB, outvar_size=0.335 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.753 GB, invar_size=1.385 GB, outvar_size=0.692 GB, temp_buffer_size=3.698 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.597 GB, invar_size=0.425 GB, outvar_size=0.335 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.597 GB, invar_size=0.425 GB, outvar_size=0.335 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.037 GB, invar_size=0.692 GB, outvar_size=0.670 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.357 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=1.137 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.358 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=1.138 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.597 GB, invar_size=0.425 GB, outvar_size=0.335 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.597 GB, invar_size=0.425 GB, outvar_size=0.335 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.597 GB, invar_size=0.425 GB, outvar_size=0.335 GB, temp_buffer_size=0.837 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.357 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=1.137 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.746 GB, invar_size=0.849 GB, outvar_size=0.425 GB, temp_buffer_size=1.562 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.746 GB, invar_size=0.849 GB, outvar_size=0.425 GB, temp_buffer_size=1.562 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.081 GB, invar_size=0.849 GB, outvar_size=0.425 GB, temp_buffer_size=1.896 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.081 GB, invar_size=0.849 GB, outvar_size=0.425 GB, temp_buffer_size=1.896 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.081 GB, invar_size=0.849 GB, outvar_size=0.425 GB, temp_buffer_size=1.897 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.081 GB, invar_size=0.849 GB, outvar_size=0.425 GB, temp_buffer_size=1.897 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.753 GB, invar_size=1.385 GB, outvar_size=0.692 GB, temp_buffer_size=3.698 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.161 GB, invar_size=0.527 GB, outvar_size=0.168 GB, temp_buffer_size=0.467 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.570 GB, invar_size=1.520 GB, outvar_size=0.084 GB, temp_buffer_size=0.966 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.358 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=1.138 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.190 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=0.970 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.190 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=0.970 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.190 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=0.970 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.190 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=0.970 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.570 GB, invar_size=1.520 GB, outvar_size=0.084 GB, temp_buffer_size=0.966 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.190 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=0.970 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.744 GB, invar_size=3.039 GB, outvar_size=1.519 GB, temp_buffer_size=1.621 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.190 GB, invar_size=1.053 GB, outvar_size=0.526 GB, temp_buffer_size=0.970 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.582 GB, invar_size=1.575 GB, outvar_size=0.000 GB, temp_buffer_size=1.008 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.582 GB, invar_size=1.575 GB, outvar_size=0.000 GB, temp_buffer_size=1.008 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.744 GB, invar_size=3.039 GB, outvar_size=1.519 GB, temp_buffer_size=1.621 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.602 GB, invar_size=3.065 GB, outvar_size=1.574 GB, temp_buffer_size=1.454 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.602 GB, invar_size=3.065 GB, outvar_size=1.574 GB, temp_buffer_size=1.454 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 8.39 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 3, 2, 0) has been pruned...
[TMP] Stage (1, 3, 2, 1) has been pruned...
[TMP] Stage (1, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 6, 3, 0) has been pruned...
[TMP] Stage (1, 6, 3, 1) has been pruned...
[TMP] Stage (1, 6, 3, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 4, 2, 0) has been pruned...
[TMP] Stage (2, 4, 2, 1) has been pruned...
[TMP] Stage (2, 4, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 7, 3, 0) has been pruned...
[TMP] Stage (2, 7, 3, 1) has been pruned...
[TMP] Stage (2, 7, 3, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (3, 5, 2, 0) has been pruned...
[TMP] Stage (3, 5, 2, 1) has been pruned...
[TMP] Stage (3, 5, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (5, 7, 2, 0) has been pruned...
[TMP] Stage (5, 7, 2, 1) has been pruned...
[TMP] Stage (5, 7, 2, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4], [5], [6, 7], [8], [9], [10], [11], [12, 13], [14], [15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 1), (1, 1)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1)]
Result autosharding_option_dicts: [{}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}]
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO comm 0x4e807d0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO comm 0x4e0e5a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO comm 0x716be70 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO comm 0xa24b750 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO comm 0x3645f40 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO comm 0xc53a620 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO comm 0x643cae0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO comm 0xc3e5690 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO comm 0x4306450 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO comm 0x62b17c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO comm 0x3cfe730 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO comm 0x986ab00 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO comm 0x5f389c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO comm 0x96b60a0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3965238)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO comm 0x4b65ea0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO comm 0x9895450 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO comm 0x79567e0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO comm 0xa002330 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO comm 0x77cb4c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO comm 0x3d39240 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO comm 0x6b2e3b0 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO comm 0x4bf5260 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO comm 0x52ecbf0 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO comm 0x6beb950 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO comm 0x3f9fff0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO comm 0x7cb2710 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO comm 0x7d85620 rank 0 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO comm 0x5e5acc0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO comm 0xa09e420 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO comm 0x3b63420 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 00 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 01 : 0[ca000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 00 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 01 : 1[31000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO comm 0xa40ad40 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO comm 0x667f150 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2309741, ip=192.168.0.55)[0m gpu25:2309741:2309741 [0] NCCL INFO comm 0x47adaa0 rank 1 nranks 2 cudaDev 0 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO comm 0x5e20c20 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
 - Compile (driver): 45.78 s
compilation time breakdown: {'stage-construction': '25.39', 'stage-construction-dp': '1.23', 'stage-construction-compilation': '5.19', 'stage-construction-profiling': '9.33'}
 - Compile (worker): 3.20 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220580 [1] NCCL INFO comm 0x7f576c7e0ac0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO comm 0x7f57855e3310 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220578 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3220386, ip=192.168.0.58)[0m gpu28:3220386:3220386 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO comm 0x7efa575bf8a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358647 [1] NCCL INFO comm 0x7efa3ee2a350 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358645 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2358541, ip=192.168.0.57)[0m gpu27:2358541:2358541 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3226353, ip=192.168.0.59)[0m gpu29:3226353:3226353 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3226354, ip=192.168.0.59)[0m gpu29:3226354:3226354 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3965238)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3965238)[0m 
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965452 [1] NCCL INFO comm 0x7f61e3c836b0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO comm 0x7f61f7283600 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965450 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3965238)[0m gpu37:3965238:3965238 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3067196, ip=192.168.0.72)[0m gpu42:3067196:3067196 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3067197, ip=192.168.0.72)[0m gpu42:3067197:3067197 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2676655, ip=192.168.0.60)[0m gpu30:2676655:2676655 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2676656, ip=192.168.0.60)[0m gpu30:2676656:2676656 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909639 [1] NCCL INFO comm 0x7fbf9cfab1e0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO comm 0x7fbfbd6930c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909637 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1909449, ip=192.168.0.56)[0m gpu26:1909449:1909449 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2309740, ip=192.168.0.55)[0m gpu25:2309740:2309740 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 243.43 s

[43.73155856132507, 32.58179712295532, 32.696335554122925, 32.44142770767212, 32.512999057769775, 32.634660959243774, 32.56925940513611]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 166.035 s.
 - Average e2e iteration time: 33.207000732421875 s.
 - Total local training time: 162.85501098632812 s.
 - Average local iteration time: 32.57100296020508 s.
 - Max allocated memory among devices: 13.845 GB.
 - Compilation times:  {'stage-construction': 25.3868408203125, 'stage-construction-dp': 1.2290959358215332, 'stage-construction-compilation': 5.192126512527466, 'stage-construction-profiling': 9.333581686019897}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 32.57093811035156
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_2B_512.pkl`...

------------------------------------------------------------------
- (3/3) Profiling wide_resnet_2B with batch size: 1024...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_2B_1024.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 448
    width_factor = 2
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (1024, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.046 GB, invar_size=0.515 GB, outvar_size=0.670 GB, temp_buffer_size=0.861 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.124, peak_memory=2.479 GB, invar_size=0.760 GB, outvar_size=0.670 GB, temp_buffer_size=1.050 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.145 GB, invar_size=0.800 GB, outvar_size=1.005 GB, temp_buffer_size=1.340 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.529, peak_memory=5.760 GB, invar_size=1.405 GB, outvar_size=1.675 GB, temp_buffer_size=2.680 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.662 GB, invar_size=0.868 GB, outvar_size=0.670 GB, temp_buffer_size=1.125 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.577 GB, invar_size=0.556 GB, outvar_size=1.340 GB, temp_buffer_size=1.681 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.145 GB, invar_size=0.800 GB, outvar_size=1.005 GB, temp_buffer_size=1.340 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.179, peak_memory=4.118 GB, invar_size=1.439 GB, outvar_size=0.670 GB, temp_buffer_size=2.010 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.662 GB, invar_size=0.868 GB, outvar_size=0.670 GB, temp_buffer_size=1.125 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.911 GB, invar_size=0.064 GB, outvar_size=1.172 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.911 GB, invar_size=0.064 GB, outvar_size=1.172 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.577 GB, invar_size=0.556 GB, outvar_size=1.340 GB, temp_buffer_size=1.681 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.314, peak_memory=4.385 GB, invar_size=1.032 GB, outvar_size=1.340 GB, temp_buffer_size=2.013 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.046 GB, invar_size=0.515 GB, outvar_size=0.670 GB, temp_buffer_size=0.861 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.386, peak_memory=3.576 GB, invar_size=0.059 GB, outvar_size=1.507 GB, temp_buffer_size=2.010 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.402, peak_memory=4.735 GB, invar_size=1.519 GB, outvar_size=0.425 GB, temp_buffer_size=2.881 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=3.632 GB, invar_size=1.364 GB, outvar_size=0.514 GB, temp_buffer_size=1.933 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.854 GB, invar_size=0.515 GB, outvar_size=0.670 GB, temp_buffer_size=0.670 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=6.374 GB, invar_size=1.935 GB, outvar_size=0.800 GB, temp_buffer_size=3.769 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.744, peak_memory=9.518 GB, invar_size=3.145 GB, outvar_size=0.735 GB, temp_buffer_size=5.703 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.854 GB, invar_size=0.515 GB, outvar_size=0.670 GB, temp_buffer_size=0.670 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.502, peak_memory=6.939 GB, invar_size=2.207 GB, outvar_size=0.769 GB, temp_buffer_size=4.062 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=5.211 GB, invar_size=1.735 GB, outvar_size=0.867 GB, temp_buffer_size=2.806 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.124, peak_memory=2.435 GB, invar_size=0.760 GB, outvar_size=0.670 GB, temp_buffer_size=1.005 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=5.546 GB, invar_size=2.070 GB, outvar_size=0.867 GB, temp_buffer_size=2.806 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.003, peak_memory=6.709 GB, invar_size=2.270 GB, outvar_size=0.800 GB, temp_buffer_size=3.769 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=7.500 GB, invar_size=1.950 GB, outvar_size=0.556 GB, temp_buffer_size=5.047 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.172 GB, invar_size=0.856 GB, outvar_size=0.503 GB, temp_buffer_size=0.814 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.002, peak_memory=7.500 GB, invar_size=1.950 GB, outvar_size=0.556 GB, temp_buffer_size=5.047 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=1.042, peak_memory=9.778 GB, invar_size=2.399 GB, outvar_size=1.032 GB, temp_buffer_size=6.375 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.814, peak_memory=8.971 GB, invar_size=1.589 GB, outvar_size=0.023 GB, temp_buffer_size=7.382 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.268, peak_memory=3.108 GB, invar_size=0.930 GB, outvar_size=0.837 GB, temp_buffer_size=1.340 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.172 GB, invar_size=0.856 GB, outvar_size=0.503 GB, temp_buffer_size=0.814 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.001, peak_memory=9.178 GB, invar_size=1.952 GB, outvar_size=0.046 GB, temp_buffer_size=7.226 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.001, peak_memory=6.823 GB, invar_size=1.282 GB, outvar_size=0.046 GB, temp_buffer_size=5.540 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.190 GB, invar_size=1.125 GB, outvar_size=0.335 GB, temp_buffer_size=0.730 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=2.405 GB, invar_size=1.065 GB, outvar_size=0.335 GB, temp_buffer_size=1.005 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=3.632 GB, invar_size=1.364 GB, outvar_size=0.514 GB, temp_buffer_size=1.933 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=3.632 GB, invar_size=1.364 GB, outvar_size=0.514 GB, temp_buffer_size=1.933 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.190 GB, invar_size=1.125 GB, outvar_size=0.335 GB, temp_buffer_size=0.730 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.747 GB, invar_size=0.886 GB, outvar_size=0.335 GB, temp_buffer_size=0.526 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=1.711 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.682 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.004, peak_memory=3.632 GB, invar_size=1.364 GB, outvar_size=0.514 GB, temp_buffer_size=1.933 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.402, peak_memory=4.735 GB, invar_size=1.519 GB, outvar_size=0.425 GB, temp_buffer_size=2.881 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.010, peak_memory=3.877 GB, invar_size=1.879 GB, outvar_size=0.856 GB, temp_buffer_size=1.663 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.747 GB, invar_size=0.886 GB, outvar_size=0.335 GB, temp_buffer_size=0.526 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.645 GB, invar_size=0.886 GB, outvar_size=0.335 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=1.532 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.503 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.645 GB, invar_size=0.886 GB, outvar_size=0.335 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.010, peak_memory=4.367 GB, invar_size=2.046 GB, outvar_size=0.856 GB, temp_buffer_size=1.986 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.645 GB, invar_size=0.886 GB, outvar_size=0.335 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.378, peak_memory=4.574 GB, invar_size=2.028 GB, outvar_size=0.595 GB, temp_buffer_size=2.211 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=1.532 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.503 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.015, peak_memory=4.392 GB, invar_size=2.249 GB, outvar_size=1.125 GB, temp_buffer_size=1.808 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.645 GB, invar_size=0.886 GB, outvar_size=0.335 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.261, peak_memory=4.308 GB, invar_size=1.795 GB, outvar_size=0.730 GB, temp_buffer_size=2.178 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=3.392 GB, invar_size=1.938 GB, outvar_size=0.885 GB, temp_buffer_size=1.286 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.645 GB, invar_size=0.886 GB, outvar_size=0.335 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=3.392 GB, invar_size=1.938 GB, outvar_size=0.885 GB, temp_buffer_size=1.286 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.208, peak_memory=3.112 GB, invar_size=1.388 GB, outvar_size=0.526 GB, temp_buffer_size=1.557 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=3.392 GB, invar_size=1.938 GB, outvar_size=0.885 GB, temp_buffer_size=1.286 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.208, peak_memory=3.112 GB, invar_size=1.388 GB, outvar_size=0.526 GB, temp_buffer_size=1.557 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.645 GB, invar_size=0.886 GB, outvar_size=0.335 GB, temp_buffer_size=0.425 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=1.532 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.503 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.015, peak_memory=4.560 GB, invar_size=2.417 GB, outvar_size=1.125 GB, temp_buffer_size=1.808 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=3.392 GB, invar_size=1.938 GB, outvar_size=0.885 GB, temp_buffer_size=1.286 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.208, peak_memory=2.800 GB, invar_size=1.388 GB, outvar_size=0.526 GB, temp_buffer_size=1.245 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.626 GB, invar_size=2.250 GB, outvar_size=0.251 GB, temp_buffer_size=1.125 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=3.225 GB, invar_size=1.938 GB, outvar_size=0.885 GB, temp_buffer_size=1.119 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.148, peak_memory=2.657 GB, invar_size=1.376 GB, outvar_size=0.419 GB, temp_buffer_size=0.862 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.133, peak_memory=2.836 GB, invar_size=1.556 GB, outvar_size=0.419 GB, temp_buffer_size=0.862 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.619 GB, invar_size=3.327 GB, outvar_size=0.168 GB, temp_buffer_size=1.125 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=3.016 GB, invar_size=1.915 GB, outvar_size=0.168 GB, temp_buffer_size=0.933 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=3.225 GB, invar_size=1.938 GB, outvar_size=0.885 GB, temp_buffer_size=1.119 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.208, peak_memory=2.800 GB, invar_size=1.388 GB, outvar_size=0.526 GB, temp_buffer_size=1.245 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=3.225 GB, invar_size=1.938 GB, outvar_size=0.885 GB, temp_buffer_size=1.119 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=3.016 GB, invar_size=1.915 GB, outvar_size=0.168 GB, temp_buffer_size=0.933 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.014, peak_memory=3.225 GB, invar_size=1.938 GB, outvar_size=0.885 GB, temp_buffer_size=1.119 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.102 GB, invar_size=3.010 GB, outvar_size=0.084 GB, temp_buffer_size=1.008 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.397 GB, invar_size=1.631 GB, outvar_size=0.084 GB, temp_buffer_size=0.682 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.063, peak_memory=2.397 GB, invar_size=1.631 GB, outvar_size=0.084 GB, temp_buffer_size=0.682 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.039, peak_memory=8.435 GB, invar_size=4.582 GB, outvar_size=2.249 GB, temp_buffer_size=3.685 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.212, peak_memory=4.715 GB, invar_size=2.836 GB, outvar_size=1.208 GB, temp_buffer_size=1.711 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.060, peak_memory=11.510 GB, invar_size=6.652 GB, outvar_size=3.326 GB, temp_buffer_size=4.690 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.114, peak_memory=4.822 GB, invar_size=3.195 GB, outvar_size=1.388 GB, temp_buffer_size=1.460 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=5.639 GB, invar_size=3.661 GB, outvar_size=1.747 GB, temp_buffer_size=1.810 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=4.611 GB, invar_size=3.178 GB, outvar_size=1.547 GB, temp_buffer_size=1.350 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.055, peak_memory=10.465 GB, invar_size=6.020 GB, outvar_size=3.010 GB, temp_buffer_size=4.362 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.169, peak_memory=5.639 GB, invar_size=3.661 GB, outvar_size=1.747 GB, temp_buffer_size=1.810 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=4.611 GB, invar_size=3.178 GB, outvar_size=1.547 GB, temp_buffer_size=1.350 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 15.02 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.052 GB, invar_size=1.362 GB, outvar_size=1.340 GB, temp_buffer_size=3.350 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=11.448 GB, invar_size=2.725 GB, outvar_size=1.362 GB, temp_buffer_size=7.383 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.105 GB, invar_size=0.760 GB, outvar_size=0.670 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.105 GB, invar_size=0.760 GB, outvar_size=0.670 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.105 GB, invar_size=0.760 GB, outvar_size=0.670 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.781 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=2.058 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.105 GB, invar_size=0.760 GB, outvar_size=0.670 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.105 GB, invar_size=0.760 GB, outvar_size=0.670 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.052 GB, invar_size=1.362 GB, outvar_size=1.340 GB, temp_buffer_size=3.350 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.782 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=2.060 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.105 GB, invar_size=0.760 GB, outvar_size=0.670 GB, temp_buffer_size=1.675 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.781 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=2.058 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.928 GB, invar_size=1.519 GB, outvar_size=0.760 GB, temp_buffer_size=3.739 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.259 GB, invar_size=1.519 GB, outvar_size=0.760 GB, temp_buffer_size=3.069 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.929 GB, invar_size=1.519 GB, outvar_size=0.760 GB, temp_buffer_size=3.739 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.259 GB, invar_size=1.519 GB, outvar_size=0.760 GB, temp_buffer_size=3.069 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.928 GB, invar_size=1.519 GB, outvar_size=0.760 GB, temp_buffer_size=3.739 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.929 GB, invar_size=1.519 GB, outvar_size=0.760 GB, temp_buffer_size=3.739 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=11.448 GB, invar_size=2.725 GB, outvar_size=1.362 GB, temp_buffer_size=7.383 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.782 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=2.060 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=1.795 GB, invar_size=0.694 GB, outvar_size=0.335 GB, temp_buffer_size=0.766 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.842 GB, invar_size=1.604 GB, outvar_size=0.168 GB, temp_buffer_size=1.071 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.842 GB, invar_size=1.604 GB, outvar_size=0.168 GB, temp_buffer_size=1.071 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.447 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=1.725 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.447 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=1.725 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.447 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=1.725 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.447 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=1.725 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.447 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=1.725 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=3.447 GB, invar_size=1.388 GB, outvar_size=0.694 GB, temp_buffer_size=1.725 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.372 GB, invar_size=3.206 GB, outvar_size=1.603 GB, temp_buffer_size=1.998 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.813 GB, invar_size=1.658 GB, outvar_size=0.000 GB, temp_buffer_size=1.154 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=2.813 GB, invar_size=1.658 GB, outvar_size=0.000 GB, temp_buffer_size=1.154 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=5.372 GB, invar_size=3.206 GB, outvar_size=1.603 GB, temp_buffer_size=1.998 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.979 GB, invar_size=3.148 GB, outvar_size=1.658 GB, temp_buffer_size=1.663 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=4.979 GB, invar_size=3.148 GB, outvar_size=1.658 GB, temp_buffer_size=1.663 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 8.30 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 3, 2, 0) has been pruned...
[TMP] Stage (1, 3, 2, 1) has been pruned...
[TMP] Stage (1, 3, 2, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 6, 3, 0) has been pruned...
[TMP] Stage (1, 6, 3, 1) has been pruned...
[TMP] Stage (1, 6, 3, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (2, 4, 2, 0) has been pruned...
[TMP] Stage (2, 4, 2, 1) has been pruned...
[TMP] Stage (2, 4, 2, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 7, 3, 0) has been pruned...
[TMP] Stage (2, 7, 3, 1) has been pruned...
[TMP] Stage (2, 7, 3, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (3, 5, 2, 0) has been pruned...
[TMP] Stage (3, 5, 2, 1) has been pruned...
[TMP] Stage (3, 5, 2, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (5, 7, 2, 0) has been pruned...
[TMP] Stage (5, 7, 2, 1) has been pruned...
[TMP] Stage (5, 7, 2, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{}, {}, {'force_batch_dim_to_mesh_dim': 0}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO comm 0x3f6f660 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO comm 0x5520090 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO comm 0x5f72c00 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO comm 0xa8e95e0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO comm 0x517fad0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO comm 0x9d0a060 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO comm 0x9f60e30 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO comm 0x71c6df0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO comm 0xaf593c0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO comm 0x4673ee0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO comm 0x9a24e20 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO comm 0xb1b66e0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO comm 0xa8ebee0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO comm 0x41f21c0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO comm 0xa955020 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO comm 0x95f3fc0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO comm 0x40c61e0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO comm 0xa4b8c90 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO comm 0x72457f0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO comm 0xa521dd0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3973356)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO comm 0x378e820 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO comm 0x9f843b0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO comm 0xa5b8bd0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO comm 0x8b90660 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [0] NCCL INFO comm 0x42afa40 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO comm 0x9a5a560 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO comm 0x9ac36a0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3230935 [1] NCCL INFO comm 0x62febc0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
 - Compile (driver): 45.91 s
compilation time breakdown: {'stage-construction': '25.37', 'stage-construction-dp': '1.21', 'stage-construction-compilation': '5.15', 'stage-construction-profiling': '9.39'}
 - Compile (worker): 3.43 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914284 [1] NCCL INFO comm 0x7f718e49a700 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO comm 0x7f71ac69b030 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914282 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1914220, ip=192.168.0.56)[0m gpu26:1914220:1914220 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362813 [1] NCCL INFO comm 0x7fe180397920 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO comm 0x7fe19e956610 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362811 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2362696, ip=192.168.0.57)[0m gpu27:2362696:2362696 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225011 [1] NCCL INFO comm 0x7f2d74943e10 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO comm 0x7f2d89ea3850 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3225009 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3224863, ip=192.168.0.58)[0m gpu28:3224863:3224863 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680109 [1] NCCL INFO comm 0x7f472adb67e0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO comm 0x7f47259a4c40 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2680107 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2679961, ip=192.168.0.60)[0m gpu30:2679961:2679961 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313633 [1] NCCL INFO comm 0x7fa3b84bc460 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO comm 0x7fa3d4068120 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313631 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2313557, ip=192.168.0.55)[0m gpu25:2313557:2313557 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3973356)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3973356)[0m 
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973436 [1] NCCL INFO comm 0x7fd80ff93450 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO comm 0x7fd81fb1bbc0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973434 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3973356)[0m gpu37:3973356:3973356 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069475 [1] NCCL INFO comm 0x7f4c95851780 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO comm 0x7f4cadbeab20 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069473 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3069366, ip=192.168.0.72)[0m gpu42:3069366:3069366 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231083 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3230935, ip=192.168.0.59)[0m gpu29:3230935:3231081 [0] NCCL INFO Connected all trees
