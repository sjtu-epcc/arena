
------------------------------------------------------------------
- (1/3) Profiling moe_1.3B with batch size: 256...
------------------------------------------------------------------
[TMP] Profiling results not found in `./jaxpr/prof_log/optimal_prune_no_prof/moe_1.3B_256.pkl`, creating it...
[I] Alpa's built-in profiling database is disabled.
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 2
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f664f9c5d30>
    dtype = float16
    bias_init = zeros
) 

[I] Compiling and executing model with timeout = 3600 s...
[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
[TMP] The range of stage num is (min #stage -> max #stage): 2 -> 4
[I] Coarsening pipeline layers from 16 to 4...
[I] Coarsened scheme: [[0, 1, 2], [3, 4, 5, 6], [7, 8, 9, 10], [11, 12, 13, 14, 15]]
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2))
[TMP] The range of device num per stage is (min #gpu -> max #gpu): 1 -> 2
- Profiling for submesh 2 (2, 2):

[TMP] Since submesh device num (4) > max gpu num per stage (2) or < min gpu num per stage (1), skip compiling and profiling on pruned stages and forge infeasible profiling results for them ...
--------------------------------------------------

- Profiling for submesh 1 (1, 2):
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
[TMP] Layer indices [9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.061, peak_memory=1.912 GB, invar_size=1.256 GB, outvar_size=0.168 GB, temp_buffer_size=0.488 GB, available_memory=35.242 GB)
result[(0, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.179, peak_memory=4.082 GB, invar_size=2.680 GB, outvar_size=1.256 GB, temp_buffer_size=1.402 GB, available_memory=35.446 GB)
result[(0, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.102, peak_memory=1.417 GB, invar_size=0.628 GB, outvar_size=0.301 GB, temp_buffer_size=0.488 GB, available_memory=35.242 GB)
result[(0, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.070, peak_memory=1.350 GB, invar_size=0.694 GB, outvar_size=0.168 GB, temp_buffer_size=0.488 GB, available_memory=35.242 GB)
result[(0, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.227, peak_memory=3.440 GB, invar_size=1.569 GB, outvar_size=0.628 GB, temp_buffer_size=1.871 GB, available_memory=35.446 GB)
result[(3, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=1.723 GB, invar_size=1.242 GB, outvar_size=0.094 GB, temp_buffer_size=0.387 GB, available_memory=35.446 GB)
result[(0, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.193, peak_memory=2.983 GB, invar_size=1.555 GB, outvar_size=0.693 GB, temp_buffer_size=1.428 GB, available_memory=35.242 GB)
result[(3, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.110, peak_memory=1.214 GB, invar_size=0.639 GB, outvar_size=0.176 GB, temp_buffer_size=0.399 GB, available_memory=35.242 GB)
result[(3, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.186, peak_memory=3.955 GB, invar_size=2.567 GB, outvar_size=1.242 GB, temp_buffer_size=1.376 GB, available_memory=35.446 GB)
result[(3, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.071, peak_memory=1.161 GB, invar_size=0.680 GB, outvar_size=0.094 GB, temp_buffer_size=0.387 GB, available_memory=35.446 GB)
result[(3, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.253, peak_memory=3.384 GB, invar_size=1.442 GB, outvar_size=0.639 GB, temp_buffer_size=1.918 GB, available_memory=35.242 GB)
result[(7, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.066, peak_memory=1.716 GB, invar_size=1.247 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(3, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.193, peak_memory=2.830 GB, invar_size=1.442 GB, outvar_size=0.680 GB, temp_buffer_size=1.376 GB, available_memory=35.446 GB)
result[(7, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.107, peak_memory=1.204 GB, invar_size=0.641 GB, outvar_size=0.188 GB, temp_buffer_size=0.376 GB, available_memory=35.446 GB)
result[(7, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.235, peak_memory=4.095 GB, invar_size=2.703 GB, outvar_size=1.310 GB, temp_buffer_size=1.381 GB, available_memory=35.242 GB)
result[(7, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.284, peak_memory=3.607 GB, invar_size=1.510 GB, outvar_size=0.673 GB, temp_buffer_size=2.073 GB, available_memory=35.446 GB)
result[(7, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.091, peak_memory=1.153 GB, invar_size=0.684 GB, outvar_size=0.094 GB, temp_buffer_size=0.375 GB, available_memory=35.242 GB)
result[(7, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.230, peak_memory=2.924 GB, invar_size=1.532 GB, outvar_size=0.725 GB, temp_buffer_size=1.380 GB, available_memory=35.446 GB)
Profiling for submesh 1 (1, 2) takes 91.01 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
[TMP] Layer indices [0, 1, 2, 3] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [12, 13, 14, 15] violates the layer coarsening rules, pruned.
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.057, peak_memory=1.860 GB, invar_size=0.641 GB, outvar_size=0.242 GB, temp_buffer_size=0.977 GB, available_memory=35.446 GB)
result[(0, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.080, peak_memory=1.860 GB, invar_size=0.641 GB, outvar_size=0.242 GB, temp_buffer_size=0.977 GB, available_memory=35.242 GB)
result[(0, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.156, peak_memory=4.307 GB, invar_size=1.524 GB, outvar_size=0.641 GB, temp_buffer_size=2.784 GB, available_memory=35.446 GB)
result[(3, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.507 GB, invar_size=0.639 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(0, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.166, peak_memory=4.307 GB, invar_size=1.524 GB, outvar_size=0.641 GB, temp_buffer_size=2.784 GB, available_memory=35.242 GB)
result[(3, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.061, peak_memory=1.507 GB, invar_size=0.639 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(7, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.070, peak_memory=1.507 GB, invar_size=0.639 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(3, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=4.571 GB, invar_size=1.348 GB, outvar_size=0.639 GB, temp_buffer_size=3.199 GB, available_memory=35.242 GB)
result[(3, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.171, peak_memory=4.571 GB, invar_size=1.348 GB, outvar_size=0.639 GB, temp_buffer_size=3.199 GB, available_memory=35.446 GB)
result[(7, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.064, peak_memory=1.507 GB, invar_size=0.639 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.242 GB)
result[(7, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.170, peak_memory=4.498 GB, invar_size=1.348 GB, outvar_size=0.639 GB, temp_buffer_size=3.127 GB, available_memory=35.446 GB)
result[(11, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.488 GB, invar_size=0.643 GB, outvar_size=0.094 GB, temp_buffer_size=0.751 GB, available_memory=35.446 GB)
result[(7, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.178, peak_memory=4.498 GB, invar_size=1.348 GB, outvar_size=0.639 GB, temp_buffer_size=3.127 GB, available_memory=35.242 GB)
result[(11, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.488 GB, invar_size=0.643 GB, outvar_size=0.094 GB, temp_buffer_size=0.751 GB, available_memory=35.446 GB)
result[(11, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.255, peak_memory=4.952 GB, invar_size=1.484 GB, outvar_size=0.707 GB, temp_buffer_size=3.445 GB, available_memory=35.242 GB)
result[(11, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.241, peak_memory=4.952 GB, invar_size=1.484 GB, outvar_size=0.707 GB, temp_buffer_size=3.445 GB, available_memory=35.446 GB)
Profiling for submesh 0 (1, 1) takes 35.88 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 3, 0, 0) has been pruned...
[TMP] Stage (0, 3, 0, 1) has been pruned...
[TMP] Stage (0, 7, 1, 0) has been pruned...
[TMP] Stage (0, 7, 1, 1) has been pruned...
[TMP] Stage (0, 7, 1, 2) has been pruned...
[TMP] Stage (0, 8, 1, 0) has been pruned...
[TMP] Stage (0, 8, 1, 1) has been pruned...
[TMP] Stage (0, 8, 1, 2) has been pruned...
[TMP] Stage (0, 15, 2, 0) has been pruned...
[TMP] Stage (0, 15, 2, 1) has been pruned...
[TMP] Stage (0, 15, 2, 2) has been pruned...
[TMP] Stage (1, 3, 0, 0) has been pruned...
[TMP] Stage (1, 3, 0, 1) has been pruned...
[TMP] Stage (1, 4, 0, 0) has been pruned...
[TMP] Stage (1, 4, 0, 1) has been pruned...
[TMP] Stage (1, 7, 1, 0) has been pruned...
[TMP] Stage (1, 7, 1, 1) has been pruned...
[TMP] Stage (1, 7, 1, 2) has been pruned...
[TMP] Stage (1, 8, 1, 0) has been pruned...
[TMP] Stage (1, 8, 1, 1) has been pruned...
[TMP] Stage (1, 8, 1, 2) has been pruned...
[TMP] Stage (1, 9, 1, 0) has been pruned...
[TMP] Stage (1, 9, 1, 1) has been pruned...
[TMP] Stage (1, 9, 1, 2) has been pruned...
[TMP] Stage (2, 5, 0, 0) has been pruned...
[TMP] Stage (2, 5, 0, 1) has been pruned...
[TMP] Stage (2, 6, 0, 0) has been pruned...
[TMP] Stage (2, 6, 0, 1) has been pruned...
[TMP] Stage (2, 8, 1, 0) has been pruned...
[TMP] Stage (2, 8, 1, 1) has been pruned...
[TMP] Stage (2, 8, 1, 2) has been pruned...
[TMP] Stage (2, 9, 1, 0) has been pruned...
[TMP] Stage (2, 9, 1, 1) has been pruned...
[TMP] Stage (2, 9, 1, 2) has been pruned...
[TMP] Stage (2, 10, 1, 0) has been pruned...
[TMP] Stage (2, 10, 1, 1) has been pruned...
[TMP] Stage (2, 10, 1, 2) has been pruned...
[TMP] Stage (2, 11, 1, 0) has been pruned...
[TMP] Stage (2, 11, 1, 1) has been pruned...
[TMP] Stage (2, 11, 1, 2) has been pruned...
[TMP] Stage (3, 7, 0, 0) has been pruned...
[TMP] Stage (3, 7, 0, 1) has been pruned...
[TMP] Stage (3, 11, 1, 0) has been pruned...
[TMP] Stage (3, 11, 1, 1) has been pruned...
[TMP] Stage (3, 11, 1, 2) has been pruned...
[TMP] Stage (3, 12, 1, 0) has been pruned...
[TMP] Stage (3, 12, 1, 1) has been pruned...
[TMP] Stage (3, 12, 1, 2) has been pruned...
[TMP] Stage (3, 13, 1, 0) has been pruned...
[TMP] Stage (3, 13, 1, 1) has been pruned...
[TMP] Stage (3, 13, 1, 2) has been pruned...
[TMP] Stage (4, 7, 0, 0) has been pruned...
[TMP] Stage (4, 7, 0, 1) has been pruned...
[TMP] Stage (4, 8, 0, 0) has been pruned...
[TMP] Stage (4, 8, 0, 1) has been pruned...
[TMP] Stage (4, 10, 1, 0) has been pruned...
[TMP] Stage (4, 10, 1, 1) has been pruned...
[TMP] Stage (4, 10, 1, 2) has been pruned...
[TMP] Stage (4, 11, 1, 0) has been pruned...
[TMP] Stage (4, 11, 1, 1) has been pruned...
[TMP] Stage (4, 11, 1, 2) has been pruned...
[TMP] Stage (4, 12, 1, 0) has been pruned...
[TMP] Stage (4, 12, 1, 1) has been pruned...
[TMP] Stage (4, 12, 1, 2) has been pruned...
[TMP] Stage (4, 13, 1, 0) has been pruned...
[TMP] Stage (4, 13, 1, 1) has been pruned...
[TMP] Stage (4, 13, 1, 2) has been pruned...
[TMP] Stage (5, 8, 0, 0) has been pruned...
[TMP] Stage (5, 8, 0, 1) has been pruned...
[TMP] Stage (5, 9, 0, 0) has been pruned...
[TMP] Stage (5, 9, 0, 1) has been pruned...
[TMP] Stage (5, 12, 1, 0) has been pruned...
[TMP] Stage (5, 12, 1, 1) has been pruned...
[TMP] Stage (5, 12, 1, 2) has been pruned...
[TMP] Stage (5, 13, 1, 0) has been pruned...
[TMP] Stage (5, 13, 1, 1) has been pruned...
[TMP] Stage (5, 13, 1, 2) has been pruned...
[TMP] Stage (5, 14, 1, 0) has been pruned...
[TMP] Stage (5, 14, 1, 1) has been pruned...
[TMP] Stage (5, 14, 1, 2) has been pruned...
[TMP] Stage (6, 9, 0, 0) has been pruned...
[TMP] Stage (6, 9, 0, 1) has been pruned...
[TMP] Stage (6, 10, 0, 0) has been pruned...
[TMP] Stage (6, 10, 0, 1) has been pruned...
[TMP] Stage (6, 12, 1, 0) has been pruned...
[TMP] Stage (6, 12, 1, 1) has been pruned...
[TMP] Stage (6, 12, 1, 2) has been pruned...
[TMP] Stage (6, 13, 1, 0) has been pruned...
[TMP] Stage (6, 13, 1, 1) has been pruned...
[TMP] Stage (6, 13, 1, 2) has been pruned...
[TMP] Stage (6, 14, 1, 0) has been pruned...
[TMP] Stage (6, 14, 1, 1) has been pruned...
[TMP] Stage (6, 14, 1, 2) has been pruned...
[TMP] Stage (6, 15, 1, 0) has been pruned...
[TMP] Stage (6, 15, 1, 1) has been pruned...
[TMP] Stage (6, 15, 1, 2) has been pruned...
[TMP] Stage (7, 11, 0, 0) has been pruned...
[TMP] Stage (7, 11, 0, 1) has been pruned...
[TMP] Stage (7, 14, 1, 0) has been pruned...
[TMP] Stage (7, 14, 1, 1) has been pruned...
[TMP] Stage (7, 14, 1, 2) has been pruned...
[TMP] Stage (8, 11, 0, 0) has been pruned...
[TMP] Stage (8, 11, 0, 1) has been pruned...
[TMP] Stage (8, 12, 0, 0) has been pruned...
[TMP] Stage (8, 12, 0, 1) has been pruned...
[TMP] Stage (8, 14, 1, 0) has been pruned...
[TMP] Stage (8, 14, 1, 1) has been pruned...
[TMP] Stage (8, 14, 1, 2) has been pruned...
[TMP] Stage (8, 15, 1, 0) has been pruned...
[TMP] Stage (8, 15, 1, 1) has been pruned...
[TMP] Stage (8, 15, 1, 2) has been pruned...
[TMP] Stage (9, 12, 0, 0) has been pruned...
[TMP] Stage (9, 12, 0, 1) has been pruned...
[TMP] Stage (9, 13, 0, 0) has been pruned...
[TMP] Stage (9, 13, 0, 1) has been pruned...
[TMP] Stage (9, 15, 1, 0) has been pruned...
[TMP] Stage (9, 15, 1, 1) has been pruned...
[TMP] Stage (9, 15, 1, 2) has been pruned...
[TMP] Stage (10, 13, 0, 0) has been pruned...
[TMP] Stage (10, 13, 0, 1) has been pruned...
[TMP] Stage (10, 14, 0, 0) has been pruned...
[TMP] Stage (10, 14, 0, 1) has been pruned...
[TMP] Stage (11, 14, 0, 0) has been pruned...
[TMP] Stage (11, 14, 0, 1) has been pruned...
[TMP] Stage (12, 15, 0, 0) has been pruned...
[TMP] Stage (12, 15, 0, 1) has been pruned...
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12, 13, 14, 15]]
Result mesh_shapes: [(1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 175.47 s
compilation time breakdown: {'stage-construction': '132.96', 'stage-construction-dp': '1.32', 'stage-construction-compilation': '20.65', 'stage-construction-profiling': '87.59'}
 - Compile (worker): 16.54 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 46.17 s

[9.693835735321045, 5.350179672241211, 5.323216676712036, 5.315746307373047, 5.323533296585083, 5.202046871185303, 5.3097825050354]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 27.491 s.
 - Average e2e iteration time: 5.498000144958496 s.
 - Total local training time: 26.474000930786133 s.
 - Average local iteration time: 5.295000076293945 s.
 - Max allocated memory among devices: 7.699 GB.
 - Compilation times:  {'stage-construction': 132.96394205093384, 'stage-construction-dp': 1.3204433917999268, 'stage-construction-compilation': 20.65322518348694, 'stage-construction-profiling': 87.5944561958313}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `2_a40_2_n_2_d`: 5.294865608215332
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal_prune_no_prof/moe_1.3B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling moe_1.3B with batch size: 512...
------------------------------------------------------------------
