
------------------------------------------------------------------
- (1/3) Profiling moe_1.3B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_1.3B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 2
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f65afb589a0>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (2, 1))
- Profiling for submesh 1 (2, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=2.787 GB, invar_size=2.201 GB, outvar_size=0.082 GB, temp_buffer_size=0.504 GB, available_memory=35.242 GB)
result[(0, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.803 GB, invar_size=1.217 GB, outvar_size=0.082 GB, temp_buffer_size=0.504 GB, available_memory=35.242 GB)
result[(0, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.173, peak_memory=8.092 GB, invar_size=5.191 GB, outvar_size=2.554 GB, temp_buffer_size=2.901 GB, available_memory=35.242 GB)
result[(0, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.189, peak_memory=5.842 GB, invar_size=2.941 GB, outvar_size=1.429 GB, temp_buffer_size=2.901 GB, available_memory=35.242 GB)
Profiling for submesh 1 (2, 1) takes 58.04 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(2, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.140 GB, invar_size=1.272 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(1, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.140 GB, invar_size=1.272 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(1, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.140 GB, invar_size=1.272 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(0, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.362 GB, invar_size=1.261 GB, outvar_size=0.094 GB, temp_buffer_size=1.008 GB, available_memory=35.446 GB)
result[(0, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.046, peak_memory=2.362 GB, invar_size=1.261 GB, outvar_size=0.094 GB, temp_buffer_size=1.008 GB, available_memory=35.446 GB)
result[(1, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.055, peak_memory=2.471 GB, invar_size=1.579 GB, outvar_size=0.117 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(1, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.055, peak_memory=2.471 GB, invar_size=1.579 GB, outvar_size=0.117 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(2, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.140 GB, invar_size=1.272 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(2, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=7.778 GB, invar_size=2.614 GB, outvar_size=1.272 GB, temp_buffer_size=5.141 GB, available_memory=35.446 GB)
result[(0, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.129, peak_memory=7.686 GB, invar_size=2.615 GB, outvar_size=1.260 GB, temp_buffer_size=5.071 GB, available_memory=35.446 GB)
result[(1, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=7.847 GB, invar_size=2.614 GB, outvar_size=1.272 GB, temp_buffer_size=5.210 GB, available_memory=35.446 GB)
result[(0, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.129, peak_memory=7.686 GB, invar_size=2.615 GB, outvar_size=1.260 GB, temp_buffer_size=5.071 GB, available_memory=35.446 GB)
result[(1, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=7.847 GB, invar_size=2.614 GB, outvar_size=1.272 GB, temp_buffer_size=5.210 GB, available_memory=35.446 GB)
result[(2, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.055, peak_memory=2.471 GB, invar_size=1.579 GB, outvar_size=0.117 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(3, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.140 GB, invar_size=1.272 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(2, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.055, peak_memory=2.471 GB, invar_size=1.579 GB, outvar_size=0.117 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(1, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.161, peak_memory=8.793 GB, invar_size=3.253 GB, outvar_size=1.579 GB, temp_buffer_size=5.516 GB, available_memory=35.446 GB)
result[(1, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.161, peak_memory=8.793 GB, invar_size=3.253 GB, outvar_size=1.579 GB, temp_buffer_size=5.516 GB, available_memory=35.446 GB)
result[(4, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.808 GB, invar_size=0.964 GB, outvar_size=0.070 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(4, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.808 GB, invar_size=0.964 GB, outvar_size=0.070 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(3, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.140 GB, invar_size=1.272 GB, outvar_size=0.094 GB, temp_buffer_size=0.774 GB, available_memory=35.446 GB)
result[(2, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=7.778 GB, invar_size=2.614 GB, outvar_size=1.272 GB, temp_buffer_size=5.141 GB, available_memory=35.446 GB)
result[(2, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.161, peak_memory=8.909 GB, invar_size=3.253 GB, outvar_size=1.579 GB, temp_buffer_size=5.632 GB, available_memory=35.446 GB)
result[(2, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.161, peak_memory=8.909 GB, invar_size=3.253 GB, outvar_size=1.579 GB, temp_buffer_size=5.632 GB, available_memory=35.446 GB)
result[(3, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=7.989 GB, invar_size=2.614 GB, outvar_size=1.272 GB, temp_buffer_size=5.352 GB, available_memory=35.446 GB)
result[(3, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.130, peak_memory=7.989 GB, invar_size=2.614 GB, outvar_size=1.272 GB, temp_buffer_size=5.352 GB, available_memory=35.446 GB)
result[(4, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.147, peak_memory=8.545 GB, invar_size=2.682 GB, outvar_size=1.318 GB, temp_buffer_size=5.839 GB, available_memory=35.446 GB)
result[(4, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.147, peak_memory=8.545 GB, invar_size=2.682 GB, outvar_size=1.318 GB, temp_buffer_size=5.839 GB, available_memory=35.446 GB)
Profiling for submesh 0 (1, 1) takes 49.32 seconds
--------------------------------------------------
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3], [4, 5, 6, 7]]
Result mesh_shapes: [(1, 1), (1, 1)]
Result logical_mesh_shapes: [(1, 1), (1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {}]
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1034995)[0m 
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO comm 0x3539240 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1034995)[0m 
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1034995)[0m 
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1034995)[0m gpu2:1034995:1034995 [0] NCCL INFO comm 0x3cdf380 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
 - Compile (driver): 143.75 s
compilation time breakdown: {'stage-construction': '111.17', 'stage-construction-dp': '1.35', 'stage-construction-compilation': '35.72', 'stage-construction-profiling': '36.59'}
 - Compile (worker): 14.68 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2364784, ip=192.168.0.18)[0m gpu3:2364784:2364784 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 67.51 s

[10.377764701843262, 8.860941410064697, 8.86095380783081, 8.855651378631592, 8.854485034942627, 8.85242247581482, 8.852830410003662]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 45.776 s.
 - Average e2e iteration time: 9.155000686645508 s.
 - Total local training time: 44.2760009765625 s.
 - Average local iteration time: 8.855000495910645 s.
 - Max allocated memory among devices: 12.545 GB.
 - Compilation times:  {'stage-construction': 111.16702699661255, 'stage-construction-dp': 1.350961685180664, 'stage-construction-compilation': 35.71749830245972, 'stage-construction-profiling': 36.58593130111694}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `2_a40_2_n_1_d`: 8.855269432067871
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_1.3B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling moe_1.3B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_1.3B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 2
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7fc3a3590850>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (2, 1))
- Profiling for submesh 1 (2, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.080, peak_memory=3.373 GB, invar_size=2.201 GB, outvar_size=0.164 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(0, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.112, peak_memory=2.389 GB, invar_size=1.217 GB, outvar_size=0.164 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(0, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.300, peak_memory=11.075 GB, invar_size=5.273 GB, outvar_size=2.554 GB, temp_buffer_size=5.801 GB, available_memory=35.242 GB)
result[(0, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.351, peak_memory=8.825 GB, invar_size=3.023 GB, outvar_size=1.429 GB, temp_buffer_size=5.801 GB, available_memory=35.242 GB)
Profiling for submesh 1 (2, 1) takes 59.25 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(1, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=3.031 GB, invar_size=1.295 GB, outvar_size=0.188 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(0, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=3.464 GB, invar_size=1.261 GB, outvar_size=0.188 GB, temp_buffer_size=2.016 GB, available_memory=35.446 GB)
result[(2, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=3.031 GB, invar_size=1.295 GB, outvar_size=0.188 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(0, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.090, peak_memory=3.464 GB, invar_size=1.261 GB, outvar_size=0.188 GB, temp_buffer_size=2.016 GB, available_memory=35.446 GB)
result[(1, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=3.031 GB, invar_size=1.295 GB, outvar_size=0.188 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(1, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.107, peak_memory=3.385 GB, invar_size=1.603 GB, outvar_size=0.234 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(1, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.107, peak_memory=3.385 GB, invar_size=1.603 GB, outvar_size=0.234 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(0, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.251, peak_memory=12.849 GB, invar_size=2.709 GB, outvar_size=1.260 GB, temp_buffer_size=10.140 GB, available_memory=35.446 GB)
result[(0, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.251, peak_memory=12.849 GB, invar_size=2.709 GB, outvar_size=1.260 GB, temp_buffer_size=10.140 GB, available_memory=35.446 GB)
result[(1, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.252, peak_memory=13.196 GB, invar_size=2.731 GB, outvar_size=1.295 GB, temp_buffer_size=10.418 GB, available_memory=35.446 GB)
result[(2, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=3.031 GB, invar_size=1.295 GB, outvar_size=0.188 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(2, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.252, peak_memory=13.058 GB, invar_size=2.731 GB, outvar_size=1.295 GB, temp_buffer_size=10.280 GB, available_memory=35.446 GB)
result[(1, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.252, peak_memory=13.196 GB, invar_size=2.731 GB, outvar_size=1.295 GB, temp_buffer_size=10.418 GB, available_memory=35.446 GB)
result[(2, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.107, peak_memory=3.385 GB, invar_size=1.603 GB, outvar_size=0.234 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(3, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=3.031 GB, invar_size=1.295 GB, outvar_size=0.188 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(2, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.107, peak_memory=3.385 GB, invar_size=1.603 GB, outvar_size=0.234 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(1, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.312, peak_memory=14.471 GB, invar_size=3.393 GB, outvar_size=1.603 GB, temp_buffer_size=11.031 GB, available_memory=35.446 GB)
result[(1, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.312, peak_memory=14.471 GB, invar_size=3.393 GB, outvar_size=1.603 GB, temp_buffer_size=11.031 GB, available_memory=35.446 GB)
result[(4, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.066, peak_memory=2.676 GB, invar_size=0.988 GB, outvar_size=0.141 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(4, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.066, peak_memory=2.676 GB, invar_size=0.988 GB, outvar_size=0.141 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(3, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=3.031 GB, invar_size=1.295 GB, outvar_size=0.188 GB, temp_buffer_size=1.548 GB, available_memory=35.446 GB)
result[(2, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.252, peak_memory=13.058 GB, invar_size=2.731 GB, outvar_size=1.295 GB, temp_buffer_size=10.280 GB, available_memory=35.446 GB)
result[(2, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.312, peak_memory=14.704 GB, invar_size=3.393 GB, outvar_size=1.603 GB, temp_buffer_size=11.263 GB, available_memory=35.446 GB)
result[(2, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.312, peak_memory=14.704 GB, invar_size=3.393 GB, outvar_size=1.603 GB, temp_buffer_size=11.263 GB, available_memory=35.446 GB)
result[(3, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.252, peak_memory=13.480 GB, invar_size=2.731 GB, outvar_size=1.295 GB, temp_buffer_size=10.702 GB, available_memory=35.446 GB)
result[(3, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.252, peak_memory=13.480 GB, invar_size=2.731 GB, outvar_size=1.295 GB, temp_buffer_size=10.702 GB, available_memory=35.446 GB)
result[(4, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.287, peak_memory=14.499 GB, invar_size=2.776 GB, outvar_size=1.341 GB, temp_buffer_size=11.676 GB, available_memory=35.446 GB)
result[(4, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.287, peak_memory=14.499 GB, invar_size=2.776 GB, outvar_size=1.341 GB, temp_buffer_size=11.676 GB, available_memory=35.446 GB)
Profiling for submesh 0 (1, 1) takes 50.27 seconds
--------------------------------------------------
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3], [4, 5, 6, 7]]
Result mesh_shapes: [(1, 1), (1, 1)]
Result logical_mesh_shapes: [(1, 1), (1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1040918)[0m 
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.16<0>
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1040918)[0m 
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1040918)[0m 
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO comm 0x40a1710 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1040918)[0m gpu2:1040918:1040918 [0] NCCL INFO comm 0x4dfcee0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
 - Compile (driver): 145.95 s
compilation time breakdown: {'stage-construction': '113.33', 'stage-construction-dp': '1.35', 'stage-construction-compilation': '37.13', 'stage-construction-profiling': '36.71'}
 - Compile (worker): 14.88 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2367914, ip=192.168.0.18)[0m gpu3:2367914:2367914 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 130.19 s

[19.398152351379395, 17.524243354797363, 17.546199560165405, 17.550330638885498, 17.547994375228882, 17.53873348236084, 17.544631242752075]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 90.406 s.
 - Average e2e iteration time: 18.08100128173828 s.
 - Total local training time: 87.7280044555664 s.
 - Average local iteration time: 17.546001434326172 s.
 - Max allocated memory among devices: 19.908 GB.
 - Compilation times:  {'stage-construction': 113.33290219306946, 'stage-construction-dp': 1.351438045501709, 'stage-construction-compilation': 37.13179397583008, 'stage-construction-profiling': 36.70805263519287}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `2_a40_2_n_1_d`: 17.545578002929688
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_1.3B_512.pkl`...

------------------------------------------------------------------
- (3/3) Profiling moe_1.3B with batch size: 1024...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_1.3B_1024.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 2
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f8e729d17f0>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (2, 1))
- Profiling for submesh 1 (2, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.156, peak_memory=4.545 GB, invar_size=2.201 GB, outvar_size=0.328 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(0, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.218, peak_memory=3.561 GB, invar_size=1.217 GB, outvar_size=0.328 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(0, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.562, peak_memory=17.041 GB, invar_size=5.438 GB, outvar_size=2.554 GB, temp_buffer_size=11.603 GB, available_memory=35.242 GB)
result[(0, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.682, peak_memory=14.791 GB, invar_size=3.188 GB, outvar_size=1.429 GB, temp_buffer_size=11.603 GB, available_memory=35.242 GB)
Profiling for submesh 1 (2, 1) takes 58.28 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.176, peak_memory=5.667 GB, invar_size=1.261 GB, outvar_size=0.375 GB, temp_buffer_size=4.031 GB, available_memory=35.446 GB)
result[(2, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.170, peak_memory=4.813 GB, invar_size=1.342 GB, outvar_size=0.375 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(0, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.176, peak_memory=5.667 GB, invar_size=1.261 GB, outvar_size=0.375 GB, temp_buffer_size=4.031 GB, available_memory=35.446 GB)
result[(1, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.170, peak_memory=4.813 GB, invar_size=1.342 GB, outvar_size=0.375 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(1, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.170, peak_memory=4.813 GB, invar_size=1.342 GB, outvar_size=0.375 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(1, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.210, peak_memory=5.215 GB, invar_size=1.650 GB, outvar_size=0.469 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(1, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.210, peak_memory=5.215 GB, invar_size=1.650 GB, outvar_size=0.469 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(0, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.493, peak_memory=23.173 GB, invar_size=2.896 GB, outvar_size=1.260 GB, temp_buffer_size=20.276 GB, available_memory=35.446 GB)
result[(1, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.493, peak_memory=23.894 GB, invar_size=2.966 GB, outvar_size=1.342 GB, temp_buffer_size=20.835 GB, available_memory=35.446 GB)
result[(0, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.493, peak_memory=23.173 GB, invar_size=2.896 GB, outvar_size=1.260 GB, temp_buffer_size=20.276 GB, available_memory=35.446 GB)
result[(2, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.170, peak_memory=4.813 GB, invar_size=1.342 GB, outvar_size=0.375 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(1, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.493, peak_memory=23.894 GB, invar_size=2.966 GB, outvar_size=1.342 GB, temp_buffer_size=20.835 GB, available_memory=35.446 GB)
result[(2, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.493, peak_memory=23.616 GB, invar_size=2.966 GB, outvar_size=1.342 GB, temp_buffer_size=20.556 GB, available_memory=35.446 GB)
result[(2, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.210, peak_memory=5.215 GB, invar_size=1.650 GB, outvar_size=0.469 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(2, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.210, peak_memory=5.215 GB, invar_size=1.650 GB, outvar_size=0.469 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(3, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.170, peak_memory=4.813 GB, invar_size=1.342 GB, outvar_size=0.375 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(1, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.611, peak_memory=25.826 GB, invar_size=3.675 GB, outvar_size=1.650 GB, temp_buffer_size=22.058 GB, available_memory=35.446 GB)
result[(1, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.611, peak_memory=25.826 GB, invar_size=3.675 GB, outvar_size=1.650 GB, temp_buffer_size=22.058 GB, available_memory=35.446 GB)
result[(4, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.130, peak_memory=4.412 GB, invar_size=1.035 GB, outvar_size=0.281 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(4, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.130, peak_memory=4.412 GB, invar_size=1.035 GB, outvar_size=0.281 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(3, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.170, peak_memory=4.813 GB, invar_size=1.342 GB, outvar_size=0.375 GB, temp_buffer_size=3.096 GB, available_memory=35.446 GB)
result[(2, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.493, peak_memory=23.616 GB, invar_size=2.966 GB, outvar_size=1.342 GB, temp_buffer_size=20.556 GB, available_memory=35.446 GB)
result[(2, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.611, peak_memory=26.293 GB, invar_size=3.675 GB, outvar_size=1.650 GB, temp_buffer_size=22.524 GB, available_memory=35.446 GB)
result[(2, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.611, peak_memory=26.293 GB, invar_size=3.675 GB, outvar_size=1.650 GB, temp_buffer_size=22.524 GB, available_memory=35.446 GB)
result[(4, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.562, peak_memory=26.407 GB, invar_size=2.964 GB, outvar_size=1.388 GB, temp_buffer_size=23.350 GB, available_memory=35.446 GB)
result[(3, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.493, peak_memory=24.460 GB, invar_size=2.966 GB, outvar_size=1.342 GB, temp_buffer_size=21.400 GB, available_memory=35.446 GB)
result[(3, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.493, peak_memory=24.460 GB, invar_size=2.966 GB, outvar_size=1.342 GB, temp_buffer_size=21.400 GB, available_memory=35.446 GB)
result[(4, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.562, peak_memory=26.407 GB, invar_size=2.964 GB, outvar_size=1.388 GB, temp_buffer_size=23.350 GB, available_memory=35.446 GB)
Profiling for submesh 0 (1, 1) takes 49.12 seconds
--------------------------------------------------
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7]]
Result mesh_shapes: [(2, 1)]
Result logical_mesh_shapes: [(2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 157.84 s
compilation time breakdown: {'stage-construction': '110.83', 'stage-construction-dp': '1.12', 'stage-construction-compilation': '36.75', 'stage-construction-profiling': '36.71'}
 - Compile (worker): 31.54 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.17<0>
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m 
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO comm 0x3f750700 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2371258, ip=192.168.0.18)[0m gpu3:2371258:2371258 [0] NCCL INFO Launch mode Parallel
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 225.07 s

[32.47681164741516, 31.210955142974854, 31.198041677474976, 31.199490547180176, 31.201894760131836, 31.18455958366394, 31.192134380340576]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 157.665 s.
 - Average e2e iteration time: 31.533000946044922 s.
 - Total local training time: 155.97601318359375 s.
 - Average local iteration time: 31.19500160217285 s.
 - Max allocated memory among devices: 24.532 GB.
 - Compilation times:  {'stage-construction': 110.83195877075195, 'stage-construction-dp': 1.123978614807129, 'stage-construction-compilation': 36.745259046554565, 'stage-construction-profiling': 36.70662212371826}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `2_a40_2_n_1_d`: 31.19522476196289
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_1.3B_1024.pkl`...
