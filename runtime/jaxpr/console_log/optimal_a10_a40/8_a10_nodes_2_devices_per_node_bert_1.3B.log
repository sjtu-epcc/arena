
------------------------------------------------------------------
- (1/3) Profiling bert_1.3B with batch size: 128...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_128.pkl`, updating/rewriting it...
[WARN] Local batch size 8 is not divisible by num devices 16, skipping...
[TMP] Current profiling results of key `8_a10_8_n_2_d`: none
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_128.pkl`...

------------------------------------------------------------------
- (2/3) Profiling bert_1.3B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7fdad47139d0>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.103, peak_memory=0.985 GB, invar_size=0.235 GB, outvar_size=0.125 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=1.031 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.043, peak_memory=1.260 GB, invar_size=0.416 GB, outvar_size=0.062 GB, temp_buffer_size=0.781 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.093, peak_memory=1.083 GB, invar_size=0.208 GB, outvar_size=0.094 GB, temp_buffer_size=0.781 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.103, peak_memory=0.985 GB, invar_size=0.235 GB, outvar_size=0.125 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.052, peak_memory=1.224 GB, invar_size=0.318 GB, outvar_size=0.062 GB, temp_buffer_size=0.844 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=1.031 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.000 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.000 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=0.922 GB, invar_size=0.203 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.094, peak_memory=0.938 GB, invar_size=0.219 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=1.031 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=1.031 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=1.031 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.103, peak_memory=0.985 GB, invar_size=0.235 GB, outvar_size=0.125 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=1.031 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.203, peak_memory=3.731 GB, invar_size=0.541 GB, outvar_size=0.208 GB, temp_buffer_size=3.189 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=4.133 GB, invar_size=0.532 GB, outvar_size=0.235 GB, temp_buffer_size=3.538 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.000 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.113, peak_memory=3.928 GB, invar_size=0.895 GB, outvar_size=0.416 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.000 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.094, peak_memory=0.938 GB, invar_size=0.219 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.123, peak_memory=3.793 GB, invar_size=0.729 GB, outvar_size=0.318 GB, temp_buffer_size=3.064 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=3.846 GB, invar_size=0.782 GB, outvar_size=0.375 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=4.133 GB, invar_size=0.532 GB, outvar_size=0.235 GB, temp_buffer_size=3.538 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.225, peak_memory=3.948 GB, invar_size=0.500 GB, outvar_size=0.219 GB, temp_buffer_size=3.385 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.094, peak_memory=3.378 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.691 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=3.846 GB, invar_size=0.782 GB, outvar_size=0.375 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.205, peak_memory=3.349 GB, invar_size=0.469 GB, outvar_size=0.203 GB, temp_buffer_size=2.818 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.105, peak_memory=3.752 GB, invar_size=0.719 GB, outvar_size=0.344 GB, temp_buffer_size=3.002 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.094, peak_memory=3.378 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.691 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.105, peak_memory=3.815 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=3.846 GB, invar_size=0.782 GB, outvar_size=0.375 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=0.953 GB, invar_size=0.203 GB, outvar_size=0.125 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=0.922 GB, invar_size=0.203 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.230, peak_memory=3.787 GB, invar_size=0.532 GB, outvar_size=0.235 GB, temp_buffer_size=3.193 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.087, peak_memory=0.953 GB, invar_size=0.203 GB, outvar_size=0.125 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=3.846 GB, invar_size=0.782 GB, outvar_size=0.375 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.110, peak_memory=3.878 GB, invar_size=0.782 GB, outvar_size=0.375 GB, temp_buffer_size=3.066 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.213, peak_memory=4.134 GB, invar_size=0.500 GB, outvar_size=0.219 GB, temp_buffer_size=3.571 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.102, peak_memory=3.847 GB, invar_size=0.719 GB, outvar_size=0.344 GB, temp_buffer_size=3.097 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.110, peak_memory=3.941 GB, invar_size=0.813 GB, outvar_size=0.375 GB, temp_buffer_size=3.097 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=0.922 GB, invar_size=0.203 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.102, peak_memory=3.879 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=3.097 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.000 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=1.031 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=3.440 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.752 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.034, peak_memory=1.000 GB, invar_size=0.344 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.094, peak_memory=0.938 GB, invar_size=0.219 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.195, peak_memory=3.758 GB, invar_size=0.469 GB, outvar_size=0.203 GB, temp_buffer_size=3.226 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.195, peak_memory=3.283 GB, invar_size=0.469 GB, outvar_size=0.203 GB, temp_buffer_size=2.752 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.103, peak_memory=0.985 GB, invar_size=0.235 GB, outvar_size=0.125 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=3.440 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.752 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.037, peak_memory=1.031 GB, invar_size=0.375 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=3.377 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.689 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=3.439 GB, invar_size=0.688 GB, outvar_size=0.313 GB, temp_buffer_size=2.720 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.081, peak_memory=0.922 GB, invar_size=0.203 GB, outvar_size=0.094 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.195, peak_memory=3.692 GB, invar_size=0.469 GB, outvar_size=0.203 GB, temp_buffer_size=3.160 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=3.408 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.720 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.030, peak_memory=0.969 GB, invar_size=0.313 GB, outvar_size=0.062 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=3.408 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.720 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=0.781 GB, invar_size=0.156 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.042, peak_memory=0.813 GB, invar_size=0.125 GB, outvar_size=0.062 GB, temp_buffer_size=0.625 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.094, peak_memory=3.378 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.691 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.014, peak_memory=0.781 GB, invar_size=0.156 GB, outvar_size=0.031 GB, temp_buffer_size=0.594 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.205, peak_memory=3.349 GB, invar_size=0.469 GB, outvar_size=0.203 GB, temp_buffer_size=2.818 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.094, peak_memory=3.378 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.691 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.225, peak_memory=3.948 GB, invar_size=0.500 GB, outvar_size=0.219 GB, temp_buffer_size=3.385 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.105, peak_memory=3.752 GB, invar_size=0.719 GB, outvar_size=0.344 GB, temp_buffer_size=3.002 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.232, peak_memory=4.133 GB, invar_size=0.532 GB, outvar_size=0.235 GB, temp_buffer_size=3.538 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=3.846 GB, invar_size=0.782 GB, outvar_size=0.375 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.105, peak_memory=3.815 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=3.377 GB, invar_size=0.657 GB, outvar_size=0.313 GB, temp_buffer_size=2.689 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.195, peak_memory=3.283 GB, invar_size=0.469 GB, outvar_size=0.203 GB, temp_buffer_size=2.752 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.112, peak_memory=3.846 GB, invar_size=0.782 GB, outvar_size=0.375 GB, temp_buffer_size=3.033 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.121, peak_memory=3.596 GB, invar_size=0.844 GB, outvar_size=0.422 GB, temp_buffer_size=2.721 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.093, peak_memory=3.439 GB, invar_size=0.688 GB, outvar_size=0.313 GB, temp_buffer_size=2.720 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.205, peak_memory=3.522 GB, invar_size=0.516 GB, outvar_size=0.258 GB, temp_buffer_size=2.944 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.131, peak_memory=3.400 GB, invar_size=0.649 GB, outvar_size=0.324 GB, temp_buffer_size=2.720 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 24.70 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.417 GB, invar_size=0.229 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.045, peak_memory=2.417 GB, invar_size=0.229 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.500 GB, invar_size=0.250 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.500 GB, invar_size=0.250 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.500 GB, invar_size=0.250 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.500 GB, invar_size=0.250 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.500 GB, invar_size=0.250 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.097, peak_memory=4.726 GB, invar_size=0.520 GB, outvar_size=0.229 GB, temp_buffer_size=4.206 GB, available_memory=17.580 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.500 GB, invar_size=0.250 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.097, peak_memory=4.726 GB, invar_size=0.520 GB, outvar_size=0.229 GB, temp_buffer_size=4.206 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.115, peak_memory=6.695 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=6.132 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.084, peak_memory=5.820 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.382 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.084, peak_memory=5.820 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.382 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.115, peak_memory=6.695 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=6.132 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=6.566 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=6.003 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=6.566 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=6.003 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=6.566 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=6.003 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=6.566 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=6.003 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.082, peak_memory=5.816 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.378 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.082, peak_memory=5.879 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.441 GB, available_memory=17.580 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.082, peak_memory=5.879 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.441 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.082, peak_memory=5.816 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.378 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.500 GB, invar_size=0.250 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(13, 13, 0, 0), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(13, 13, 0, 1), 0] = ModuleProfileResult(compute_cost=0.033, peak_memory=2.407 GB, invar_size=0.219 GB, outvar_size=0.062 GB, temp_buffer_size=2.126 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.040, peak_memory=1.500 GB, invar_size=0.250 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.084, peak_memory=5.820 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.382 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.082, peak_memory=5.816 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.378 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.084, peak_memory=5.820 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.382 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.082, peak_memory=5.816 GB, invar_size=0.375 GB, outvar_size=0.188 GB, temp_buffer_size=5.378 GB, available_memory=17.580 GB)
result[(13, 13, 0, 0), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(13, 13, 0, 1), 1] = ModuleProfileResult(compute_cost=0.098, peak_memory=4.380 GB, invar_size=0.438 GB, outvar_size=0.219 GB, temp_buffer_size=3.880 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.151, peak_memory=4.532 GB, invar_size=0.594 GB, outvar_size=0.328 GB, temp_buffer_size=3.875 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.151, peak_memory=4.532 GB, invar_size=0.594 GB, outvar_size=0.328 GB, temp_buffer_size=3.875 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=6.566 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=6.003 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.119, peak_memory=6.566 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=6.003 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 13.97 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 2, 2, 0) has been pruned...
[TMP] Stage (0, 2, 2, 1) has been pruned...
[TMP] Stage (0, 2, 2, 2) has been pruned...
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (1, 10, 3, 0) has been pruned...
[TMP] Stage (1, 10, 3, 1) has been pruned...
[TMP] Stage (1, 10, 3, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (2, 11, 3, 0) has been pruned...
[TMP] Stage (2, 11, 3, 1) has been pruned...
[TMP] Stage (2, 11, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (3, 12, 3, 0) has been pruned...
[TMP] Stage (3, 12, 3, 1) has been pruned...
[TMP] Stage (3, 12, 3, 2) has been pruned...
[TMP] Stage (4, 6, 2, 0) has been pruned...
[TMP] Stage (4, 6, 2, 1) has been pruned...
[TMP] Stage (4, 6, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (4, 13, 3, 0) has been pruned...
[TMP] Stage (4, 13, 3, 1) has been pruned...
[TMP] Stage (4, 13, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 9, 2, 0) has been pruned...
[TMP] Stage (5, 9, 2, 1) has been pruned...
[TMP] Stage (5, 9, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 10, 2, 0) has been pruned...
[TMP] Stage (6, 10, 2, 1) has been pruned...
[TMP] Stage (6, 10, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}, {}, {}, {}, {}, {'force_batch_dim_to_mesh_dim': 0}, {}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO comm 0x3dffd60 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO comm 0x4fe6cd0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO comm 0x60042d0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO comm 0x71eabf0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO comm 0x9e514a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO comm 0x4b78f00 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO comm 0x9de8360 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO comm 0x6926500 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3981377)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO comm 0x4a0aa10 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO comm 0xa8f9be0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO comm 0xafecf90 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO comm 0x7dd2c20 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO comm 0x49fc2e0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO comm 0xae1f220 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO comm 0xadb60e0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO comm 0x6a6e0f0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO comm 0xa806f60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO comm 0x484c600 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO comm 0x6b74d90 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO comm 0xaa5dd30 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO comm 0xc1552a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO comm 0x40748a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO comm 0xbf53a70 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO comm 0x6273c00 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO comm 0xa0bd830 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [0] NCCL INFO comm 0x40a0e90 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO comm 0xa0546f0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684013 [1] NCCL INFO comm 0x94980b0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
 - Compile (driver): 77.41 s
compilation time breakdown: {'stage-construction': '42.02', 'stage-construction-dp': '1.22', 'stage-construction-compilation': '8.81', 'stage-construction-profiling': '9.62'}
 - Compile (worker): 3.18 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366630 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229266 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981377 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918386 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071147 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235032 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317352 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO comm 0x7f9ed940f430 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684162 [1] NCCL INFO comm 0x7f9ee3562e50 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2684013, ip=192.168.0.60)[0m gpu30:2684013:2684160 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO comm 0x7fae7e1da4a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317458 [1] NCCL INFO comm 0x7fae84617b30 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO comm 0x7fe436006a70 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235179 [1] NCCL INFO comm 0x7fe43b454370 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071258 [1] NCCL INFO comm 0x7fb7af43f7f0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO comm 0x7fb7b7eefb30 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3071147, ip=192.168.0.72)[0m gpu42:3071147:3071256 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918450 [1] NCCL INFO comm 0x7f8c69c2ec70 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO comm 0x7f8c64a9cc40 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1918386, ip=192.168.0.56)[0m gpu26:1918386:1918448 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3981377)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3981377)[0m 
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO comm 0x7fb957236640 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981541 [1] NCCL INFO comm 0x7fb95c3a50c0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229330 [1] NCCL INFO comm 0x7f3a5a60bcd0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO comm 0x7f3a6301a390 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO comm 0x7f90ed9b1550 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366694 [1] NCCL INFO comm 0x7f91198a25b0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2317352, ip=192.168.0.55)[0m gpu25:2317352:2317456 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3235032, ip=192.168.0.59)[0m gpu29:3235032:3235177 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3981377)[0m gpu37:3981377:3981539 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3229266, ip=192.168.0.58)[0m gpu28:3229266:3229328 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2366630, ip=192.168.0.57)[0m gpu27:2366630:2366692 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 61.71 s

[17.0864098072052, 6.861104488372803, 6.891299486160278, 6.929945468902588, 6.918041467666626, 6.923854351043701, 6.913816213607788]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 36.035 s.
 - Average e2e iteration time: 7.207000255584717 s.
 - Total local training time: 34.577003479003906 s.
 - Average local iteration time: 6.9150004386901855 s.
 - Max allocated memory among devices: 5.847 GB.
 - Compilation times:  {'stage-construction': 42.01871204376221, 'stage-construction-dp': 1.2236552238464355, 'stage-construction-compilation': 8.807126998901367, 'stage-construction-profiling': 9.618938684463501}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 6.915391445159912
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_256.pkl`...

------------------------------------------------------------------
- (3/3) Profiling bert_1.3B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/bert_1.3B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 8
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f8c9ad58790>
    dtype = float16
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2), (2, 2), (4, 2))
- Profiling for submesh 3 (4, 2):
[TMP] Skip profiling of 4 due to legacy error in tensorflow...
- Profiling for submesh 2 (2, 2):
[TMP] Skip profiling of 2 due to legacy error in tensorflow...
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(4, 5, 1, 1), 0] = ModuleProfileResult(compute_cost=0.205, peak_memory=1.797 GB, invar_size=0.297 GB, outvar_size=0.250 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 0] = ModuleProfileResult(compute_cost=0.073, peak_memory=1.719 GB, invar_size=0.406 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=2.104 GB, invar_size=0.416 GB, outvar_size=0.125 GB, temp_buffer_size=1.563 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=2.104 GB, invar_size=0.416 GB, outvar_size=0.125 GB, temp_buffer_size=1.563 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.688 GB, invar_size=0.375 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 0] = ModuleProfileResult(compute_cost=0.161, peak_memory=1.703 GB, invar_size=0.266 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 0] = ModuleProfileResult(compute_cost=0.185, peak_memory=1.958 GB, invar_size=0.208 GB, outvar_size=0.188 GB, temp_buffer_size=1.563 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 0] = ModuleProfileResult(compute_cost=0.073, peak_memory=1.719 GB, invar_size=0.406 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.688 GB, invar_size=0.375 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 0] = ModuleProfileResult(compute_cost=0.187, peak_memory=1.719 GB, invar_size=0.281 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 0] = ModuleProfileResult(compute_cost=0.073, peak_memory=1.719 GB, invar_size=0.406 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 0] = ModuleProfileResult(compute_cost=0.205, peak_memory=1.797 GB, invar_size=0.297 GB, outvar_size=0.250 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 0] = ModuleProfileResult(compute_cost=0.073, peak_memory=1.719 GB, invar_size=0.406 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 0] = ModuleProfileResult(compute_cost=0.073, peak_memory=1.719 GB, invar_size=0.406 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 0] = ModuleProfileResult(compute_cost=0.205, peak_memory=1.797 GB, invar_size=0.297 GB, outvar_size=0.250 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(4, 5, 1, 1), 1] = ModuleProfileResult(compute_cost=0.463, peak_memory=7.918 GB, invar_size=0.719 GB, outvar_size=0.297 GB, temp_buffer_size=7.074 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 0] = ModuleProfileResult(compute_cost=0.073, peak_memory=1.719 GB, invar_size=0.406 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.688 GB, invar_size=0.375 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(0, 1, 1, 1), 1] = ModuleProfileResult(compute_cost=0.405, peak_memory=7.045 GB, invar_size=0.667 GB, outvar_size=0.208 GB, temp_buffer_size=6.379 GB, available_memory=17.580 GB)
result[(0, 1, 1, 0), 1] = ModuleProfileResult(compute_cost=0.220, peak_memory=7.023 GB, invar_size=0.957 GB, outvar_size=0.416 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 0] = ModuleProfileResult(compute_cost=0.187, peak_memory=1.719 GB, invar_size=0.281 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.688 GB, invar_size=0.375 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(0, 1, 1, 2), 1] = ModuleProfileResult(compute_cost=0.220, peak_memory=7.148 GB, invar_size=1.020 GB, outvar_size=0.416 GB, temp_buffer_size=6.128 GB, available_memory=17.580 GB)
result[(4, 5, 1, 0), 1] = ModuleProfileResult(compute_cost=0.220, peak_memory=7.004 GB, invar_size=0.875 GB, outvar_size=0.406 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(2, 3, 1, 1), 1] = ModuleProfileResult(compute_cost=0.408, peak_memory=6.416 GB, invar_size=0.657 GB, outvar_size=0.266 GB, temp_buffer_size=5.635 GB, available_memory=17.580 GB)
result[(2, 3, 1, 0), 1] = ModuleProfileResult(compute_cost=0.184, peak_memory=6.194 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.381 GB, available_memory=17.580 GB)
result[(3, 4, 1, 1), 1] = ModuleProfileResult(compute_cost=0.449, peak_memory=7.579 GB, invar_size=0.688 GB, outvar_size=0.281 GB, temp_buffer_size=6.767 GB, available_memory=17.580 GB)
result[(2, 3, 1, 2), 1] = ModuleProfileResult(compute_cost=0.184, peak_memory=6.194 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.381 GB, available_memory=17.580 GB)
result[(1, 2, 1, 1), 1] = ModuleProfileResult(compute_cost=0.463, peak_memory=7.918 GB, invar_size=0.719 GB, outvar_size=0.297 GB, temp_buffer_size=7.074 GB, available_memory=17.580 GB)
result[(3, 4, 1, 0), 1] = ModuleProfileResult(compute_cost=0.206, peak_memory=6.879 GB, invar_size=0.813 GB, outvar_size=0.375 GB, temp_buffer_size=6.003 GB, available_memory=17.580 GB)
result[(1, 2, 1, 0), 1] = ModuleProfileResult(compute_cost=0.220, peak_memory=7.004 GB, invar_size=0.875 GB, outvar_size=0.406 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(1, 2, 1, 2), 1] = ModuleProfileResult(compute_cost=0.220, peak_memory=7.004 GB, invar_size=0.875 GB, outvar_size=0.406 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(3, 4, 1, 2), 1] = ModuleProfileResult(compute_cost=0.206, peak_memory=7.004 GB, invar_size=0.875 GB, outvar_size=0.375 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 0] = ModuleProfileResult(compute_cost=0.174, peak_memory=1.766 GB, invar_size=0.266 GB, outvar_size=0.250 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 0] = ModuleProfileResult(compute_cost=0.161, peak_memory=1.703 GB, invar_size=0.266 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(4, 5, 1, 2), 1] = ModuleProfileResult(compute_cost=0.220, peak_memory=7.004 GB, invar_size=0.875 GB, outvar_size=0.406 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(5, 6, 1, 1), 1] = ModuleProfileResult(compute_cost=0.458, peak_memory=7.229 GB, invar_size=0.719 GB, outvar_size=0.297 GB, temp_buffer_size=6.385 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 0] = ModuleProfileResult(compute_cost=0.174, peak_memory=1.766 GB, invar_size=0.266 GB, outvar_size=0.250 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(5, 6, 1, 0), 1] = ModuleProfileResult(compute_cost=0.216, peak_memory=7.069 GB, invar_size=0.875 GB, outvar_size=0.406 GB, temp_buffer_size=6.131 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(6, 7, 1, 1), 1] = ModuleProfileResult(compute_cost=0.424, peak_memory=7.952 GB, invar_size=0.688 GB, outvar_size=0.281 GB, temp_buffer_size=7.139 GB, available_memory=17.580 GB)
result[(5, 6, 1, 2), 1] = ModuleProfileResult(compute_cost=0.216, peak_memory=7.194 GB, invar_size=0.938 GB, outvar_size=0.406 GB, temp_buffer_size=6.194 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(6, 7, 1, 0), 1] = ModuleProfileResult(compute_cost=0.200, peak_memory=7.069 GB, invar_size=0.813 GB, outvar_size=0.375 GB, temp_buffer_size=6.194 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 0] = ModuleProfileResult(compute_cost=0.161, peak_memory=1.703 GB, invar_size=0.266 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(6, 7, 1, 2), 1] = ModuleProfileResult(compute_cost=0.200, peak_memory=7.132 GB, invar_size=0.875 GB, outvar_size=0.375 GB, temp_buffer_size=6.194 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.688 GB, invar_size=0.375 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 0] = ModuleProfileResult(compute_cost=0.187, peak_memory=1.719 GB, invar_size=0.281 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 0] = ModuleProfileResult(compute_cost=0.068, peak_memory=1.688 GB, invar_size=0.375 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(7, 8, 1, 1), 1] = ModuleProfileResult(compute_cost=0.388, peak_memory=7.230 GB, invar_size=0.657 GB, outvar_size=0.266 GB, temp_buffer_size=6.449 GB, available_memory=17.580 GB)
result[(7, 8, 1, 0), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=6.316 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.503 GB, available_memory=17.580 GB)
result[(8, 9, 1, 1), 1] = ModuleProfileResult(compute_cost=0.388, peak_memory=6.285 GB, invar_size=0.657 GB, outvar_size=0.266 GB, temp_buffer_size=5.503 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 0] = ModuleProfileResult(compute_cost=0.073, peak_memory=1.719 GB, invar_size=0.406 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 0] = ModuleProfileResult(compute_cost=0.205, peak_memory=1.797 GB, invar_size=0.297 GB, outvar_size=0.250 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 0] = ModuleProfileResult(compute_cost=0.073, peak_memory=1.719 GB, invar_size=0.406 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(8, 9, 1, 0), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=6.191 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.378 GB, available_memory=17.580 GB)
result[(7, 8, 1, 2), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=6.316 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.503 GB, available_memory=17.580 GB)
result[(8, 9, 1, 2), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=6.316 GB, invar_size=0.813 GB, outvar_size=0.344 GB, temp_buffer_size=5.441 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 0] = ModuleProfileResult(compute_cost=0.161, peak_memory=1.703 GB, invar_size=0.266 GB, outvar_size=0.188 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(9, 10, 1, 1), 1] = ModuleProfileResult(compute_cost=0.388, peak_memory=7.101 GB, invar_size=0.657 GB, outvar_size=0.266 GB, temp_buffer_size=6.319 GB, available_memory=17.580 GB)
result[(9, 10, 1, 0), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=6.254 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.441 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 0] = ModuleProfileResult(compute_cost=0.060, peak_memory=1.656 GB, invar_size=0.344 GB, outvar_size=0.125 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(9, 10, 1, 2), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=6.254 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.441 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.085, peak_memory=1.563 GB, invar_size=0.188 GB, outvar_size=0.125 GB, temp_buffer_size=1.250 GB, available_memory=17.580 GB)
result[(10, 11, 1, 0), 1] = ModuleProfileResult(compute_cost=0.184, peak_memory=6.194 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.381 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.028, peak_memory=1.438 GB, invar_size=0.188 GB, outvar_size=0.062 GB, temp_buffer_size=1.188 GB, available_memory=17.580 GB)
result[(10, 11, 1, 1), 1] = ModuleProfileResult(compute_cost=0.408, peak_memory=6.416 GB, invar_size=0.657 GB, outvar_size=0.266 GB, temp_buffer_size=5.635 GB, available_memory=17.580 GB)
result[(10, 11, 1, 2), 1] = ModuleProfileResult(compute_cost=0.184, peak_memory=6.194 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.381 GB, available_memory=17.580 GB)
result[(11, 12, 1, 1), 1] = ModuleProfileResult(compute_cost=0.449, peak_memory=7.579 GB, invar_size=0.688 GB, outvar_size=0.281 GB, temp_buffer_size=6.767 GB, available_memory=17.580 GB)
result[(12, 13, 1, 1), 1] = ModuleProfileResult(compute_cost=0.463, peak_memory=7.918 GB, invar_size=0.719 GB, outvar_size=0.297 GB, temp_buffer_size=7.074 GB, available_memory=17.580 GB)
result[(11, 12, 1, 0), 1] = ModuleProfileResult(compute_cost=0.206, peak_memory=6.879 GB, invar_size=0.813 GB, outvar_size=0.375 GB, temp_buffer_size=6.003 GB, available_memory=17.580 GB)
result[(12, 13, 1, 0), 1] = ModuleProfileResult(compute_cost=0.220, peak_memory=7.004 GB, invar_size=0.875 GB, outvar_size=0.406 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(13, 14, 1, 0), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=6.191 GB, invar_size=0.750 GB, outvar_size=0.344 GB, temp_buffer_size=5.378 GB, available_memory=17.580 GB)
result[(13, 14, 1, 1), 1] = ModuleProfileResult(compute_cost=0.388, peak_memory=6.285 GB, invar_size=0.657 GB, outvar_size=0.266 GB, temp_buffer_size=5.503 GB, available_memory=17.580 GB)
result[(12, 13, 1, 2), 1] = ModuleProfileResult(compute_cost=0.220, peak_memory=7.004 GB, invar_size=0.875 GB, outvar_size=0.406 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(11, 12, 1, 2), 1] = ModuleProfileResult(compute_cost=0.206, peak_memory=7.004 GB, invar_size=0.875 GB, outvar_size=0.375 GB, temp_buffer_size=6.066 GB, available_memory=17.580 GB)
result[(14, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.237, peak_memory=6.410 GB, invar_size=0.907 GB, outvar_size=0.453 GB, temp_buffer_size=5.441 GB, available_memory=17.580 GB)
result[(14, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.409, peak_memory=6.651 GB, invar_size=0.641 GB, outvar_size=0.320 GB, temp_buffer_size=5.885 GB, available_memory=17.580 GB)
result[(13, 14, 1, 2), 1] = ModuleProfileResult(compute_cost=0.183, peak_memory=6.316 GB, invar_size=0.813 GB, outvar_size=0.344 GB, temp_buffer_size=5.441 GB, available_memory=17.580 GB)
result[(14, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.260, peak_memory=6.215 GB, invar_size=0.711 GB, outvar_size=0.356 GB, temp_buffer_size=5.441 GB, available_memory=17.580 GB)
Profiling for submesh 1 (1, 2) takes 24.70 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(3, 3, 0, 0), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(3, 3, 0, 1), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 0] = ModuleProfileResult(compute_cost=0.089, peak_memory=4.606 GB, invar_size=0.229 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 0] = ModuleProfileResult(compute_cost=0.089, peak_memory=4.606 GB, invar_size=0.229 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.813 GB, invar_size=0.313 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.813 GB, invar_size=0.313 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.813 GB, invar_size=0.313 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.813 GB, invar_size=0.313 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(1, 1, 0, 0), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.813 GB, invar_size=0.313 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(1, 1, 0, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.813 GB, invar_size=0.313 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(0, 0, 0, 0), 1] = ModuleProfileResult(compute_cost=0.193, peak_memory=8.995 GB, invar_size=0.582 GB, outvar_size=0.229 GB, temp_buffer_size=8.413 GB, available_memory=17.580 GB)
result[(0, 0, 0, 1), 1] = ModuleProfileResult(compute_cost=0.193, peak_memory=8.995 GB, invar_size=0.582 GB, outvar_size=0.229 GB, temp_buffer_size=8.413 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(7, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(7, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(3, 3, 0, 1), 1] = ModuleProfileResult(compute_cost=0.160, peak_memory=11.389 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.764 GB, available_memory=17.580 GB)
result[(2, 2, 0, 1), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(2, 2, 0, 0), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(3, 3, 0, 0), 1] = ModuleProfileResult(compute_cost=0.160, peak_memory=11.389 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.764 GB, available_memory=17.580 GB)
result[(5, 5, 0, 0), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(5, 5, 0, 1), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(6, 6, 0, 1), 1] = ModuleProfileResult(compute_cost=0.219, peak_memory=13.014 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=12.264 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(6, 6, 0, 0), 1] = ModuleProfileResult(compute_cost=0.219, peak_memory=13.014 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=12.264 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(4, 4, 0, 1), 1] = ModuleProfileResult(compute_cost=0.227, peak_memory=12.757 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=12.007 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(4, 4, 0, 0), 1] = ModuleProfileResult(compute_cost=0.227, peak_memory=12.757 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=12.007 GB, available_memory=17.580 GB)
result[(1, 1, 0, 1), 1] = ModuleProfileResult(compute_cost=0.227, peak_memory=12.757 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=12.007 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=0.000 GB, invar_size=0.000 GB, outvar_size=0.000 GB, temp_buffer_size=0.000 GB, available_memory=17.580 GB)
result[(1, 1, 0, 0), 1] = ModuleProfileResult(compute_cost=0.227, peak_memory=12.757 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=12.007 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(9, 9, 0, 0), 1] = ModuleProfileResult(compute_cost=0.157, peak_memory=11.382 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.756 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(8, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(7, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.157, peak_memory=11.507 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.882 GB, available_memory=17.580 GB)
result[(13, 13, 0, 0), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.813 GB, invar_size=0.313 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(7, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.157, peak_memory=11.507 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.882 GB, available_memory=17.580 GB)
result[(13, 13, 0, 1), 0] = ModuleProfileResult(compute_cost=0.062, peak_memory=4.658 GB, invar_size=0.281 GB, outvar_size=0.125 GB, temp_buffer_size=4.252 GB, available_memory=17.580 GB)
result[(9, 9, 0, 1), 1] = ModuleProfileResult(compute_cost=0.157, peak_memory=11.382 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.756 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.077, peak_memory=2.813 GB, invar_size=0.313 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(8, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 0] = ModuleProfileResult(compute_cost=0.053, peak_memory=2.750 GB, invar_size=0.250 GB, outvar_size=0.125 GB, temp_buffer_size=2.375 GB, available_memory=17.580 GB)
result[(10, 10, 0, 0), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(10, 10, 0, 1), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(13, 13, 0, 0), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(11, 11, 0, 0), 1] = ModuleProfileResult(compute_cost=0.160, peak_memory=11.389 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.764 GB, available_memory=17.580 GB)
result[(11, 11, 0, 1), 1] = ModuleProfileResult(compute_cost=0.160, peak_memory=11.389 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.764 GB, available_memory=17.580 GB)
result[(14, 14, 0, 0), 1] = ModuleProfileResult(compute_cost=0.157, peak_memory=11.382 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.756 GB, available_memory=17.580 GB)
result[(13, 13, 0, 1), 1] = ModuleProfileResult(compute_cost=0.185, peak_memory=8.447 GB, invar_size=0.563 GB, outvar_size=0.281 GB, temp_buffer_size=7.759 GB, available_memory=17.580 GB)
result[(14, 14, 0, 1), 1] = ModuleProfileResult(compute_cost=0.157, peak_memory=11.382 GB, invar_size=0.500 GB, outvar_size=0.250 GB, temp_buffer_size=10.756 GB, available_memory=17.580 GB)
result[(15, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.298, peak_memory=8.533 GB, invar_size=0.657 GB, outvar_size=0.391 GB, temp_buffer_size=7.751 GB, available_memory=17.580 GB)
result[(12, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.227, peak_memory=12.757 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=12.007 GB, available_memory=17.580 GB)
result[(12, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.227, peak_memory=12.757 GB, invar_size=0.625 GB, outvar_size=0.313 GB, temp_buffer_size=12.007 GB, available_memory=17.580 GB)
result[(15, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.298, peak_memory=8.533 GB, invar_size=0.657 GB, outvar_size=0.391 GB, temp_buffer_size=7.751 GB, available_memory=17.580 GB)
Profiling for submesh 0 (1, 1) takes 13.63 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 2, 2, 0) has been pruned...
[TMP] Stage (0, 2, 2, 1) has been pruned...
[TMP] Stage (0, 2, 2, 2) has been pruned...
[TMP] Stage (0, 3, 2, 0) has been pruned...
[TMP] Stage (0, 3, 2, 1) has been pruned...
[TMP] Stage (0, 3, 2, 2) has been pruned...
[TMP] Stage (0, 6, 3, 0) has been pruned...
[TMP] Stage (0, 6, 3, 1) has been pruned...
[TMP] Stage (0, 6, 3, 2) has been pruned...
[TMP] Stage (0, 7, 3, 0) has been pruned...
[TMP] Stage (0, 7, 3, 1) has been pruned...
[TMP] Stage (0, 7, 3, 2) has been pruned...
[TMP] Stage (0, 8, 3, 0) has been pruned...
[TMP] Stage (0, 8, 3, 1) has been pruned...
[TMP] Stage (0, 8, 3, 2) has been pruned...
[TMP] Stage (1, 4, 2, 0) has been pruned...
[TMP] Stage (1, 4, 2, 1) has been pruned...
[TMP] Stage (1, 4, 2, 2) has been pruned...
[TMP] Stage (1, 7, 3, 0) has been pruned...
[TMP] Stage (1, 7, 3, 1) has been pruned...
[TMP] Stage (1, 7, 3, 2) has been pruned...
[TMP] Stage (1, 8, 3, 0) has been pruned...
[TMP] Stage (1, 8, 3, 1) has been pruned...
[TMP] Stage (1, 8, 3, 2) has been pruned...
[TMP] Stage (1, 9, 3, 0) has been pruned...
[TMP] Stage (1, 9, 3, 1) has been pruned...
[TMP] Stage (1, 9, 3, 2) has been pruned...
[TMP] Stage (1, 10, 3, 0) has been pruned...
[TMP] Stage (1, 10, 3, 1) has been pruned...
[TMP] Stage (1, 10, 3, 2) has been pruned...
[TMP] Stage (2, 5, 2, 0) has been pruned...
[TMP] Stage (2, 5, 2, 1) has been pruned...
[TMP] Stage (2, 5, 2, 2) has been pruned...
[TMP] Stage (2, 8, 3, 0) has been pruned...
[TMP] Stage (2, 8, 3, 1) has been pruned...
[TMP] Stage (2, 8, 3, 2) has been pruned...
[TMP] Stage (2, 9, 3, 0) has been pruned...
[TMP] Stage (2, 9, 3, 1) has been pruned...
[TMP] Stage (2, 9, 3, 2) has been pruned...
[TMP] Stage (2, 10, 3, 0) has been pruned...
[TMP] Stage (2, 10, 3, 1) has been pruned...
[TMP] Stage (2, 10, 3, 2) has been pruned...
[TMP] Stage (2, 11, 3, 0) has been pruned...
[TMP] Stage (2, 11, 3, 1) has been pruned...
[TMP] Stage (2, 11, 3, 2) has been pruned...
[TMP] Stage (3, 6, 2, 0) has been pruned...
[TMP] Stage (3, 6, 2, 1) has been pruned...
[TMP] Stage (3, 6, 2, 2) has been pruned...
[TMP] Stage (3, 7, 2, 0) has been pruned...
[TMP] Stage (3, 7, 2, 1) has been pruned...
[TMP] Stage (3, 7, 2, 2) has been pruned...
[TMP] Stage (3, 9, 3, 0) has been pruned...
[TMP] Stage (3, 9, 3, 1) has been pruned...
[TMP] Stage (3, 9, 3, 2) has been pruned...
[TMP] Stage (3, 10, 3, 0) has been pruned...
[TMP] Stage (3, 10, 3, 1) has been pruned...
[TMP] Stage (3, 10, 3, 2) has been pruned...
[TMP] Stage (3, 11, 3, 0) has been pruned...
[TMP] Stage (3, 11, 3, 1) has been pruned...
[TMP] Stage (3, 11, 3, 2) has been pruned...
[TMP] Stage (3, 12, 3, 0) has been pruned...
[TMP] Stage (3, 12, 3, 1) has been pruned...
[TMP] Stage (3, 12, 3, 2) has been pruned...
[TMP] Stage (4, 6, 2, 0) has been pruned...
[TMP] Stage (4, 6, 2, 1) has been pruned...
[TMP] Stage (4, 6, 2, 2) has been pruned...
[TMP] Stage (4, 7, 2, 0) has been pruned...
[TMP] Stage (4, 7, 2, 1) has been pruned...
[TMP] Stage (4, 7, 2, 2) has been pruned...
[TMP] Stage (4, 10, 3, 0) has been pruned...
[TMP] Stage (4, 10, 3, 1) has been pruned...
[TMP] Stage (4, 10, 3, 2) has been pruned...
[TMP] Stage (4, 11, 3, 0) has been pruned...
[TMP] Stage (4, 11, 3, 1) has been pruned...
[TMP] Stage (4, 11, 3, 2) has been pruned...
[TMP] Stage (4, 12, 3, 0) has been pruned...
[TMP] Stage (4, 12, 3, 1) has been pruned...
[TMP] Stage (4, 12, 3, 2) has been pruned...
[TMP] Stage (4, 13, 3, 0) has been pruned...
[TMP] Stage (4, 13, 3, 1) has been pruned...
[TMP] Stage (4, 13, 3, 2) has been pruned...
[TMP] Stage (5, 8, 2, 0) has been pruned...
[TMP] Stage (5, 8, 2, 1) has been pruned...
[TMP] Stage (5, 8, 2, 2) has been pruned...
[TMP] Stage (5, 9, 2, 0) has been pruned...
[TMP] Stage (5, 9, 2, 1) has been pruned...
[TMP] Stage (5, 9, 2, 2) has been pruned...
[TMP] Stage (5, 11, 3, 0) has been pruned...
[TMP] Stage (5, 11, 3, 1) has been pruned...
[TMP] Stage (5, 11, 3, 2) has been pruned...
[TMP] Stage (5, 12, 3, 0) has been pruned...
[TMP] Stage (5, 12, 3, 1) has been pruned...
[TMP] Stage (5, 12, 3, 2) has been pruned...
[TMP] Stage (5, 13, 3, 0) has been pruned...
[TMP] Stage (5, 13, 3, 1) has been pruned...
[TMP] Stage (5, 13, 3, 2) has been pruned...
[TMP] Stage (5, 14, 3, 0) has been pruned...
[TMP] Stage (5, 14, 3, 1) has been pruned...
[TMP] Stage (5, 14, 3, 2) has been pruned...
[TMP] Stage (6, 9, 2, 0) has been pruned...
[TMP] Stage (6, 9, 2, 1) has been pruned...
[TMP] Stage (6, 9, 2, 2) has been pruned...
[TMP] Stage (6, 10, 2, 0) has been pruned...
[TMP] Stage (6, 10, 2, 1) has been pruned...
[TMP] Stage (6, 10, 2, 2) has been pruned...
[TMP] Stage (6, 12, 3, 0) has been pruned...
[TMP] Stage (6, 12, 3, 1) has been pruned...
[TMP] Stage (6, 12, 3, 2) has been pruned...
[TMP] Stage (6, 13, 3, 0) has been pruned...
[TMP] Stage (6, 13, 3, 1) has been pruned...
[TMP] Stage (6, 13, 3, 2) has been pruned...
[TMP] Stage (6, 14, 3, 0) has been pruned...
[TMP] Stage (6, 14, 3, 1) has been pruned...
[TMP] Stage (6, 14, 3, 2) has been pruned...
[TMP] Stage (6, 15, 3, 0) has been pruned...
[TMP] Stage (6, 15, 3, 1) has been pruned...
[TMP] Stage (6, 15, 3, 2) has been pruned...
[TMP] Stage (7, 10, 2, 0) has been pruned...
[TMP] Stage (7, 10, 2, 1) has been pruned...
[TMP] Stage (7, 10, 2, 2) has been pruned...
[TMP] Stage (7, 11, 2, 0) has been pruned...
[TMP] Stage (7, 11, 2, 1) has been pruned...
[TMP] Stage (7, 11, 2, 2) has been pruned...
[TMP] Stage (7, 13, 3, 0) has been pruned...
[TMP] Stage (7, 13, 3, 1) has been pruned...
[TMP] Stage (7, 13, 3, 2) has been pruned...
[TMP] Stage (7, 14, 3, 0) has been pruned...
[TMP] Stage (7, 14, 3, 1) has been pruned...
[TMP] Stage (7, 14, 3, 2) has been pruned...
[TMP] Stage (7, 15, 3, 0) has been pruned...
[TMP] Stage (7, 15, 3, 1) has been pruned...
[TMP] Stage (7, 15, 3, 2) has been pruned...
[TMP] Stage (8, 11, 2, 0) has been pruned...
[TMP] Stage (8, 11, 2, 1) has been pruned...
[TMP] Stage (8, 11, 2, 2) has been pruned...
[TMP] Stage (8, 12, 2, 0) has been pruned...
[TMP] Stage (8, 12, 2, 1) has been pruned...
[TMP] Stage (8, 12, 2, 2) has been pruned...
[TMP] Stage (8, 14, 3, 0) has been pruned...
[TMP] Stage (8, 14, 3, 1) has been pruned...
[TMP] Stage (8, 14, 3, 2) has been pruned...
[TMP] Stage (8, 15, 3, 0) has been pruned...
[TMP] Stage (8, 15, 3, 1) has been pruned...
[TMP] Stage (8, 15, 3, 2) has been pruned...
[TMP] Stage (9, 12, 2, 0) has been pruned...
[TMP] Stage (9, 12, 2, 1) has been pruned...
[TMP] Stage (9, 12, 2, 2) has been pruned...
[TMP] Stage (9, 13, 2, 0) has been pruned...
[TMP] Stage (9, 13, 2, 1) has been pruned...
[TMP] Stage (9, 13, 2, 2) has been pruned...
[TMP] Stage (9, 15, 3, 0) has been pruned...
[TMP] Stage (9, 15, 3, 1) has been pruned...
[TMP] Stage (9, 15, 3, 2) has been pruned...
[TMP] Stage (10, 13, 2, 0) has been pruned...
[TMP] Stage (10, 13, 2, 1) has been pruned...
[TMP] Stage (10, 13, 2, 2) has been pruned...
[TMP] Stage (10, 14, 2, 0) has been pruned...
[TMP] Stage (10, 14, 2, 1) has been pruned...
[TMP] Stage (10, 14, 2, 2) has been pruned...
[TMP] Stage (11, 14, 2, 0) has been pruned...
[TMP] Stage (11, 14, 2, 1) has been pruned...
[TMP] Stage (11, 14, 2, 2) has been pruned...
[TMP] Stage (11, 15, 2, 0) has been pruned...
[TMP] Stage (11, 15, 2, 1) has been pruned...
[TMP] Stage (11, 15, 2, 2) has been pruned...
[TMP] Stage (12, 15, 2, 0) has been pruned...
[TMP] Stage (12, 15, 2, 1) has been pruned...
[TMP] Stage (12, 15, 2, 2) has been pruned...
Result forward_stage_layer_ids: [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14, 15]]
Result mesh_shapes: [(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2)]
Result logical_mesh_shapes: [(2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1), (2, 1)]
Result autosharding_option_dicts: [{}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}, {'force_batch_dim_to_mesh_dim': 0}]
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO comm 0x4bf88e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO comm 0x45bfd70 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO comm 0x6608eb0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO comm 0x6c843f0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO comm 0x4763f10 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO comm 0xa39be90 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO comm 0x730ebc0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO comm 0xa47ab80 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3992860)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO comm 0xa5f9720 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO comm 0x45dd8a0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO comm 0x67e28a0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO comm 0xa71ffb0 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO comm 0xa6349a0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO comm 0x358c9b0 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO comm 0x55e53f0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO comm 0xa5cb860 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO comm 0x9376400 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO NCCL_NSOCKS_PERTHREAD set by environment to 8.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO NCCL_SOCKET_NTHREADS set by environment to 8.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO comm 0x3678910 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO comm 0x56c6cb0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO comm 0x9454310 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO comm 0x99c4fa0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO comm 0x38f1120 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO NET/Socket: Using 8 threads and 8 sockets per thread
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO comm 0x560ee20 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO comm 0x99cbd70 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [0] NCCL INFO comm 0x3710590 rank 1 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 00 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 01 : 1[31000] -> 0[31000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 00 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Channel 01 : 0[31000] -> 1[31000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO comm 0x993efa0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370334 [1] NCCL INFO comm 0x55cb7e0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[ca000] [receive] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 00 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Channel 01 : 0[ca000] -> 1[ca000] [send] via NET/Socket/0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO comm 0x98d5e60 rank 0 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
 - Compile (driver): 75.60 s
compilation time breakdown: {'stage-construction': '41.65', 'stage-construction-dp': '1.22', 'stage-construction-compilation': '8.84', 'stage-construction-profiling': '9.49'}
 - Compile (worker): 3.25 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687809 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321244 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992860 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239236 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072836 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1922845 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [0] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233591 [1] NCCL INFO Launch mode Parallel
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.59<0>
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.71<0>
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.56<0>
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m 
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO comm 0x7f76a363cb50 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370398 [1] NCCL INFO comm 0x7f7698c55640 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2370334, ip=192.168.0.57)[0m gpu27:2370334:2370396 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.57<0>
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m 
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233655 [1] NCCL INFO comm 0x7f1fc4dab500 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO comm 0x7f1fd3b75210 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.55<0>
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m 
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923005 [1] NCCL INFO comm 0x7fad72f62370 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO comm 0x7fad6e038780 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m 
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072988 [1] NCCL INFO comm 0x7fd8fa7eebd0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO comm 0x7fd9037393e0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3072836, ip=192.168.0.72)[0m gpu42:3072836:3072986 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.58<0>
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m 
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239342 [1] NCCL INFO comm 0x7f2b3764bd10 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO comm 0x7f2b299b1550 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.66<0>
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=3992860)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3992860)[0m 
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO comm 0x7f13051e0d60 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992982 [1] NCCL INFO comm 0x7f130f5dfa80 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Bootstrap : Using ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO NET/Socket : Using [0]ib0.8068:192.168.1.54<0>
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Using network Socket
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m NCCL version 2.8.4+cuda11.2
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m 
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO comm 0x7f670d0d3ef0 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321349 [1] NCCL INFO comm 0x7f6717f53ed0 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] misc/nvmlwrap.cc:47 NCCL WARN Failed to open libnvidia-ml.so.1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m 
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] graph/xml.cc:595 NCCL WARN No NVML device handle. Skipping nvlink detection.
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Channel 00/02 :    0   1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Channel 01/02 :    0   1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ff000000
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO Channel 00 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO Channel 01 : 1[ca000] -> 0[31000] via direct shared memory
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Channel 00 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Channel 01 : 0[31000] -> 1[ca000] via direct shared memory
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO Connected all rings
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO Connected all trees
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO comm 0x7fa6a02b1120 rank 0 nranks 2 cudaDev 0 busId 31000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687914 [1] NCCL INFO comm 0x7fa6c2b17080 rank 1 nranks 2 cudaDev 1 busId ca000 - Init COMPLETE
[2m[36m(MeshHostWorker pid=2687809, ip=192.168.0.60)[0m gpu30:2687809:2687912 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3233591, ip=192.168.0.58)[0m gpu28:3233591:3233653 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=1922845, ip=192.168.0.56)[0m gpu26:1922845:1923003 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3239236, ip=192.168.0.59)[0m gpu29:3239236:3239340 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=3992860)[0m gpu37:3992860:3992980 [0] NCCL INFO Launch mode Group/CGMD
[2m[36m(MeshHostWorker pid=2321244, ip=192.168.0.55)[0m gpu25:2321244:2321347 [0] NCCL INFO Launch mode Group/CGMD
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 107.90 s

[23.211506128311157, 13.318855047225952, 13.395021677017212, 13.49558424949646, 13.400934934616089, 13.442220211029053, 13.393233060836792]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 69.537 s.
 - Average e2e iteration time: 13.907000541687012 s.
 - Total local training time: 67.12700653076172 s.
 - Average local iteration time: 13.425000190734863 s.
 - Max allocated memory among devices: 9.974 GB.
 - Compilation times:  {'stage-construction': 41.65215730667114, 'stage-construction-dp': 1.2150630950927734, 'stage-construction-compilation': 8.839248895645142, 'stage-construction-profiling': 9.48927092552185}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `8_a10_8_n_2_d`: 13.425399780273438
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/bert_1.3B_512.pkl`...
