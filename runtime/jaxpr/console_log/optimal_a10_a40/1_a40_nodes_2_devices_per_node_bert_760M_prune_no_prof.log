
------------------------------------------------------------------
- (1/3) Profiling bert_760M with batch size: 128...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal_prune_no_prof/bert_760M_128.pkl`, updating/rewriting it...
[I] Alpa's built-in profiling database is disabled.
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f39a6422bb0>
    dtype = float16
) 

[I] Compiling and executing model with timeout = 1200 s...
[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
[TMP] The range of stage num is (min #stage -> max #stage): 1 -> 2
[I] Coarsening pipeline layers from 16 to 4...
[I] Coarsened scheme: [[0, 1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15]]
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2))
[TMP] The range of device num per stage is (min #gpu -> max #gpu): 1 -> 2
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.134, peak_memory=2.045 GB, invar_size=1.397 GB, outvar_size=0.258 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.356, peak_memory=4.955 GB, invar_size=3.389 GB, outvar_size=1.565 GB, temp_buffer_size=1.566 GB, available_memory=35.242 GB)
result[(0, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.222, peak_memory=1.523 GB, invar_size=0.699 GB, outvar_size=0.434 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=0.542, peak_memory=3.752 GB, invar_size=2.000 GB, outvar_size=0.783 GB, temp_buffer_size=1.752 GB, available_memory=35.242 GB)
result[(0, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.125, peak_memory=1.971 GB, invar_size=1.323 GB, outvar_size=0.258 GB, temp_buffer_size=0.391 GB, available_memory=35.242 GB)
result[(0, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.359, peak_memory=4.807 GB, invar_size=3.094 GB, outvar_size=1.418 GB, temp_buffer_size=1.712 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 101.13 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6] violates the layer coarsening rules, pruned.
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.137, peak_memory=1.897 GB, invar_size=0.834 GB, outvar_size=0.281 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.143, peak_memory=1.897 GB, invar_size=0.834 GB, outvar_size=0.281 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.361, peak_memory=5.699 GB, invar_size=1.949 GB, outvar_size=0.834 GB, temp_buffer_size=3.750 GB, available_memory=35.242 GB)
result[(5, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.141, peak_memory=1.305 GB, invar_size=0.797 GB, outvar_size=0.188 GB, temp_buffer_size=0.320 GB, available_memory=35.242 GB)
result[(0, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.356, peak_memory=5.699 GB, invar_size=1.949 GB, outvar_size=0.834 GB, temp_buffer_size=3.750 GB, available_memory=35.242 GB)
result[(5, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.147, peak_memory=1.305 GB, invar_size=0.797 GB, outvar_size=0.188 GB, temp_buffer_size=0.320 GB, available_memory=35.242 GB)
result[(5, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.374, peak_memory=5.509 GB, invar_size=1.759 GB, outvar_size=0.797 GB, temp_buffer_size=3.727 GB, available_memory=35.242 GB)
result[(9, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.102, peak_memory=1.141 GB, invar_size=0.586 GB, outvar_size=0.234 GB, temp_buffer_size=0.320 GB, available_memory=35.242 GB)
result[(5, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.371, peak_memory=5.509 GB, invar_size=1.759 GB, outvar_size=0.797 GB, temp_buffer_size=3.727 GB, available_memory=35.242 GB)
result[(9, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.096, peak_memory=1.141 GB, invar_size=0.586 GB, outvar_size=0.234 GB, temp_buffer_size=0.320 GB, available_memory=35.242 GB)
result[(9, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.339, peak_memory=4.769 GB, invar_size=1.721 GB, outvar_size=0.755 GB, temp_buffer_size=3.025 GB, available_memory=35.242 GB)
result[(9, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.335, peak_memory=4.769 GB, invar_size=1.721 GB, outvar_size=0.755 GB, temp_buffer_size=3.025 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 63.76 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 6, 0, 0) has been pruned...
[TMP] Stage (0, 6, 0, 1) has been pruned...
[TMP] Stage (0, 7, 0, 0) has been pruned...
[TMP] Stage (0, 7, 0, 1) has been pruned...
[TMP] Stage (0, 9, 0, 0) has been pruned...
[TMP] Stage (0, 9, 0, 1) has been pruned...
[TMP] Stage (1, 7, 0, 0) has been pruned...
[TMP] Stage (1, 7, 0, 1) has been pruned...
[TMP] Stage (1, 8, 0, 0) has been pruned...
[TMP] Stage (1, 8, 0, 1) has been pruned...
[TMP] Stage (1, 9, 0, 0) has been pruned...
[TMP] Stage (1, 9, 0, 1) has been pruned...
[TMP] Stage (1, 10, 0, 0) has been pruned...
[TMP] Stage (1, 10, 0, 1) has been pruned...
[TMP] Stage (2, 8, 0, 0) has been pruned...
[TMP] Stage (2, 8, 0, 1) has been pruned...
[TMP] Stage (2, 9, 0, 0) has been pruned...
[TMP] Stage (2, 9, 0, 1) has been pruned...
[TMP] Stage (2, 10, 0, 0) has been pruned...
[TMP] Stage (2, 10, 0, 1) has been pruned...
[TMP] Stage (3, 9, 0, 0) has been pruned...
[TMP] Stage (3, 9, 0, 1) has been pruned...
[TMP] Stage (3, 10, 0, 0) has been pruned...
[TMP] Stage (3, 10, 0, 1) has been pruned...
[TMP] Stage (3, 11, 0, 0) has been pruned...
[TMP] Stage (3, 11, 0, 1) has been pruned...
[TMP] Stage (4, 10, 0, 0) has been pruned...
[TMP] Stage (4, 10, 0, 1) has been pruned...
[TMP] Stage (4, 11, 0, 0) has been pruned...
[TMP] Stage (4, 11, 0, 1) has been pruned...
[TMP] Stage (4, 12, 0, 0) has been pruned...
[TMP] Stage (4, 12, 0, 1) has been pruned...
[TMP] Stage (5, 11, 0, 0) has been pruned...
[TMP] Stage (5, 11, 0, 1) has been pruned...
[TMP] Stage (5, 13, 0, 0) has been pruned...
[TMP] Stage (5, 13, 0, 1) has been pruned...
[TMP] Stage (6, 12, 0, 0) has been pruned...
[TMP] Stage (6, 12, 0, 1) has been pruned...
[TMP] Stage (6, 13, 0, 0) has been pruned...
[TMP] Stage (6, 13, 0, 1) has been pruned...
[TMP] Stage (6, 14, 0, 0) has been pruned...
[TMP] Stage (6, 14, 0, 1) has been pruned...
[TMP] Stage (7, 13, 0, 0) has been pruned...
[TMP] Stage (7, 13, 0, 1) has been pruned...
[TMP] Stage (7, 14, 0, 0) has been pruned...
[TMP] Stage (7, 14, 0, 1) has been pruned...
[TMP] Stage (7, 15, 0, 0) has been pruned...
[TMP] Stage (7, 15, 0, 1) has been pruned...
[TMP] Stage (8, 14, 0, 0) has been pruned...
[TMP] Stage (8, 14, 0, 1) has been pruned...
[TMP] Stage (8, 15, 0, 0) has been pruned...
[TMP] Stage (8, 15, 0, 1) has been pruned...
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]
Result mesh_shapes: [(1, 2)]
Result logical_mesh_shapes: [(2, 1)]
Result autosharding_option_dicts: [{}]
 - Compile (driver): 229.10 s
compilation time breakdown: {'stage-construction': '170.66', 'stage-construction-dp': '1.39', 'stage-construction-compilation': '34.43', 'stage-construction-profiling': '109.20'}
 - Compile (worker): 22.75 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 59.99 s

[10.701604127883911, 7.2554779052734375, 7.254592180252075, 7.261321067810059, 7.261836528778076, 7.254899740219116, 7.261728525161743]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 38.186 s.
 - Average e2e iteration time: 7.637000560760498 s.
 - Total local training time: 36.294002532958984 s.
 - Average local iteration time: 7.259000301361084 s.
 - Max allocated memory among devices: 13.372 GB.
 - Compilation times:  {'stage-construction': 170.662127494812, 'stage-construction-dp': 1.3867788314819336, 'stage-construction-compilation': 34.42883586883545, 'stage-construction-profiling': 109.20076203346252}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_2_d`: 7.258875370025635
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal_prune_no_prof/bert_760M_128.pkl`...

------------------------------------------------------------------
- (2/3) Profiling bert_760M with batch size: 256...
------------------------------------------------------------------
[TMP] Profiling results not found in `./jaxpr/prof_log/optimal_prune_no_prof/bert_760M_256.pkl`, creating it...
[I] Alpa's built-in profiling database is disabled.
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7fe114049820>
    dtype = float16
) 

[I] Compiling and executing model with timeout = 1200 s...
[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
[TMP] The range of stage num is (min #stage -> max #stage): 1 -> 2
[I] Coarsening pipeline layers from 16 to 4...
[I] Coarsened scheme: [[0, 1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15]]
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2))
[TMP] The range of device num per stage is (min #gpu -> max #gpu): 1 -> 2
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.240, peak_memory=2.694 GB, invar_size=1.397 GB, outvar_size=0.516 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=0.693, peak_memory=5.493 GB, invar_size=3.647 GB, outvar_size=1.565 GB, temp_buffer_size=1.846 GB, available_memory=35.242 GB)
result[(0, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.426, peak_memory=2.347 GB, invar_size=0.699 GB, outvar_size=0.867 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=1.039, peak_memory=5.922 GB, invar_size=2.433 GB, outvar_size=0.783 GB, temp_buffer_size=3.489 GB, available_memory=35.242 GB)
result[(0, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.237, peak_memory=2.620 GB, invar_size=1.323 GB, outvar_size=0.516 GB, temp_buffer_size=0.781 GB, available_memory=35.242 GB)
result[(0, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=0.705, peak_memory=5.436 GB, invar_size=3.352 GB, outvar_size=1.418 GB, temp_buffer_size=2.083 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 117.73 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6] violates the layer coarsening rules, pruned.
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.269, peak_memory=2.959 GB, invar_size=0.834 GB, outvar_size=0.562 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.262, peak_memory=2.959 GB, invar_size=0.834 GB, outvar_size=0.562 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=0.698, peak_memory=9.729 GB, invar_size=2.231 GB, outvar_size=0.834 GB, temp_buffer_size=7.498 GB, available_memory=35.242 GB)
result[(5, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.273, peak_memory=1.837 GB, invar_size=0.821 GB, outvar_size=0.375 GB, temp_buffer_size=0.641 GB, available_memory=35.242 GB)
result[(0, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=0.696, peak_memory=9.729 GB, invar_size=2.231 GB, outvar_size=0.834 GB, temp_buffer_size=7.498 GB, available_memory=35.242 GB)
result[(5, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.273, peak_memory=1.837 GB, invar_size=0.821 GB, outvar_size=0.375 GB, temp_buffer_size=0.641 GB, available_memory=35.242 GB)
result[(5, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=0.745, peak_memory=9.466 GB, invar_size=1.970 GB, outvar_size=0.821 GB, temp_buffer_size=7.449 GB, available_memory=35.242 GB)
result[(9, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.200, peak_memory=1.719 GB, invar_size=0.610 GB, outvar_size=0.469 GB, temp_buffer_size=0.641 GB, available_memory=35.242 GB)
result[(5, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=0.749, peak_memory=9.466 GB, invar_size=1.970 GB, outvar_size=0.821 GB, temp_buffer_size=7.449 GB, available_memory=35.242 GB)
result[(9, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.199, peak_memory=1.719 GB, invar_size=0.610 GB, outvar_size=0.469 GB, temp_buffer_size=0.641 GB, available_memory=35.242 GB)
result[(9, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.661, peak_memory=8.070 GB, invar_size=1.979 GB, outvar_size=0.778 GB, temp_buffer_size=6.045 GB, available_memory=35.242 GB)
result[(9, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.686, peak_memory=8.070 GB, invar_size=1.979 GB, outvar_size=0.778 GB, temp_buffer_size=6.045 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 76.67 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 6, 0, 0) has been pruned...
[TMP] Stage (0, 6, 0, 1) has been pruned...
[TMP] Stage (0, 7, 0, 0) has been pruned...
[TMP] Stage (0, 7, 0, 1) has been pruned...
[TMP] Stage (0, 9, 0, 0) has been pruned...
[TMP] Stage (0, 9, 0, 1) has been pruned...
[TMP] Stage (1, 7, 0, 0) has been pruned...
[TMP] Stage (1, 7, 0, 1) has been pruned...
[TMP] Stage (1, 8, 0, 0) has been pruned...
[TMP] Stage (1, 8, 0, 1) has been pruned...
[TMP] Stage (1, 9, 0, 0) has been pruned...
[TMP] Stage (1, 9, 0, 1) has been pruned...
[TMP] Stage (1, 10, 0, 0) has been pruned...
[TMP] Stage (1, 10, 0, 1) has been pruned...
[TMP] Stage (2, 8, 0, 0) has been pruned...
[TMP] Stage (2, 8, 0, 1) has been pruned...
[TMP] Stage (2, 9, 0, 0) has been pruned...
[TMP] Stage (2, 9, 0, 1) has been pruned...
[TMP] Stage (2, 10, 0, 0) has been pruned...
[TMP] Stage (2, 10, 0, 1) has been pruned...
[TMP] Stage (3, 9, 0, 0) has been pruned...
[TMP] Stage (3, 9, 0, 1) has been pruned...
[TMP] Stage (3, 10, 0, 0) has been pruned...
[TMP] Stage (3, 10, 0, 1) has been pruned...
[TMP] Stage (3, 11, 0, 0) has been pruned...
[TMP] Stage (3, 11, 0, 1) has been pruned...
[TMP] Stage (4, 10, 0, 0) has been pruned...
[TMP] Stage (4, 10, 0, 1) has been pruned...
[TMP] Stage (4, 11, 0, 0) has been pruned...
[TMP] Stage (4, 11, 0, 1) has been pruned...
[TMP] Stage (4, 12, 0, 0) has been pruned...
[TMP] Stage (4, 12, 0, 1) has been pruned...
[TMP] Stage (5, 11, 0, 0) has been pruned...
[TMP] Stage (5, 11, 0, 1) has been pruned...
[TMP] Stage (5, 13, 0, 0) has been pruned...
[TMP] Stage (5, 13, 0, 1) has been pruned...
[TMP] Stage (6, 12, 0, 0) has been pruned...
[TMP] Stage (6, 12, 0, 1) has been pruned...
[TMP] Stage (6, 13, 0, 0) has been pruned...
[TMP] Stage (6, 13, 0, 1) has been pruned...
[TMP] Stage (6, 14, 0, 0) has been pruned...
[TMP] Stage (6, 14, 0, 1) has been pruned...
[TMP] Stage (7, 13, 0, 0) has been pruned...
[TMP] Stage (7, 13, 0, 1) has been pruned...
[TMP] Stage (7, 14, 0, 0) has been pruned...
[TMP] Stage (7, 14, 0, 1) has been pruned...
[TMP] Stage (7, 15, 0, 0) has been pruned...
[TMP] Stage (7, 15, 0, 1) has been pruned...
[TMP] Stage (8, 14, 0, 0) has been pruned...
[TMP] Stage (8, 14, 0, 1) has been pruned...
[TMP] Stage (8, 15, 0, 0) has been pruned...
[TMP] Stage (8, 15, 0, 1) has been pruned...
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]
Result mesh_shapes: [(1, 2)]
Result logical_mesh_shapes: [(2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 243.44 s
compilation time breakdown: {'stage-construction': '199.97', 'stage-construction-dp': '1.39', 'stage-construction-compilation': '32.71', 'stage-construction-profiling': '141.53'}
 - Compile (worker): 20.07 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 110.43 s

[17.798377990722656, 14.26503849029541, 14.282126665115356, 14.325257778167725, 14.299293994903564, 14.304885387420654, 14.309415578842163]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 74.113 s.
 - Average e2e iteration time: 14.82300090789795 s.
 - Total local training time: 71.52100372314453 s.
 - Average local iteration time: 14.304000854492188 s.
 - Max allocated memory among devices: 17.925 GB.
 - Compilation times:  {'stage-construction': 199.96639227867126, 'stage-construction-dp': 1.3865299224853516, 'stage-construction-compilation': 32.70660138130188, 'stage-construction-profiling': 141.5276381969452}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_2_d`: 14.30419635772705
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal_prune_no_prof/bert_760M_256.pkl`...

------------------------------------------------------------------
- (3/3) Profiling bert_760M with batch size: 512...
------------------------------------------------------------------
[TMP] Profiling results not found in `./jaxpr/prof_log/optimal_prune_no_prof/bert_760M_512.pkl`, creating it...
[I] Alpa's built-in profiling database is disabled.
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 2
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7ff34aabfd90>
    dtype = float16
) 

[I] Compiling and executing model with timeout = 1200 s...
[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
[TMP] The range of stage num is (min #stage -> max #stage): 1 -> 2
[I] Coarsening pipeline layers from 16 to 4...
[I] Coarsened scheme: [[0, 1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15]]
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1), (1, 2))
[TMP] The range of device num per stage is (min #gpu -> max #gpu): 1 -> 2
- Profiling for submesh 1 (1, 2):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 15, 1, 0), 0] = ModuleProfileResult(compute_cost=0.456, peak_memory=3.991 GB, invar_size=1.397 GB, outvar_size=1.031 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 15, 1, 0), 1] = ModuleProfileResult(compute_cost=1.363, peak_memory=7.854 GB, invar_size=4.162 GB, outvar_size=1.565 GB, temp_buffer_size=3.691 GB, available_memory=35.242 GB)
result[(0, 15, 1, 1), 0] = ModuleProfileResult(compute_cost=0.812, peak_memory=3.996 GB, invar_size=0.699 GB, outvar_size=1.734 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 15, 1, 1), 1] = ModuleProfileResult(compute_cost=2.018, peak_memory=10.263 GB, invar_size=3.301 GB, outvar_size=0.783 GB, temp_buffer_size=6.962 GB, available_memory=35.242 GB)
result[(0, 15, 1, 2), 0] = ModuleProfileResult(compute_cost=0.457, peak_memory=3.991 GB, invar_size=1.397 GB, outvar_size=1.031 GB, temp_buffer_size=1.563 GB, available_memory=35.242 GB)
result[(0, 15, 1, 2), 1] = ModuleProfileResult(compute_cost=1.372, peak_memory=7.854 GB, invar_size=4.162 GB, outvar_size=1.565 GB, temp_buffer_size=3.691 GB, available_memory=35.242 GB)
Profiling for submesh 1 (1, 2) takes 143.49 seconds
--------------------------------------------------
- Profiling for submesh 0 (1, 1):
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6] violates the layer coarsening rules, pruned.
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [2, 3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [3, 4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [4, 5, 6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11] violates the layer coarsening rules, pruned.
[TMP] Layer indices [5, 6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [6, 7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [7, 8, 9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12, 13, 14] violates the layer coarsening rules, pruned.
[TMP] Layer indices [8, 9, 10, 11, 12, 13, 14, 15] violates the layer coarsening rules, pruned.
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 8, 0, 0), 0] = ModuleProfileResult(compute_cost=0.504, peak_memory=5.084 GB, invar_size=0.834 GB, outvar_size=1.125 GB, temp_buffer_size=3.125 GB, available_memory=35.242 GB)
result[(0, 8, 0, 1), 0] = ModuleProfileResult(compute_cost=0.501, peak_memory=5.084 GB, invar_size=0.834 GB, outvar_size=1.125 GB, temp_buffer_size=3.125 GB, available_memory=35.242 GB)
result[(0, 8, 0, 0), 1] = ModuleProfileResult(compute_cost=1.327, peak_memory=17.784 GB, invar_size=2.793 GB, outvar_size=0.834 GB, temp_buffer_size=14.990 GB, available_memory=35.242 GB)
result[(5, 12, 0, 0), 0] = ModuleProfileResult(compute_cost=0.503, peak_memory=2.899 GB, invar_size=0.868 GB, outvar_size=0.750 GB, temp_buffer_size=1.281 GB, available_memory=35.242 GB)
result[(0, 8, 0, 1), 1] = ModuleProfileResult(compute_cost=1.341, peak_memory=17.784 GB, invar_size=2.793 GB, outvar_size=0.834 GB, temp_buffer_size=14.990 GB, available_memory=35.242 GB)
result[(5, 12, 0, 1), 0] = ModuleProfileResult(compute_cost=0.502, peak_memory=2.899 GB, invar_size=0.868 GB, outvar_size=0.750 GB, temp_buffer_size=1.281 GB, available_memory=35.242 GB)
result[(5, 12, 0, 0), 1] = ModuleProfileResult(compute_cost=1.383, peak_memory=17.378 GB, invar_size=2.392 GB, outvar_size=0.868 GB, temp_buffer_size=14.892 GB, available_memory=35.242 GB)
result[(9, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.380, peak_memory=2.876 GB, invar_size=0.657 GB, outvar_size=0.938 GB, temp_buffer_size=1.281 GB, available_memory=35.242 GB)
result[(5, 12, 0, 1), 1] = ModuleProfileResult(compute_cost=1.376, peak_memory=17.378 GB, invar_size=2.392 GB, outvar_size=0.868 GB, temp_buffer_size=14.892 GB, available_memory=35.242 GB)
result[(9, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.377, peak_memory=2.876 GB, invar_size=0.657 GB, outvar_size=0.938 GB, temp_buffer_size=1.281 GB, available_memory=35.242 GB)
result[(9, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=1.296, peak_memory=14.672 GB, invar_size=2.494 GB, outvar_size=0.825 GB, temp_buffer_size=12.084 GB, available_memory=35.242 GB)
result[(9, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=1.293, peak_memory=14.672 GB, invar_size=2.494 GB, outvar_size=0.825 GB, temp_buffer_size=12.084 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 102.02 seconds
--------------------------------------------------
----------------------------------------------------------------------
[TMP] Stage (0, 6, 0, 0) has been pruned...
[TMP] Stage (0, 6, 0, 1) has been pruned...
[TMP] Stage (0, 7, 0, 0) has been pruned...
[TMP] Stage (0, 7, 0, 1) has been pruned...
[TMP] Stage (0, 9, 0, 0) has been pruned...
[TMP] Stage (0, 9, 0, 1) has been pruned...
[TMP] Stage (1, 7, 0, 0) has been pruned...
[TMP] Stage (1, 7, 0, 1) has been pruned...
[TMP] Stage (1, 8, 0, 0) has been pruned...
[TMP] Stage (1, 8, 0, 1) has been pruned...
[TMP] Stage (1, 9, 0, 0) has been pruned...
[TMP] Stage (1, 9, 0, 1) has been pruned...
[TMP] Stage (1, 10, 0, 0) has been pruned...
[TMP] Stage (1, 10, 0, 1) has been pruned...
[TMP] Stage (2, 8, 0, 0) has been pruned...
[TMP] Stage (2, 8, 0, 1) has been pruned...
[TMP] Stage (2, 9, 0, 0) has been pruned...
[TMP] Stage (2, 9, 0, 1) has been pruned...
[TMP] Stage (2, 10, 0, 0) has been pruned...
[TMP] Stage (2, 10, 0, 1) has been pruned...
[TMP] Stage (3, 9, 0, 0) has been pruned...
[TMP] Stage (3, 9, 0, 1) has been pruned...
[TMP] Stage (3, 10, 0, 0) has been pruned...
[TMP] Stage (3, 10, 0, 1) has been pruned...
[TMP] Stage (3, 11, 0, 0) has been pruned...
[TMP] Stage (3, 11, 0, 1) has been pruned...
[TMP] Stage (4, 10, 0, 0) has been pruned...
[TMP] Stage (4, 10, 0, 1) has been pruned...
[TMP] Stage (4, 11, 0, 0) has been pruned...
[TMP] Stage (4, 11, 0, 1) has been pruned...
[TMP] Stage (4, 12, 0, 0) has been pruned...
[TMP] Stage (4, 12, 0, 1) has been pruned...
[TMP] Stage (5, 11, 0, 0) has been pruned...
[TMP] Stage (5, 11, 0, 1) has been pruned...
[TMP] Stage (5, 13, 0, 0) has been pruned...
[TMP] Stage (5, 13, 0, 1) has been pruned...
[TMP] Stage (6, 12, 0, 0) has been pruned...
[TMP] Stage (6, 12, 0, 1) has been pruned...
[TMP] Stage (6, 13, 0, 0) has been pruned...
[TMP] Stage (6, 13, 0, 1) has been pruned...
[TMP] Stage (6, 14, 0, 0) has been pruned...
[TMP] Stage (6, 14, 0, 1) has been pruned...
[TMP] Stage (7, 13, 0, 0) has been pruned...
[TMP] Stage (7, 13, 0, 1) has been pruned...
[TMP] Stage (7, 14, 0, 0) has been pruned...
[TMP] Stage (7, 14, 0, 1) has been pruned...
[TMP] Stage (7, 15, 0, 0) has been pruned...
[TMP] Stage (7, 15, 0, 1) has been pruned...
[TMP] Stage (8, 14, 0, 0) has been pruned...
[TMP] Stage (8, 14, 0, 1) has been pruned...
[TMP] Stage (8, 15, 0, 0) has been pruned...
[TMP] Stage (8, 15, 0, 1) has been pruned...
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]
Result mesh_shapes: [(1, 2)]
Result logical_mesh_shapes: [(2, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 293.55 s
compilation time breakdown: {'stage-construction': '251.48', 'stage-construction-dp': '1.34', 'stage-construction-compilation': '30.73', 'stage-construction-profiling': '195.51'}
 - Compile (worker): 21.15 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 207.65 s

[31.625194311141968, 28.102874994277954, 28.109789848327637, 28.125226736068726, 28.106879949569702, 28.105111122131348, 28.105916023254395]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 144.348 s.
 - Average e2e iteration time: 28.8700008392334 s.
 - Total local training time: 140.55300903320312 s.
 - Average local iteration time: 28.11100196838379 s.
 - Max allocated memory among devices: 28.023 GB.
 - Compilation times:  {'stage-construction': 251.48201251029968, 'stage-construction-dp': 1.3404321670532227, 'stage-construction-compilation': 30.731512308120728, 'stage-construction-profiling': 195.50939178466797}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_2_d`: 28.110584259033203
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal_prune_no_prof/bert_760M_512.pkl`...
