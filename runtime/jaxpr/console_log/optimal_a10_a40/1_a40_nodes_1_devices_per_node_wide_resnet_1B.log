
------------------------------------------------------------------
- (1/3) Profiling wide_resnet_1B with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_1B_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 320
    width_factor = 2
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (256, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1),)
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.799 GB, invar_size=3.758 GB, outvar_size=1.556 GB, temp_buffer_size=1.486 GB, available_memory=35.242 GB)
result[(0, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=6.799 GB, invar_size=3.758 GB, outvar_size=1.556 GB, temp_buffer_size=1.486 GB, available_memory=35.242 GB)
result[(0, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=11.092 GB, invar_size=9.057 GB, outvar_size=3.746 GB, temp_buffer_size=2.035 GB, available_memory=35.242 GB)
result[(0, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=11.092 GB, invar_size=9.057 GB, outvar_size=3.746 GB, temp_buffer_size=2.035 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 19.80 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-13-45-46.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]
Result mesh_shapes: [(1, 1)]
Result logical_mesh_shapes: [(1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 36.31 s
compilation time breakdown: {'stage-construction': '21.94', 'stage-construction-dp': '1.30', 'stage-construction-compilation': '2.63', 'stage-construction-profiling': '13.73'}
 - Compile (worker): 12.78 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[E] Meet unexpected error in profiling executables...

[E] Unexpected error occurred in compiling or profiling executables...
[E] Meet unexpected error in compiling and executing model...
[TMP] Current profiling results of key `1_a40_1_n_1_d`: none
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_1B_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling wide_resnet_1B with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_1B_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 320
    width_factor = 2
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (512, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1),)
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=14.578 GB, invar_size=10.621 GB, outvar_size=3.746 GB, temp_buffer_size=3.957 GB, available_memory=35.242 GB)
result[(0, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.911 GB, invar_size=3.767 GB, outvar_size=3.111 GB, temp_buffer_size=2.035 GB, available_memory=35.242 GB)
result[(0, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=8.911 GB, invar_size=3.767 GB, outvar_size=3.111 GB, temp_buffer_size=2.035 GB, available_memory=35.242 GB)
result[(0, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=14.578 GB, invar_size=10.621 GB, outvar_size=3.746 GB, temp_buffer_size=3.957 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 31.34 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-13-47-17.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]
Result mesh_shapes: [(1, 1)]
Result logical_mesh_shapes: [(1, 1)]
Result autosharding_option_dicts: [{}]
 - Compile (driver): 48.95 s
compilation time breakdown: {'stage-construction': '33.53', 'stage-construction-dp': '1.35', 'stage-construction-compilation': '2.67', 'stage-construction-profiling': '25.23'}
 - Compile (worker): 25.68 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[E] Meet unexpected error in profiling executables...

[E] Unexpected error occurred in compiling or profiling executables...
[E] Meet unexpected error in compiling and executing model...
[TMP] Current profiling results of key `1_a40_1_n_1_d`: none
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_1B_512.pkl`...

------------------------------------------------------------------
- (3/3) Profiling wide_resnet_1B with batch size: 1024...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/wide_resnet_1B_1024.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'wide_resnet' loads sucessfully. Model Info: 

WideResNet(
    # attributes
    stage_sizes = [3, 4, 6, 3]
    block_cls = BottleneckResNetBlock
    num_classes = 1024
    num_filters = 320
    width_factor = 2
    dtype = float32
    act = relu
) 

[I] Manually construct dummy batch with the shape of (1024, 224, 224, 3).
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1),)
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 15, 0, 0), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=21.655 GB, invar_size=13.749 GB, outvar_size=3.746 GB, temp_buffer_size=7.906 GB, available_memory=35.242 GB)
result[(0, 15, 0, 0), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=15.233 GB, invar_size=3.784 GB, outvar_size=6.222 GB, temp_buffer_size=5.228 GB, available_memory=35.242 GB)
result[(0, 15, 0, 1), 1] = ModuleProfileResult(compute_cost=0.000, peak_memory=21.655 GB, invar_size=13.749 GB, outvar_size=3.746 GB, temp_buffer_size=7.906 GB, available_memory=35.242 GB)
result[(0, 15, 0, 1), 0] = ModuleProfileResult(compute_cost=0.000, peak_memory=15.233 GB, invar_size=3.784 GB, outvar_size=6.222 GB, temp_buffer_size=5.228 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 32.48 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-13-49-00.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]
Result mesh_shapes: [(1, 1)]
Result logical_mesh_shapes: [(1, 1)]
Result autosharding_option_dicts: [{}]
 - Compile (driver): 50.61 s
compilation time breakdown: {'stage-construction': '34.43', 'stage-construction-dp': '1.07', 'stage-construction-compilation': '2.69', 'stage-construction-profiling': '25.87'}
 - Compile (worker): 26.41 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
[E] Meet unexpected error in profiling executables...

[E] Unexpected error occurred in compiling or profiling executables...
[E] Meet unexpected error in compiling and executing model...
[TMP] Current profiling results of key `1_a40_1_n_1_d`: none
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/wide_resnet_1B_1024.pkl`...
