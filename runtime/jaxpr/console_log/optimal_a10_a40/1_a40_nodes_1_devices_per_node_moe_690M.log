
------------------------------------------------------------------
- (1/3) Profiling moe_690M with batch size: 256...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_690M_256.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7f4843983b50>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1),)
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=2.428 GB, invar_size=1.256 GB, outvar_size=0.164 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(0, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.067, peak_memory=2.428 GB, invar_size=1.256 GB, outvar_size=0.164 GB, temp_buffer_size=1.008 GB, available_memory=35.242 GB)
result[(0, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.226, peak_memory=6.706 GB, invar_size=2.812 GB, outvar_size=1.324 GB, temp_buffer_size=3.894 GB, available_memory=35.242 GB)
result[(0, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.226, peak_memory=6.706 GB, invar_size=2.812 GB, outvar_size=1.324 GB, temp_buffer_size=3.894 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 18.32 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-13-35-58.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7]]
Result mesh_shapes: [(1, 1)]
Result logical_mesh_shapes: [(1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 36.82 s
compilation time breakdown: {'stage-construction': '20.71', 'stage-construction-dp': '1.33', 'stage-construction-compilation': '2.59', 'stage-construction-profiling': '12.05'}
 - Compile (worker): 15.64 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 60.68 s

[9.036920547485352, 8.037878274917603, 8.03979778289795, 8.037550926208496, 8.036851167678833, 8.039652585983276, 8.038717031478882]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 41.523 s.
 - Average e2e iteration time: 8.305000305175781 s.
 - Total local training time: 40.19300079345703 s.
 - Average local iteration time: 8.039000511169434 s.
 - Max allocated memory among devices: 11.822 GB.
 - Compilation times:  {'stage-construction': 20.70962142944336, 'stage-construction-dp': 1.3256635665893555, 'stage-construction-compilation': 2.5935213565826416, 'stage-construction-profiling': 12.053913831710815}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_1_d`: 8.03851318359375
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_690M_256.pkl`...

------------------------------------------------------------------
- (2/3) Profiling moe_690M with batch size: 512...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_690M_512.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7fea7d94bb20>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1),)
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.129, peak_memory=3.600 GB, invar_size=1.256 GB, outvar_size=0.328 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(0, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.129, peak_memory=3.600 GB, invar_size=1.256 GB, outvar_size=0.328 GB, temp_buffer_size=2.016 GB, available_memory=35.242 GB)
result[(0, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.438, peak_memory=10.762 GB, invar_size=2.976 GB, outvar_size=1.324 GB, temp_buffer_size=7.786 GB, available_memory=35.242 GB)
result[(0, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.438, peak_memory=10.762 GB, invar_size=2.976 GB, outvar_size=1.324 GB, temp_buffer_size=7.786 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 18.40 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-13-37-58.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7]]
Result mesh_shapes: [(1, 1)]
Result logical_mesh_shapes: [(1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 36.68 s
compilation time breakdown: {'stage-construction': '20.81', 'stage-construction-dp': '1.32', 'stage-construction-compilation': '2.66', 'stage-construction-profiling': '12.26'}
 - Compile (worker): 15.55 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 117.58 s

[17.16958999633789, 15.943976163864136, 15.938909769058228, 15.938525199890137, 15.94452714920044, 15.945771217346191, 15.950509548187256]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 82.105 s.
 - Average e2e iteration time: 16.421001434326172 s.
 - Total local training time: 79.71800231933594 s.
 - Average local iteration time: 15.944001197814941 s.
 - Max allocated memory among devices: 18.343 GB.
 - Compilation times:  {'stage-construction': 20.810569524765015, 'stage-construction-dp': 1.3228847980499268, 'stage-construction-compilation': 2.664794921875, 'stage-construction-profiling': 12.25601315498352}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_1_d`: 15.943649291992188
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_690M_512.pkl`...

------------------------------------------------------------------
- (3/3) Profiling moe_690M with batch size: 1024...
------------------------------------------------------------------
[TMP] Existed profiling results in `./jaxpr/prof_log/optimal/moe_690M_1024.pkl`, updating/rewriting it...
[I] Ray Cluster & Alpa backend initialization is completed.
[I] Device Info:
    - Devices num per node: 1
    - Nodes num: 1
[I] Loading flax model....
[I] Model 'moe' loads sucessfully. Model Info: 

FlaxMoEForLMModule(
    # attributes
    config = <model.moe_model.MoEConfig object at 0x7fb9fa3f5be0>
    dtype = float16
    bias_init = zeros
) 

[I] Manually constructing dummy batch...
[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing Alpa parallelized train step func...
[I] Alpa parallelized train step func construction is completed.
-------------------- Automatic stage clustering --------------------
submesh_choices: ((1, 1),)
- Profiling for submesh 0 (1, 1):
- Generate all stage infos (Jaxpr -> HLO)
- Compile all stages
- Profile all stages
result[(0, 7, 0, 0), 0] = ModuleProfileResult(compute_cost=0.254, peak_memory=5.944 GB, invar_size=1.257 GB, outvar_size=0.656 GB, temp_buffer_size=4.031 GB, available_memory=35.242 GB)
result[(0, 7, 0, 1), 0] = ModuleProfileResult(compute_cost=0.254, peak_memory=5.944 GB, invar_size=1.257 GB, outvar_size=0.656 GB, temp_buffer_size=4.031 GB, available_memory=35.242 GB)
result[(0, 7, 0, 0), 1] = ModuleProfileResult(compute_cost=0.861, peak_memory=18.873 GB, invar_size=3.305 GB, outvar_size=1.324 GB, temp_buffer_size=15.568 GB, available_memory=35.242 GB)
result[(0, 7, 0, 1), 1] = ModuleProfileResult(compute_cost=0.861, peak_memory=18.873 GB, invar_size=3.305 GB, outvar_size=1.324 GB, temp_buffer_size=15.568 GB, available_memory=35.242 GB)
Profiling for submesh 0 (1, 1) takes 18.07 seconds
--------------------------------------------------
Profile result saved to: profile-results-2023-11-17-13-40-55.npy
----------------------------------------------------------------------
Result forward_stage_layer_ids: [[0, 1, 2, 3, 4, 5, 6, 7]]
Result mesh_shapes: [(1, 1)]
Result logical_mesh_shapes: [(1, 1)]
Result autosharding_option_dicts: [{'force_batch_dim_to_mesh_dim': 0}]
 - Compile (driver): 35.74 s
compilation time breakdown: {'stage-construction': '20.40', 'stage-construction-dp': '1.26', 'stage-construction-compilation': '2.72', 'stage-construction-profiling': '11.77'}
 - Compile (worker): 15.56 s
[I] Training process warmup (2 rounds) with dummy input batch...
    - Warmup iteration: 1/2
    - Warmup iteration: 2/2
[I] Ready to perform training process.
[I] Benchmark the training process with entire dataset and profile with driver overhead...
    - Iteration 1 / 5 is performed...
    - Iteration 2 / 5 is performed...
    - Iteration 3 / 5 is performed...
    - Iteration 4 / 5 is performed...
 - Benchmark: 230.62 s

[33.28611707687378, 31.693425178527832, 31.716246604919434, 31.715956449508667, 31.69863224029541, 31.671645402908325, 31.68647575378418]


[I] Performance metrics:
 - Iteration count: 5.
 - Total e2e training time : 162.893 s.
 - Average e2e iteration time: 32.579002380371094 s.
 - Total local training time: 158.489013671875 s.
 - Average local iteration time: 31.698001861572266 s.
 - Max allocated memory among devices: 31.384 GB.
 - Compilation times:  {'stage-construction': 20.40024757385254, 'stage-construction-dp': 1.2621095180511475, 'stage-construction-compilation': 2.724397659301758, 'stage-construction-profiling': 11.766631841659546}
 - Metadata:  []
 - Is need save result:  True

[TMP] Current profiling results of key `1_a40_1_n_1_d`: 31.697790145874023
[TMP] Updated profiling results stored in `./jaxpr/prof_log/optimal/moe_690M_1024.pkl`...
