
[I] Loading Crius kernel-level profiler...
[TMP] Profiling results not found in `None`, creating it...

[I] Loading model and generating sharded HLO module...
[I] Initializing XLA devices takes 0.3920011520385742 s.
[I] Loading flax model....
[I] Model 'bert' loads sucessfully. Model Info: 

FlaxBertForMaskedLMModule(
    # attributes
    config = <model.bert_model.BertConfig object at 0x7f425f662850>
    dtype = float16
) 

[I] Initialize training state...
[I] Training state initialization is completed.
[I] Constructing general train step func...
[I] General train step func construction is completed.
[I] Model has been loaded, begin Jaxpr transformation...


Layer 0:
Eqn 5 in layer 0: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 10 in layer 0: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 36 in layer 0: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 56 in layer 0: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 68 in layer 0: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 71 in layer 0: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 100 in layer 0: Primitive: remat2 | FLOPs (GB): 20512.0 | Memory access (GB): 18.43164063245058 | Attainable performance: 37400 | Computation load: 0.5484491978609626
Layer computation load: 0.8188235294117647

Layer 1:
Eqn 1 in layer 1: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 9 in layer 1: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 36 in layer 1: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 56 in layer 1: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 68 in layer 1: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 71 in layer 1: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 98 in layer 1: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 106 in layer 1: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 133 in layer 1: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 153 in layer 1: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 165 in layer 1: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 168 in layer 1: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 174 in layer 1: Primitive: remat2 | FLOPs (GB): 35456.0 | Memory access (GB): 33.9921875 | Attainable performance: 37400 | Computation load: 0.9480213903743315
Layer computation load: 1.3450267379679144

Layer 2:
Eqn 24 in layer 2: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 32 in layer 2: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 59 in layer 2: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 79 in layer 2: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 91 in layer 2: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 94 in layer 2: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 121 in layer 2: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 129 in layer 2: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 158 in layer 2: Primitive: remat2 | FLOPs (GB): 27776.0 | Memory access (GB): 22.921875 | Attainable performance: 37400 | Computation load: 0.7426737967914439
Layer computation load: 1.040427807486631

Layer 3:
Eqn 1 in layer 3: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 21 in layer 3: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 33 in layer 3: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 36 in layer 3: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 63 in layer 3: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 71 in layer 3: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 98 in layer 3: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 118 in layer 3: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 130 in layer 3: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 133 in layer 3: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 162 in layer 3: Primitive: remat2 | FLOPs (GB): 30208.0 | Memory access (GB): 30.796875 | Attainable performance: 37400 | Computation load: 0.8077005347593583
Layer computation load: 1.1054545454545455

Layer 4:
Eqn 1 in layer 4: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 9 in layer 4: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 36 in layer 4: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 56 in layer 4: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 68 in layer 4: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 71 in layer 4: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 98 in layer 4: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 106 in layer 4: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 133 in layer 4: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 153 in layer 4: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 165 in layer 4: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 168 in layer 4: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 174 in layer 4: Primitive: remat2 | FLOPs (GB): 35456.0 | Memory access (GB): 33.9921875 | Attainable performance: 37400 | Computation load: 0.9480213903743315
Layer computation load: 1.3450267379679144

Layer 5:
Eqn 24 in layer 5: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 32 in layer 5: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 59 in layer 5: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 79 in layer 5: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 91 in layer 5: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 94 in layer 5: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 121 in layer 5: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 129 in layer 5: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 158 in layer 5: Primitive: remat2 | FLOPs (GB): 27776.0 | Memory access (GB): 22.921875 | Attainable performance: 37400 | Computation load: 0.7426737967914439
Layer computation load: 1.040427807486631

Layer 6:
Eqn 1 in layer 6: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 21 in layer 6: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 33 in layer 6: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 36 in layer 6: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 63 in layer 6: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 71 in layer 6: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 98 in layer 6: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 118 in layer 6: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 130 in layer 6: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 133 in layer 6: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 160 in layer 6: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 168 in layer 6: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 174 in layer 6: Primitive: remat2 | FLOPs (GB): 35456.0 | Memory access (GB): 33.9921875 | Attainable performance: 37400 | Computation load: 0.9480213903743315
Layer computation load: 1.3450267379679144

Layer 7:
Eqn 24 in layer 7: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 44 in layer 7: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 56 in layer 7: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 59 in layer 7: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 86 in layer 7: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 94 in layer 7: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 121 in layer 7: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 141 in layer 7: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 153 in layer 7: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 156 in layer 7: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 162 in layer 7: Primitive: remat2 | FLOPs (GB): 27008.0 | Memory access (GB): 28.9765625 | Attainable performance: 37400 | Computation load: 0.7221390374331551
Layer computation load: 1.0198930481283424

Layer 8:
Eqn 24 in layer 8: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 32 in layer 8: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 59 in layer 8: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 79 in layer 8: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 91 in layer 8: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 94 in layer 8: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 121 in layer 8: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 129 in layer 8: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 158 in layer 8: Primitive: remat2 | FLOPs (GB): 27776.0 | Memory access (GB): 22.921875 | Attainable performance: 37400 | Computation load: 0.7426737967914439
Layer computation load: 1.040427807486631

Layer 9:
Eqn 1 in layer 9: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 21 in layer 9: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 33 in layer 9: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 36 in layer 9: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 63 in layer 9: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 71 in layer 9: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 98 in layer 9: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 118 in layer 9: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 130 in layer 9: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 133 in layer 9: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 139 in layer 9: Primitive: remat2 | FLOPs (GB): 27008.0 | Memory access (GB): 28.9765625 | Attainable performance: 37400 | Computation load: 0.7221390374331551
Layer computation load: 1.0198930481283424

Layer 10:
Eqn 24 in layer 10: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 32 in layer 10: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 59 in layer 10: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 79 in layer 10: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 91 in layer 10: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 94 in layer 10: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 121 in layer 10: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 129 in layer 10: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 158 in layer 10: Primitive: remat2 | FLOPs (GB): 27776.0 | Memory access (GB): 22.921875 | Attainable performance: 37400 | Computation load: 0.7426737967914439
Layer computation load: 1.040427807486631

Layer 11:
Eqn 1 in layer 11: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 21 in layer 11: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 33 in layer 11: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 36 in layer 11: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 63 in layer 11: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 71 in layer 11: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 98 in layer 11: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 118 in layer 11: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 130 in layer 11: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 133 in layer 11: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 162 in layer 11: Primitive: remat2 | FLOPs (GB): 30208.0 | Memory access (GB): 30.796875 | Attainable performance: 37400 | Computation load: 0.8077005347593583
Layer computation load: 1.1054545454545455

Layer 12:
Eqn 1 in layer 12: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 9 in layer 12: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 36 in layer 12: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 56 in layer 12: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 68 in layer 12: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 71 in layer 12: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 98 in layer 12: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 106 in layer 12: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 133 in layer 12: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 153 in layer 12: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 165 in layer 12: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 168 in layer 12: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 174 in layer 12: Primitive: remat2 | FLOPs (GB): 35456.0 | Memory access (GB): 33.9921875 | Attainable performance: 37400 | Computation load: 0.9480213903743315
Layer computation load: 1.3450267379679144

Layer 13:
Eqn 24 in layer 13: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 32 in layer 13: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 59 in layer 13: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 79 in layer 13: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 91 in layer 13: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 94 in layer 13: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 121 in layer 13: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 129 in layer 13: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 158 in layer 13: Primitive: remat2 | FLOPs (GB): 27776.0 | Memory access (GB): 22.921875 | Attainable performance: 37400 | Computation load: 0.7426737967914439
Layer computation load: 1.040427807486631

Layer 14:
Eqn 1 in layer 14: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 21 in layer 14: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 33 in layer 14: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 36 in layer 14: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 63 in layer 14: Primitive: dot_general | FLOPs (GB): 512.0 | Memory access (GB): 0.34375 | Attainable performance: 37400 | Computation load: 0.013689839572192513
Eqn 71 in layer 14: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 98 in layer 14: Primitive: dot_general | FLOPs (GB): 384.0 | Memory access (GB): 0.2734375 | Attainable performance: 37400 | Computation load: 0.010267379679144385
Eqn 118 in layer 14: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 130 in layer 14: Primitive: dot_general | FLOPs (GB): 64.0 | Memory access (GB): 1.125 | Attainable performance: 37400 | Computation load: 0.001711229946524064
Eqn 133 in layer 14: Primitive: dot_general | FLOPs (GB): 3200.0 | Memory access (GB): 1.8203125 | Attainable performance: 37400 | Computation load: 0.0855614973262032
Eqn 139 in layer 14: Primitive: remat2 | FLOPs (GB): 27008.0 | Memory access (GB): 28.9765625 | Attainable performance: 37400 | Computation load: 0.7221390374331551
Layer computation load: 1.0198930481283424

Layer 15:
Eqn 3 in layer 15: Primitive: remat2 | FLOPs (GB): 24576.0 | Memory access (GB): 14.25 | Attainable performance: 37400 | Computation load: 0.6571122994652406
Layer computation load: 0.6571122994652406
Layer memory access: [26.41601563245058, 47.0078125, 31.59375, 41.6484375, 47.0078125, 31.59375, 47.0078125, 39.828125, 31.59375, 39.828125, 31.59375, 41.6484375, 47.0078125, 31.59375, 39.828125, 14.25]

Layer GPU fractions:
[0.09, 0.17, 0.149, 0.177, 0.237, 0.201, 0.282, 0.23, 0.252, 0.264, 0.287, 0.323, 0.415, 0.338, 0.348, 0.235]

Layer GPU fractions:
[0.09, 0.17, 0.149, 0.177, 0.237, 0.201, 0.282, 0.23, 0.252, 0.264, 0.287, 0.323, 0.415, 0.338, 0.348, 0.235]

[[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]], [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]], [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15]], [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]]

[[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15]], [[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]], [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15]], [[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]]

[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15]]
4290248704.0
0.07496665925596548
([2, 2], 0.07496665925596548)

[[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]]
4290248704.0
0.2984024128588775
([2, 2], 0.2984024128588775)

[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]
4290248704.0
0.4808346909281818
([2, 2], 0.4808346909281818)

[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]
4290248704.0
0.6547824066054309
([2, 2], 0.6547824066054309)

{'0_9__10_15': {0: {'1_2': (2.052, 2, 18.625882352941176, 13857980416.0, 0, 0), '2_1': (2.052, 2, 18.625882352941176, 0, 2835873792.0, 0)}, 1: {'1_2': (1.9459999999999997, 2, 17.66314438502674, 6979321856.0, 0, 0), '2_1': (1.9459999999999997, 2, 17.66314438502674, 0, 1454374912.0, 0)}}, '0_8__9_15': {0: {'1_2': (1.788, 2, 16.22913368983957, 12280922112.0, 0, 0), '2_1': (1.788, 2, 16.22913368983957, 0, 2522873856.0, 0)}, 1: {'1_2': (2.21, 2, 20.059893048128345, 8556380160.0, 0, 0), '2_1': (2.21, 2, 20.059893048128345, 0, 1767374848.0, 0)}}, '0_10__11_15': {0: {'1_2': (2.339, 2, 21.226951871657754, 14898167808.0, 0, 0), '2_1': (2.339, 2, 21.226951871657754, 0, 3045588992.0, 0)}, 1: {'1_2': (1.6589999999999998, 2, 15.062074866310162, 5939134464.0, 0, 0), '2_1': (1.6589999999999998, 2, 15.062074866310162, 0, 1244659712.0, 0)}}, '0_7__8_15': {0: {'1_2': (1.536, 2, 13.940192513368984, 11240734720.0, 0, 0), '2_1': (1.536, 2, 13.940192513368984, 0, 2313158656.0, 0)}, 1: {'1_2': (2.4619999999999997, 2, 22.34883422459893, 9596567552.0, 0, 0), '2_1': (2.4619999999999997, 2, 22.34883422459893, 0, 1977090048.0, 0)}}}
[I] Pipeline partition mode: auto | Layer-to-stage partition: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]
[I] Pipeline partition mode: auto | Cell-generated physical mesh shapes: [(1, 2), (1, 2)]
[I] Loading model and transform to Jaxpr stages takes 29.45167636871338 s.
[I] The GPU sharding of pipeline stages is: [2, 2]
[TMP] Plans in the non-dominated set:
0_9__10_15::1_2__1_2
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]
0.07496665925596548
207869706240.0

0_9__10_15::1_2__2_1
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(2, 1), layer_shape=None)]
0.07496665925596548
231866892288.0

0_9__10_15::2_1__1_2
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(2, 1), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]
0.07496665925596548
157696917504.0

0_9__10_15::2_1__2_1
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(2, 1), layer_shape=None), StageShape(type='single', stage_shape=(2, 1), layer_shape=None)]
0.07496665925596548
64353730560.0

0_8__9_15::1_2__1_2
[[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]
0.2984024128588775
184213831680.0

0_8__9_15::1_2__2_1
[[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(2, 1), layer_shape=None)]
0.2984024128588775
213375516672.0

0_8__9_15::2_1__1_2
[[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(2, 1), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]
0.2984024128588775
179023380480.0

0_8__9_15::2_1__2_1
[[0, 1, 2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(2, 1), layer_shape=None), StageShape(type='single', stage_shape=(2, 1), layer_shape=None)]
0.2984024128588775
64353730560.0

0_10__11_15::1_2__1_2
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]
0.4808346909281818
223472517120.0

0_10__11_15::1_2__2_1
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(2, 1), layer_shape=None)]
0.4808346909281818
244009402368.0

0_10__11_15::2_1__1_2
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(2, 1), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]
0.4808346909281818
143679553536.00003

0_10__11_15::2_1__2_1
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(2, 1), layer_shape=None), StageShape(type='single', stage_shape=(2, 1), layer_shape=None)]
0.4808346909281818
64353730560.0

0_7__8_15::1_2__1_2
[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]
0.6547824066054309
168611020800.0

0_7__8_15::1_2__2_1
[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(2, 1), layer_shape=None)]
0.6547824066054309
201233006592.0

0_7__8_15::2_1__1_2
[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(2, 1), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]
0.6547824066054309
193040744448.0

0_7__8_15::2_1__2_1
[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]
[StageShape(type='single', stage_shape=(2, 1), layer_shape=None), StageShape(type='single', stage_shape=(2, 1), layer_shape=None)]
0.6547824066054309
64353730560.0

[TMP] Existed tuning database in `/home/cyxue/Projects/crius/Crius/runtime/jaxpr/tuning_database/tuning_database.pkl`, updating/rewriting it...
{'plan_set': {'wide_resnet__1B::256__16::1::a40__2__2': ['0_15::1_4', '0_15::2_2', '0_15::4_1'], 'wide_resnet__1B::256__16::2::a40__2__2': ['0_9__10_15::2_1__1_2', '0_9__10_15::2_1__2_1', '0_8__9_15::2_1__1_2', '0_8__9_15::2_1__2_1', '0_10__11_15::2_1__1_2', '0_10__11_15::2_1__2_1', '0_7__8_15::2_1__1_2', '0_7__8_15::2_1__2_1'], 'wide_resnet__1B::256__16::3::a40__2__2': ['0_5__6_9__10_15::2_1__1_1__1_1', '0_6__7_9__10_15::2_1__1_1__1_1', '0_5__6_10__11_15::2_1__1_1__1_1', '0_6__7_10__11_15::2_1__1_1__1_1', '0_3__4_11__12_15::1_1__1_2__1_1', '0_3__4_11__12_15::1_1__2_1__1_1', '0_5__6_11__12_15::2_1__1_1__1_1', '0_6__7_11__12_15::2_1__1_1__1_1', '0_7__8_11__12_15::2_1__1_1__1_1', '0_7__8_12__13_15::2_1__1_1__1_1'], 'wide_resnet__1B::256__16::4::a40__2__2': ['0_6__7_9__10_12__13_15::1_1__1_1__1_1__1_1', '0_6__7_10__11_13__14_15::1_1__1_1__1_1__1_1', '0_5__6_9__10_12__13_15::1_1__1_1__1_1__1_1', '0_7__8_11__12_13__14_15::1_1__1_1__1_1__1_1', '0_7__8_10__11_13__14_15::1_1__1_1__1_1__1_1', '0_5__6_8__9_12__13_15::1_1__1_1__1_1__1_1', '0_5__6_10__11_13__14_15::1_1__1_1__1_1__1_1', '0_6__7_11__12_13__14_15::1_1__1_1__1_1__1_1', '0_6__7_9__10_13__14_15::1_1__1_1__1_1__1_1', '0_5__6_9__10_13__14_15::1_1__1_1__1_1__1_1', '0_8__9_11__12_13__14_15::1_1__1_1__1_1__1_1', '0_5__6_8__9_11__12_15::1_1__1_1__1_1__1_1', '0_5__6_11__12_13__14_15::1_1__1_1__1_1__1_1', '0_5__6_8__9_13__14_15::1_1__1_1__1_1__1_1'], 'wide_resnet__500M::256__16::2::a40__2__2': ['0_7__8_15::2_1__2_1', '0_8__9_15::2_1__2_1'], 'wide_resnet__500M::512__16::2::a40__2__2': ['0_7__8_15::2_1__2_1', '0_8__9_15::2_1__2_1'], 'wide_resnet__2B::512__16::4::a40__4__2': ['0_5__6_9__10_12__13_15::1_2__1_2__1_2__1_2', '0_5__6_9__10_12__13_15::2_1__2_1__2_1__2_1', '0_4__5_8__9_12__13_15::2_1__2_1__2_1__2_1', '0_5__6_8__9_12__13_15::2_1__2_1__2_1__2_1', '0_4__5_9__10_12__13_15::2_1__2_1__2_1__2_1', '0_6__7_9__10_12__13_15::2_1__2_1__2_1__2_1', '0_3__4_8__9_12__13_15::2_1__2_1__2_1__2_1', '0_6__7_10__11_13__14_15::2_1__2_1__2_1__2_1', '0_5__6_10__11_13__14_15::2_1__2_1__2_1__2_1', '0_4__5_8__9_11__12_15::2_1__2_1__2_1__2_1', '0_5__6_9__10_13__14_15::2_1__2_1__2_1__2_1', '0_4__5_7__8_12__13_15::2_1__2_1__2_1__2_1', '0_5__6_8__9_11__12_15::2_1__2_1__2_1__2_1', '0_6__7_10__11_12__13_15::2_1__2_1__2_1__2_1', '0_4__5_7__8_11__12_15::2_1__2_1__2_1__2_1', '0_3__4_7__8_12__13_15::2_1__2_1__2_1__2_1', '0_5__6_10__11_12__13_15::2_1__2_1__2_1__2_1', '0_6__7_8__9_12__13_15::2_1__2_1__2_1__2_1', '0_3__4_7__8_11__12_15::2_1__2_1__2_1__2_1', '0_4__5_9__10_13__14_15::2_1__2_1__2_1__2_1', '0_3__4_9__10_12__13_15::2_1__2_1__2_1__2_1', '0_6__7_9__10_13__14_15::2_1__2_1__2_1__2_1', '0_3__4_8__9_11__12_15::2_1__2_1__2_1__2_1', '0_5__6_7__8_12__13_15::2_1__2_1__2_1__2_1', '0_5__6_9__10_11__12_15::2_1__2_1__2_1__2_1', '0_5__6_7__8_11__12_15::2_1__2_1__2_1__2_1', '0_6__7_11__12_13__14_15::2_1__2_1__2_1__2_1', '0_4__5_9__10_11__12_15::2_1__2_1__2_1__2_1', '0_6__7_8__9_11__12_15::2_1__2_1__2_1__2_1', '0_6__7_9__10_11__12_15::2_1__2_1__2_1__2_1', '0_2__3_7__8_12__13_15::2_1__2_1__2_1__2_1', '0_2__3_8__9_12__13_15::2_1__2_1__2_1__2_1'], 'wide_resnet__2B::256__16::4::a40__4__2': ['0_6__7_10__11_13__14_15::2_1__1_2__1_2__2_1', '0_6__7_10__11_13__14_15::2_1__1_2__2_1__1_2', '0_6__7_10__11_13__14_15::2_1__2_1__1_2__1_2', '0_6__7_9__10_12__13_15::2_1__1_2__1_2__2_1', '0_6__7_9__10_12__13_15::2_1__1_2__2_1__1_2', '0_6__7_9__10_12__13_15::2_1__2_1__1_2__1_2', '0_5__6_9__10_12__13_15::2_1__1_2__1_2__2_1', '0_5__6_9__10_12__13_15::2_1__1_2__2_1__1_2', '0_5__6_9__10_12__13_15::2_1__2_1__1_2__1_2', '0_7__8_11__12_13__14_15::1_2__1_2__2_1__2_1', '0_7__8_11__12_13__14_15::1_2__2_1__1_2__2_1', '0_7__8_11__12_13__14_15::1_2__2_1__2_1__1_2', '0_7__8_11__12_13__14_15::2_1__1_2__1_2__2_1', '0_7__8_11__12_13__14_15::2_1__1_2__2_1__1_2', '0_7__8_11__12_13__14_15::2_1__2_1__1_2__1_2', '0_7__8_10__11_13__14_15::1_2__1_2__2_1__2_1', '0_7__8_10__11_13__14_15::1_2__2_1__1_2__2_1', '0_7__8_10__11_13__14_15::1_2__2_1__2_1__1_2', '0_7__8_10__11_13__14_15::2_1__1_2__1_2__2_1', '0_7__8_10__11_13__14_15::2_1__1_2__2_1__1_2', '0_7__8_10__11_13__14_15::2_1__2_1__1_2__1_2', '0_5__6_8__9_12__13_15::2_1__1_2__1_2__2_1', '0_5__6_8__9_12__13_15::2_1__1_2__2_1__1_2', '0_5__6_8__9_12__13_15::2_1__2_1__1_2__1_2', '0_5__6_10__11_13__14_15::2_1__1_2__1_2__2_1', '0_5__6_10__11_13__14_15::2_1__1_2__2_1__1_2', '0_5__6_10__11_13__14_15::2_1__2_1__1_2__1_2', '0_6__7_11__12_13__14_15::2_1__1_2__2_1__1_2', '0_6__7_11__12_13__14_15::2_1__2_1__1_2__1_2', '0_6__7_9__10_13__14_15::2_1__2_1__1_2__1_2', '0_5__6_9__10_13__14_15::2_1__2_1__1_2__1_2', '0_8__9_11__12_13__14_15::2_1__2_1__1_2__1_2'], 'wide_resnet__4B::256__16::8::a40__8__2': ['0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__1_2__1_2__1_2__1_2', '0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__1_2__1_2__1_2__2_1', '0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__1_2__1_2__2_1__1_2', '0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__1_2__1_2__2_1__2_1', '0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__1_2__2_1__1_2__1_2', '0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__2_1__1_2__1_2__1_2', '0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__2_1__1_2__1_2__2_1', '0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__2_1__1_2__2_1__1_2', '0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__2_1__2_1__1_2__1_2', '0_4__5_6__7_8__9_10__11_12__13_13__14_14__15_15::2_1__2_1__2_1__2_1__1_2__1_2__1_2__1_2'], 'wide_resnet__500M::256__16::1::a40__1__2': ['0_15::1_2', '0_15::2_1'], 'wide_resnet__500M::256__16::2::a40__1__2': ['0_10__11_15::1_1__1_1', '0_9__10_15::1_1__1_1', '0_11__12_15::1_1__1_1', '0_8__9_15::1_1__1_1'], 'wide_resnet__2B::256__16::8::a40__4__2': ['0_3__4_6__7_8__9_10__11_12__13_13__14_14__15_15::1_1__1_1__1_1__1_1__1_1__1_1__1_1__1_1', '0_4__5_6__7_8__9_10__11_12__13_13__14_14__15_15::1_1__1_1__1_1__1_1__1_1__1_1__1_1__1_1'], 'bert__760M::256__16::1::a40__1__2': ['0_15::1_2', '0_15::2_1'], 'bert__760M::256__16::2::a40__1__2': ['0_9__10_15::1_1__1_1'], 'moe__690M::256__16::1::a40__1__2': ['0_7::2_1'], 'moe__690M::256__16::2::a40__1__2': ['0_3__4_7::1_1__1_1'], 'bert__1.3B::256__16::2::a40__2__2': ['0_9__10_15::1_2__1_2', '0_9__10_15::1_2__2_1', '0_9__10_15::2_1__1_2', '0_9__10_15::2_1__2_1', '0_8__9_15::1_2__1_2', '0_8__9_15::1_2__2_1', '0_8__9_15::2_1__1_2', '0_8__9_15::2_1__2_1', '0_10__11_15::1_2__1_2', '0_10__11_15::1_2__2_1', '0_10__11_15::2_1__1_2', '0_10__11_15::2_1__2_1', '0_7__8_15::1_2__1_2', '0_7__8_15::1_2__2_1', '0_7__8_15::2_1__1_2', '0_7__8_15::2_1__2_1'], 'bert__1.3B::256__16::4::a40__4__2': ['0_5__6_9__10_12__13_15::1_2__1_2__1_2__1_2', '0_5__6_9__10_12__13_15::1_2__1_2__1_2__2_1', '0_5__6_9__10_12__13_15::1_2__1_2__2_1__1_2', '0_5__6_9__10_12__13_15::1_2__1_2__2_1__2_1', '0_5__6_9__10_12__13_15::1_2__2_1__1_2__1_2', '0_5__6_9__10_12__13_15::1_2__2_1__1_2__2_1', '0_5__6_9__10_12__13_15::1_2__2_1__2_1__1_2', '0_5__6_9__10_12__13_15::1_2__2_1__2_1__2_1', '0_5__6_9__10_12__13_15::2_1__1_2__1_2__1_2', '0_5__6_9__10_12__13_15::2_1__1_2__1_2__2_1', '0_5__6_9__10_12__13_15::2_1__1_2__2_1__1_2', '0_5__6_9__10_12__13_15::2_1__1_2__2_1__2_1', '0_5__6_9__10_12__13_15::2_1__2_1__1_2__1_2', '0_5__6_9__10_12__13_15::2_1__2_1__1_2__2_1', '0_5__6_9__10_12__13_15::2_1__2_1__2_1__1_2', '0_5__6_9__10_12__13_15::2_1__2_1__2_1__2_1', '0_4__5_9__10_12__13_15::1_2__1_2__1_2__1_2', '0_4__5_9__10_12__13_15::1_2__1_2__1_2__2_1', '0_4__5_9__10_12__13_15::2_1__2_1__2_1__1_2', '0_4__5_9__10_12__13_15::2_1__2_1__2_1__2_1', '0_4__5_8__9_12__13_15::2_1__2_1__2_1__2_1', '0_5__6_8__9_12__13_15::2_1__2_1__2_1__2_1', '0_4__5_8__9_11__12_15::2_1__2_1__2_1__2_1', '0_6__7_9__10_12__13_15::2_1__2_1__2_1__2_1', '0_6__7_10__11_12__13_15::2_1__2_1__2_1__2_1', '0_5__6_10__11_12__13_15::2_1__2_1__2_1__2_1', '0_5__6_8__9_11__12_15::2_1__2_1__2_1__2_1', '0_4__5_7__8_11__12_15::2_1__2_1__2_1__2_1', '0_4__5_7__8_10__11_15::2_1__1_1__1_1__4_1', '0_4__5_7__8_12__13_15::1_1__1_1__4_1__2_1', '0_7__8_10__11_12__13_15::4_1__1_1__1_1__2_1', '0_4__5_10__11_12__13_15::2_1__2_1__2_1__2_1']}, 'selected_cell_num_stages': {'wide_resnet__1B::256__16::a40__2__2': 2}}
[TMP] Storing tuning database to '/home/cyxue/Projects/crius/Crius/runtime/jaxpr/tuning_database/tuning_database.pkl'...
[I] Pipeline partition mode: auto | Parallel enum mode: auto | Parallel plans: [[StageShape(type='single', stage_shape=(1, 2), layer_shape=None), StageShape(type='single', stage_shape=(1, 2), layer_shape=None)]]

[I] (Parallel plan idx: 0) Sharding stages...
[I] Sharding stages takes 21.75452184677124 s.
[I] (Parallel plan idx: 0) SPMD partitioning and compiling (kernel fusing) HLO stages...
[I] SPMD partitioning and pre-compiling HLO modules concurrently takes 15.357958555221558 s.

[I] All parallel plans in the cell have been sharded and compiled.
[TMP] Writing only-sharded HLO text to '/home/cyxue/Projects/crius/Crius/runtime/jaxpr/tmp/bert_1.3B_256_sharded_stages.pkl'...
[TMP] Writing optimized HLO text to '/home/cyxue/Projects/crius/Crius/runtime/jaxpr/tmp/bert_1.3B_256_optimized_stages.pkl'...
[TMP] Writing inter-stages communicated vars to '/home/cyxue/Projects/crius/Crius/runtime/jaxpr/tmp/bert_1.3B_256_inter_stages_comm_vars.pkl'

[I] Parallel plan idx: 0 | Parallelism: [(1, 2), (1, 2)]

[I] (Parallel plan idx: 0) Parsing HLO texts and profiling XLA operators...
[I] Pipeline partition mode: auto | Preset physical mesh shapes: [(1, 2), (1, 2)]
[TMP] Loading offline profiled communication data: `1_a40_1_n_2_d_ib.pkl`...
[TMP] Loading offline profiled communication data: `2_a40_2_n_1_d_ib.pkl`...
\Time of module 0 (stage 0):
Intra-stage comm time: 0.21092094480991364
Grad sync time: 0

[I] Optimized module 0 for stage 0, comm time has been statically analyzed.
\Time of module 1 (stage 1):
Intra-stage comm time: 0.07834206521511078
Grad sync time: 0

[I] Optimized module 1 for stage 1, comm time has been statically analyzed.
\Time of module 2 (stage 1):
Intra-stage comm time: 0.1719757220009342
Grad sync time: 0

[I] Optimized module 2 for stage 1, comm time has been statically analyzed.
\Time of module 3 (stage 0):
Intra-stage comm time: 0.3856840133666992
Grad sync time: 0

[I] Optimized module 3 for stage 0, comm time has been statically analyzed.
\Time of module 4 (stage 0):
Intra-stage comm time: 0
Grad sync time: 0

[I] Optimized module 4 for stage 0, comm time has been statically analyzed.
\Time of module 5 (stage 1):
Intra-stage comm time: 0
Grad sync time: 0

[I] Optimized module 5 for stage 1, comm time has been statically analyzed.
[TMP] Memory footprint of the stage 0 is 10.545270927250385 GB, while the available memory of the XLA device is 35.33237304631621 GB.
[TMP] Memory footprint of the stage 1 is 4.972215656191111 GB, while the available memory of the XLA device is 35.33237304631621 GB.
[I] Only-sharded module 0 for stage 0, constructing entry XLA computation...
[I] Compiling HLO module...
[I] Profiling HLO modules...
    - Iteration 0/5: Kernel execution time: 0.29758537200000035 s.
    - Iteration 1/5: Kernel execution time: 0.29773165399999996 s.
    - Iteration 2/5: Kernel execution time: 0.2977675180000003 s.
    - Iteration 3/5: Kernel execution time: 0.29766398500000024 s.
    - Iteration 4/5: Kernel execution time: 0.29760297599999996 s.
[I] Only-sharded module 1 for stage 1, constructing entry XLA computation...
[I] Compiling HLO module...
[I] Profiling HLO modules...
    - Iteration 0/5: Kernel execution time: 0.11057469600000003 s.
    - Iteration 1/5: Kernel execution time: 0.11053792199999997 s.
    - Iteration 2/5: Kernel execution time: 0.11038115300000002 s.
    - Iteration 3/5: Kernel execution time: 0.11040150700000004 s.
    - Iteration 4/5: Kernel execution time: 0.11022874000000009 s.
[I] Only-sharded module 2 for stage 1, constructing entry XLA computation...
[I] Compiling HLO module...
[I] Profiling HLO modules...
    - Iteration 0/5: Kernel execution time: 0.3393367680000001 s.
    - Iteration 1/5: Kernel execution time: 0.3397424029999998 s.
    - Iteration 2/5: Kernel execution time: 0.33905757400000003 s.
    - Iteration 3/5: Kernel execution time: 0.33935535699999986 s.
    - Iteration 4/5: Kernel execution time: 0.3389696220000004 s.
[I] Only-sharded module 3 for stage 0, constructing entry XLA computation...
[I] Compiling HLO module...
[I] Profiling HLO modules...
    - Iteration 0/5: Kernel execution time: 0.7112929860000003 s.
    - Iteration 1/5: Kernel execution time: 0.7116400289999988 s.
    - Iteration 2/5: Kernel execution time: 0.7119683120000001 s.
    - Iteration 3/5: Kernel execution time: 0.7115709670000002 s.
    - Iteration 4/5: Kernel execution time: 0.7116439689999999 s.
[I] Only-sharded module 4 for stage 0, constructing entry XLA computation...
[I] Compiling HLO module...
[I] Profiling HLO modules...
    - Iteration 0/5: Kernel execution time: 0.030408581000000004 s.
    - Iteration 1/5: Kernel execution time: 0.030390880000000002 s.
    - Iteration 2/5: Kernel execution time: 0.030381409000000005 s.
    - Iteration 3/5: Kernel execution time: 0.030387040000000004 s.
    - Iteration 4/5: Kernel execution time: 0.030403650000000008 s.
[I] Only-sharded module 5 for stage 1, constructing entry XLA computation...
[I] Compiling HLO module...
[I] Profiling HLO modules...
    - Iteration 0/5: Kernel execution time: 0.01302752 s.
    - Iteration 1/5: Kernel execution time: 0.013037280000000002 s.
    - Iteration 2/5: Kernel execution time: 0.013028643 s.
    - Iteration 3/5: Kernel execution time: 0.013032672 s.
    - Iteration 4/5: Kernel execution time: 0.013027488 s.
[I] Constructing single-device HLO modules concurrently takes 0.20814776420593262 s.
[I] Compile single-device HLO modules concurrently takes 32.42800569534302 s.
[I] Profile all compiled sequentially on one GPU takes 18.213912963867188 s.
[I] Estimated e2e pipeline iteration time is: 27.244742569830915 s.
    - Kernel computation time is: -1.0 s.
    - Communication time is: -1.0 s.
    - Cross-stages communication time is: -1.0 s.
