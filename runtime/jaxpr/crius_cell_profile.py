#!/usr/bin/env python3
# -*- coding:utf-8 -*-
# Author: Chunyu Xue

""" 
Implementation of profiling methods towards multiple cells generated by 
one model and hardware configuration. 
"""

from typing import (
    List, Any, Tuple, Dict)
import argparse
import time
import threading
import traceback
import numpy as np

# Back to upper dir
import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from jaxpr.runtime_profiler import profile_once
from jaxpr.utils import (
    ProfileConfigs, is_power_of, load_tuning_database, store_tuning_database,
    gen_hashkey_with_model_configs)
from cell.cell import Cell

# Current absolute path of this script
CUR_PATH = os.path.dirname(os.path.abspath(__file__))


def gen_cand_cell_prof_configs() -> List[ProfileConfigs]:
    """ 
    Generate candidate profiling configurations for each cell with the same allocated 
    devices but varying number of stages. 
    """

    # Candidate list of num stages
    num_devices = args.num_hosts * args.num_devices_per_host
    assert is_power_of(2, num_devices), \
        f"Total allocated GPU num must be a power of 2, got {num_devices}."
    cand_num_stages = [_i + 1 for _i in range(num_devices)]

    # Generate profiling configurations
    cand_prof_configs = [
        ProfileConfigs(
            # Device
            devices_name=args.devices_name, 
            num_hosts=args.num_hosts, 
            num_devices_per_host=args.num_devices_per_host,
            base_gpu_type=None,
            real_gpu_rank=args.real_gpu_rank,
            compute_major=None,
            # Model
            model_name=args.model_name, 
            param_num=args.param_num,
            batch_size=args.batch_size, 
            num_micro_batches=args.num_micro_batches,
            num_pipeline_layers=args.num_pipeline_layers, 
            niter=args.niter, 
            warmup_num=args.warmup_num, 
            # Cell profile
            enable_cell_profile=True,
            cell_prof_strategy=args.cell_prof_strategy,
            num_pipeline_stages=_num_stages,
        ) for _num_stages in cand_num_stages
    ]

    return cand_prof_configs


def profile_one_cell(
    prof_configs: ProfileConfigs,
) -> None:
    """ Profile one cell with the its profiling configurations. """

    iter_time_table = None
    try:
        (_, _, _, iter_time_table) = profile_once(prof_configs, estimate_e2e=True)
    except Exception as e:
        print(f"[E] Meet unexpected error in compiling and executing model: {e}")
        traceback.print_exc()
        # Kill current process and all subprocesses
        # os.killpg(os.getpgid(os.getpid()), 9)
        time.sleep(5)
        return

    if prof_configs.cell_prof_strategy == "auto":
        # Only one parallelism is profiled
        perf_hashkeys = list(iter_time_table.keys())
        assert len(perf_hashkeys) == 1, \
            "When cell profiling strategy is set to 'auto', only one parallelism " + \
            "should be profiled for each cell."
        return float(iter_time_table[perf_hashkeys[0]])
    else:
        raise NotImplementedError()


def main():
    """ Entrypoint. """
    
    # Selected stage num
    selected_cell_num_stages = None
    min_e2e_iter_time = 1e12
    # Candidate profiling configurations for each cell
    cand_prof_configs = gen_cand_cell_prof_configs()

    for prof_configs in cand_prof_configs:
        # Profile one cell
        print("")
        print("-" * 50)
        print(f" - Cell configurations: Devices name: {prof_configs.devices_name} | " + 
              f"Num hosts: {prof_configs.num_hosts} | " + 
              f"Num devices per host: {prof_configs.num_devices_per_host} | " + 
              f"Num stages: {prof_configs.num_pipeline_stages}")
        print("-" * 50)
        
        e2e_iter_time = profile_one_cell(prof_configs)
        print("")
        print(f"[TMP] Estimated e2e iteration time (s): {e2e_iter_time}")

        if e2e_iter_time < min_e2e_iter_time:
            selected_cell_num_stages = prof_configs.num_pipeline_stages
            min_e2e_iter_time = e2e_iter_time

    print("")
    print(f"[TMP] The stage num of the selected cell is: {selected_cell_num_stages}")

    # Load the global tuning database and update
    tuning_database = load_tuning_database()
    model_cfgs_hashkey = gen_hashkey_with_model_configs(
        model_name=args.model_name,
        param_num=args.param_num,
        batch_size=args.batch_size,
        num_micro_batches=args.num_micro_batches,
        gpu_type=args.devices_name.split("_")[1],
        num_hosts=args.num_hosts,
        num_devices_per_host=args.num_devices_per_host,
        ignore_num_stages=True,
    )
    tuning_database["selected_cell_num_stages"][model_cfgs_hashkey] = selected_cell_num_stages

    print(tuning_database)
    
    # Store the global tuning database
    store_tuning_database(tuning_database)


if __name__ == "__main__":
    # Args 
    parser = argparse.ArgumentParser()
    # Hardware settings
    parser.add_argument("--devices_name", default="1_a40", type=str)
    parser.add_argument("--num_devices_per_host", default=2, type=int)
    parser.add_argument("--num_hosts", default=1, type=int)
    parser.add_argument("--real_gpu_rank", default=-1, type=str, 
                        help="Rank of the GPU that used to compile, parse and profile hlo modules.")
    # Model settings
    parser.add_argument("--model_name", default="wide_resnet", type=str)
    parser.add_argument("--param_num", default="500M", type=str)
    parser.add_argument("--batch_size", default=256, type=int)
    parser.add_argument("--num_micro_batches", default=16, type=int, 
                        help="The num of micro batches for pipeline. Local bs of each stage = bs / num_mb at each time slot.")
    parser.add_argument("--num_pipeline_layers", default=16, type=int, help="The num of layers for operators clustering.")
    parser.add_argument("--niter", default=1, type=int, 
                        help="Iteration num when profiling one compiled.")
    parser.add_argument("--warmup_num", default=1, type=int, 
                        help="Iteration num of warmup phase before profiling.")
    # Cell profile settings
    parser.add_argument("--cell_prof_strategy", default="auto", type=str, 
                        help="The strategy to generate multiple parallel plans in one cell. " + 
                             "Options: ['minimal', 'uniform', 'auto']")
    
    args = parser.parse_args()

    # Environmental variables
    os.environ["PROF_LOG_PATH"] = f"{CUR_PATH}/prof_log"
    os.environ["DEVICE_INFO_PATH"] = f"{CUR_PATH}/device_info/device_infos.json"
    os.environ["TUNING_DB_PATH"] = f"{CUR_PATH}/tuning_database"
    os.environ["TUNING_DB_FILENAME"] = f"tuning_database.pkl"
    # Enable crius kernel-level profiler
    os.environ["ENABLE_CRIUS_PROFILER"] = "true"

    main()
