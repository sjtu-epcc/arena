# Docker for Alpa Profile

[https://github.com/DicardoX/alpa_docker](https://github.com/DicardoX/alpa_docker)

> Toolkit for Alpa auto-profiling with Docker/Singularity support.
---------

***Content***

[TOC]

---------

###### References

- [Alpa Docker](https://github.com/alpa-projects/alpa/tree/main/docker)
- [Docker Run Mount/Bind](https://docs.docker.com/storage/bind-mounts/)
- [Upload Docker Image to Docker Hub](https://zhuanlan.zhihu.com/p/489660427)
- [Download Docker Image from Docker Hub](https://www.runoob.com/docker/docker-pull-command.html)
- [Networking using the host network](https://docs.docker.com/network/network-tutorial-host/)
- [SJTU JCloud HPC+AI Platform Documentations](https://docs.hpc.sjtu.edu.cn/index.html)
- [Container in SJTU JCloud Slurm System](https://docs.hpc.sjtu.edu.cn/container/index.html)
- [Singularity Run Documentation](https://docs.sylabs.io/guides/3.1/user-guide/cli/singularity_run.html)
- [Singularity Exec Documentation](https://docs.sylabs.io/guides/3.1/user-guide/cli/singularity_exec.html)
- [Singularity GPU Support](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)
- [Singularity Limiting Container Resources (after Version 3.10)](https://docs.sylabs.io/guides/main/user-guide/cgroups.html)
- [Obtain Slurm Nodes Info](https://gist.github.com/TengdaHan/1dd10d335c7ca6f13810fff41e809904)
- [Slurm Job Script for Multiple Nodes](https://stackoverflow.com/questions/52117145/slurm-job-script-for-multiple-nodes)
- [Slurm Multiple Program Configuration](https://slurm.schedmd.com/srun.html#SECTION_MULTIPLE-PROGRAM-CONFIGURATION)
- [Alpa Benchmark Doc](https://github.com/alpa-projects/alpa/blob/main/benchmark/alpa/README.md)


--------


### Pre. Issues on the Representation of Parallel Method (only annotations) in Alpa

Note that the following results are only annotations generated by Alpa to pass to the ILP solver in the XLA compiler side.

After running Alpa profiling with specified model and hardware, we get the entries of `logical_mesh_shapes` and `autosharding_option_dicts` as part of the profiling result. Here we explain the meaning of these entries:

 - There can be multiple items (corresponded to each stage) in `autosharding_option_dicts` (e.g., `[{'force_batch_dim_to_mesh_dim': 0}, {}]`) and `logical_mesh_shapes` (e.g., `[(2, 1), (2, 1)]`).

 - For each item, if `force_batch_dim_to_mesh_dim` is set to `0`, then the first dim of the logical mesh shape is related to the batch dim and the second related to the mesh dim. For instance, `(2, 1)` denotes a vanilla data parallel, while `(2, 2)` denotes a data + model parallel.

 - If `force_batch_dim_to_mesh_dim` is set to `None`, then the first dim of the logical mesh shape is related to the first mesh dim, which is determined by ILP solver in Alpa on applying data or model parallel. The second is not used for usual. For instance, `(2, 1)` denotes can also denote a model parallel (if better than data parallel).

----------

### 1. Build Alpa Docker Image

#### Option 1. Build Jaxlib-Alpa Wheels Using Docker

Download the source code of alpa using `git clone --recursive https://github.com/alpa-projects/alpa.git`.

Current available CUDA and Python version: CUDA 11.1, 11.2, 11.3; Python 3.7, 3.8, 3.9.

Build Docker image:

```bash
# Create a folder to save the output wheels
cd alpa/docker && mkdir -p dist
# Build the image using the chosen CUDA version
docker build -t build-jaxlib-image -f build_jaxlib.Dockerfile . --build-arg JAX_CUDA_VERSION=11.3
```

Build the wheels inside a container:

```bash
# Create a subfolder for the specific wheel version.
mkdir -p dist/cuda113
# Build the wheel in a container using the selected Python and CUDA versions
nvidia-docker run --tmpfs /build:exec --rm -v $(pwd)/dist:/dist build-jaxlib-image 3.8 cuda 11.3 main
# Move the output wheel
mv -f dist/*.whl dist/cuda113/
```

NOTE: To enter the container in interactive mode:

- (Normal enter) `docker run -it --entrypoint /bin/bash build-jaxlib-image`
- (Enter with cuda enabled) `docker run --runtime=nvidia -it --entrypoint /bin/bash build-jaxlib-image`
    - Or use `nvidia-docker run ...`, which is equal to `docker run --runtime=nvidia` (the latter is available since nvidia-docker v2)

--------

#### Option 2. Run Alpa in a Docker Container (Not build from the source, directly pip install alpa)

You can run Alpa inside a Docker container. Below are steps on how to run Alpa in a Docker container in the interactive mode.

Download the source code of alpa using `git clone --recursive https://github.com/alpa-projects/alpa.git`.

First, build a docker image based on the provided dockerfile:

```bash
cd alpa/docker
docker build -t run-alpa-image -f run_alpa.Dockerfile .
```

For cloud provider with InfiniBand (such as CoreWeave) we need to include additional dependencies:

```bash
docker build -t run-alpa-image -f run_alpa_infiniband.Dockerfile .
```

Second, build a container from the image and enter the container's interactive shell:

```bash
docker run --gpus all --rm --shm-size=10.24gb -it run-alpa-image
```

Alternatively, you can skip the interactive shell, and pass commands or job scripts via the docker run command to the container.

--------

#### Option 3. (VITAL) Build & Run Alpa Profile Image in a Docker Container

The customized Dockerfile is in `./Dockerfile`, the related debug process is recorded in the Research Log.

- Build Command: `docker build -t alpa-profile-image:v1 . `

- Run Command: `docker run --runtime=nvidia -it --rm --gpus all --shm-size=10.24gb --network=host --volume ./profile_result:/app/jax/profile_result --volume ./prof_database:/app/jax/prof_database --privileged dicardo/alpa-profile:v1`
    - Detail explainations of the given flags are presented in Section 4.

- To clear the build cache: `docker builder prune`

--------

### 2. Check Alpa Installation

To check alpa installation is correct:

```bash
conda activate alpa
# Start ray:
ray start --head
# Test Alpa can run correctly:
python -m alpa.test_install
```

---------

### 3. Upload/Doload Customized Alpa Image to/from Docker Hub

#### 3.1 Upload Docker Image

To upload the docker image onto the customized repository in Docker Hub, use: 

```bash
# Login your docker account
docker login
# Tag your image
docker tag [IMAGE_ID] dicardo/alpa-profile:v1
# Push
docker push dicardo/alpa-profile:v1
```

Then, you can check your customized Docker image in https://hub.docker.com/repository/docker/dicardo/alpa-profile/general.

---------

#### 3.2 Download Docker Image

To download docker image, use:

```bash
docker pull dicardo/alpa-profile:v1
```

----------

### 4. Use and Manipulate Customized Alpa Image

- To pull the image from Docker Hub: `docker pull dicardo/alpa-profile:v1`

- To run the image: `docker run --runtime=nvidia -it --rm --gpus all --shm-size=10.24gb --network=host --volume ./profile_result:/app/jax/profile_result --volume ./prof_database:/app/jax/prof_database --privileged dicardo/alpa-profile:v1`
    - **NOTE: Run this command on the dir of `/alpa_docker` and `mkdir & chmod` related folder.**
    - `--rm` means automatically delete (`exit`, not temporarily exit) the container when exiting it.
    - `--network=host` is to directly bind the container network to the Docker hostâ€™s network.
    - `--volume` binds mount a volume.
    - `--privileged` gives all capabilities to the container, and it also lifts all the limitations enforced by the device cgroup controller. In other words, the container can then do almost everything that the host can do. This flag exists to allow special use-cases, like running Docker within Docker.

- To run the image with entrypoint set to a script in the container: `docker run --runtime=nvidia -it --rm --gpus all --shm-size=10.24gb --network=host --volume ./profile_result:/app/jax/profile_result --volume ./prof_database:/app/jax/prof_database --privileged --entrypoint "./single_node_profile.sh" dicardo/alpa-profile:v1`
    - **NOTE: Run this command on the dir of `/alpa_docker`.**
    - In this way, after the container finished, if you use `docker attach [CONTAINER_ID]` to attach, the container will re-run with the .sh script, not enter the container.

- To temporarily exit the docker container: `ctrl + P + Q` (`exit` will close the container)

- To enter a running docker container: `docker attach [CONTAINER_NAME]`

- To stop a running docker container, use: `docker stop [CONTAINER_ID]`

- To runtime copy files from the host to Docker container storage: `docker cp ./jax/profile.sh [CONTAINER_ID or CONTAINER_NAME]:/app/jax/profile.sh`
    - Not support directly copy a folder.

- To construct a new Docker Image based on a Docker container: `docker commit -a "dicardo" -m "test" [CONTAINER_ID] dicardo/[NEW_IMAGE_NAME]:[NEW_TAG]`

----------

### 5. Deploy Customized Alpa Image in Local Cluster

#### 5.1 Within Interactive Style

This section introduces how to deploy customized Alpa image in two-nodes local cluster.

First, we pull the image from Docker hub on each server using:

```bash
docker pull dicardo/alpa-profile:v1
```

Then, we use the following command to enter the Docker container (**NOTE: Run this command on the dir of `/alpa_docker`**):

Note that you should first `mkdir` like:

```bash
# cd alpa_docker
mkdir prof_database
chmod 777 prof_database
mkdir profile_result
chmod 777 profile_result
```

Then, you can use:

```bash
docker run --runtime=nvidia -it --rm --gpus all --shm-size=10.24gb --network=host --volume ./profile_result:/app/jax/profile_result --volume ./prof_database:/app/jax/prof_database --privileged dicardo/alpa-profile:v1
# Absolute path version
docker run --runtime=nvidia -it --rm --gpus all --shm-size=10.24gb --network=host --volume /home/cyxue/Projects/playground/alpa_docker/profile_result:/app/jax/profile_result --volume /home/cyxue/Projects/playground/alpa_docker/prof_database:/app/jax/prof_database  --privileged dicardo/alpa-profile:v1
```

**TODO: How to setup a multi-nodes Ray cluster in a `.yaml` file with `ray up` in docker containers? Still need to figure out.**

Thus, after entering the docker images, we first apply the following commands on each node:

```bash
# Activate alpa env, if come to `CommandNotFoundError`, use `source activate` instead.
conda activate alpa
# Work dir
cd jax
# Get default network interface
NET_IF=$(route | grep default | grep -o "eno.")
echo "${NET_IF}"
# Specify the network interface based on the using situation in `ifconfig`
export NCCL_SOCKET_IFNAME=${NET_IF}
# Specify the fraction of pre-allocated memory for JAX
export XLA_PYTHON_CLIENT_MEM_FRACTION=0.8
```

then, we run `ray start` command on each node:

- On head node: 

```bash
ulimit -c unlimited -n 65536 && RAY_DISABLE_MEMORY_MONITOR=1 ray start --head --port=6379 --num-cpus 60 --object-store-memory 10737418240 --disable-usage-stats
```

- On worker node:

```bash
ulimit -c unlimited -n 65536 && RAY_DISABLE_MEMORY_MONITOR=1 ray start --address=[HEAD_NODE_IP or HEAD_NODE_NAME]:6379 --num-cpus 60 --object-store-memory 10737418240 --disable-usage-stats
```

For instance, use the node name like: 

```bash
ulimit -c unlimited -n 65536 && RAY_DISABLE_MEMORY_MONITOR=1 ray start --address=10.2.64.51:6379 --num-cpus 60 --object-store-memory 10737418240 --disable-usage-stats
```

To restrict the GPU num on the node, we should add `--num-gpus 2` to the command.

Then, we can execute `bash ./run.sh -x [DEVICES_NAME] -n [NODES_NUM] -d [DEVICES_NUM_PER_NODE] -m [MODEL_NAME] -t [TRY_TIMES]` on the head node. **For local cluster, you can MODIFY (e.g., device name, node num, device num per node) and run `./run_all.sh` script to perform multiple profiling groups.**

The available models are: `wide_resnet`, `bert` and `moe`. **Note that if you are using `bert` and `moe` (whose `AutoStageOption` is set as `use_hlo_cost_model=True`, `wide_resnet` can also apply), you should execute the following command after building the Ray cluster and before running profling `bash` scripts**:

```bash
# NOTE: `--cache-filename` should be an absolute path that all Ray workers can access.
python gen_prof_database.py --filename "./prof_database/prof_database.pkl" --max-comm-size-intra-node 32 --max-comm-size-inter-node 29 --cache-filename "/app/jax/tmp/hlo_op_cost_dict.pkl"
```

This helps us build up a profiling database, so that the auto-parallel process can exploit HLO cost model for computational cost or profile for the cost (described in `./stage_construction.py/class AutoStageOption`). **Note that in different hardware & topologies, the profiling result can be quite different, thus we need to execute the above command each time when first planting to a new hardware environment**. Unfortunately, this profiling process can take quite a long time.

In Alpa benchmark doc: 

> Alpa requires a cost model to estimate the performance of different parallelization strategies. This cost model is based on profiling results on the target cluster. We can generate a profiling database with the following commands, which profiles the time costs of various computation and communication patterns. Note that this procedure is very slow and can take hours, but you only need to do it once for your cluster.

From another perspective, **we can store the `prof_database.pkl` database with specified hardware information. For instance, naming it as `prof_database_2_1080ti.pkl` and skip the profiling process the next time when we access the same hardware again**.

To manually test alpa profiling with self-specified configurations, use:

```bash
bash ./profile.sh -x 1_1080ti -n 1 -d 4 -m wide_resnet -p 500M -b 256 -l 16 -c 16 -a
```

----------

#### 5.2 Within Automated Style

##### 5.2.1 Single-Node Auto-Profiling

The automated script is presented in `./single_node_profile.sh`, which **must be included in the Docker container FS and changed to executable permission**.

Note that for Docker, we need to modify the details in this script (which is pre-stored inside the container) when using other benchmarks (e.g., Bert, MoE, the default is Wide-ResNet). Specifically, we need to modify the pipeline layer num in `bash ./run.sh` command.

Unlike Docker, if we use Singularity to execute the `.sif` image, the script provided in the `singularity exec` command should be directly on the host dir (not in the container). 
 
##### 5.2.2 Multi-Nodes Auto-Profiling (Not Implemented Yet)

**TODO: This method is temporarily not supported**. As refernece, the multi-nodes auto-profiling in Slurm is given in Section 6.2.

----------

### 6. Deploy Customized Alpa Image on JCloud PI Cluster

First, you need to use the following command to keep requesting for hardware resources: 

```bash
salloc -p dgx2 -N 1 -n 1 --gres=gpu:4 --cpus-per-task=24 --mail-type=ALL --mail-user=dicardo@sjtu.edu.cn
```

The above command could lead to long wait and the session will be automatially closed by remote host (no matter whether you use a tmux session). **TODO: Check if there exists a native can run `salloc` command in background.**

Therefore, we use slurm script and `sbatch` in this scenario.

#### 6.1 Single-Node Auto-profiling 

We first create a `single_node_profile.slurm` script, in which we use:

- To pull docker image and save as a `.sif` (Singularity Image File): `singularity pull alpa-profile.sif docker://dicardo/alpa-profile:v1`
    - According to ref, we need to add `unset XDG_RUNTIME_DIR; unset SINGULARITY_BIND; unset MODULEPATH` before the command.
    - Use `--force` to forcibly overwrite the `.sif` file.

- To chmod script and prepare the output dir: 

```bash
# Change permission
chmod 777 ./single_node_profile.sh
# Check output dir
if [ ! -d "./profile_result" ];then
    mkdir ./profile_result
fi
# Check tmp dir
if [ ! -d "./tmp" ];then
    mkdir ./tmp
fi
```

- To execute (host) script in the container with Nvidia support: `singularity exec --bind "./profile_result:/app/jax/profile_result" --bind "./tmp:/app/jax/tmp" --network host --nv alpa-profile.sif ./single_node_profile.sh`:
    - NOTE: **The script `./single_node_profile.sh` should be in the host dir rather than in the container dir and chmod to 777. In fact, the script is composed of a series of commands, so this equals to pass multiple command from host into the container.**
    - NOTE: Since most job schedulers (e.g., Slurm) will assign specified resources amount to the job, resource limitation when running the container is not so urgent.
    - `--bind "./profile_result:/app/jax/profile_result"`: a user-bind path specification.  spec has the format "src:dest", where src and dest are outside and inside paths.  If dest is not given, it is set equal to src.  Mount options ('opts') may be specified as 'ro' (read-only) or 'rw' (read/write, which is the default). Multiple bind paths can be given by a comma separated list. **Note that when you bind `./empty:/app/jax` where `./empty` is an empty directory on the host (you may want to make the output to `/app/jax` to store in `./empty`), the content in the `/app/jax` of Singularity container will be removed.**
    - `--contain`: (not use) Use minimal /dev and empty other directories (e.g. /tmp and $HOME) instead of sharing filesystems from your host
    - `--containall`: (not use) Contain not only file systems, but also PID, IPC, and environment.
    - `--cpus`: (avail in 3.10) Set the number of CPUs, or fractional CPUs, that the container can use.
    - `--memory`: (avail in 3.10) Set the maximum amount of RAM that a container can use, in bytes. You can use suffixes such as M or G to specify megabytes or gigabytes.
    - `--memory-swap -1`: (avail in 3.10) sets the total amount of memory and swap space that a container can use, `-1` means unlimited.
    - `--network host`: Specify desired network type separated by commas.
    - `--nv`: Enable experimental Nvidia support.
    - `--writable-tmpfs`: Make the target SIF image writable.

----------

#### 6.2 Multi-Nodes Auto-Profiling

To enable `infiniband` in Singularity container, use `-B /etc/libibverbs.d` in `singularity run` command.

To mount nvidia driver to sigularity image, use `-B /usr/local/nvidia/lib` in `singularity run` command.

In Slurm, we can obtain allocated node list and decide the head node using:

```bash
# Get node list
echo "[I][SHELL] Allocated node list: ${SLURM_JOB_NODELIST}"
# Assign the first node as the head node
HEAD_ADDR=$(scontrol show hostnames "$SLURM_JOB_NODELIST" | head -n 1)
echo "[I][SHELL] The address of the head node: ${HEAD_ADDR}"
```

Then, we can use `srun` command to execute different scripts on different nodes. Here we take two nodes as example and present a prototype command demo:

```bash
# Lanuch on node 0
srun -lN1 -n1 -r 0 ./script_0.sh
# Lanuch on node 1
srun -lN1 -n1 -r 1 ./script_1.sh
# Wait
sleep 1
wait
```

where `-lN1` denotes `-l` (Prepend task number to lines of stdout/err. The --label option will prepend lines of output with the remote task id. This option applies to step allocations.) and `-N 1` (1 node). `-n1` denotes there is only 1 task on each node.

What's more, `-r n`: Running a job step relative to node n of the current allocation. This option may be used to spread several job steps out among the nodes of the current job. If -r is used, the current job step will begin at node n of the allocated nodelist, where the first node is considered node 0.

Note that in `./script_i.sh`, we can use the environment variable `SLURMD_NODENAME` to get the current local node name.

Therefore, we use the following commands in `multi_nodes_profile.slurm` to run multi-nodes auto-profiling:

```bash
# Execute
# Lanuch on node 0
srun -lN1 -n1 -r 0 singularity exec --bind "./profile_result:/app/jax/profile_result" --bind "./tmp:/app/jax/tmp" --network host --nv alpa-profile.sif ./multi_nodes_profile.sh -m ${HEAD_ADDR}
# Lanuch on node 1
srun -lN1 -n1 -r 1 singularity exec --bind "./profile_result:/app/jax/profile_result" --bind "./tmp:/app/jax/tmp" --network host --nv alpa-profile.sif ./multi_nodes_profile.sh -m ${HEAD_ADDR}
# Wait
sleep 1
wait
```

And in `./multi_nodes_profile.sh`, we have:

```bash
if [ ${SLURMD_NODENAME} == ${head_ip_addr} ];then
    # Head node
    echo "I'm the head node, the underlying node is ${SLURMD_NODENAME}."
    . /opt/conda/etc/profile.d/conda.sh && conda activate /opt/conda/envs/alpa && \
    ulimit -c unlimited -n 65536 && RAY_DISABLE_MEMORY_MONITOR=1 ray start --head --port=6379 --num-cpus 60 --object-store-memory 10737418240 --disable-usage-stats && \
    sleep 30 && \
    # Profiling script. 
    # You need to modify the command line arguments to profile different configurations.
    # bash ./run.sh -x 1_node -n 1 -d 2 -l 16
    ray status
else
    # Worker node
    echo "I'm the worker node, the underlying node is ${ip_addr}."
    . /opt/conda/etc/profile.d/conda.sh && conda activate /opt/conda/envs/alpa && \
    ulimit -c unlimited -n 65536 && RAY_DISABLE_MEMORY_MONITOR=1 ray start --address=${head_ip_addr}:6379 --num-cpus 60 --object-store-memory 10737418240 --disable-usage-stats
fi
```

**TODO: How to stop the ray processes in worker node after the profiling is compeleted?**

