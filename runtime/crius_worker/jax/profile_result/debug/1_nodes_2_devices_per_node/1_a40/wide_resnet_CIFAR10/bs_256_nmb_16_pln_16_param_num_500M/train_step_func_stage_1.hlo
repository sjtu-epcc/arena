HloModule train_step_func_pipeshard_parallel_mesh_1-1, input_output_alias={ {0}: (0, {}, may-alias), {1}: (1, {}, may-alias), {2}: (2, {}, may-alias), {3}: (3, {}, may-alias), {4}: (4, {}, may-alias), {5}: (5, {}, may-alias), {6}: (6, {}, may-alias), {7}: (7, {}, may-alias), {8}: (8, {}, may-alias), {9}: (9, {}, may-alias), {10}: (10, {}, may-alias), {11}: (11, {}, may-alias), {12}: (12, {}, may-alias), {13}: (13, {}, may-alias), {14}: (14, {}, may-alias), {15}: (15, {}, may-alias), {16}: (16, {}, may-alias), {17}: (17, {}, may-alias), {18}: (18, {}, may-alias), {19}: (19, {}, may-alias), {20}: (20, {}, may-alias), {21}: (21, {}, may-alias), {22}: (22, {}, may-alias), {23}: (23, {}, may-alias), {24}: (24, {}, may-alias), {25}: (25, {}, may-alias), {26}: (26, {}, may-alias), {27}: (27, {}, may-alias), {28}: (28, {}, may-alias), {29}: (29, {}, may-alias), {30}: (30, {}, may-alias), {31}: (31, {}, may-alias), {32}: (32, {}, may-alias), {33}: (33, {}, may-alias), {34}: (34, {}, may-alias), {35}: (35, {}, may-alias), {36}: (36, {}, may-alias), {37}: (37, {}, may-alias), {38}: (38, {}, may-alias), {39}: (39, {}, may-alias), {40}: (40, {}, may-alias), {41}: (41, {}, may-alias), {42}: (42, {}, may-alias), {43}: (43, {}, may-alias), {44}: (44, {}, may-alias), {45}: (45, {}, may-alias), {46}: (46, {}, may-alias), {47}: (47, {}, may-alias), {48}: (48, {}, may-alias), {49}: (49, {}, may-alias), {50}: (50, {}, may-alias), {51}: (51, {}, may-alias), {52}: (52, {}, may-alias) }, entry_computation_layout={(f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[7168]{0},f32[7168]{0},f32[7168]{0},f32[7168]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[7168]{0},f32[7168]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[7168]{0},f32[7168]{0},f32[],f32[],f32[],f32[16,14,14,3584]{3,2,1,0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[896]{0},f32[896]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[7168]{0},f32[7168]{0},f32[7168]{0},f32[7168]{0},f32[1,1,7168,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[7168]{0},f32[7168]{0},f32[1,1,7168,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[7168,1024]{1,0},f32[1024]{0},f32[1792]{0},f32[1792]{0},f32[3584]{0},f32[3584]{0},f32[7168]{0},f32[7168]{0},s32[16]{0},s32[])->(f32[896]{0}, f32[896]{0}, f32[1792]{0}, f32[1792]{0}, f32[3584]{0}, /*index=5*/f32[3584]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[3584]{0}, f32[3584]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[896]{0}, f32[896]{0}, /*index=20*/f32[1792]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[896]{0}, /*index=25*/f32[896]{0}, f32[1792]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, /*index=30*/f32[1792]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[7168]{0}, /*index=35*/f32[7168]{0}, f32[7168]{0}, f32[7168]{0}, f32[1792]{0}, f32[1792]{0}, /*index=40*/f32[3584]{0}, f32[3584]{0}, f32[7168]{0}, f32[7168]{0}, f32[1792]{0}, /*index=45*/f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[7168]{0}, f32[7168]{0}, /*index=50*/f32[], f32[], f32[], f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{3,2,1,0}, /*index=55*/f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{3,2,1,0}, f32[16,7,7,7168]{3,2,1,0}, f32[16,7,7,7168]{3,2,1,0})}

%region_0.1142.1 (Arg_0.1143: f32[], Arg_1.1144: f32[]) -> f32[] {
  %Arg_0.1143 = f32[] parameter(0)
  %Arg_1.1144 = f32[] parameter(1)
  ROOT %add.1145 = f32[] add(f32[] %Arg_0.1143, f32[] %Arg_1.1144), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.2 (param_0.5: f32[], param_1.570: s32[]) -> f32[] {
  %param_0.5 = f32[] parameter(0)
  %param_1.570 = s32[] parameter(1)
  %convert.1 = f32[] convert(s32[] %param_1.570), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/convert_element_type[new_dtype=float32 weak_type=True]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=394}
  %constant_90 = f32[] constant(50000)
  %compare.4 = pred[] compare(f32[] %convert.1, f32[] %constant_90), direction=LT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/lt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=394}
  %constant_93 = f32[] constant(1)
  %constant_94 = s32[] constant(0)
  %maximum.0 = s32[] maximum(s32[] %param_1.570, s32[] %constant_94), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=86}
  %convert.0 = f32[] convert(s32[] %maximum.0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/convert_element_type[new_dtype=float32 weak_type=True]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=86}
  %minimum.1 = f32[] minimum(f32[] %convert.0, f32[] %constant_90), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/min" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=86}
  %constant_89 = f32[] constant(2e-05)
  %multiply.137 = f32[] multiply(f32[] %minimum.1, f32[] %constant_89), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=87}
  %subtract.0 = f32[] subtract(f32[] %constant_93, f32[] %multiply.137), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=87}
  %constant_88 = f32[] constant(-0.1)
  %multiply.136 = f32[] multiply(f32[] %subtract.0, f32[] %constant_88), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=88}
  %constant_95 = f32[] constant(0.1)
  %add.29 = f32[] add(f32[] %multiply.136, f32[] %constant_95), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=88}
  %constant_87 = f32[] constant(-50000)
  %add.28 = f32[] add(f32[] %convert.1, f32[] %constant_87), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=394}
  %constant_86 = f32[] constant(950000)
  %minimum.0 = f32[] minimum(f32[] %add.28, f32[] %constant_86), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/min" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=235}
  %constant_85 = f32[] constant(3.30693956e-06)
  %multiply.135 = f32[] multiply(f32[] %minimum.0, f32[] %constant_85), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=236}
  %cosine.0 = f32[] cosine(f32[] %multiply.135), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/cos" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=236}
  %add.27 = f32[] add(f32[] %cosine.0, f32[] %constant_93), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=236}
  %constant_84 = f32[] constant(0.05)
  %multiply.134 = f32[] multiply(f32[] %add.27, f32[] %constant_84), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=238}
  %select.1 = f32[] select(pred[] %compare.4, f32[] %add.29, f32[] %multiply.134), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/schedule.py" source_line=394}
  ROOT %add.26 = f32[] add(f32[] %param_0.5, f32[] %select.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
}

%fused_computation.6 (param_0.332: f32[16], param_1.721: s32[16], param_2.659: s32[16]) -> (f32[], f32[]) {
  %param_0.332 = f32[16]{0} parameter(0)
  %negate.1 = f32[16]{0} negate(f32[16]{0} %param_0.332), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %constant_99 = f32[] constant(0)
  %reduce.262 = f32[] reduce(f32[16]{0} %negate.1, f32[] %constant_99), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce_sum[axes=(0,)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=113}
  %param_1.721 = s32[16]{0} parameter(1)
  %param_2.659 = s32[16]{0} parameter(2)
  %compare.5.clone.1 = pred[16]{0} compare(s32[16]{0} %param_1.721, s32[16]{0} %param_2.659), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/eq" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %convert.3.clone.1 = s32[16]{0} convert(pred[16]{0} %compare.5.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/convert_element_type[new_dtype=int32 weak_type=False]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %convert.2.clone.1 = f32[16]{0} convert(s32[16]{0} %convert.3.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %reduce.261.clone.1 = f32[] reduce(f32[16]{0} %convert.2.clone.1, f32[] %constant_99), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce_sum[axes=(0,)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  ROOT %tuple.94 = (f32[], f32[]) tuple(f32[] %reduce.262, f32[] %reduce.261.clone.1)
}

%fused_computation.7 (param_0.485: f32[16], param_1.632: s32[16], param_2.548: f32[16,1024], param_3.516: f32[16]) -> f32[16] {
  %param_1.632 = s32[16]{0} parameter(1)
  %broadcast.183 = s32[16,1024]{1,0} broadcast(s32[16]{0} %param_1.632), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %iota.6 = s32[16,1024]{1,0} iota(), iota_dimension=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %compare.6 = pred[16,1024]{1,0} compare(s32[16,1024]{1,0} %broadcast.183, s32[16,1024]{1,0} %iota.6), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %constant_100 = f32[] constant(1)
  %broadcast.182 = f32[16,1024]{1,0} broadcast(f32[] %constant_100), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %constant_101 = f32[] constant(0)
  %broadcast.181 = f32[16,1024]{1,0} broadcast(f32[] %constant_101), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %select.2 = f32[16,1024]{1,0} select(pred[16,1024]{1,0} %compare.6, f32[16,1024]{1,0} %broadcast.182, f32[16,1024]{1,0} %broadcast.181), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %param_2.548 = f32[16,1024]{1,0} parameter(2)
  %param_3.516 = f32[16]{0} parameter(3)
  %broadcast.644 = f32[16,1024]{1,0} broadcast(f32[16]{0} %param_3.516), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %subtract.68 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %param_2.548, f32[16,1024]{1,0} %broadcast.644), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %param_0.485 = f32[16]{0} parameter(0)
  %broadcast.180 = f32[16,1024]{1,0} broadcast(f32[16]{0} %param_0.485), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %subtract.1 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %subtract.68, f32[16,1024]{1,0} %broadcast.180), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %multiply.140 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %select.2, f32[16,1024]{1,0} %subtract.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  ROOT %reduce.263 = f32[16]{0} reduce(f32[16,1024]{1,0} %multiply.140, f32[] %constant_101), dimensions={1}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce_sum[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
}

%fused_computation.8 (param_0.483: f32[16,1024], param_1.630: f32[16]) -> f32[16] {
  %param_0.483 = f32[16,1024]{1,0} parameter(0)
  %param_1.630 = f32[16]{0} parameter(1)
  %broadcast.642 = f32[16,1024]{1,0} broadcast(f32[16]{0} %param_1.630), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %subtract.66 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %param_0.483, f32[16,1024]{1,0} %broadcast.642), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %exponential.0 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %subtract.66), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/exp" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %constant_102 = f32[] constant(0)
  ROOT %reduce.264 = f32[16]{0} reduce(f32[16,1024]{1,0} %exponential.0, f32[] %constant_102), dimensions={1}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce_sum[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
}

%fused_computation (param_0.2: s32[], param_1.2: s32[], param_2.549: f32[], param_3.517: f32[]) -> (s32[], f32[]) {
  %param_2.549 = f32[] parameter(2)
  %param_3.517 = f32[] parameter(3)
  %compare.3.clone.1 = pred[] compare(f32[] %param_2.549, f32[] %param_3.517), direction=GT, metadata={op_name="/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %compare.2.clone.1 = pred[] compare(f32[] %param_2.549, f32[] %param_2.549), direction=NE, metadata={op_name="/ne" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %or.1.clone.1 = pred[] or(pred[] %compare.3.clone.1, pred[] %compare.2.clone.1), metadata={op_name="/or" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %compare.1 = pred[] compare(f32[] %param_2.549, f32[] %param_3.517), direction=EQ, metadata={op_name="/eq" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %param_0.2 = s32[] parameter(0)
  %param_1.2 = s32[] parameter(1)
  %compare.0 = pred[] compare(s32[] %param_0.2, s32[] %param_1.2), direction=LT, metadata={op_name="/lt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %and.0 = pred[] and(pred[] %compare.1, pred[] %compare.0), metadata={op_name="/and" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %or.0 = pred[] or(pred[] %or.1.clone.1, pred[] %and.0), metadata={op_name="/or" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %select.0 = s32[] select(pred[] %or.0, s32[] %param_0.2, s32[] %param_1.2), metadata={op_name="/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %select.3 = f32[] select(pred[] %or.1.clone.1, f32[] %param_2.549, f32[] %param_3.517), metadata={op_name="/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  ROOT %tuple.1 = (s32[], f32[]) tuple(s32[] %select.0, f32[] %select.3)
}

%region_55.2615.1 (Arg_0.2616: f32[], Arg_1.2617: s32[], Arg_2.2618: f32[], Arg_3.2619: s32[]) -> (f32[], s32[]) {
  %Arg_1.2617 = s32[] parameter(1)
  %Arg_3.2619 = s32[] parameter(3)
  %Arg_0.2616 = f32[] parameter(0)
  %Arg_2.2618 = f32[] parameter(2)
  %fusion = (s32[], f32[]) fusion(s32[] %Arg_1.2617, s32[] %Arg_3.2619, f32[] %Arg_0.2616, f32[] %Arg_2.2618), kind=kLoop, calls=%fused_computation, metadata={op_name="/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %get-tuple-element.87 = f32[] get-tuple-element((s32[], f32[]) %fusion), index=1
  %get-tuple-element.86 = s32[] get-tuple-element((s32[], f32[]) %fusion), index=0
  ROOT %tuple.2629 = (f32[], s32[]) tuple(f32[] %get-tuple-element.87, s32[] %get-tuple-element.86)
}

%fused_computation.10 (param_0.17: f32[16,1024]) -> (f32[16], s32[16]) {
  %param_0.17 = f32[16,1024]{1,0} parameter(0)
  %iota.7 = s32[16,1024]{1,0} iota(), iota_dimension=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/iota[dtype=int32 shape=(16, 1024) dimension=1]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %constant_91 = f32[] constant(-inf)
  %constant_103 = s32[] constant(0)
  ROOT %reduce.265 = (f32[16]{0}, s32[16]{0}) reduce(f32[16,1024]{1,0} %param_0.17, s32[16,1024]{1,0} %iota.7, f32[] %constant_91, s32[] %constant_103), dimensions={1}, to_apply=%region_55.2615.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce[computation=<function _compute_argminmax.<locals>.reducer_fn at 0x7f21c42cf5e0> consts=() dimensions=(1,)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
}

%fused_computation.11 (param_0.18: f32[16,7168]) -> f32[16,7168] {
  %param_0.18 = f32[16,7168]{1,0} parameter(0)
  %constant_92 = f32[] constant(0.0204081628)
  %broadcast.185 = f32[16,7168]{1,0} broadcast(f32[] %constant_92), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
  ROOT %multiply.141 = f32[16,7168]{1,0} multiply(f32[16,7168]{1,0} %param_0.18, f32[16,7168]{1,0} %broadcast.185), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
}

%fused_computation.13 (param_0.21: f32[7168], param_1.633: f32[7168], param_2.552: f32[7168], param_3.522: f32[16,7168], param_4.375: f32[7168], param_5.193: f32[7168]) -> (f32[7168], f32[7168], f32[7168]) {
  %param_0.21 = f32[7168]{0} parameter(0)
  %param_1.633 = f32[7168]{0} parameter(1)
  %constant_107 = f32[] constant(0.9)
  %broadcast.192 = f32[7168]{0} broadcast(f32[] %constant_107), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.145 = f32[7168]{0} multiply(f32[7168]{0} %param_1.633, f32[7168]{0} %broadcast.192), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.522 = f32[16,7168]{1,0} parameter(3)
  %constant_109_clone_1 = f32[] constant(0)
  %reduce.267.clone.1 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_3.522, f32[] %constant_109_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_717_clone_1 = f32[] constant(0.00127551018)
  %broadcast.194.clone.1 = f32[7168]{0} broadcast(f32[] %constant_717_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.147.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %reduce.267.clone.1, f32[7168]{0} %broadcast.194.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.552 = f32[7168]{0} parameter(2)
  %multiply.527.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.552, f32[7168]{0} %broadcast.194.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.146.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %multiply.527.clone.1, f32[7168]{0} %multiply.527.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.4.clone.1 = f32[7168]{0} subtract(f32[7168]{0} %multiply.147.clone.1, f32[7168]{0} %multiply.146.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.193.clone.1 = f32[7168]{0} broadcast(f32[] %constant_109_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.2.clone.1 = f32[7168]{0} maximum(f32[7168]{0} %subtract.4.clone.1, f32[7168]{0} %broadcast.193.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_106 = f32[] constant(0.1)
  %broadcast.191 = f32[7168]{0} broadcast(f32[] %constant_106), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.144 = f32[7168]{0} multiply(f32[7168]{0} %maximum.2.clone.1, f32[7168]{0} %broadcast.191), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.36 = f32[7168]{0} add(f32[7168]{0} %multiply.145, f32[7168]{0} %multiply.144), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.35 = f32[7168]{0} add(f32[7168]{0} %param_0.21, f32[7168]{0} %add.36), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %param_4.375 = f32[7168]{0} parameter(4)
  %param_5.193 = f32[7168]{0} parameter(5)
  %multiply.151.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_5.193, f32[7168]{0} %broadcast.192), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_112_clone_1 = f32[] constant(0.000127551015)
  %broadcast.196.clone.1 = f32[7168]{0} broadcast(f32[] %constant_112_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.150.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.552, f32[7168]{0} %broadcast.196.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.38.clone.1 = f32[7168]{0} add(f32[7168]{0} %multiply.151.clone.1, f32[7168]{0} %multiply.150.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.37.clone.1 = f32[7168]{0} add(f32[7168]{0} %param_4.375, f32[7168]{0} %add.38.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  ROOT %tuple.3 = (f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) tuple(f32[7168]{0} %add.35, f32[7168]{0} %maximum.2.clone.1, f32[7168]{0} %add.37.clone.1)
}

%fused_computation.19 (param_0.33: f32[3584], param_1.57: f32[3584], param_2.36: f32[3584], param_3.38: f32[16,7,7,3584], param_4.368: f32[3584]) -> f32[16,7,7,3584] {
  %param_3.38 = f32[16,7,7,3584]{2,1,3,0} parameter(3)
  %param_4.368 = f32[3584]{0} parameter(4)
  %constant_708 = f32[] constant(0.00127551018)
  %broadcast.634 = f32[3584]{0} broadcast(f32[] %constant_708), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.521 = f32[3584]{0} multiply(f32[3584]{0} %param_4.368, f32[3584]{0} %broadcast.634), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.200 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.521), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.5 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_3.38, f32[16,7,7,3584]{2,1,3,0} %broadcast.200), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.36 = f32[3584]{0} parameter(2)
  %constant_115 = f32[] constant(1e-05)
  %broadcast.202 = f32[3584]{0} broadcast(f32[] %constant_115), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.40 = f32[3584]{0} add(f32[3584]{0} %param_2.36, f32[3584]{0} %broadcast.202), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.26 = f32[3584]{0} rsqrt(f32[3584]{0} %add.40), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.57 = f32[3584]{0} parameter(1)
  %multiply.153 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.26, f32[3584]{0} %param_1.57), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.199 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.153), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.152 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.5, f32[16,7,7,3584]{2,1,3,0} %broadcast.199), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.33 = f32[3584]{0} parameter(0)
  %broadcast.198 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_0.33), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.39 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.152, f32[16,7,7,3584]{2,1,3,0} %broadcast.198), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_116 = f32[] constant(0)
  %broadcast.201 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_116), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.3 = f32[16,7,7,3584]{2,1,3,0} maximum(f32[16,7,7,3584]{2,1,3,0} %add.39, f32[16,7,7,3584]{2,1,3,0} %broadcast.201), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.20 (param_0.34: f32[3584], param_1.636: f32[3584], param_2.556: f32[3584], param_3.527: f32[16,3584], param_4.381: f32[3584], param_5.200: f32[3584]) -> (f32[3584], f32[3584], f32[3584]) {
  %param_0.34 = f32[3584]{0} parameter(0)
  %param_1.636 = f32[3584]{0} parameter(1)
  %constant_118 = f32[] constant(0.9)
  %broadcast.204 = f32[3584]{0} broadcast(f32[] %constant_118), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.155 = f32[3584]{0} multiply(f32[3584]{0} %param_1.636, f32[3584]{0} %broadcast.204), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.527 = f32[16,3584]{1,0} parameter(3)
  %constant_120_clone_1 = f32[] constant(0)
  %reduce.270.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.527, f32[] %constant_120_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_711_clone_1 = f32[] constant(0.00127551018)
  %broadcast.205.clone.1 = f32[3584]{0} broadcast(f32[] %constant_711_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.157.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.270.clone.1, f32[3584]{0} %broadcast.205.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.556 = f32[3584]{0} parameter(2)
  %multiply.523.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.556, f32[3584]{0} %broadcast.205.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.156.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.523.clone.1, f32[3584]{0} %multiply.523.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.6.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.157.clone.1, f32[3584]{0} %multiply.156.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.206.clone.1 = f32[3584]{0} broadcast(f32[] %constant_120_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.4.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %subtract.6.clone.1, f32[3584]{0} %broadcast.206.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_117 = f32[] constant(0.1)
  %broadcast.203 = f32[3584]{0} broadcast(f32[] %constant_117), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.154 = f32[3584]{0} multiply(f32[3584]{0} %maximum.4.clone.1, f32[3584]{0} %broadcast.203), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.42 = f32[3584]{0} add(f32[3584]{0} %multiply.155, f32[3584]{0} %multiply.154), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.41 = f32[3584]{0} add(f32[3584]{0} %param_0.34, f32[3584]{0} %add.42), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %param_4.381 = f32[3584]{0} parameter(4)
  %param_5.200 = f32[3584]{0} parameter(5)
  %multiply.161.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.200, f32[3584]{0} %broadcast.204), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_123_clone_1 = f32[] constant(0.000127551015)
  %broadcast.208.clone.1 = f32[3584]{0} broadcast(f32[] %constant_123_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.160.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.556, f32[3584]{0} %broadcast.208.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.44.clone.1 = f32[3584]{0} add(f32[3584]{0} %multiply.161.clone.1, f32[3584]{0} %multiply.160.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.43.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_4.381, f32[3584]{0} %add.44.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  ROOT %tuple.6 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.41, f32[3584]{0} %maximum.4.clone.1, f32[3584]{0} %add.43.clone.1)
}

%fused_computation.26 (param_0.46: f32[1792], param_1.78: f32[1792], param_2.55: f32[1792], param_3.57: f32[16,7,7,1792], param_4.367: f32[1792]) -> f32[16,7,7,1792] {
  %param_3.57 = f32[16,7,7,1792]{2,1,3,0} parameter(3)
  %param_4.367 = f32[1792]{0} parameter(4)
  %constant_702 = f32[] constant(0.00127551018)
  %broadcast.630 = f32[1792]{0} broadcast(f32[] %constant_702), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.517 = f32[1792]{0} multiply(f32[1792]{0} %param_4.367, f32[1792]{0} %broadcast.630), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.212 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.517), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.7 = f32[16,7,7,1792]{2,1,3,0} subtract(f32[16,7,7,1792]{2,1,3,0} %param_3.57, f32[16,7,7,1792]{2,1,3,0} %broadcast.212), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.55 = f32[1792]{0} parameter(2)
  %constant_126 = f32[] constant(1e-05)
  %broadcast.214 = f32[1792]{0} broadcast(f32[] %constant_126), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.46 = f32[1792]{0} add(f32[1792]{0} %param_2.55, f32[1792]{0} %broadcast.214), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.27 = f32[1792]{0} rsqrt(f32[1792]{0} %add.46), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.78 = f32[1792]{0} parameter(1)
  %multiply.163 = f32[1792]{0} multiply(f32[1792]{0} %rsqrt.27, f32[1792]{0} %param_1.78), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.211 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.163), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.162 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.7, f32[16,7,7,1792]{2,1,3,0} %broadcast.211), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.46 = f32[1792]{0} parameter(0)
  %broadcast.210 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.46), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.45 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.162, f32[16,7,7,1792]{2,1,3,0} %broadcast.210), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_127 = f32[] constant(0)
  %broadcast.213 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[] %constant_127), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.5 = f32[16,7,7,1792]{2,1,3,0} maximum(f32[16,7,7,1792]{2,1,3,0} %add.45, f32[16,7,7,1792]{2,1,3,0} %broadcast.213), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.27 (param_0.47: f32[1792], param_1.639: f32[1792], param_2.560: f32[1792], param_3.532: f32[16,1792], param_4.387: f32[1792], param_5.207: f32[1792]) -> (f32[1792], f32[1792], f32[1792]) {
  %param_0.47 = f32[1792]{0} parameter(0)
  %param_1.639 = f32[1792]{0} parameter(1)
  %constant_129 = f32[] constant(0.9)
  %broadcast.216 = f32[1792]{0} broadcast(f32[] %constant_129), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.165 = f32[1792]{0} multiply(f32[1792]{0} %param_1.639, f32[1792]{0} %broadcast.216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.532 = f32[16,1792]{1,0} parameter(3)
  %constant_131_clone_1 = f32[] constant(0)
  %reduce.273.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.532, f32[] %constant_131_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_705_clone_1 = f32[] constant(0.00127551018)
  %broadcast.217.clone.1 = f32[1792]{0} broadcast(f32[] %constant_705_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.167.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.273.clone.1, f32[1792]{0} %broadcast.217.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.560 = f32[1792]{0} parameter(2)
  %multiply.519.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.560, f32[1792]{0} %broadcast.217.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.166.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.519.clone.1, f32[1792]{0} %multiply.519.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.8.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.167.clone.1, f32[1792]{0} %multiply.166.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.218.clone.1 = f32[1792]{0} broadcast(f32[] %constant_131_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.6.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %subtract.8.clone.1, f32[1792]{0} %broadcast.218.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_128 = f32[] constant(0.1)
  %broadcast.215 = f32[1792]{0} broadcast(f32[] %constant_128), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.164 = f32[1792]{0} multiply(f32[1792]{0} %maximum.6.clone.1, f32[1792]{0} %broadcast.215), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.48 = f32[1792]{0} add(f32[1792]{0} %multiply.165, f32[1792]{0} %multiply.164), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.47 = f32[1792]{0} add(f32[1792]{0} %param_0.47, f32[1792]{0} %add.48), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %param_4.387 = f32[1792]{0} parameter(4)
  %param_5.207 = f32[1792]{0} parameter(5)
  %multiply.171.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_5.207, f32[1792]{0} %broadcast.216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_134_clone_1 = f32[] constant(0.000127551015)
  %broadcast.220.clone.1 = f32[1792]{0} broadcast(f32[] %constant_134_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.170.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.560, f32[1792]{0} %broadcast.220.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.50.clone.1 = f32[1792]{0} add(f32[1792]{0} %multiply.171.clone.1, f32[1792]{0} %multiply.170.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.49.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_4.387, f32[1792]{0} %add.50.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  ROOT %tuple.9 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.47, f32[1792]{0} %maximum.6.clone.1, f32[1792]{0} %add.49.clone.1)
}

%fused_computation.34 (param_0.60: f32[7168], param_1.647: f32[7168], param_2.568: f32[7168], param_3.542: f32[16,7168], param_4.397: f32[7168], param_5.219: f32[7168]) -> (f32[7168], f32[7168], f32[7168]) {
  %param_0.60 = f32[7168]{0} parameter(0)
  %param_1.647 = f32[7168]{0} parameter(1)
  %constant_140 = f32[] constant(0.9)
  %broadcast.228 = f32[7168]{0} broadcast(f32[] %constant_140), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.175 = f32[7168]{0} multiply(f32[7168]{0} %param_1.647, f32[7168]{0} %broadcast.228), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.542 = f32[16,7168]{1,0} parameter(3)
  %constant_142_clone_1 = f32[] constant(0)
  %reduce.276.clone.1 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_3.542, f32[] %constant_142_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_699_clone_1 = f32[] constant(0.00127551018)
  %broadcast.230.clone.1 = f32[7168]{0} broadcast(f32[] %constant_699_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.177.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %reduce.276.clone.1, f32[7168]{0} %broadcast.230.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.568 = f32[7168]{0} parameter(2)
  %multiply.515.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.568, f32[7168]{0} %broadcast.230.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.176.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %multiply.515.clone.1, f32[7168]{0} %multiply.515.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.10.clone.1 = f32[7168]{0} subtract(f32[7168]{0} %multiply.177.clone.1, f32[7168]{0} %multiply.176.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.229.clone.1 = f32[7168]{0} broadcast(f32[] %constant_142_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.8.clone.1 = f32[7168]{0} maximum(f32[7168]{0} %subtract.10.clone.1, f32[7168]{0} %broadcast.229.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_139 = f32[] constant(0.1)
  %broadcast.227 = f32[7168]{0} broadcast(f32[] %constant_139), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.174 = f32[7168]{0} multiply(f32[7168]{0} %maximum.8.clone.1, f32[7168]{0} %broadcast.227), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.55 = f32[7168]{0} add(f32[7168]{0} %multiply.175, f32[7168]{0} %multiply.174), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.54 = f32[7168]{0} add(f32[7168]{0} %param_0.60, f32[7168]{0} %add.55), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  %param_4.397 = f32[7168]{0} parameter(4)
  %param_5.219 = f32[7168]{0} parameter(5)
  %multiply.181.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_5.219, f32[7168]{0} %broadcast.228), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_145_clone_1 = f32[] constant(0.000127551015)
  %broadcast.232.clone.1 = f32[7168]{0} broadcast(f32[] %constant_145_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.180.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.568, f32[7168]{0} %broadcast.232.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.57.clone.1 = f32[7168]{0} add(f32[7168]{0} %multiply.181.clone.1, f32[7168]{0} %multiply.180.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.56.clone.1 = f32[7168]{0} add(f32[7168]{0} %param_4.397, f32[7168]{0} %add.57.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  ROOT %tuple.13 = (f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) tuple(f32[7168]{0} %add.54, f32[7168]{0} %maximum.8.clone.1, f32[7168]{0} %add.56.clone.1)
}

%fused_computation.40 (param_0.72: f32[3584], param_1.120: f32[3584], param_2.92: f32[3584], param_3.93: f32[16,7,7,3584], param_4.366: f32[3584]) -> f32[16,7,7,3584] {
  %param_3.93 = f32[16,7,7,3584]{2,1,3,0} parameter(3)
  %param_4.366 = f32[3584]{0} parameter(4)
  %constant_690 = f32[] constant(0.00127551018)
  %broadcast.622 = f32[3584]{0} broadcast(f32[] %constant_690), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.509 = f32[3584]{0} multiply(f32[3584]{0} %param_4.366, f32[3584]{0} %broadcast.622), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.236 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.509), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.11 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_3.93, f32[16,7,7,3584]{2,1,3,0} %broadcast.236), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.92 = f32[3584]{0} parameter(2)
  %constant_148 = f32[] constant(1e-05)
  %broadcast.238 = f32[3584]{0} broadcast(f32[] %constant_148), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.59 = f32[3584]{0} add(f32[3584]{0} %param_2.92, f32[3584]{0} %broadcast.238), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.29 = f32[3584]{0} rsqrt(f32[3584]{0} %add.59), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.120 = f32[3584]{0} parameter(1)
  %multiply.183 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.29, f32[3584]{0} %param_1.120), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.235 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.183), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.182 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.11, f32[16,7,7,3584]{2,1,3,0} %broadcast.235), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.72 = f32[3584]{0} parameter(0)
  %broadcast.234 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_0.72), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.58 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.182, f32[16,7,7,3584]{2,1,3,0} %broadcast.234), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_149 = f32[] constant(0)
  %broadcast.237 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_149), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.9 = f32[16,7,7,3584]{2,1,3,0} maximum(f32[16,7,7,3584]{2,1,3,0} %add.58, f32[16,7,7,3584]{2,1,3,0} %broadcast.237), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.41 (param_0.73: f32[3584], param_1.650: f32[3584], param_2.572: f32[3584], param_3.547: f32[16,3584], param_4.403: f32[3584], param_5.226: f32[3584]) -> (f32[3584], f32[3584], f32[3584]) {
  %param_0.73 = f32[3584]{0} parameter(0)
  %param_1.650 = f32[3584]{0} parameter(1)
  %constant_151 = f32[] constant(0.9)
  %broadcast.240 = f32[3584]{0} broadcast(f32[] %constant_151), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.185 = f32[3584]{0} multiply(f32[3584]{0} %param_1.650, f32[3584]{0} %broadcast.240), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.547 = f32[16,3584]{1,0} parameter(3)
  %constant_153_clone_1 = f32[] constant(0)
  %reduce.279.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.547, f32[] %constant_153_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_693_clone_1 = f32[] constant(0.00127551018)
  %broadcast.241.clone.1 = f32[3584]{0} broadcast(f32[] %constant_693_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.187.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.279.clone.1, f32[3584]{0} %broadcast.241.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.572 = f32[3584]{0} parameter(2)
  %multiply.511.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.572, f32[3584]{0} %broadcast.241.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.186.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.511.clone.1, f32[3584]{0} %multiply.511.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.12.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.187.clone.1, f32[3584]{0} %multiply.186.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.242.clone.1 = f32[3584]{0} broadcast(f32[] %constant_153_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.10.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %subtract.12.clone.1, f32[3584]{0} %broadcast.242.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_150 = f32[] constant(0.1)
  %broadcast.239 = f32[3584]{0} broadcast(f32[] %constant_150), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.184 = f32[3584]{0} multiply(f32[3584]{0} %maximum.10.clone.1, f32[3584]{0} %broadcast.239), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.61 = f32[3584]{0} add(f32[3584]{0} %multiply.185, f32[3584]{0} %multiply.184), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.60 = f32[3584]{0} add(f32[3584]{0} %param_0.73, f32[3584]{0} %add.61), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  %param_4.403 = f32[3584]{0} parameter(4)
  %param_5.226 = f32[3584]{0} parameter(5)
  %multiply.191.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.226, f32[3584]{0} %broadcast.240), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_156_clone_1 = f32[] constant(0.000127551015)
  %broadcast.244.clone.1 = f32[3584]{0} broadcast(f32[] %constant_156_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.190.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.572, f32[3584]{0} %broadcast.244.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.63.clone.1 = f32[3584]{0} add(f32[3584]{0} %multiply.191.clone.1, f32[3584]{0} %multiply.190.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.62.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_4.403, f32[3584]{0} %add.63.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  ROOT %tuple.16 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.60, f32[3584]{0} %maximum.10.clone.1, f32[3584]{0} %add.62.clone.1)
}

%fused_computation.47 (param_0.346: f32[1792], param_1.574: f32[1792], param_2.455: f32[1792], param_3.458: f32[16,7,7,1792], param_4.365: f32[1792]) -> f32[16,7,7,1792] {
  %param_3.458 = f32[16,7,7,1792]{2,1,3,0} parameter(3)
  %param_4.365 = f32[1792]{0} parameter(4)
  %constant_684 = f32[] constant(0.00127551018)
  %broadcast.618 = f32[1792]{0} broadcast(f32[] %constant_684), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.505 = f32[1792]{0} multiply(f32[1792]{0} %param_4.365, f32[1792]{0} %broadcast.618), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.249 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.505), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.13 = f32[16,7,7,1792]{2,1,3,0} subtract(f32[16,7,7,1792]{2,1,3,0} %param_3.458, f32[16,7,7,1792]{2,1,3,0} %broadcast.249), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.455 = f32[1792]{0} parameter(2)
  %constant_159 = f32[] constant(1e-05)
  %broadcast.250 = f32[1792]{0} broadcast(f32[] %constant_159), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.65 = f32[1792]{0} add(f32[1792]{0} %param_2.455, f32[1792]{0} %broadcast.250), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.30 = f32[1792]{0} rsqrt(f32[1792]{0} %add.65), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.574 = f32[1792]{0} parameter(1)
  %multiply.193 = f32[1792]{0} multiply(f32[1792]{0} %rsqrt.30, f32[1792]{0} %param_1.574), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.248 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.193), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.192 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.13, f32[16,7,7,1792]{2,1,3,0} %broadcast.248), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.346 = f32[1792]{0} parameter(0)
  %broadcast.247 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.346), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.64 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.192, f32[16,7,7,1792]{2,1,3,0} %broadcast.247), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_160 = f32[] constant(0)
  %broadcast.246 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[] %constant_160), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.11 = f32[16,7,7,1792]{2,1,3,0} maximum(f32[16,7,7,1792]{2,1,3,0} %add.64, f32[16,7,7,1792]{2,1,3,0} %broadcast.246), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.48 (param_0.85: f32[1792], param_1.653: f32[1792], param_2.576: f32[1792], param_3.552: f32[16,1792], param_4.409: f32[1792], param_5.233: f32[1792]) -> (f32[1792], f32[1792], f32[1792]) {
  %param_0.85 = f32[1792]{0} parameter(0)
  %param_1.653 = f32[1792]{0} parameter(1)
  %constant_162 = f32[] constant(0.9)
  %broadcast.252 = f32[1792]{0} broadcast(f32[] %constant_162), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.195 = f32[1792]{0} multiply(f32[1792]{0} %param_1.653, f32[1792]{0} %broadcast.252), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.552 = f32[16,1792]{1,0} parameter(3)
  %constant_164_clone_1 = f32[] constant(0)
  %reduce.282.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.552, f32[] %constant_164_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_687_clone_1 = f32[] constant(0.00127551018)
  %broadcast.253.clone.1 = f32[1792]{0} broadcast(f32[] %constant_687_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.197.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.282.clone.1, f32[1792]{0} %broadcast.253.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.576 = f32[1792]{0} parameter(2)
  %multiply.507.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.576, f32[1792]{0} %broadcast.253.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.196.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.507.clone.1, f32[1792]{0} %multiply.507.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.14.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.197.clone.1, f32[1792]{0} %multiply.196.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.254.clone.1 = f32[1792]{0} broadcast(f32[] %constant_164_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.12.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %subtract.14.clone.1, f32[1792]{0} %broadcast.254.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_161 = f32[] constant(0.1)
  %broadcast.251 = f32[1792]{0} broadcast(f32[] %constant_161), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.194 = f32[1792]{0} multiply(f32[1792]{0} %maximum.12.clone.1, f32[1792]{0} %broadcast.251), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.67 = f32[1792]{0} add(f32[1792]{0} %multiply.195, f32[1792]{0} %multiply.194), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.66 = f32[1792]{0} add(f32[1792]{0} %param_0.85, f32[1792]{0} %add.67), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  %param_4.409 = f32[1792]{0} parameter(4)
  %param_5.233 = f32[1792]{0} parameter(5)
  %multiply.201.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_5.233, f32[1792]{0} %broadcast.252), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_167_clone_1 = f32[] constant(0.000127551015)
  %broadcast.256.clone.1 = f32[1792]{0} broadcast(f32[] %constant_167_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.200.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.576, f32[1792]{0} %broadcast.256.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.69.clone.1 = f32[1792]{0} add(f32[1792]{0} %multiply.201.clone.1, f32[1792]{0} %multiply.200.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.68.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_4.409, f32[1792]{0} %add.69.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  ROOT %tuple.19 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.66, f32[1792]{0} %maximum.12.clone.1, f32[1792]{0} %add.68.clone.1)
}

%fused_computation.54 (param_0.463: f32[7168], param_1.621: f32[7168], param_2.535: f32[7168], param_3.514: f32[16,7,7,7168], param_4.364: f32[7168], param_5.175: f32[7168], param_6.133: f32[7168], param_7.49: f32[7168], param_8.25: f32[16,7,7,7168], param_9.24: f32[7168]) -> f32[16,7,7,7168] {
  %param_8.25 = f32[16,7,7,7168]{2,1,3,0} parameter(8)
  %param_9.24 = f32[7168]{0} parameter(9)
  %constant_679 = f32[] constant(0.00127551018)
  %broadcast.616 = f32[7168]{0} broadcast(f32[] %constant_679), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.503 = f32[7168]{0} multiply(f32[7168]{0} %param_9.24, f32[7168]{0} %broadcast.616), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.615 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.503), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.64 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_8.25, f32[16,7,7,7168]{2,1,3,0} %broadcast.615), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_7.49 = f32[7168]{0} parameter(7)
  %constant_680 = f32[] constant(1e-05)
  %broadcast.614 = f32[7168]{0} broadcast(f32[] %constant_680), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.221 = f32[7168]{0} add(f32[7168]{0} %param_7.49, f32[7168]{0} %broadcast.614), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.86 = f32[7168]{0} rsqrt(f32[7168]{0} %add.221), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_6.133 = f32[7168]{0} parameter(6)
  %multiply.502 = f32[7168]{0} multiply(f32[7168]{0} %rsqrt.86, f32[7168]{0} %param_6.133), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.613 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.502), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.501 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.64, f32[16,7,7,7168]{2,1,3,0} %broadcast.613), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_5.175 = f32[7168]{0} parameter(5)
  %broadcast.612 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_5.175), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.220 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.501, f32[16,7,7,7168]{2,1,3,0} %broadcast.612), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %param_3.514 = f32[16,7,7,7168]{2,1,3,0} parameter(3)
  %param_4.364 = f32[7168]{0} parameter(4)
  %multiply.500 = f32[7168]{0} multiply(f32[7168]{0} %param_4.364, f32[7168]{0} %broadcast.616), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.610 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.500), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.63 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_3.514, f32[16,7,7,7168]{2,1,3,0} %broadcast.610), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.535 = f32[7168]{0} parameter(2)
  %add.219 = f32[7168]{0} add(f32[7168]{0} %param_2.535, f32[7168]{0} %broadcast.614), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.85 = f32[7168]{0} rsqrt(f32[7168]{0} %add.219), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.621 = f32[7168]{0} parameter(1)
  %multiply.499 = f32[7168]{0} multiply(f32[7168]{0} %rsqrt.85, f32[7168]{0} %param_1.621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.609 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.499), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.498 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.63, f32[16,7,7,7168]{2,1,3,0} %broadcast.609), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.463 = f32[7168]{0} parameter(0)
  %broadcast.608 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_0.463), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.218 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.498, f32[16,7,7,7168]{2,1,3,0} %broadcast.608), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.217 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %add.220, f32[16,7,7,7168]{2,1,3,0} %add.218), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %constant_170 = f32[] constant(0)
  %broadcast.258 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[] %constant_170), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.13 = f32[16,7,7,7168]{2,1,3,0} maximum(f32[16,7,7,7168]{2,1,3,0} %add.217, f32[16,7,7,7168]{2,1,3,0} %broadcast.258), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.56 (param_0.98: f32[7168], param_1.656: f32[7168], param_2.580: f32[7168], param_3.557: f32[16,7168], param_4.415: f32[7168], param_5.240: f32[7168]) -> (f32[7168], f32[7168], f32[7168]) {
  %param_0.98 = f32[7168]{0} parameter(0)
  %param_1.656 = f32[7168]{0} parameter(1)
  %constant_173 = f32[] constant(0.9)
  %broadcast.267 = f32[7168]{0} broadcast(f32[] %constant_173), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.207 = f32[7168]{0} multiply(f32[7168]{0} %param_1.656, f32[7168]{0} %broadcast.267), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.557 = f32[16,7168]{1,0} parameter(3)
  %constant_175_clone_1 = f32[] constant(0)
  %reduce.285.clone.1 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_3.557, f32[] %constant_175_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_667_clone_1 = f32[] constant(0.00127551018)
  %broadcast.269.clone.1 = f32[7168]{0} broadcast(f32[] %constant_667_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.209.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %reduce.285.clone.1, f32[7168]{0} %broadcast.269.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.580 = f32[7168]{0} parameter(2)
  %multiply.479.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.580, f32[7168]{0} %broadcast.269.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.208.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %multiply.479.clone.1, f32[7168]{0} %multiply.479.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.17.clone.1 = f32[7168]{0} subtract(f32[7168]{0} %multiply.209.clone.1, f32[7168]{0} %multiply.208.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.268.clone.1 = f32[7168]{0} broadcast(f32[] %constant_175_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.14.clone.1 = f32[7168]{0} maximum(f32[7168]{0} %subtract.17.clone.1, f32[7168]{0} %broadcast.268.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_172 = f32[] constant(0.1)
  %broadcast.266 = f32[7168]{0} broadcast(f32[] %constant_172), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.206 = f32[7168]{0} multiply(f32[7168]{0} %maximum.14.clone.1, f32[7168]{0} %broadcast.266), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.76 = f32[7168]{0} add(f32[7168]{0} %multiply.207, f32[7168]{0} %multiply.206), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.75 = f32[7168]{0} add(f32[7168]{0} %param_0.98, f32[7168]{0} %add.76), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  %param_4.415 = f32[7168]{0} parameter(4)
  %param_5.240 = f32[7168]{0} parameter(5)
  %multiply.213.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_5.240, f32[7168]{0} %broadcast.267), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_178_clone_1 = f32[] constant(0.000127551015)
  %broadcast.271.clone.1 = f32[7168]{0} broadcast(f32[] %constant_178_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.212.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.580, f32[7168]{0} %broadcast.271.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.78.clone.1 = f32[7168]{0} add(f32[7168]{0} %multiply.213.clone.1, f32[7168]{0} %multiply.212.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.77.clone.1 = f32[7168]{0} add(f32[7168]{0} %param_4.415, f32[7168]{0} %add.78.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  ROOT %tuple.22 = (f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) tuple(f32[7168]{0} %add.75, f32[7168]{0} %maximum.14.clone.1, f32[7168]{0} %add.77.clone.1)
}

%fused_computation.62 (param_0.108: f32[7168], param_1.659: f32[7168], param_2.584: f32[7168], param_3.562: f32[16,7168], param_4.421: f32[7168], param_5.247: f32[7168]) -> (f32[7168], f32[7168], f32[7168]) {
  %param_0.108 = f32[7168]{0} parameter(0)
  %param_1.659 = f32[7168]{0} parameter(1)
  %constant_182 = f32[] constant(0.9)
  %broadcast.274 = f32[7168]{0} broadcast(f32[] %constant_182), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.215 = f32[7168]{0} multiply(f32[7168]{0} %param_1.659, f32[7168]{0} %broadcast.274), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.562 = f32[16,7168]{1,0} parameter(3)
  %constant_184_clone_1 = f32[] constant(0)
  %reduce.288.clone.1 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_3.562, f32[] %constant_184_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_661_clone_1 = f32[] constant(0.00127551018)
  %broadcast.276.clone.1 = f32[7168]{0} broadcast(f32[] %constant_661_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.217.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %reduce.288.clone.1, f32[7168]{0} %broadcast.276.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.584 = f32[7168]{0} parameter(2)
  %multiply.475.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.584, f32[7168]{0} %broadcast.276.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.216.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %multiply.475.clone.1, f32[7168]{0} %multiply.475.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.18.clone.1 = f32[7168]{0} subtract(f32[7168]{0} %multiply.217.clone.1, f32[7168]{0} %multiply.216.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.275.clone.1 = f32[7168]{0} broadcast(f32[] %constant_184_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.15.clone.1 = f32[7168]{0} maximum(f32[7168]{0} %subtract.18.clone.1, f32[7168]{0} %broadcast.275.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_181 = f32[] constant(0.1)
  %broadcast.273 = f32[7168]{0} broadcast(f32[] %constant_181), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.214 = f32[7168]{0} multiply(f32[7168]{0} %maximum.15.clone.1, f32[7168]{0} %broadcast.273), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.80 = f32[7168]{0} add(f32[7168]{0} %multiply.215, f32[7168]{0} %multiply.214), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.79 = f32[7168]{0} add(f32[7168]{0} %param_0.108, f32[7168]{0} %add.80), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  %param_4.421 = f32[7168]{0} parameter(4)
  %param_5.247 = f32[7168]{0} parameter(5)
  %multiply.221.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_5.247, f32[7168]{0} %broadcast.274), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_187_clone_1 = f32[] constant(0.000127551015)
  %broadcast.278.clone.1 = f32[7168]{0} broadcast(f32[] %constant_187_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.220.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.584, f32[7168]{0} %broadcast.278.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.82.clone.1 = f32[7168]{0} add(f32[7168]{0} %multiply.221.clone.1, f32[7168]{0} %multiply.220.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.81.clone.1 = f32[7168]{0} add(f32[7168]{0} %param_4.421, f32[7168]{0} %add.82.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  ROOT %tuple.25 = (f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) tuple(f32[7168]{0} %add.79, f32[7168]{0} %maximum.15.clone.1, f32[7168]{0} %add.81.clone.1)
}

%fused_computation.68 (param_0.354: f32[3584], param_1.577: f32[3584], param_2.461: f32[3584], param_3.465: f32[16,7,7,3584], param_4.349: f32[3584]) -> f32[16,7,7,3584] {
  %param_3.465 = f32[16,7,7,3584]{2,1,3,0} parameter(3)
  %param_4.349 = f32[3584]{0} parameter(4)
  %constant_652 = f32[] constant(0.00127551018)
  %broadcast.570 = f32[3584]{0} broadcast(f32[] %constant_652), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.469 = f32[3584]{0} multiply(f32[3584]{0} %param_4.349, f32[3584]{0} %broadcast.570), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.283 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.469), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.19 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_3.465, f32[16,7,7,3584]{2,1,3,0} %broadcast.283), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.461 = f32[3584]{0} parameter(2)
  %constant_190 = f32[] constant(1e-05)
  %broadcast.284 = f32[3584]{0} broadcast(f32[] %constant_190), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.84 = f32[3584]{0} add(f32[3584]{0} %param_2.461, f32[3584]{0} %broadcast.284), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.33 = f32[3584]{0} rsqrt(f32[3584]{0} %add.84), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.577 = f32[3584]{0} parameter(1)
  %multiply.223 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.33, f32[3584]{0} %param_1.577), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.282 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.223), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.222 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.19, f32[16,7,7,3584]{2,1,3,0} %broadcast.282), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.354 = f32[3584]{0} parameter(0)
  %broadcast.281 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_0.354), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.83 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.222, f32[16,7,7,3584]{2,1,3,0} %broadcast.281), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_191 = f32[] constant(0)
  %broadcast.280 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_191), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.16 = f32[16,7,7,3584]{2,1,3,0} maximum(f32[16,7,7,3584]{2,1,3,0} %add.83, f32[16,7,7,3584]{2,1,3,0} %broadcast.280), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.69 (param_0.119: f32[3584], param_1.662: f32[3584], param_2.588: f32[3584], param_3.567: f32[16,3584], param_4.427: f32[3584], param_5.254: f32[3584]) -> (f32[3584], f32[3584], f32[3584]) {
  %param_0.119 = f32[3584]{0} parameter(0)
  %param_1.662 = f32[3584]{0} parameter(1)
  %constant_193 = f32[] constant(0.9)
  %broadcast.286 = f32[3584]{0} broadcast(f32[] %constant_193), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.225 = f32[3584]{0} multiply(f32[3584]{0} %param_1.662, f32[3584]{0} %broadcast.286), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.567 = f32[16,3584]{1,0} parameter(3)
  %constant_195_clone_1 = f32[] constant(0)
  %reduce.291.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.567, f32[] %constant_195_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_655_clone_1 = f32[] constant(0.00127551018)
  %broadcast.287.clone.1 = f32[3584]{0} broadcast(f32[] %constant_655_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.227.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.291.clone.1, f32[3584]{0} %broadcast.287.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.588 = f32[3584]{0} parameter(2)
  %multiply.471.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.588, f32[3584]{0} %broadcast.287.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.226.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.471.clone.1, f32[3584]{0} %multiply.471.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.20.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.227.clone.1, f32[3584]{0} %multiply.226.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.288.clone.1 = f32[3584]{0} broadcast(f32[] %constant_195_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.17.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %subtract.20.clone.1, f32[3584]{0} %broadcast.288.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_192 = f32[] constant(0.1)
  %broadcast.285 = f32[3584]{0} broadcast(f32[] %constant_192), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.224 = f32[3584]{0} multiply(f32[3584]{0} %maximum.17.clone.1, f32[3584]{0} %broadcast.285), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.86 = f32[3584]{0} add(f32[3584]{0} %multiply.225, f32[3584]{0} %multiply.224), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.85 = f32[3584]{0} add(f32[3584]{0} %param_0.119, f32[3584]{0} %add.86), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  %param_4.427 = f32[3584]{0} parameter(4)
  %param_5.254 = f32[3584]{0} parameter(5)
  %multiply.231.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.254, f32[3584]{0} %broadcast.286), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_198_clone_1 = f32[] constant(0.000127551015)
  %broadcast.290.clone.1 = f32[3584]{0} broadcast(f32[] %constant_198_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.230.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.588, f32[3584]{0} %broadcast.290.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.88.clone.1 = f32[3584]{0} add(f32[3584]{0} %multiply.231.clone.1, f32[3584]{0} %multiply.230.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.87.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_4.427, f32[3584]{0} %add.88.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  ROOT %tuple.28 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.85, f32[3584]{0} %maximum.17.clone.1, f32[3584]{0} %add.87.clone.1)
}

%fused_computation.75 (param_0.357: f32[1792], param_1.579: f32[1792], param_2.464: f32[1792], param_3.468: f32[16,14,14,1792], param_4.348: f32[1792]) -> f32[16,15,15,1792] {
  %param_3.468 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.348 = f32[1792]{0} parameter(4)
  %constant_646 = f32[] constant(0.000318877544)
  %broadcast.566 = f32[1792]{0} broadcast(f32[] %constant_646), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.465 = f32[1792]{0} multiply(f32[1792]{0} %param_4.348, f32[1792]{0} %broadcast.566), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.294 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.465), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.21 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.468, f32[16,14,14,1792]{2,1,3,0} %broadcast.294), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.464 = f32[1792]{0} parameter(2)
  %constant_201 = f32[] constant(1e-05)
  %broadcast.296 = f32[1792]{0} broadcast(f32[] %constant_201), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.90 = f32[1792]{0} add(f32[1792]{0} %param_2.464, f32[1792]{0} %broadcast.296), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.34 = f32[1792]{0} rsqrt(f32[1792]{0} %add.90), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.579 = f32[1792]{0} parameter(1)
  %multiply.233 = f32[1792]{0} multiply(f32[1792]{0} %rsqrt.34, f32[1792]{0} %param_1.579), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.293 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.233), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.232 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.21, f32[16,14,14,1792]{2,1,3,0} %broadcast.293), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.357 = f32[1792]{0} parameter(0)
  %broadcast.292 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.357), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.89 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.232, f32[16,14,14,1792]{2,1,3,0} %broadcast.292), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_202 = f32[] constant(0)
  %broadcast.295 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_202), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %maximum.18 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.89, f32[16,14,14,1792]{2,1,3,0} %broadcast.295), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %pad.1 = f32[16,15,15,1792]{2,1,3,0} pad(f32[16,14,14,1792]{2,1,3,0} %maximum.18, f32[] %constant_202), padding=0_0x0_1x0_1x0_0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.76 (param_0.131: f32[1792], param_1.665: f32[1792], param_2.592: f32[1792], param_3.572: f32[16,1792], param_4.433: f32[1792], param_5.261: f32[1792]) -> (f32[1792], f32[1792], f32[1792]) {
  %param_0.131 = f32[1792]{0} parameter(0)
  %param_1.665 = f32[1792]{0} parameter(1)
  %constant_204 = f32[] constant(0.9)
  %broadcast.298 = f32[1792]{0} broadcast(f32[] %constant_204), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.235 = f32[1792]{0} multiply(f32[1792]{0} %param_1.665, f32[1792]{0} %broadcast.298), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.572 = f32[16,1792]{1,0} parameter(3)
  %constant_206_clone_1 = f32[] constant(0)
  %reduce.294.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.572, f32[] %constant_206_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_649_clone_1 = f32[] constant(0.000318877544)
  %broadcast.300.clone.1 = f32[1792]{0} broadcast(f32[] %constant_649_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.237.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.294.clone.1, f32[1792]{0} %broadcast.300.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.592 = f32[1792]{0} parameter(2)
  %multiply.467.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.592, f32[1792]{0} %broadcast.300.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.236.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.467.clone.1, f32[1792]{0} %multiply.467.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.22.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.237.clone.1, f32[1792]{0} %multiply.236.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.299.clone.1 = f32[1792]{0} broadcast(f32[] %constant_206_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.19.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %subtract.22.clone.1, f32[1792]{0} %broadcast.299.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_203 = f32[] constant(0.1)
  %broadcast.297 = f32[1792]{0} broadcast(f32[] %constant_203), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.234 = f32[1792]{0} multiply(f32[1792]{0} %maximum.19.clone.1, f32[1792]{0} %broadcast.297), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.92 = f32[1792]{0} add(f32[1792]{0} %multiply.235, f32[1792]{0} %multiply.234), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.91 = f32[1792]{0} add(f32[1792]{0} %param_0.131, f32[1792]{0} %add.92), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  %param_4.433 = f32[1792]{0} parameter(4)
  %param_5.261 = f32[1792]{0} parameter(5)
  %multiply.241.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_5.261, f32[1792]{0} %broadcast.298), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_210_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.302.clone.1 = f32[1792]{0} broadcast(f32[] %constant_210_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.240.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.592, f32[1792]{0} %broadcast.302.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.94.clone.1 = f32[1792]{0} add(f32[1792]{0} %multiply.241.clone.1, f32[1792]{0} %multiply.240.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.93.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_4.433, f32[1792]{0} %add.94.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  ROOT %tuple.42 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.91, f32[1792]{0} %maximum.19.clone.1, f32[1792]{0} %add.93.clone.1)
}

%fused_computation.83 (param_0.144: f32[3584], param_1.673: f32[3584], param_2.600: f32[3584], param_3.582: f32[16,3584], param_4.443: f32[3584], param_5.273: f32[3584]) -> (f32[3584], f32[3584], f32[3584]) {
  %param_0.144 = f32[3584]{0} parameter(0)
  %param_1.673 = f32[3584]{0} parameter(1)
  %constant_215 = f32[] constant(0.9)
  %broadcast.310 = f32[3584]{0} broadcast(f32[] %constant_215), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.245 = f32[3584]{0} multiply(f32[3584]{0} %param_1.673, f32[3584]{0} %broadcast.310), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.582 = f32[16,3584]{1,0} parameter(3)
  %constant_217_clone_1 = f32[] constant(0)
  %reduce.297.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.582, f32[] %constant_217_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_643_clone_1 = f32[] constant(0.000318877544)
  %broadcast.312.clone.1 = f32[3584]{0} broadcast(f32[] %constant_643_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.247.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.297.clone.1, f32[3584]{0} %broadcast.312.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.600 = f32[3584]{0} parameter(2)
  %multiply.463.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.600, f32[3584]{0} %broadcast.312.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.246.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.463.clone.1, f32[3584]{0} %multiply.463.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.24.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.247.clone.1, f32[3584]{0} %multiply.246.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.311.clone.1 = f32[3584]{0} broadcast(f32[] %constant_217_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.21.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %subtract.24.clone.1, f32[3584]{0} %broadcast.311.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_214 = f32[] constant(0.1)
  %broadcast.309 = f32[3584]{0} broadcast(f32[] %constant_214), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.244 = f32[3584]{0} multiply(f32[3584]{0} %maximum.21.clone.1, f32[3584]{0} %broadcast.309), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.99 = f32[3584]{0} add(f32[3584]{0} %multiply.245, f32[3584]{0} %multiply.244), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.98 = f32[3584]{0} add(f32[3584]{0} %param_0.144, f32[3584]{0} %add.99), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  %param_4.443 = f32[3584]{0} parameter(4)
  %param_5.273 = f32[3584]{0} parameter(5)
  %multiply.251.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.273, f32[3584]{0} %broadcast.310), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_221_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.314.clone.1 = f32[3584]{0} broadcast(f32[] %constant_221_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.250.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.600, f32[3584]{0} %broadcast.314.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.101.clone.1 = f32[3584]{0} add(f32[3584]{0} %multiply.251.clone.1, f32[3584]{0} %multiply.250.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.100.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_4.443, f32[3584]{0} %add.101.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  ROOT %tuple.46 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.98, f32[3584]{0} %maximum.21.clone.1, f32[3584]{0} %add.100.clone.1)
}

%fused_computation.89 (param_0.156: f32[1792], param_1.267: f32[1792], param_2.208: f32[1792], param_3.206: f32[16,14,14,1792], param_4.347: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.206 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.347 = f32[1792]{0} parameter(4)
  %constant_634 = f32[] constant(0.000318877544)
  %broadcast.558 = f32[1792]{0} broadcast(f32[] %constant_634), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.457 = f32[1792]{0} multiply(f32[1792]{0} %param_4.347, f32[1792]{0} %broadcast.558), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.318 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.457), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.25 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.206, f32[16,14,14,1792]{2,1,3,0} %broadcast.318), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.208 = f32[1792]{0} parameter(2)
  %constant_223 = f32[] constant(1e-05)
  %broadcast.320 = f32[1792]{0} broadcast(f32[] %constant_223), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.103 = f32[1792]{0} add(f32[1792]{0} %param_2.208, f32[1792]{0} %broadcast.320), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.36 = f32[1792]{0} rsqrt(f32[1792]{0} %add.103), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.267 = f32[1792]{0} parameter(1)
  %multiply.253 = f32[1792]{0} multiply(f32[1792]{0} %rsqrt.36, f32[1792]{0} %param_1.267), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.317 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.253), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.252 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.25, f32[16,14,14,1792]{2,1,3,0} %broadcast.317), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.156 = f32[1792]{0} parameter(0)
  %broadcast.316 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.156), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.102 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.252, f32[16,14,14,1792]{2,1,3,0} %broadcast.316), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_224 = f32[] constant(0)
  %broadcast.319 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_224), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.22 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.102, f32[16,14,14,1792]{2,1,3,0} %broadcast.319), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.90 (param_0.157: f32[1792], param_1.676: f32[1792], param_2.604: f32[1792], param_3.587: f32[16,1792], param_4.449: f32[1792], param_5.280: f32[1792]) -> (f32[1792], f32[1792], f32[1792]) {
  %param_0.157 = f32[1792]{0} parameter(0)
  %param_1.676 = f32[1792]{0} parameter(1)
  %constant_226 = f32[] constant(0.9)
  %broadcast.322 = f32[1792]{0} broadcast(f32[] %constant_226), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.255 = f32[1792]{0} multiply(f32[1792]{0} %param_1.676, f32[1792]{0} %broadcast.322), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.587 = f32[16,1792]{1,0} parameter(3)
  %constant_228_clone_1 = f32[] constant(0)
  %reduce.300.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.587, f32[] %constant_228_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_637_clone_1 = f32[] constant(0.000318877544)
  %broadcast.324.clone.1 = f32[1792]{0} broadcast(f32[] %constant_637_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.257.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.300.clone.1, f32[1792]{0} %broadcast.324.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.604 = f32[1792]{0} parameter(2)
  %multiply.459.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.604, f32[1792]{0} %broadcast.324.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.256.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.459.clone.1, f32[1792]{0} %multiply.459.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.26.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.257.clone.1, f32[1792]{0} %multiply.256.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.323.clone.1 = f32[1792]{0} broadcast(f32[] %constant_228_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.23.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %subtract.26.clone.1, f32[1792]{0} %broadcast.323.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_225 = f32[] constant(0.1)
  %broadcast.321 = f32[1792]{0} broadcast(f32[] %constant_225), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.254 = f32[1792]{0} multiply(f32[1792]{0} %maximum.23.clone.1, f32[1792]{0} %broadcast.321), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.105 = f32[1792]{0} add(f32[1792]{0} %multiply.255, f32[1792]{0} %multiply.254), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.104 = f32[1792]{0} add(f32[1792]{0} %param_0.157, f32[1792]{0} %add.105), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  %param_4.449 = f32[1792]{0} parameter(4)
  %param_5.280 = f32[1792]{0} parameter(5)
  %multiply.261.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_5.280, f32[1792]{0} %broadcast.322), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_232_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.326.clone.1 = f32[1792]{0} broadcast(f32[] %constant_232_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.260.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.604, f32[1792]{0} %broadcast.326.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.107.clone.1 = f32[1792]{0} add(f32[1792]{0} %multiply.261.clone.1, f32[1792]{0} %multiply.260.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.106.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_4.449, f32[1792]{0} %add.107.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  ROOT %tuple.49 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.104, f32[1792]{0} %maximum.23.clone.1, f32[1792]{0} %add.106.clone.1)
}

%fused_computation.96 (param_0.169: f32[896], param_1.289: f32[896], param_2.227: f32[896], param_3.225: f32[16,14,14,896], param_4.346: f32[896]) -> f32[16,14,14,896] {
  %param_3.225 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.346 = f32[896]{0} parameter(4)
  %constant_628 = f32[] constant(0.000318877544)
  %broadcast.554 = f32[896]{0} broadcast(f32[] %constant_628), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.453 = f32[896]{0} multiply(f32[896]{0} %param_4.346, f32[896]{0} %broadcast.554), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.330 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.453), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.27 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.225, f32[16,14,14,896]{2,1,3,0} %broadcast.330), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.227 = f32[896]{0} parameter(2)
  %constant_234 = f32[] constant(1e-05)
  %broadcast.332 = f32[896]{0} broadcast(f32[] %constant_234), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.109 = f32[896]{0} add(f32[896]{0} %param_2.227, f32[896]{0} %broadcast.332), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.37 = f32[896]{0} rsqrt(f32[896]{0} %add.109), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.289 = f32[896]{0} parameter(1)
  %multiply.263 = f32[896]{0} multiply(f32[896]{0} %rsqrt.37, f32[896]{0} %param_1.289), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.329 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.263), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.262 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.27, f32[16,14,14,896]{2,1,3,0} %broadcast.329), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.169 = f32[896]{0} parameter(0)
  %broadcast.328 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.169), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.108 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.262, f32[16,14,14,896]{2,1,3,0} %broadcast.328), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_235 = f32[] constant(0)
  %broadcast.331 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_235), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.24 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.108, f32[16,14,14,896]{2,1,3,0} %broadcast.331), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.97 (param_0.170: f32[896], param_1.679: f32[896], param_2.608: f32[896], param_3.592: f32[16,896], param_4.455: f32[896], param_5.287: f32[896]) -> (f32[896], f32[896], f32[896]) {
  %param_0.170 = f32[896]{0} parameter(0)
  %param_1.679 = f32[896]{0} parameter(1)
  %constant_237 = f32[] constant(0.9)
  %broadcast.334 = f32[896]{0} broadcast(f32[] %constant_237), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.265 = f32[896]{0} multiply(f32[896]{0} %param_1.679, f32[896]{0} %broadcast.334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.592 = f32[16,896]{1,0} parameter(3)
  %constant_239_clone_1 = f32[] constant(0)
  %reduce.303.clone.1 = f32[896]{0} reduce(f32[16,896]{1,0} %param_3.592, f32[] %constant_239_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_631_clone_1 = f32[] constant(0.000318877544)
  %broadcast.336.clone.1 = f32[896]{0} broadcast(f32[] %constant_631_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.267.clone.1 = f32[896]{0} multiply(f32[896]{0} %reduce.303.clone.1, f32[896]{0} %broadcast.336.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.608 = f32[896]{0} parameter(2)
  %multiply.455.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.608, f32[896]{0} %broadcast.336.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.266.clone.1 = f32[896]{0} multiply(f32[896]{0} %multiply.455.clone.1, f32[896]{0} %multiply.455.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.28.clone.1 = f32[896]{0} subtract(f32[896]{0} %multiply.267.clone.1, f32[896]{0} %multiply.266.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.335.clone.1 = f32[896]{0} broadcast(f32[] %constant_239_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.25.clone.1 = f32[896]{0} maximum(f32[896]{0} %subtract.28.clone.1, f32[896]{0} %broadcast.335.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_236 = f32[] constant(0.1)
  %broadcast.333 = f32[896]{0} broadcast(f32[] %constant_236), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.264 = f32[896]{0} multiply(f32[896]{0} %maximum.25.clone.1, f32[896]{0} %broadcast.333), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.111 = f32[896]{0} add(f32[896]{0} %multiply.265, f32[896]{0} %multiply.264), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.110 = f32[896]{0} add(f32[896]{0} %param_0.170, f32[896]{0} %add.111), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  %param_4.455 = f32[896]{0} parameter(4)
  %param_5.287 = f32[896]{0} parameter(5)
  %multiply.271.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_5.287, f32[896]{0} %broadcast.334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_243_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.338.clone.1 = f32[896]{0} broadcast(f32[] %constant_243_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.270.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.608, f32[896]{0} %broadcast.338.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.113.clone.1 = f32[896]{0} add(f32[896]{0} %multiply.271.clone.1, f32[896]{0} %multiply.270.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.112.clone.1 = f32[896]{0} add(f32[896]{0} %param_4.455, f32[896]{0} %add.113.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  ROOT %tuple.52 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) tuple(f32[896]{0} %add.110, f32[896]{0} %maximum.25.clone.1, f32[896]{0} %add.112.clone.1)
}

%fused_computation.103 (param_0.182: f32[16,14,14,3584], param_1.310: f32[3584], param_2.245: f32[3584], param_3.242: f32[3584], param_4.183: f32[16,14,14,3584], param_5.155: f32[3584]) -> (f32[16,14,14,3584], f32[16,14,14,3584]) {
  %param_0.182 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_4.183 = f32[16,14,14,3584]{2,1,3,0} parameter(4)
  %param_5.155 = f32[3584]{0} parameter(5)
  %constant_622 = f32[] constant(0.000318877544)
  %broadcast.550 = f32[3584]{0} broadcast(f32[] %constant_622), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.449 = f32[3584]{0} multiply(f32[3584]{0} %param_5.155, f32[3584]{0} %broadcast.550), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.342 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.449), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.29 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_4.183, f32[16,14,14,3584]{2,1,3,0} %broadcast.342), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.242 = f32[3584]{0} parameter(3)
  %constant_245 = f32[] constant(1e-05)
  %broadcast.343 = f32[3584]{0} broadcast(f32[] %constant_245), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.116 = f32[3584]{0} add(f32[3584]{0} %param_3.242, f32[3584]{0} %broadcast.343), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.38 = f32[3584]{0} rsqrt(f32[3584]{0} %add.116), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.245 = f32[3584]{0} parameter(2)
  %multiply.273 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.38, f32[3584]{0} %param_2.245), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.341 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.273), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.272 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.29, f32[16,14,14,3584]{2,1,3,0} %broadcast.341), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.310 = f32[3584]{0} parameter(1)
  %broadcast.340 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.310), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.115 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.272, f32[16,14,14,3584]{2,1,3,0} %broadcast.340), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.114 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_0.182, f32[16,14,14,3584]{2,1,3,0} %add.115), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %constant_246 = f32[] constant(0)
  %broadcast.344 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_246), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %maximum.26 = f32[16,14,14,3584]{2,1,3,0} maximum(f32[16,14,14,3584]{2,1,3,0} %add.114, f32[16,14,14,3584]{2,1,3,0} %broadcast.344), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %copy.38 = f32[16,14,14,3584]{3,2,1,0} copy(f32[16,14,14,3584]{2,1,3,0} %param_0.182), metadata={op_name="tuple.61"}
  ROOT %tuple.64 = (f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) tuple(f32[16,14,14,3584]{2,1,3,0} %maximum.26, f32[16,14,14,3584]{3,2,1,0} %copy.38)
}

%fused_computation.104 (param_0.183: f32[3584], param_1.682: f32[3584], param_2.612: f32[3584], param_3.597: f32[16,3584], param_4.461: f32[3584], param_5.294: f32[3584]) -> (f32[3584], f32[3584], f32[3584]) {
  %param_0.183 = f32[3584]{0} parameter(0)
  %param_1.682 = f32[3584]{0} parameter(1)
  %constant_248 = f32[] constant(0.9)
  %broadcast.346 = f32[3584]{0} broadcast(f32[] %constant_248), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.275 = f32[3584]{0} multiply(f32[3584]{0} %param_1.682, f32[3584]{0} %broadcast.346), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.597 = f32[16,3584]{1,0} parameter(3)
  %constant_250_clone_1 = f32[] constant(0)
  %reduce.306.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.597, f32[] %constant_250_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_625_clone_1 = f32[] constant(0.000318877544)
  %broadcast.348.clone.1 = f32[3584]{0} broadcast(f32[] %constant_625_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.277.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.306.clone.1, f32[3584]{0} %broadcast.348.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.612 = f32[3584]{0} parameter(2)
  %multiply.451.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.612, f32[3584]{0} %broadcast.348.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.276.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.451.clone.1, f32[3584]{0} %multiply.451.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.30.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.277.clone.1, f32[3584]{0} %multiply.276.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.347.clone.1 = f32[3584]{0} broadcast(f32[] %constant_250_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.27.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %subtract.30.clone.1, f32[3584]{0} %broadcast.347.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_247 = f32[] constant(0.1)
  %broadcast.345 = f32[3584]{0} broadcast(f32[] %constant_247), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.274 = f32[3584]{0} multiply(f32[3584]{0} %maximum.27.clone.1, f32[3584]{0} %broadcast.345), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.118 = f32[3584]{0} add(f32[3584]{0} %multiply.275, f32[3584]{0} %multiply.274), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.117 = f32[3584]{0} add(f32[3584]{0} %param_0.183, f32[3584]{0} %add.118), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  %param_4.461 = f32[3584]{0} parameter(4)
  %param_5.294 = f32[3584]{0} parameter(5)
  %multiply.281.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.294, f32[3584]{0} %broadcast.346), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_254_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.350.clone.1 = f32[3584]{0} broadcast(f32[] %constant_254_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.280.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.612, f32[3584]{0} %broadcast.350.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.120.clone.1 = f32[3584]{0} add(f32[3584]{0} %multiply.281.clone.1, f32[3584]{0} %multiply.280.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.119.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_4.461, f32[3584]{0} %add.120.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  ROOT %tuple.56 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.117, f32[3584]{0} %maximum.27.clone.1, f32[3584]{0} %add.119.clone.1)
}

%fused_computation.110 (param_0.195: f32[1792], param_1.332: f32[1792], param_2.264: f32[1792], param_3.261: f32[16,14,14,1792], param_4.345: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.261 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.345 = f32[1792]{0} parameter(4)
  %constant_616 = f32[] constant(0.000318877544)
  %broadcast.546 = f32[1792]{0} broadcast(f32[] %constant_616), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.445 = f32[1792]{0} multiply(f32[1792]{0} %param_4.345, f32[1792]{0} %broadcast.546), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.354 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.445), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.31 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.261, f32[16,14,14,1792]{2,1,3,0} %broadcast.354), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.264 = f32[1792]{0} parameter(2)
  %constant_256 = f32[] constant(1e-05)
  %broadcast.356 = f32[1792]{0} broadcast(f32[] %constant_256), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.122 = f32[1792]{0} add(f32[1792]{0} %param_2.264, f32[1792]{0} %broadcast.356), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.39 = f32[1792]{0} rsqrt(f32[1792]{0} %add.122), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.332 = f32[1792]{0} parameter(1)
  %multiply.283 = f32[1792]{0} multiply(f32[1792]{0} %rsqrt.39, f32[1792]{0} %param_1.332), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.353 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.283), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.282 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.31, f32[16,14,14,1792]{2,1,3,0} %broadcast.353), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.195 = f32[1792]{0} parameter(0)
  %broadcast.352 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.195), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.121 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.282, f32[16,14,14,1792]{2,1,3,0} %broadcast.352), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_257 = f32[] constant(0)
  %broadcast.355 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_257), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.28 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.121, f32[16,14,14,1792]{2,1,3,0} %broadcast.355), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.111 (param_0.196: f32[1792], param_1.685: f32[1792], param_2.616: f32[1792], param_3.602: f32[16,1792], param_4.467: f32[1792], param_5.301: f32[1792]) -> (f32[1792], f32[1792], f32[1792]) {
  %param_0.196 = f32[1792]{0} parameter(0)
  %param_1.685 = f32[1792]{0} parameter(1)
  %constant_259 = f32[] constant(0.9)
  %broadcast.358 = f32[1792]{0} broadcast(f32[] %constant_259), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.285 = f32[1792]{0} multiply(f32[1792]{0} %param_1.685, f32[1792]{0} %broadcast.358), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.602 = f32[16,1792]{1,0} parameter(3)
  %constant_261_clone_1 = f32[] constant(0)
  %reduce.309.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.602, f32[] %constant_261_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_619_clone_1 = f32[] constant(0.000318877544)
  %broadcast.360.clone.1 = f32[1792]{0} broadcast(f32[] %constant_619_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.287.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.309.clone.1, f32[1792]{0} %broadcast.360.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.616 = f32[1792]{0} parameter(2)
  %multiply.447.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.616, f32[1792]{0} %broadcast.360.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.286.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.447.clone.1, f32[1792]{0} %multiply.447.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.32.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.287.clone.1, f32[1792]{0} %multiply.286.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.359.clone.1 = f32[1792]{0} broadcast(f32[] %constant_261_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.29.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %subtract.32.clone.1, f32[1792]{0} %broadcast.359.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_258 = f32[] constant(0.1)
  %broadcast.357 = f32[1792]{0} broadcast(f32[] %constant_258), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.284 = f32[1792]{0} multiply(f32[1792]{0} %maximum.29.clone.1, f32[1792]{0} %broadcast.357), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.124 = f32[1792]{0} add(f32[1792]{0} %multiply.285, f32[1792]{0} %multiply.284), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.123 = f32[1792]{0} add(f32[1792]{0} %param_0.196, f32[1792]{0} %add.124), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  %param_4.467 = f32[1792]{0} parameter(4)
  %param_5.301 = f32[1792]{0} parameter(5)
  %multiply.291.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_5.301, f32[1792]{0} %broadcast.358), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_265_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.362.clone.1 = f32[1792]{0} broadcast(f32[] %constant_265_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.290.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.616, f32[1792]{0} %broadcast.362.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.126.clone.1 = f32[1792]{0} add(f32[1792]{0} %multiply.291.clone.1, f32[1792]{0} %multiply.290.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.125.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_4.467, f32[1792]{0} %add.126.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  ROOT %tuple.59 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.123, f32[1792]{0} %maximum.29.clone.1, f32[1792]{0} %add.125.clone.1)
}

%fused_computation.117 (param_0.208: f32[896], param_1.354: f32[896], param_2.283: f32[896], param_3.280: f32[16,14,14,896], param_4.344: f32[896]) -> f32[16,14,14,896] {
  %param_3.280 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.344 = f32[896]{0} parameter(4)
  %constant_610 = f32[] constant(0.000318877544)
  %broadcast.542 = f32[896]{0} broadcast(f32[] %constant_610), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.441 = f32[896]{0} multiply(f32[896]{0} %param_4.344, f32[896]{0} %broadcast.542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.366 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.441), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.33 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.280, f32[16,14,14,896]{2,1,3,0} %broadcast.366), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.283 = f32[896]{0} parameter(2)
  %constant_267 = f32[] constant(1e-05)
  %broadcast.368 = f32[896]{0} broadcast(f32[] %constant_267), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.128 = f32[896]{0} add(f32[896]{0} %param_2.283, f32[896]{0} %broadcast.368), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.40 = f32[896]{0} rsqrt(f32[896]{0} %add.128), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.354 = f32[896]{0} parameter(1)
  %multiply.293 = f32[896]{0} multiply(f32[896]{0} %rsqrt.40, f32[896]{0} %param_1.354), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.365 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.293), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.292 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.33, f32[16,14,14,896]{2,1,3,0} %broadcast.365), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.208 = f32[896]{0} parameter(0)
  %broadcast.364 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.208), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.127 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.292, f32[16,14,14,896]{2,1,3,0} %broadcast.364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_268 = f32[] constant(0)
  %broadcast.367 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_268), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.30 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.127, f32[16,14,14,896]{2,1,3,0} %broadcast.367), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.118 (param_0.209: f32[896], param_1.688: f32[896], param_2.620: f32[896], param_3.607: f32[16,896], param_4.473: f32[896], param_5.308: f32[896]) -> (f32[896], f32[896], f32[896]) {
  %param_0.209 = f32[896]{0} parameter(0)
  %param_1.688 = f32[896]{0} parameter(1)
  %constant_270 = f32[] constant(0.9)
  %broadcast.370 = f32[896]{0} broadcast(f32[] %constant_270), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.295 = f32[896]{0} multiply(f32[896]{0} %param_1.688, f32[896]{0} %broadcast.370), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.607 = f32[16,896]{1,0} parameter(3)
  %constant_272_clone_1 = f32[] constant(0)
  %reduce.312.clone.1 = f32[896]{0} reduce(f32[16,896]{1,0} %param_3.607, f32[] %constant_272_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_613_clone_1 = f32[] constant(0.000318877544)
  %broadcast.372.clone.1 = f32[896]{0} broadcast(f32[] %constant_613_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.297.clone.1 = f32[896]{0} multiply(f32[896]{0} %reduce.312.clone.1, f32[896]{0} %broadcast.372.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.620 = f32[896]{0} parameter(2)
  %multiply.443.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.620, f32[896]{0} %broadcast.372.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.296.clone.1 = f32[896]{0} multiply(f32[896]{0} %multiply.443.clone.1, f32[896]{0} %multiply.443.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.34.clone.1 = f32[896]{0} subtract(f32[896]{0} %multiply.297.clone.1, f32[896]{0} %multiply.296.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.371.clone.1 = f32[896]{0} broadcast(f32[] %constant_272_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.31.clone.1 = f32[896]{0} maximum(f32[896]{0} %subtract.34.clone.1, f32[896]{0} %broadcast.371.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_269 = f32[] constant(0.1)
  %broadcast.369 = f32[896]{0} broadcast(f32[] %constant_269), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.294 = f32[896]{0} multiply(f32[896]{0} %maximum.31.clone.1, f32[896]{0} %broadcast.369), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.130 = f32[896]{0} add(f32[896]{0} %multiply.295, f32[896]{0} %multiply.294), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.129 = f32[896]{0} add(f32[896]{0} %param_0.209, f32[896]{0} %add.130), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  %param_4.473 = f32[896]{0} parameter(4)
  %param_5.308 = f32[896]{0} parameter(5)
  %multiply.301.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_5.308, f32[896]{0} %broadcast.370), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_276_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.374.clone.1 = f32[896]{0} broadcast(f32[] %constant_276_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.300.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.620, f32[896]{0} %broadcast.374.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.132.clone.1 = f32[896]{0} add(f32[896]{0} %multiply.301.clone.1, f32[896]{0} %multiply.300.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.131.clone.1 = f32[896]{0} add(f32[896]{0} %param_4.473, f32[896]{0} %add.132.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  ROOT %tuple.62 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) tuple(f32[896]{0} %add.129, f32[896]{0} %maximum.31.clone.1, f32[896]{0} %add.131.clone.1)
}

%fused_computation.124 (param_0.221: f32[16,14,14,3584], param_1.375: f32[3584], param_2.301: f32[3584], param_3.297: f32[3584], param_4.222: f32[16,14,14,3584], param_5.150: f32[3584]) -> (f32[16,14,14,3584], f32[16,14,14,3584]) {
  %param_0.221 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_4.222 = f32[16,14,14,3584]{2,1,3,0} parameter(4)
  %param_5.150 = f32[3584]{0} parameter(5)
  %constant_604 = f32[] constant(0.000318877544)
  %broadcast.538 = f32[3584]{0} broadcast(f32[] %constant_604), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.437 = f32[3584]{0} multiply(f32[3584]{0} %param_5.150, f32[3584]{0} %broadcast.538), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.378 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.437), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.35 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_4.222, f32[16,14,14,3584]{2,1,3,0} %broadcast.378), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.297 = f32[3584]{0} parameter(3)
  %constant_278 = f32[] constant(1e-05)
  %broadcast.379 = f32[3584]{0} broadcast(f32[] %constant_278), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.135 = f32[3584]{0} add(f32[3584]{0} %param_3.297, f32[3584]{0} %broadcast.379), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.41 = f32[3584]{0} rsqrt(f32[3584]{0} %add.135), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.301 = f32[3584]{0} parameter(2)
  %multiply.303 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.41, f32[3584]{0} %param_2.301), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.377 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.303), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.302 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.35, f32[16,14,14,3584]{2,1,3,0} %broadcast.377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.375 = f32[3584]{0} parameter(1)
  %broadcast.376 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.375), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.134 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.302, f32[16,14,14,3584]{2,1,3,0} %broadcast.376), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.133 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_0.221, f32[16,14,14,3584]{2,1,3,0} %add.134), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %constant_279 = f32[] constant(0)
  %broadcast.380 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_279), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %maximum.32 = f32[16,14,14,3584]{2,1,3,0} maximum(f32[16,14,14,3584]{2,1,3,0} %add.133, f32[16,14,14,3584]{2,1,3,0} %broadcast.380), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %copy.39 = f32[16,14,14,3584]{3,2,1,0} copy(f32[16,14,14,3584]{2,1,3,0} %param_0.221), metadata={op_name="tuple.61"}
  ROOT %tuple.74 = (f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) tuple(f32[16,14,14,3584]{2,1,3,0} %maximum.32, f32[16,14,14,3584]{3,2,1,0} %copy.39)
}

%fused_computation.125 (param_0.222: f32[3584], param_1.691: f32[3584], param_2.624: f32[3584], param_3.612: f32[16,3584], param_4.479: f32[3584], param_5.315: f32[3584]) -> (f32[3584], f32[3584], f32[3584]) {
  %param_0.222 = f32[3584]{0} parameter(0)
  %param_1.691 = f32[3584]{0} parameter(1)
  %constant_281 = f32[] constant(0.9)
  %broadcast.382 = f32[3584]{0} broadcast(f32[] %constant_281), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.305 = f32[3584]{0} multiply(f32[3584]{0} %param_1.691, f32[3584]{0} %broadcast.382), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.612 = f32[16,3584]{1,0} parameter(3)
  %constant_283_clone_1 = f32[] constant(0)
  %reduce.315.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.612, f32[] %constant_283_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_607_clone_1 = f32[] constant(0.000318877544)
  %broadcast.384.clone.1 = f32[3584]{0} broadcast(f32[] %constant_607_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.307.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.315.clone.1, f32[3584]{0} %broadcast.384.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.624 = f32[3584]{0} parameter(2)
  %multiply.439.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.624, f32[3584]{0} %broadcast.384.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.306.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.439.clone.1, f32[3584]{0} %multiply.439.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.36.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.307.clone.1, f32[3584]{0} %multiply.306.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.383.clone.1 = f32[3584]{0} broadcast(f32[] %constant_283_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.33.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %subtract.36.clone.1, f32[3584]{0} %broadcast.383.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_280 = f32[] constant(0.1)
  %broadcast.381 = f32[3584]{0} broadcast(f32[] %constant_280), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.304 = f32[3584]{0} multiply(f32[3584]{0} %maximum.33.clone.1, f32[3584]{0} %broadcast.381), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.137 = f32[3584]{0} add(f32[3584]{0} %multiply.305, f32[3584]{0} %multiply.304), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.136 = f32[3584]{0} add(f32[3584]{0} %param_0.222, f32[3584]{0} %add.137), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  %param_4.479 = f32[3584]{0} parameter(4)
  %param_5.315 = f32[3584]{0} parameter(5)
  %multiply.311.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.315, f32[3584]{0} %broadcast.382), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_287_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.386.clone.1 = f32[3584]{0} broadcast(f32[] %constant_287_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.310.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.624, f32[3584]{0} %broadcast.386.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.139.clone.1 = f32[3584]{0} add(f32[3584]{0} %multiply.311.clone.1, f32[3584]{0} %multiply.310.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.138.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_4.479, f32[3584]{0} %add.139.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  ROOT %tuple.66 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.136, f32[3584]{0} %maximum.33.clone.1, f32[3584]{0} %add.138.clone.1)
}

%fused_computation.131 (param_0.234: f32[1792], param_1.397: f32[1792], param_2.320: f32[1792], param_3.316: f32[16,14,14,1792], param_4.343: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.316 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.343 = f32[1792]{0} parameter(4)
  %constant_598 = f32[] constant(0.000318877544)
  %broadcast.534 = f32[1792]{0} broadcast(f32[] %constant_598), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.433 = f32[1792]{0} multiply(f32[1792]{0} %param_4.343, f32[1792]{0} %broadcast.534), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.390 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.433), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.37 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.316, f32[16,14,14,1792]{2,1,3,0} %broadcast.390), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.320 = f32[1792]{0} parameter(2)
  %constant_289 = f32[] constant(1e-05)
  %broadcast.392 = f32[1792]{0} broadcast(f32[] %constant_289), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.141 = f32[1792]{0} add(f32[1792]{0} %param_2.320, f32[1792]{0} %broadcast.392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.42 = f32[1792]{0} rsqrt(f32[1792]{0} %add.141), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.397 = f32[1792]{0} parameter(1)
  %multiply.313 = f32[1792]{0} multiply(f32[1792]{0} %rsqrt.42, f32[1792]{0} %param_1.397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.389 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.313), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.312 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.37, f32[16,14,14,1792]{2,1,3,0} %broadcast.389), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.234 = f32[1792]{0} parameter(0)
  %broadcast.388 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.234), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.140 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.312, f32[16,14,14,1792]{2,1,3,0} %broadcast.388), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_290 = f32[] constant(0)
  %broadcast.391 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_290), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.34 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.140, f32[16,14,14,1792]{2,1,3,0} %broadcast.391), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.132 (param_0.235: f32[1792], param_1.694: f32[1792], param_2.628: f32[1792], param_3.617: f32[16,1792], param_4.485: f32[1792], param_5.322: f32[1792]) -> (f32[1792], f32[1792], f32[1792]) {
  %param_0.235 = f32[1792]{0} parameter(0)
  %param_1.694 = f32[1792]{0} parameter(1)
  %constant_292 = f32[] constant(0.9)
  %broadcast.394 = f32[1792]{0} broadcast(f32[] %constant_292), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.315 = f32[1792]{0} multiply(f32[1792]{0} %param_1.694, f32[1792]{0} %broadcast.394), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.617 = f32[16,1792]{1,0} parameter(3)
  %constant_294_clone_1 = f32[] constant(0)
  %reduce.318.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.617, f32[] %constant_294_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_601_clone_1 = f32[] constant(0.000318877544)
  %broadcast.396.clone.1 = f32[1792]{0} broadcast(f32[] %constant_601_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.317.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.318.clone.1, f32[1792]{0} %broadcast.396.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.628 = f32[1792]{0} parameter(2)
  %multiply.435.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.628, f32[1792]{0} %broadcast.396.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.316.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.435.clone.1, f32[1792]{0} %multiply.435.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.38.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.317.clone.1, f32[1792]{0} %multiply.316.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.395.clone.1 = f32[1792]{0} broadcast(f32[] %constant_294_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.35.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %subtract.38.clone.1, f32[1792]{0} %broadcast.395.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_291 = f32[] constant(0.1)
  %broadcast.393 = f32[1792]{0} broadcast(f32[] %constant_291), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.314 = f32[1792]{0} multiply(f32[1792]{0} %maximum.35.clone.1, f32[1792]{0} %broadcast.393), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.143 = f32[1792]{0} add(f32[1792]{0} %multiply.315, f32[1792]{0} %multiply.314), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.142 = f32[1792]{0} add(f32[1792]{0} %param_0.235, f32[1792]{0} %add.143), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  %param_4.485 = f32[1792]{0} parameter(4)
  %param_5.322 = f32[1792]{0} parameter(5)
  %multiply.321.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_5.322, f32[1792]{0} %broadcast.394), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_298_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.398.clone.1 = f32[1792]{0} broadcast(f32[] %constant_298_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.320.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.628, f32[1792]{0} %broadcast.398.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.145.clone.1 = f32[1792]{0} add(f32[1792]{0} %multiply.321.clone.1, f32[1792]{0} %multiply.320.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.144.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_4.485, f32[1792]{0} %add.145.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  ROOT %tuple.69 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.142, f32[1792]{0} %maximum.35.clone.1, f32[1792]{0} %add.144.clone.1)
}

%fused_computation.138 (param_0.247: f32[896], param_1.419: f32[896], param_2.339: f32[896], param_3.335: f32[16,14,14,896], param_4.342: f32[896]) -> f32[16,14,14,896] {
  %param_3.335 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.342 = f32[896]{0} parameter(4)
  %constant_592 = f32[] constant(0.000318877544)
  %broadcast.530 = f32[896]{0} broadcast(f32[] %constant_592), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.429 = f32[896]{0} multiply(f32[896]{0} %param_4.342, f32[896]{0} %broadcast.530), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.402 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.429), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.39 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.335, f32[16,14,14,896]{2,1,3,0} %broadcast.402), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.339 = f32[896]{0} parameter(2)
  %constant_300 = f32[] constant(1e-05)
  %broadcast.404 = f32[896]{0} broadcast(f32[] %constant_300), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.147 = f32[896]{0} add(f32[896]{0} %param_2.339, f32[896]{0} %broadcast.404), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.43 = f32[896]{0} rsqrt(f32[896]{0} %add.147), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.419 = f32[896]{0} parameter(1)
  %multiply.323 = f32[896]{0} multiply(f32[896]{0} %rsqrt.43, f32[896]{0} %param_1.419), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.401 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.323), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.322 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.39, f32[16,14,14,896]{2,1,3,0} %broadcast.401), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.247 = f32[896]{0} parameter(0)
  %broadcast.400 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.247), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.146 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.322, f32[16,14,14,896]{2,1,3,0} %broadcast.400), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_301 = f32[] constant(0)
  %broadcast.403 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_301), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.36 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.146, f32[16,14,14,896]{2,1,3,0} %broadcast.403), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.139 (param_0.248: f32[896], param_1.697: f32[896], param_2.632: f32[896], param_3.622: f32[16,896], param_4.491: f32[896], param_5.329: f32[896]) -> (f32[896], f32[896], f32[896]) {
  %param_0.248 = f32[896]{0} parameter(0)
  %param_1.697 = f32[896]{0} parameter(1)
  %constant_303 = f32[] constant(0.9)
  %broadcast.406 = f32[896]{0} broadcast(f32[] %constant_303), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.325 = f32[896]{0} multiply(f32[896]{0} %param_1.697, f32[896]{0} %broadcast.406), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.622 = f32[16,896]{1,0} parameter(3)
  %constant_305_clone_1 = f32[] constant(0)
  %reduce.321.clone.1 = f32[896]{0} reduce(f32[16,896]{1,0} %param_3.622, f32[] %constant_305_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_595_clone_1 = f32[] constant(0.000318877544)
  %broadcast.408.clone.1 = f32[896]{0} broadcast(f32[] %constant_595_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.327.clone.1 = f32[896]{0} multiply(f32[896]{0} %reduce.321.clone.1, f32[896]{0} %broadcast.408.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.632 = f32[896]{0} parameter(2)
  %multiply.431.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.632, f32[896]{0} %broadcast.408.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.326.clone.1 = f32[896]{0} multiply(f32[896]{0} %multiply.431.clone.1, f32[896]{0} %multiply.431.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.40.clone.1 = f32[896]{0} subtract(f32[896]{0} %multiply.327.clone.1, f32[896]{0} %multiply.326.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.407.clone.1 = f32[896]{0} broadcast(f32[] %constant_305_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.37.clone.1 = f32[896]{0} maximum(f32[896]{0} %subtract.40.clone.1, f32[896]{0} %broadcast.407.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_302 = f32[] constant(0.1)
  %broadcast.405 = f32[896]{0} broadcast(f32[] %constant_302), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.324 = f32[896]{0} multiply(f32[896]{0} %maximum.37.clone.1, f32[896]{0} %broadcast.405), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.149 = f32[896]{0} add(f32[896]{0} %multiply.325, f32[896]{0} %multiply.324), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.148 = f32[896]{0} add(f32[896]{0} %param_0.248, f32[896]{0} %add.149), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  %param_4.491 = f32[896]{0} parameter(4)
  %param_5.329 = f32[896]{0} parameter(5)
  %multiply.331.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_5.329, f32[896]{0} %broadcast.406), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_309_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.410.clone.1 = f32[896]{0} broadcast(f32[] %constant_309_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.330.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.632, f32[896]{0} %broadcast.410.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.151.clone.1 = f32[896]{0} add(f32[896]{0} %multiply.331.clone.1, f32[896]{0} %multiply.330.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.150.clone.1 = f32[896]{0} add(f32[896]{0} %param_4.491, f32[896]{0} %add.151.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  ROOT %tuple.72 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) tuple(f32[896]{0} %add.148, f32[896]{0} %maximum.37.clone.1, f32[896]{0} %add.150.clone.1)
}

%fused_computation.145 (param_0.260: f32[16,14,14,3584], param_1.440: f32[3584], param_2.357: f32[3584], param_3.352: f32[3584], param_4.261: f32[16,14,14,3584], param_5.145: f32[3584]) -> f32[16,14,14,3584] {
  %param_0.260 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_4.261 = f32[16,14,14,3584]{2,1,3,0} parameter(4)
  %param_5.145 = f32[3584]{0} parameter(5)
  %constant_586 = f32[] constant(0.000318877544)
  %broadcast.526 = f32[3584]{0} broadcast(f32[] %constant_586), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.425 = f32[3584]{0} multiply(f32[3584]{0} %param_5.145, f32[3584]{0} %broadcast.526), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.414 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.425), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.41 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_4.261, f32[16,14,14,3584]{2,1,3,0} %broadcast.414), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.352 = f32[3584]{0} parameter(3)
  %constant_311 = f32[] constant(1e-05)
  %broadcast.415 = f32[3584]{0} broadcast(f32[] %constant_311), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.154 = f32[3584]{0} add(f32[3584]{0} %param_3.352, f32[3584]{0} %broadcast.415), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.44 = f32[3584]{0} rsqrt(f32[3584]{0} %add.154), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.357 = f32[3584]{0} parameter(2)
  %multiply.333 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.44, f32[3584]{0} %param_2.357), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.413 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.333), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.332 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.41, f32[16,14,14,3584]{2,1,3,0} %broadcast.413), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.440 = f32[3584]{0} parameter(1)
  %broadcast.412 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.440), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.153 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.332, f32[16,14,14,3584]{2,1,3,0} %broadcast.412), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.152 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_0.260, f32[16,14,14,3584]{2,1,3,0} %add.153), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %constant_312 = f32[] constant(0)
  %broadcast.416 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_312), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.38 = f32[16,14,14,3584]{2,1,3,0} maximum(f32[16,14,14,3584]{2,1,3,0} %add.152, f32[16,14,14,3584]{2,1,3,0} %broadcast.416), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.146 (param_0.261: f32[3584], param_1.700: f32[3584], param_2.636: f32[3584], param_3.627: f32[16,3584], param_4.497: f32[3584], param_5.336: f32[3584]) -> (f32[3584], f32[3584], f32[3584]) {
  %param_0.261 = f32[3584]{0} parameter(0)
  %param_1.700 = f32[3584]{0} parameter(1)
  %constant_314 = f32[] constant(0.9)
  %broadcast.418 = f32[3584]{0} broadcast(f32[] %constant_314), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.335 = f32[3584]{0} multiply(f32[3584]{0} %param_1.700, f32[3584]{0} %broadcast.418), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.627 = f32[16,3584]{1,0} parameter(3)
  %constant_316_clone_1 = f32[] constant(0)
  %reduce.324.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.627, f32[] %constant_316_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_589_clone_1 = f32[] constant(0.000318877544)
  %broadcast.420.clone.1 = f32[3584]{0} broadcast(f32[] %constant_589_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.337.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.324.clone.1, f32[3584]{0} %broadcast.420.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.636 = f32[3584]{0} parameter(2)
  %multiply.427.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.636, f32[3584]{0} %broadcast.420.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.336.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.427.clone.1, f32[3584]{0} %multiply.427.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.42.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.337.clone.1, f32[3584]{0} %multiply.336.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.419.clone.1 = f32[3584]{0} broadcast(f32[] %constant_316_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.39.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %subtract.42.clone.1, f32[3584]{0} %broadcast.419.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_313 = f32[] constant(0.1)
  %broadcast.417 = f32[3584]{0} broadcast(f32[] %constant_313), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.334 = f32[3584]{0} multiply(f32[3584]{0} %maximum.39.clone.1, f32[3584]{0} %broadcast.417), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.156 = f32[3584]{0} add(f32[3584]{0} %multiply.335, f32[3584]{0} %multiply.334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.155 = f32[3584]{0} add(f32[3584]{0} %param_0.261, f32[3584]{0} %add.156), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  %param_4.497 = f32[3584]{0} parameter(4)
  %param_5.336 = f32[3584]{0} parameter(5)
  %multiply.341.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.336, f32[3584]{0} %broadcast.418), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_320_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.422.clone.1 = f32[3584]{0} broadcast(f32[] %constant_320_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.340.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.636, f32[3584]{0} %broadcast.422.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.158.clone.1 = f32[3584]{0} add(f32[3584]{0} %multiply.341.clone.1, f32[3584]{0} %multiply.340.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.157.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_4.497, f32[3584]{0} %add.158.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  ROOT %tuple.76 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.155, f32[3584]{0} %maximum.39.clone.1, f32[3584]{0} %add.157.clone.1)
}

%fused_computation.152 (param_0.273: f32[1792], param_1.462: f32[1792], param_2.376: f32[1792], param_3.371: f32[16,14,14,1792], param_4.341: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.371 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.341 = f32[1792]{0} parameter(4)
  %constant_580 = f32[] constant(0.000318877544)
  %broadcast.522 = f32[1792]{0} broadcast(f32[] %constant_580), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.421 = f32[1792]{0} multiply(f32[1792]{0} %param_4.341, f32[1792]{0} %broadcast.522), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.426 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.421), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.43 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.371, f32[16,14,14,1792]{2,1,3,0} %broadcast.426), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.376 = f32[1792]{0} parameter(2)
  %constant_322 = f32[] constant(1e-05)
  %broadcast.428 = f32[1792]{0} broadcast(f32[] %constant_322), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.160 = f32[1792]{0} add(f32[1792]{0} %param_2.376, f32[1792]{0} %broadcast.428), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.45 = f32[1792]{0} rsqrt(f32[1792]{0} %add.160), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.462 = f32[1792]{0} parameter(1)
  %multiply.343 = f32[1792]{0} multiply(f32[1792]{0} %rsqrt.45, f32[1792]{0} %param_1.462), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.425 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.343), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.342 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.43, f32[16,14,14,1792]{2,1,3,0} %broadcast.425), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.273 = f32[1792]{0} parameter(0)
  %broadcast.424 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.273), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.159 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.342, f32[16,14,14,1792]{2,1,3,0} %broadcast.424), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_323 = f32[] constant(0)
  %broadcast.427 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_323), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.40 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.159, f32[16,14,14,1792]{2,1,3,0} %broadcast.427), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.153 (param_0.274: f32[1792], param_1.703: f32[1792], param_2.640: f32[1792], param_3.632: f32[16,1792], param_4.503: f32[1792], param_5.343: f32[1792]) -> (f32[1792], f32[1792], f32[1792]) {
  %param_0.274 = f32[1792]{0} parameter(0)
  %param_1.703 = f32[1792]{0} parameter(1)
  %constant_325 = f32[] constant(0.9)
  %broadcast.430 = f32[1792]{0} broadcast(f32[] %constant_325), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.345 = f32[1792]{0} multiply(f32[1792]{0} %param_1.703, f32[1792]{0} %broadcast.430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.632 = f32[16,1792]{1,0} parameter(3)
  %constant_327_clone_1 = f32[] constant(0)
  %reduce.327.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.632, f32[] %constant_327_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_583_clone_1 = f32[] constant(0.000318877544)
  %broadcast.432.clone.1 = f32[1792]{0} broadcast(f32[] %constant_583_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.347.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.327.clone.1, f32[1792]{0} %broadcast.432.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.640 = f32[1792]{0} parameter(2)
  %multiply.423.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.640, f32[1792]{0} %broadcast.432.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.346.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.423.clone.1, f32[1792]{0} %multiply.423.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.44.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.347.clone.1, f32[1792]{0} %multiply.346.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.431.clone.1 = f32[1792]{0} broadcast(f32[] %constant_327_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.41.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %subtract.44.clone.1, f32[1792]{0} %broadcast.431.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_324 = f32[] constant(0.1)
  %broadcast.429 = f32[1792]{0} broadcast(f32[] %constant_324), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.344 = f32[1792]{0} multiply(f32[1792]{0} %maximum.41.clone.1, f32[1792]{0} %broadcast.429), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.162 = f32[1792]{0} add(f32[1792]{0} %multiply.345, f32[1792]{0} %multiply.344), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.161 = f32[1792]{0} add(f32[1792]{0} %param_0.274, f32[1792]{0} %add.162), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  %param_4.503 = f32[1792]{0} parameter(4)
  %param_5.343 = f32[1792]{0} parameter(5)
  %multiply.351.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_5.343, f32[1792]{0} %broadcast.430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_331_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.434.clone.1 = f32[1792]{0} broadcast(f32[] %constant_331_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.350.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.640, f32[1792]{0} %broadcast.434.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.164.clone.1 = f32[1792]{0} add(f32[1792]{0} %multiply.351.clone.1, f32[1792]{0} %multiply.350.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.163.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_4.503, f32[1792]{0} %add.164.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  ROOT %tuple.79 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.161, f32[1792]{0} %maximum.41.clone.1, f32[1792]{0} %add.163.clone.1)
}

%fused_computation.159 (param_0.286: f32[896], param_1.484: f32[896], param_2.395: f32[896], param_3.390: f32[16,14,14,896], param_4.340: f32[896]) -> f32[16,14,14,896] {
  %param_3.390 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.340 = f32[896]{0} parameter(4)
  %constant_408 = f32[] constant(0.000318877544)
  %broadcast.518 = f32[896]{0} broadcast(f32[] %constant_408), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.417 = f32[896]{0} multiply(f32[896]{0} %param_4.340, f32[896]{0} %broadcast.518), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.438 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.417), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.45 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.390, f32[16,14,14,896]{2,1,3,0} %broadcast.438), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.395 = f32[896]{0} parameter(2)
  %constant_333 = f32[] constant(1e-05)
  %broadcast.440 = f32[896]{0} broadcast(f32[] %constant_333), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.166 = f32[896]{0} add(f32[896]{0} %param_2.395, f32[896]{0} %broadcast.440), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.46 = f32[896]{0} rsqrt(f32[896]{0} %add.166), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.484 = f32[896]{0} parameter(1)
  %multiply.353 = f32[896]{0} multiply(f32[896]{0} %rsqrt.46, f32[896]{0} %param_1.484), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.437 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.353), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.352 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.45, f32[16,14,14,896]{2,1,3,0} %broadcast.437), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.286 = f32[896]{0} parameter(0)
  %broadcast.436 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.286), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.165 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.352, f32[16,14,14,896]{2,1,3,0} %broadcast.436), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_334 = f32[] constant(0)
  %broadcast.439 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_334), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.42 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.165, f32[16,14,14,896]{2,1,3,0} %broadcast.439), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.160 (param_0.287: f32[896], param_1.706: f32[896], param_2.644: f32[896], param_3.637: f32[16,896], param_4.509: f32[896], param_5.350: f32[896]) -> (f32[896], f32[896], f32[896]) {
  %param_0.287 = f32[896]{0} parameter(0)
  %param_1.706 = f32[896]{0} parameter(1)
  %constant_336 = f32[] constant(0.9)
  %broadcast.442 = f32[896]{0} broadcast(f32[] %constant_336), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.355 = f32[896]{0} multiply(f32[896]{0} %param_1.706, f32[896]{0} %broadcast.442), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.637 = f32[16,896]{1,0} parameter(3)
  %constant_338_clone_1 = f32[] constant(0)
  %reduce.330.clone.1 = f32[896]{0} reduce(f32[16,896]{1,0} %param_3.637, f32[] %constant_338_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_577_clone_1 = f32[] constant(0.000318877544)
  %broadcast.444.clone.1 = f32[896]{0} broadcast(f32[] %constant_577_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.357.clone.1 = f32[896]{0} multiply(f32[896]{0} %reduce.330.clone.1, f32[896]{0} %broadcast.444.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.644 = f32[896]{0} parameter(2)
  %multiply.419.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.644, f32[896]{0} %broadcast.444.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.356.clone.1 = f32[896]{0} multiply(f32[896]{0} %multiply.419.clone.1, f32[896]{0} %multiply.419.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.46.clone.1 = f32[896]{0} subtract(f32[896]{0} %multiply.357.clone.1, f32[896]{0} %multiply.356.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.443.clone.1 = f32[896]{0} broadcast(f32[] %constant_338_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.43.clone.1 = f32[896]{0} maximum(f32[896]{0} %subtract.46.clone.1, f32[896]{0} %broadcast.443.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_335 = f32[] constant(0.1)
  %broadcast.441 = f32[896]{0} broadcast(f32[] %constant_335), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.354 = f32[896]{0} multiply(f32[896]{0} %maximum.43.clone.1, f32[896]{0} %broadcast.441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.168 = f32[896]{0} add(f32[896]{0} %multiply.355, f32[896]{0} %multiply.354), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.167 = f32[896]{0} add(f32[896]{0} %param_0.287, f32[896]{0} %add.168), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  %param_4.509 = f32[896]{0} parameter(4)
  %param_5.350 = f32[896]{0} parameter(5)
  %multiply.361.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_5.350, f32[896]{0} %broadcast.442), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_342_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.446.clone.1 = f32[896]{0} broadcast(f32[] %constant_342_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.360.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.644, f32[896]{0} %broadcast.446.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.170.clone.1 = f32[896]{0} add(f32[896]{0} %multiply.361.clone.1, f32[896]{0} %multiply.360.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.169.clone.1 = f32[896]{0} add(f32[896]{0} %param_4.509, f32[896]{0} %add.170.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  ROOT %tuple.82 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) tuple(f32[896]{0} %add.167, f32[896]{0} %maximum.43.clone.1, f32[896]{0} %add.169.clone.1)
}

%fused_computation.166 (param_0.408: f32[16,14,14,3584], param_1.595: f32[3584], param_2.491: f32[3584], param_3.498: f32[3584], param_4.339: f32[16,14,14,3584], param_5.140: f32[3584]) -> f32[16,14,14,3584] {
  %param_0.408 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_4.339 = f32[16,14,14,3584]{2,1,3,0} parameter(4)
  %param_5.140 = f32[3584]{0} parameter(5)
  %constant_405 = f32[] constant(0.000318877544)
  %broadcast.516 = f32[3584]{0} broadcast(f32[] %constant_405), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.415 = f32[3584]{0} multiply(f32[3584]{0} %param_5.140, f32[3584]{0} %broadcast.516), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.515 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.415), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.56 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_4.339, f32[16,14,14,3584]{2,1,3,0} %broadcast.515), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.498 = f32[3584]{0} parameter(3)
  %constant_404 = f32[] constant(1e-05)
  %broadcast.514 = f32[3584]{0} broadcast(f32[] %constant_404), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.201 = f32[3584]{0} add(f32[3584]{0} %param_3.498, f32[3584]{0} %broadcast.514), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.78 = f32[3584]{0} rsqrt(f32[3584]{0} %add.201), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.491 = f32[3584]{0} parameter(2)
  %multiply.414 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.78, f32[3584]{0} %param_2.491), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.513 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.414), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.413 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.56, f32[16,14,14,3584]{2,1,3,0} %broadcast.513), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.595 = f32[3584]{0} parameter(1)
  %broadcast.512 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.595), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.200 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.413, f32[16,14,14,3584]{2,1,3,0} %broadcast.512), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.199 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_0.408, f32[16,14,14,3584]{2,1,3,0} %add.200), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %constant_344 = f32[] constant(0)
  %broadcast.448 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_344), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.44 = f32[16,14,14,3584]{2,1,3,0} maximum(f32[16,14,14,3584]{2,1,3,0} %add.199, f32[16,14,14,3584]{2,1,3,0} %broadcast.448), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.168 (param_0.299: f32[3584], param_1.709: f32[3584], param_2.648: f32[3584], param_3.642: f32[16,3584], param_4.515: f32[3584], param_5.357: f32[3584]) -> (f32[3584], f32[3584], f32[3584]) {
  %param_0.299 = f32[3584]{0} parameter(0)
  %param_1.709 = f32[3584]{0} parameter(1)
  %constant_347 = f32[] constant(0.9)
  %broadcast.454 = f32[3584]{0} broadcast(f32[] %constant_347), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.365 = f32[3584]{0} multiply(f32[3584]{0} %param_1.709, f32[3584]{0} %broadcast.454), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.642 = f32[16,3584]{1,0} parameter(3)
  %constant_349_clone_1 = f32[] constant(0)
  %reduce.333.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.642, f32[] %constant_349_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_395_clone_1 = f32[] constant(0.000318877544)
  %broadcast.456.clone.1 = f32[3584]{0} broadcast(f32[] %constant_395_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.367.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.333.clone.1, f32[3584]{0} %broadcast.456.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.648 = f32[3584]{0} parameter(2)
  %multiply.403.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.648, f32[3584]{0} %broadcast.456.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.366.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.403.clone.1, f32[3584]{0} %multiply.403.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.48.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.367.clone.1, f32[3584]{0} %multiply.366.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.455.clone.1 = f32[3584]{0} broadcast(f32[] %constant_349_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.45.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %subtract.48.clone.1, f32[3584]{0} %broadcast.455.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_346 = f32[] constant(0.1)
  %broadcast.453 = f32[3584]{0} broadcast(f32[] %constant_346), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.364 = f32[3584]{0} multiply(f32[3584]{0} %maximum.45.clone.1, f32[3584]{0} %broadcast.453), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.175 = f32[3584]{0} add(f32[3584]{0} %multiply.365, f32[3584]{0} %multiply.364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.174 = f32[3584]{0} add(f32[3584]{0} %param_0.299, f32[3584]{0} %add.175), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  %param_4.515 = f32[3584]{0} parameter(4)
  %param_5.357 = f32[3584]{0} parameter(5)
  %multiply.371.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.357, f32[3584]{0} %broadcast.454), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_353_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.458.clone.1 = f32[3584]{0} broadcast(f32[] %constant_353_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.370.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.648, f32[3584]{0} %broadcast.458.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.177.clone.1 = f32[3584]{0} add(f32[3584]{0} %multiply.371.clone.1, f32[3584]{0} %multiply.370.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.176.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_4.515, f32[3584]{0} %add.177.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  ROOT %tuple.85 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.174, f32[3584]{0} %maximum.45.clone.1, f32[3584]{0} %add.176.clone.1)
}

%fused_computation.174 (param_0.387: f32[1792], param_1.581: f32[1792], param_2.468: f32[1792], param_3.483: f32[16,14,14,1792], param_4.329: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.483 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.329 = f32[1792]{0} parameter(4)
  %constant_386 = f32[] constant(0.000318877544)
  %broadcast.490 = f32[1792]{0} broadcast(f32[] %constant_386), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.397 = f32[1792]{0} multiply(f32[1792]{0} %param_4.329, f32[1792]{0} %broadcast.490), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.464 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.397), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.49 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.483, f32[16,14,14,1792]{2,1,3,0} %broadcast.464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.468 = f32[1792]{0} parameter(2)
  %constant_355 = f32[] constant(1e-05)
  %broadcast.463 = f32[1792]{0} broadcast(f32[] %constant_355), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.179 = f32[1792]{0} add(f32[1792]{0} %param_2.468, f32[1792]{0} %broadcast.463), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.48 = f32[1792]{0} rsqrt(f32[1792]{0} %add.179), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.581 = f32[1792]{0} parameter(1)
  %multiply.373 = f32[1792]{0} multiply(f32[1792]{0} %rsqrt.48, f32[1792]{0} %param_1.581), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.462 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.373), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.372 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.49, f32[16,14,14,1792]{2,1,3,0} %broadcast.462), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.387 = f32[1792]{0} parameter(0)
  %broadcast.461 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.387), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.178 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.372, f32[16,14,14,1792]{2,1,3,0} %broadcast.461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_356 = f32[] constant(0)
  %broadcast.460 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_356), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.46 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.178, f32[16,14,14,1792]{2,1,3,0} %broadcast.460), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.175 (param_0.310: f32[1792], param_1.712: f32[1792], param_2.652: f32[1792], param_3.647: f32[16,1792], param_4.521: f32[1792], param_5.364: f32[1792]) -> (f32[1792], f32[1792], f32[1792]) {
  %param_0.310 = f32[1792]{0} parameter(0)
  %param_1.712 = f32[1792]{0} parameter(1)
  %constant_358 = f32[] constant(0.9)
  %broadcast.466 = f32[1792]{0} broadcast(f32[] %constant_358), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.375 = f32[1792]{0} multiply(f32[1792]{0} %param_1.712, f32[1792]{0} %broadcast.466), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.647 = f32[16,1792]{1,0} parameter(3)
  %constant_360_clone_1 = f32[] constant(0)
  %reduce.336.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.647, f32[] %constant_360_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_389_clone_1 = f32[] constant(0.000318877544)
  %broadcast.468.clone.1 = f32[1792]{0} broadcast(f32[] %constant_389_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.377.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.336.clone.1, f32[1792]{0} %broadcast.468.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.652 = f32[1792]{0} parameter(2)
  %multiply.399.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.652, f32[1792]{0} %broadcast.468.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.376.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.399.clone.1, f32[1792]{0} %multiply.399.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.50.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.377.clone.1, f32[1792]{0} %multiply.376.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.467.clone.1 = f32[1792]{0} broadcast(f32[] %constant_360_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.47.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %subtract.50.clone.1, f32[1792]{0} %broadcast.467.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_357 = f32[] constant(0.1)
  %broadcast.465 = f32[1792]{0} broadcast(f32[] %constant_357), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.374 = f32[1792]{0} multiply(f32[1792]{0} %maximum.47.clone.1, f32[1792]{0} %broadcast.465), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.181 = f32[1792]{0} add(f32[1792]{0} %multiply.375, f32[1792]{0} %multiply.374), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.180 = f32[1792]{0} add(f32[1792]{0} %param_0.310, f32[1792]{0} %add.181), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  %param_4.521 = f32[1792]{0} parameter(4)
  %param_5.364 = f32[1792]{0} parameter(5)
  %multiply.381.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_5.364, f32[1792]{0} %broadcast.466), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_364_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.470.clone.1 = f32[1792]{0} broadcast(f32[] %constant_364_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.380.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.652, f32[1792]{0} %broadcast.470.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.183.clone.1 = f32[1792]{0} add(f32[1792]{0} %multiply.381.clone.1, f32[1792]{0} %multiply.380.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.182.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_4.521, f32[1792]{0} %add.183.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  ROOT %tuple.88 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.180, f32[1792]{0} %maximum.47.clone.1, f32[1792]{0} %add.182.clone.1)
}

%fused_computation.181 (param_0.391: f32[896], param_1.583: f32[896], param_2.472: f32[896], param_3.485: f32[16,14,14,896], param_4.328: f32[896]) -> f32[16,14,14,896] {
  %param_3.485 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.328 = f32[896]{0} parameter(4)
  %constant_380 = f32[] constant(0.000318877544)
  %broadcast.486 = f32[896]{0} broadcast(f32[] %constant_380), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.393 = f32[896]{0} multiply(f32[896]{0} %param_4.328, f32[896]{0} %broadcast.486), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.476 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.393), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.51 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.485, f32[16,14,14,896]{2,1,3,0} %broadcast.476), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.472 = f32[896]{0} parameter(2)
  %constant_366 = f32[] constant(1e-05)
  %broadcast.475 = f32[896]{0} broadcast(f32[] %constant_366), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.185 = f32[896]{0} add(f32[896]{0} %param_2.472, f32[896]{0} %broadcast.475), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.49 = f32[896]{0} rsqrt(f32[896]{0} %add.185), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.583 = f32[896]{0} parameter(1)
  %multiply.383 = f32[896]{0} multiply(f32[896]{0} %rsqrt.49, f32[896]{0} %param_1.583), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.474 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.383), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.382 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.51, f32[16,14,14,896]{2,1,3,0} %broadcast.474), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.391 = f32[896]{0} parameter(0)
  %broadcast.473 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.391), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.184 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.382, f32[16,14,14,896]{2,1,3,0} %broadcast.473), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %constant_367 = f32[] constant(0)
  %broadcast.472 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_367), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.48 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.184, f32[16,14,14,896]{2,1,3,0} %broadcast.472), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.182 (param_0.321: f32[896], param_1.715: f32[896], param_2.656: f32[896], param_3.652: f32[16,896], param_4.527: f32[896], param_5.371: f32[896]) -> (f32[896], f32[896], f32[896]) {
  %param_0.321 = f32[896]{0} parameter(0)
  %param_1.715 = f32[896]{0} parameter(1)
  %constant_369 = f32[] constant(0.9)
  %broadcast.478 = f32[896]{0} broadcast(f32[] %constant_369), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.385 = f32[896]{0} multiply(f32[896]{0} %param_1.715, f32[896]{0} %broadcast.478), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %param_3.652 = f32[16,896]{1,0} parameter(3)
  %constant_371_clone_1 = f32[] constant(0)
  %reduce.339.clone.1 = f32[896]{0} reduce(f32[16,896]{1,0} %param_3.652, f32[] %constant_371_clone_1), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_383_clone_1 = f32[] constant(0.000318877544)
  %broadcast.480.clone.1 = f32[896]{0} broadcast(f32[] %constant_383_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.387.clone.1 = f32[896]{0} multiply(f32[896]{0} %reduce.339.clone.1, f32[896]{0} %broadcast.480.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.656 = f32[896]{0} parameter(2)
  %multiply.395.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.656, f32[896]{0} %broadcast.480.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.386.clone.1 = f32[896]{0} multiply(f32[896]{0} %multiply.395.clone.1, f32[896]{0} %multiply.395.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.52.clone.1 = f32[896]{0} subtract(f32[896]{0} %multiply.387.clone.1, f32[896]{0} %multiply.386.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.479.clone.1 = f32[896]{0} broadcast(f32[] %constant_371_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.49.clone.1 = f32[896]{0} maximum(f32[896]{0} %subtract.52.clone.1, f32[896]{0} %broadcast.479.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_368 = f32[] constant(0.1)
  %broadcast.477 = f32[896]{0} broadcast(f32[] %constant_368), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.384 = f32[896]{0} multiply(f32[896]{0} %maximum.49.clone.1, f32[896]{0} %broadcast.477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.187 = f32[896]{0} add(f32[896]{0} %multiply.385, f32[896]{0} %multiply.384), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=267}
  %add.186 = f32[896]{0} add(f32[896]{0} %param_0.321, f32[896]{0} %add.187), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  %param_4.527 = f32[896]{0} parameter(4)
  %param_5.371 = f32[896]{0} parameter(5)
  %multiply.391.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_5.371, f32[896]{0} %broadcast.478), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %constant_375_clone_1 = f32[] constant(3.18877537e-05)
  %broadcast.482.clone.1 = f32[896]{0} broadcast(f32[] %constant_375_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %multiply.390.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.656, f32[896]{0} %broadcast.482.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.189.clone.1 = f32[896]{0} add(f32[896]{0} %multiply.391.clone.1, f32[896]{0} %multiply.390.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=265}
  %add.188.clone.1 = f32[896]{0} add(f32[896]{0} %param_4.527, f32[896]{0} %add.189.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  ROOT %tuple.91 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) tuple(f32[896]{0} %add.186, f32[896]{0} %maximum.49.clone.1, f32[896]{0} %add.188.clone.1)
}

%fused_computation.188 (param_0.330: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_0.330 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %constant_377 = f32[] constant(0)
  %broadcast.484 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_377), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.50 = f32[16,14,14,3584]{2,1,3,0} maximum(f32[16,14,14,3584]{2,1,3,0} %param_0.330, f32[16,14,14,3584]{2,1,3,0} %broadcast.484), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.189 (param_0.406: f32[16,14,14,3584], param_1.591: f32[3584], param_2.486: f32[3584], param_3.492: f32[3584], param_4.334: f32[16,14,14,3584], param_5.134: f32[3584]) -> f32[16,14,14,3584] {
  %param_0.406 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_4.334 = f32[16,14,14,3584]{2,1,3,0} parameter(4)
  %param_5.134 = f32[3584]{0} parameter(5)
  %constant_400 = f32[] constant(0.000318877544)
  %broadcast.506 = f32[3584]{0} broadcast(f32[] %constant_400), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.409 = f32[3584]{0} multiply(f32[3584]{0} %param_5.134, f32[3584]{0} %broadcast.506), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.505 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.409), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.54 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_4.334, f32[16,14,14,3584]{2,1,3,0} %broadcast.505), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.492 = f32[3584]{0} parameter(3)
  %constant_399 = f32[] constant(1e-05)
  %broadcast.504 = f32[3584]{0} broadcast(f32[] %constant_399), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.195 = f32[3584]{0} add(f32[3584]{0} %param_3.492, f32[3584]{0} %broadcast.504), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.76 = f32[3584]{0} rsqrt(f32[3584]{0} %add.195), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.486 = f32[3584]{0} parameter(2)
  %multiply.408 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.76, f32[3584]{0} %param_2.486), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.503 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.408), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.407 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.54, f32[16,14,14,3584]{2,1,3,0} %broadcast.503), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.591 = f32[3584]{0} parameter(1)
  %broadcast.502 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.591), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.194 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.407, f32[16,14,14,3584]{2,1,3,0} %broadcast.502), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.193 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_0.406, f32[16,14,14,3584]{2,1,3,0} %add.194), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %copy.33 = f32[16,14,14,3584]{3,2,1,0} copy(f32[16,14,14,3584]{2,1,3,0} %add.193), metadata={op_name="tuple.61"}
}

%fused_computation.190 (param_0.460: f32[7168], param_1.616: f32[7168], param_2.529: f32[7168], param_3.506: f32[16,7,7,7168], param_4.357: f32[7168], param_5.170: f32[7168], param_6.125: f32[7168], param_7.41: f32[7168], param_8.18: f32[16,7,7,7168], param_9.16: f32[7168]) -> f32[16,7,7,7168] {
  %param_8.18 = f32[16,7,7,7168]{2,1,3,0} parameter(8)
  %param_9.16 = f32[7168]{0} parameter(9)
  %constant_672 = f32[] constant(0.00127551018)
  %broadcast.598 = f32[7168]{0} broadcast(f32[] %constant_672), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.491 = f32[7168]{0} multiply(f32[7168]{0} %param_9.16, f32[7168]{0} %broadcast.598), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.597 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.491), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.60 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_8.18, f32[16,7,7,7168]{2,1,3,0} %broadcast.597), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_7.41 = f32[7168]{0} parameter(7)
  %constant_673 = f32[] constant(1e-05)
  %broadcast.596 = f32[7168]{0} broadcast(f32[] %constant_673), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.211 = f32[7168]{0} add(f32[7168]{0} %param_7.41, f32[7168]{0} %broadcast.596), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.82 = f32[7168]{0} rsqrt(f32[7168]{0} %add.211), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_6.125 = f32[7168]{0} parameter(6)
  %multiply.490 = f32[7168]{0} multiply(f32[7168]{0} %rsqrt.82, f32[7168]{0} %param_6.125), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.595 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.490), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.489 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.60, f32[16,7,7,7168]{2,1,3,0} %broadcast.595), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_5.170 = f32[7168]{0} parameter(5)
  %broadcast.594 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_5.170), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.210 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.489, f32[16,7,7,7168]{2,1,3,0} %broadcast.594), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %param_3.506 = f32[16,7,7,7168]{2,1,3,0} parameter(3)
  %param_4.357 = f32[7168]{0} parameter(4)
  %multiply.488 = f32[7168]{0} multiply(f32[7168]{0} %param_4.357, f32[7168]{0} %broadcast.598), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.592 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.488), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.59 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_3.506, f32[16,7,7,7168]{2,1,3,0} %broadcast.592), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.529 = f32[7168]{0} parameter(2)
  %add.209 = f32[7168]{0} add(f32[7168]{0} %param_2.529, f32[7168]{0} %broadcast.596), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.81 = f32[7168]{0} rsqrt(f32[7168]{0} %add.209), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.616 = f32[7168]{0} parameter(1)
  %multiply.487 = f32[7168]{0} multiply(f32[7168]{0} %rsqrt.81, f32[7168]{0} %param_1.616), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.591 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.487), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.486 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.59, f32[16,7,7,7168]{2,1,3,0} %broadcast.591), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.460 = f32[7168]{0} parameter(0)
  %broadcast.590 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_0.460), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.208 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.486, f32[16,7,7,7168]{2,1,3,0} %broadcast.590), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.207 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %add.210, f32[16,7,7,7168]{2,1,3,0} %add.208), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %copy.34 = f32[16,7,7,7168]{3,2,1,0} copy(f32[16,7,7,7168]{2,1,3,0} %add.207), metadata={op_name="tuple.61"}
}

%fused_computation.191 (param_0.488: f32[16,7,7,7168], param_1.646: f32[7168], param_2.565: f32[7168], param_3.537: f32[7168], param_4.391: f32[16,7,7,7168], param_5.212: f32[7168]) -> (f32[16,7,7,7168], f32[16,7,7,7168]) {
  %param_0.488 = f32[16,7,7,7168]{2,1,3,0} parameter(0)
  %param_4.391 = f32[16,7,7,7168]{2,1,3,0} parameter(4)
  %param_5.212 = f32[7168]{0} parameter(5)
  %constant_696_clone_1 = f32[] constant(0.00127551018)
  %broadcast.626.clone.1 = f32[7168]{0} broadcast(f32[] %constant_696_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.513.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_5.212, f32[7168]{0} %broadcast.626.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.224.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.513.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.9.clone.1 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_4.391, f32[16,7,7,7168]{2,1,3,0} %broadcast.224.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.537 = f32[7168]{0} parameter(3)
  %constant_137_clone_1 = f32[] constant(1e-05)
  %broadcast.226.clone.1 = f32[7168]{0} broadcast(f32[] %constant_137_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.53.clone.1 = f32[7168]{0} add(f32[7168]{0} %param_3.537, f32[7168]{0} %broadcast.226.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.28.clone.1 = f32[7168]{0} rsqrt(f32[7168]{0} %add.53.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.565 = f32[7168]{0} parameter(2)
  %multiply.173.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %rsqrt.28.clone.1, f32[7168]{0} %param_2.565), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.223.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.173.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.172.clone.1 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.9.clone.1, f32[16,7,7,7168]{2,1,3,0} %broadcast.223.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.646 = f32[7168]{0} parameter(1)
  %broadcast.222.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_1.646), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.52.clone.1 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.172.clone.1, f32[16,7,7,7168]{2,1,3,0} %broadcast.222.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.51.clone.1 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %param_0.488, f32[16,7,7,7168]{2,1,3,0} %add.52.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %constant_138_clone_1 = f32[] constant(0)
  %broadcast.225.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[] %constant_138_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %maximum.7.clone.1 = f32[16,7,7,7168]{2,1,3,0} maximum(f32[16,7,7,7168]{2,1,3,0} %add.51.clone.1, f32[16,7,7,7168]{2,1,3,0} %broadcast.225.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %copy.35 = f32[16,7,7,7168]{3,2,1,0} copy(f32[16,7,7,7168]{2,1,3,0} %maximum.7.clone.1), metadata={op_name="tuple.61"}
  ROOT %tuple.11 = (f32[16,7,7,7168]{3,2,1,0}, f32[16,7,7,7168]{2,1,3,0}) tuple(f32[16,7,7,7168]{3,2,1,0} %copy.35, f32[16,7,7,7168]{2,1,3,0} %maximum.7.clone.1)
}

%fused_computation.192 (param_0.491: f32[16,14,14,3584], param_1.672: f32[3584], param_2.597: f32[3584], param_3.577: f32[3584], param_4.437: f32[16,14,14,3584], param_5.266: f32[3584]) -> (f32[16,14,14,3584], f32[16,14,14,3584], f32[16,14,14,3584]) {
  %param_0.491 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_4.437 = f32[16,14,14,3584]{2,1,3,0} parameter(4)
  %param_5.266 = f32[3584]{0} parameter(5)
  %constant_640_clone_1 = f32[] constant(0.000318877544)
  %broadcast.562.clone.1 = f32[3584]{0} broadcast(f32[] %constant_640_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.461.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_5.266, f32[3584]{0} %broadcast.562.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.306.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.461.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.23.clone.1 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_4.437, f32[16,14,14,3584]{2,1,3,0} %broadcast.306.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.577 = f32[3584]{0} parameter(3)
  %constant_212_clone_1 = f32[] constant(1e-05)
  %broadcast.307.clone.1 = f32[3584]{0} broadcast(f32[] %constant_212_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.97.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_3.577, f32[3584]{0} %broadcast.307.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.35.clone.1 = f32[3584]{0} rsqrt(f32[3584]{0} %add.97.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.597 = f32[3584]{0} parameter(2)
  %multiply.243.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %rsqrt.35.clone.1, f32[3584]{0} %param_2.597), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.305.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.243.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.242.clone.1 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.23.clone.1, f32[16,14,14,3584]{2,1,3,0} %broadcast.305.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.672 = f32[3584]{0} parameter(1)
  %broadcast.304.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.672), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.96.clone.1 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.242.clone.1, f32[16,14,14,3584]{2,1,3,0} %broadcast.304.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.95.clone.1 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_0.491, f32[16,14,14,3584]{2,1,3,0} %add.96.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %constant_213_clone_1 = f32[] constant(0)
  %broadcast.308.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_213_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %maximum.20.clone.1 = f32[16,14,14,3584]{2,1,3,0} maximum(f32[16,14,14,3584]{2,1,3,0} %add.95.clone.1, f32[16,14,14,3584]{2,1,3,0} %broadcast.308.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %copy.36 = f32[16,14,14,3584]{3,2,1,0} copy(f32[16,14,14,3584]{2,1,3,0} %maximum.20.clone.1), metadata={op_name="tuple.61"}
  %copy.37 = f32[16,14,14,3584]{3,2,1,0} copy(f32[16,14,14,3584]{2,1,3,0} %param_0.491), metadata={op_name="tuple.61"}
  ROOT %tuple.54 = (f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) tuple(f32[16,14,14,3584]{3,2,1,0} %copy.36, f32[16,14,14,3584]{2,1,3,0} %maximum.20.clone.1, f32[16,14,14,3584]{3,2,1,0} %copy.37)
}

%horizontally_fused_computation (param_0_0: f32[], param_0_1: f32[], param_1_0: f32[], param_1_1: f32[]) -> (f32[1], f32[1]) {
  %param_0_0 = f32[] parameter(0)
  %param_0_1 = f32[] parameter(1)
  %constant_720 = f32[] constant(0.0625)
  %multiply.528 = f32[] multiply(f32[] %param_0_1, f32[] %constant_720), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=113}
  %add.222 = f32[] add(f32[] %param_0_0, f32[] %multiply.528), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %reshape.315 = f32[1]{0} reshape(f32[] %add.222), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %param_1_0 = f32[] parameter(2)
  %param_1_1 = f32[] parameter(3)
  %multiply.529 = f32[] multiply(f32[] %param_1_1, f32[] %constant_720), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %add.223 = f32[] add(f32[] %param_1_0, f32[] %multiply.529), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %reshape.316 = f32[1]{0} reshape(f32[] %add.223), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %concatenate = f32[2]{0} concatenate(f32[1]{0} %reshape.315, f32[1]{0} %reshape.316), dimensions={0}
  %slice = f32[1]{0} slice(f32[2]{0} %concatenate), slice={[0:1]}
  %slice.1 = f32[1]{0} slice(f32[2]{0} %concatenate), slice={[1:2]}
  ROOT %tuple.93 = (f32[1]{0}, f32[1]{0}) tuple(f32[1]{0} %slice, f32[1]{0} %slice.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
}

%fused_computation.12.clone (param_0.493: f32[16,7168,49], param_1.722: f32[7168], param_2.660: f32[7168], param_3.653: f32[7168], param_4.529: f32[16,7168,49], param_5.372: f32[7168]) -> f32[16,7168] {
  %param_0.493 = f32[16,7168,49]{2,1,0} parameter(0)
  %param_4.529 = f32[16,7168,49]{2,1,0} parameter(4)
  %param_5.372 = f32[7168]{0} parameter(5)
  %constant_724 = f32[] constant(0.00127551018)
  %broadcast.650 = f32[7168]{0} broadcast(f32[] %constant_724), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.532 = f32[7168]{0} multiply(f32[7168]{0} %param_5.372, f32[7168]{0} %broadcast.650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.647 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.532), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %broadcast.647), dimensions={0,3,1,2}
  %bitcast.216 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose)
  %subtract.70 = f32[16,7168,49]{2,1,0} subtract(f32[16,7168,49]{2,1,0} %param_4.529, f32[16,7168,49]{2,1,0} %bitcast.216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.653 = f32[7168]{0} parameter(3)
  %constant_722 = f32[] constant(1e-05)
  %broadcast.649 = f32[7168]{0} broadcast(f32[] %constant_722), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.226 = f32[7168]{0} add(f32[7168]{0} %param_3.653, f32[7168]{0} %broadcast.649), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.87 = f32[7168]{0} rsqrt(f32[7168]{0} %add.226), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.660 = f32[7168]{0} parameter(2)
  %multiply.531 = f32[7168]{0} multiply(f32[7168]{0} %rsqrt.87, f32[7168]{0} %param_2.660), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %broadcast.646 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.531), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.1 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %broadcast.646), dimensions={0,3,1,2}
  %bitcast.214 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.1)
  %multiply.533 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %subtract.70, f32[16,7168,49]{2,1,0} %bitcast.214), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.722 = f32[7168]{0} parameter(1)
  %broadcast.645 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_1.722), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %transpose.2 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %broadcast.645), dimensions={0,3,1,2}
  %bitcast.212 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.2)
  %add.228 = f32[16,7168,49]{2,1,0} add(f32[16,7168,49]{2,1,0} %multiply.533, f32[16,7168,49]{2,1,0} %bitcast.212), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.227 = f32[16,7168,49]{2,1,0} add(f32[16,7168,49]{2,1,0} %param_0.493, f32[16,7168,49]{2,1,0} %add.228), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %constant_723 = f32[] constant(0)
  %broadcast.648 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[] %constant_723), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %transpose.3 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %broadcast.648), dimensions={0,3,1,2}
  %bitcast.208 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.3)
  %maximum.52 = f32[16,7168,49]{2,1,0} maximum(f32[16,7168,49]{2,1,0} %add.227, f32[16,7168,49]{2,1,0} %bitcast.208), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %reduce.342 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %maximum.52, f32[] %constant_723), dimensions={2}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/reduce_sum[axes=(1, 2)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
}

%fused_computation.18.clone (param_0.495: f32[16,7168,49]) -> (f32[16,7168], f32[16,7168]) {
  %param_0.495 = f32[16,7168,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_725 = f32[] constant(0)
  %reduce.343 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %param_0.495, f32[] %constant_725), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.149.clone.3 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %param_0.495, f32[16,7168,49]{2,1,0} %param_0.495), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.268.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.149.clone.3, f32[] %constant_725), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.95 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.343, f32[16,7168]{1,0} %reduce.268.clone.2)
}

%fused_computation.25.clone (param_0.497: f32[16,3584,49]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.497 = f32[16,3584,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_726 = f32[] constant(0)
  %reduce.344 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %param_0.497, f32[] %constant_726), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.159.clone.3 = f32[16,3584,49]{2,1,0} multiply(f32[16,3584,49]{2,1,0} %param_0.497, f32[16,3584,49]{2,1,0} %param_0.497), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.271.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %multiply.159.clone.3, f32[] %constant_726), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.96 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.344, f32[16,3584]{1,0} %reduce.271.clone.2)
}

%fused_computation.32.clone (param_0.499: f32[16,1792,49]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.499 = f32[16,1792,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_727 = f32[] constant(0)
  %reduce.345 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %param_0.499, f32[] %constant_727), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.169.clone.3 = f32[16,1792,49]{2,1,0} multiply(f32[16,1792,49]{2,1,0} %param_0.499, f32[16,1792,49]{2,1,0} %param_0.499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.274.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %multiply.169.clone.3, f32[] %constant_727), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.97 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.345, f32[16,1792]{1,0} %reduce.274.clone.2)
}

%fused_computation.39.clone (param_0.501: f32[16,7168,49]) -> (f32[16,7168], f32[16,7168]) {
  %param_0.501 = f32[16,7168,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_728 = f32[] constant(0)
  %reduce.346 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %param_0.501, f32[] %constant_728), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.179.clone.3 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %param_0.501, f32[16,7168,49]{2,1,0} %param_0.501), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.277.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.179.clone.3, f32[] %constant_728), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.98 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.346, f32[16,7168]{1,0} %reduce.277.clone.2)
}

%fused_computation.46.clone (param_0.503: f32[16,3584,49]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.503 = f32[16,3584,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_729 = f32[] constant(0)
  %reduce.347 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %param_0.503, f32[] %constant_729), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.189.clone.3 = f32[16,3584,49]{2,1,0} multiply(f32[16,3584,49]{2,1,0} %param_0.503, f32[16,3584,49]{2,1,0} %param_0.503), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.280.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %multiply.189.clone.3, f32[] %constant_729), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.99 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.347, f32[16,3584]{1,0} %reduce.280.clone.2)
}

%fused_computation.53.clone (param_0.505: f32[16,1792,49]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.505 = f32[16,1792,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_730 = f32[] constant(0)
  %reduce.348 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %param_0.505, f32[] %constant_730), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.199.clone.3 = f32[16,1792,49]{2,1,0} multiply(f32[16,1792,49]{2,1,0} %param_0.505, f32[16,1792,49]{2,1,0} %param_0.505), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.283.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %multiply.199.clone.3, f32[] %constant_730), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.100 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.348, f32[16,1792]{1,0} %reduce.283.clone.2)
}

%fused_computation.61.clone (param_0.507: f32[16,7168,49]) -> (f32[16,7168], f32[16,7168]) {
  %param_0.507 = f32[16,7168,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_731 = f32[] constant(0)
  %reduce.349 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %param_0.507, f32[] %constant_731), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.211.clone.3 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %param_0.507, f32[16,7168,49]{2,1,0} %param_0.507), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.286.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.211.clone.3, f32[] %constant_731), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.101 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.349, f32[16,7168]{1,0} %reduce.286.clone.2)
}

%fused_computation.67.clone (param_0.509: f32[16,7168,49]) -> (f32[16,7168], f32[16,7168]) {
  %param_0.509 = f32[16,7168,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_732 = f32[] constant(0)
  %reduce.350 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %param_0.509, f32[] %constant_732), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.219.clone.3 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %param_0.509, f32[16,7168,49]{2,1,0} %param_0.509), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.289.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.219.clone.3, f32[] %constant_732), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.102 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.350, f32[16,7168]{1,0} %reduce.289.clone.2)
}

%fused_computation.74.clone (param_0.511: f32[16,3584,49]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.511 = f32[16,3584,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_733 = f32[] constant(0)
  %reduce.351 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %param_0.511, f32[] %constant_733), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.229.clone.3 = f32[16,3584,49]{2,1,0} multiply(f32[16,3584,49]{2,1,0} %param_0.511, f32[16,3584,49]{2,1,0} %param_0.511), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.292.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %multiply.229.clone.3, f32[] %constant_733), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.103 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.351, f32[16,3584]{1,0} %reduce.292.clone.2)
}

%fused_computation.81.clone (param_0.513: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.513 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_734 = f32[] constant(0)
  %reduce.352 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.513, f32[] %constant_734), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.239.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.513, f32[16,1792,196]{2,1,0} %param_0.513), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.295.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.239.clone.3, f32[] %constant_734), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.104 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.352, f32[16,1792]{1,0} %reduce.295.clone.2)
}

%fused_computation.88.clone (param_0.515: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.515 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_735 = f32[] constant(0)
  %reduce.353 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.515, f32[] %constant_735), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.249.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.515, f32[16,3584,196]{2,1,0} %param_0.515), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.298.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.249.clone.3, f32[] %constant_735), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.105 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.353, f32[16,3584]{1,0} %reduce.298.clone.2)
}

%fused_computation.95.clone (param_0.517: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.517 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_736 = f32[] constant(0)
  %reduce.354 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.517, f32[] %constant_736), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.259.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.517, f32[16,1792,196]{2,1,0} %param_0.517), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.301.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.259.clone.3, f32[] %constant_736), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.106 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.354, f32[16,1792]{1,0} %reduce.301.clone.2)
}

%fused_computation.102.clone (param_0.519: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.519 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_737 = f32[] constant(0)
  %reduce.355 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.519, f32[] %constant_737), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.269.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.519, f32[16,896,196]{2,1,0} %param_0.519), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.304.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.269.clone.3, f32[] %constant_737), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.107 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.355, f32[16,896]{1,0} %reduce.304.clone.2)
}

%fused_computation.109.clone (param_0.521: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.521 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_738 = f32[] constant(0)
  %reduce.356 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.521, f32[] %constant_738), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.279.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.521, f32[16,3584,196]{2,1,0} %param_0.521), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.307.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.279.clone.3, f32[] %constant_738), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.108 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.356, f32[16,3584]{1,0} %reduce.307.clone.2)
}

%fused_computation.116.clone (param_0.523: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.523 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_739 = f32[] constant(0)
  %reduce.357 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.523, f32[] %constant_739), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.289.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.523, f32[16,1792,196]{2,1,0} %param_0.523), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.310.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.289.clone.3, f32[] %constant_739), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.109 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.357, f32[16,1792]{1,0} %reduce.310.clone.2)
}

%fused_computation.123.clone (param_0.525: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.525 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_740 = f32[] constant(0)
  %reduce.358 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.525, f32[] %constant_740), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.299.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.525, f32[16,896,196]{2,1,0} %param_0.525), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.313.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.299.clone.3, f32[] %constant_740), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.110 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.358, f32[16,896]{1,0} %reduce.313.clone.2)
}

%fused_computation.130.clone (param_0.527: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.527 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_741 = f32[] constant(0)
  %reduce.359 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.527, f32[] %constant_741), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.309.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.527, f32[16,3584,196]{2,1,0} %param_0.527), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.316.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.309.clone.3, f32[] %constant_741), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.111 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.359, f32[16,3584]{1,0} %reduce.316.clone.2)
}

%fused_computation.137.clone (param_0.529: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.529 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_742 = f32[] constant(0)
  %reduce.360 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.529, f32[] %constant_742), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.319.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.529, f32[16,1792,196]{2,1,0} %param_0.529), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.319.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.319.clone.3, f32[] %constant_742), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.112 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.360, f32[16,1792]{1,0} %reduce.319.clone.2)
}

%fused_computation.144.clone (param_0.531: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.531 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_743 = f32[] constant(0)
  %reduce.361 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.531, f32[] %constant_743), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.329.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.531, f32[16,896,196]{2,1,0} %param_0.531), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.322.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.329.clone.3, f32[] %constant_743), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.113 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.361, f32[16,896]{1,0} %reduce.322.clone.2)
}

%fused_computation.151.clone (param_0.533: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.533 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_744 = f32[] constant(0)
  %reduce.362 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.533, f32[] %constant_744), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.339.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.533, f32[16,3584,196]{2,1,0} %param_0.533), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.325.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.339.clone.3, f32[] %constant_744), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.114 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.362, f32[16,3584]{1,0} %reduce.325.clone.2)
}

%fused_computation.158.clone (param_0.535: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.535 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_745 = f32[] constant(0)
  %reduce.363 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.535, f32[] %constant_745), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.349.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.535, f32[16,1792,196]{2,1,0} %param_0.535), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.328.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.349.clone.3, f32[] %constant_745), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.115 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.363, f32[16,1792]{1,0} %reduce.328.clone.2)
}

%fused_computation.165.clone (param_0.537: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.537 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_746 = f32[] constant(0)
  %reduce.364 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.537, f32[] %constant_746), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.359.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.537, f32[16,896,196]{2,1,0} %param_0.537), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.331.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.359.clone.3, f32[] %constant_746), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.116 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.364, f32[16,896]{1,0} %reduce.331.clone.2)
}

%fused_computation.173.clone (param_0.539: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.539 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_747 = f32[] constant(0)
  %reduce.365 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.539, f32[] %constant_747), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.369.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.539, f32[16,3584,196]{2,1,0} %param_0.539), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.334.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.369.clone.3, f32[] %constant_747), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.117 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.365, f32[16,3584]{1,0} %reduce.334.clone.2)
}

%fused_computation.180.clone (param_0.541: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.541 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_748 = f32[] constant(0)
  %reduce.366 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.541, f32[] %constant_748), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.379.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.541, f32[16,1792,196]{2,1,0} %param_0.541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.337.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.379.clone.3, f32[] %constant_748), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.118 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.366, f32[16,1792]{1,0} %reduce.337.clone.2)
}

%fused_computation.187.clone (param_0.543: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.543 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_749 = f32[] constant(0)
  %reduce.367 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.543, f32[] %constant_749), dimensions={2}, to_apply=%region_0.1142.1
  %multiply.389.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.543, f32[16,896,196]{2,1,0} %param_0.543), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.340.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.389.clone.3, f32[] %constant_749), dimensions={2}, to_apply=%region_0.1142.1
  ROOT %tuple.119 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.367, f32[16,896]{1,0} %reduce.340.clone.2)
}

ENTRY %main.10683-1 (param_0: f32[896], param_1: f32[896], param_2: f32[1792], param_3: f32[1792], param_4: f32[3584], param_5: f32[3584], param_6: f32[896], param_7: f32[896], param_8: f32[1792], param_9: f32[1792], param_10: f32[3584], param_11: f32[3584], param_12: f32[896], param_13: f32[896], param_14: f32[1792], param_15: f32[1792], param_16: f32[3584], param_17: f32[3584], param_18: f32[896], param_19: f32[896], param_20: f32[1792], param_21: f32[1792], param_22: f32[3584], param_23: f32[3584], param_24: f32[896], param_25: f32[896], param_26: f32[1792], param_27: f32[1792], param_28: f32[3584], param_29: f32[3584], param_30: f32[1792], param_31: f32[1792], param_32: f32[3584], param_33: f32[3584], param_34: f32[7168], param_35: f32[7168], param_36: f32[7168], param_37: f32[7168], param_38: f32[1792], param_39: f32[1792], param_40: f32[3584], param_41: f32[3584], param_42: f32[7168], param_43: f32[7168], param_44: f32[1792], param_45: f32[1792], param_46: f32[3584], param_47: f32[3584], param_48: f32[7168], param_49: f32[7168], param_50: f32[], param_51: f32[], param_52: f32[], param_53: f32[16,14,14,3584], param_54: f32[1,1,3584,896], param_55: f32[896], param_56: f32[896], param_57: f32[3,3,896,1792], param_58: f32[1792], param_59: f32[1792], param_60: f32[1,1,1792,3584], param_61: f32[3584], param_62: f32[3584], param_63: f32[896], param_64: f32[896], param_65: f32[1792], param_66: f32[1792], param_67: f32[3584], param_68: f32[3584], param_69: f32[1,1,3584,896], param_70: f32[896], param_71: f32[896], param_72: f32[3,3,896,1792], param_73: f32[1792], param_74: f32[1792], param_75: f32[1,1,1792,3584], param_76: f32[3584], param_77: f32[3584], param_78: f32[896], param_79: f32[896], param_80: f32[1792], param_81: f32[1792], param_82: f32[3584], param_83: f32[3584], param_84: f32[1,1,3584,896], param_85: f32[896], param_86: f32[896], param_87: f32[3,3,896,1792], param_88: f32[1792], param_89: f32[1792], param_90: f32[1,1,1792,3584], param_91: f32[3584], param_92: f32[3584], param_93: f32[896], param_94: f32[896], param_95: f32[1792], param_96: f32[1792], param_97: f32[3584], param_98: f32[3584], param_99: f32[1,1,3584,896], param_100: f32[896], param_101: f32[896], param_102: f32[3,3,896,1792], param_103: f32[1792], param_104: f32[1792], param_105: f32[1,1,1792,3584], param_106: f32[3584], param_107: f32[3584], param_108: f32[896], param_109: f32[896], param_110: f32[1792], param_111: f32[1792], param_112: f32[3584], param_113: f32[3584], param_114: f32[1,1,3584,896], param_115: f32[896], param_116: f32[896], param_117: f32[3,3,896,1792], param_118: f32[1792], param_119: f32[1792], param_120: f32[1,1,1792,3584], param_121: f32[3584], param_122: f32[3584], param_123: f32[896], param_124: f32[896], param_125: f32[1792], param_126: f32[1792], param_127: f32[3584], param_128: f32[3584], param_129: f32[1,1,3584,1792], param_130: f32[1792], param_131: f32[1792], param_132: f32[3,3,1792,3584], param_133: f32[3584], param_134: f32[3584], param_135: f32[1,1,3584,7168], param_136: f32[7168], param_137: f32[7168], param_138: f32[1,1,3584,7168], param_139: f32[7168], param_140: f32[7168], param_141: f32[1792], param_142: f32[1792], param_143: f32[3584], param_144: f32[3584], param_145: f32[7168], param_146: f32[7168], param_147: f32[7168], param_148: f32[7168], param_149: f32[1,1,7168,1792], param_150: f32[1792], param_151: f32[1792], param_152: f32[3,3,1792,3584], param_153: f32[3584], param_154: f32[3584], param_155: f32[1,1,3584,7168], param_156: f32[7168], param_157: f32[7168], param_158: f32[1792], param_159: f32[1792], param_160: f32[3584], param_161: f32[3584], param_162: f32[7168], param_163: f32[7168], param_164: f32[1,1,7168,1792], param_165: f32[1792], param_166: f32[1792], param_167: f32[3,3,1792,3584], param_168: f32[3584], param_169: f32[3584], param_170: f32[1,1,3584,7168], param_171: f32[7168], param_172: f32[7168], param_173: f32[7168,1024], param_174: f32[1024], param_175: f32[1792], param_176: f32[1792], param_177: f32[3584], param_178: f32[3584], param_179: f32[7168], param_180: f32[7168], param_181: s32[16], param_182: s32[]) -> (f32[896], f32[896], f32[1792], f32[1792], f32[3584], /*index=5*/f32[3584], f32[896], f32[896], f32[1792], f32[1792], /*index=10*/f32[3584], f32[3584], f32[896], f32[896], f32[1792], /*index=15*/f32[1792], f32[3584], f32[3584], f32[896], f32[896], /*index=20*/f32[1792], f32[1792], f32[3584], f32[3584], f32[896], /*index=25*/f32[896], f32[1792], f32[1792], f32[3584], f32[3584], /*index=30*/f32[1792], f32[1792], f32[3584], f32[3584], f32[7168], /*index=35*/f32[7168], f32[7168], f32[7168], f32[1792], f32[1792], /*index=40*/f32[3584], f32[3584], f32[7168], f32[7168], f32[1792], /*index=45*/f32[1792], f32[3584], f32[3584], f32[7168], f32[7168], /*index=50*/f32[], f32[], f32[], f32[16,14,14,3584], f32[16,14,14,3584], /*index=55*/f32[16,14,14,3584], f32[16,14,14,3584], f32[16,14,14,3584], f32[16,7,7,7168], f32[16,7,7,7168]) {
  %param_1 = f32[896]{0} parameter(1), metadata={op_name="1$start"}
  %param_64 = f32[896]{0} parameter(64), metadata={op_name="1$start"}
  %param_53 = f32[16,14,14,3584]{3,2,1,0} parameter(53), metadata={op_name="1$start"}
  %copy = f32[16,14,14,3584]{2,1,3,0} copy(f32[16,14,14,3584]{3,2,1,0} %param_53), metadata={op_name="1$start"}
  %fusion.188 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %copy), kind=kLoop, calls=%fused_computation.188, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_54 = f32[1,1,3584,896]{3,2,1,0} parameter(54), metadata={op_name="1$start"}
  %copy.1 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_54), metadata={op_name="1$start"}
  %cudnn-conv = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.188, f32[1,1,3584,896]{1,0,2,3} %copy.1), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.1 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.318 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.1)
  %fusion.187 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.318), kind=kInput, calls=%fused_computation.187.clone
  %get-tuple-element.220 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.187), index=0
  %constant_535 = f32[] constant(0)
  %reduce.189 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.220, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.221 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.187), index=1
  %param_0 = f32[896]{0} parameter(0), metadata={op_name="1$start"}
  %param_63 = f32[896]{0} parameter(63), metadata={op_name="1$start"}
  %fusion.182 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) fusion(f32[896]{0} %param_1, f32[896]{0} %param_64, f32[896]{0} %reduce.189, f32[16,896]{1,0} %get-tuple-element.221, f32[896]{0} %param_0, /*index=5*/f32[896]{0} %param_63), kind=kLoop, calls=%fused_computation.182, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  %get-tuple-element.226 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.182), index=2
  %get-tuple-element.227 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.182), index=0
  %param_3 = f32[1792]{0} parameter(3), metadata={op_name="1$start"}
  %param_66 = f32[1792]{0} parameter(66), metadata={op_name="1$start"}
  %param_56 = f32[896]{0} parameter(56), metadata={op_name="1$start"}
  %param_55 = f32[896]{0} parameter(55), metadata={op_name="1$start"}
  %get-tuple-element.218 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.182), index=1
  %fusion.181 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %param_56, f32[896]{0} %param_55, f32[896]{0} %get-tuple-element.218, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.1, f32[896]{0} %reduce.189), kind=kLoop, calls=%fused_computation.181, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_57 = f32[3,3,896,1792]{3,2,1,0} parameter(57), metadata={op_name="1$start"}
  %copy.2 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_57), metadata={op_name="1$start"}
  %cudnn-conv.1 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.181, f32[3,3,896,1792]{1,0,2,3} %copy.2), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.2 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.1), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.314 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.2)
  %fusion.180 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.314), kind=kInput, calls=%fused_computation.180.clone
  %get-tuple-element.215 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.180), index=0
  %reduce.191 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.215, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.216 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.180), index=1
  %param_2 = f32[1792]{0} parameter(2), metadata={op_name="1$start"}
  %param_65 = f32[1792]{0} parameter(65), metadata={op_name="1$start"}
  %fusion.175 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_3, f32[1792]{0} %param_66, f32[1792]{0} %reduce.191, f32[16,1792]{1,0} %get-tuple-element.216, f32[1792]{0} %param_2, /*index=5*/f32[1792]{0} %param_65), kind=kLoop, calls=%fused_computation.175, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  %get-tuple-element.228 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.175), index=2
  %get-tuple-element.229 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.175), index=0
  %param_5 = f32[3584]{0} parameter(5), metadata={op_name="1$start"}
  %param_68 = f32[3584]{0} parameter(68), metadata={op_name="1$start"}
  %param_59 = f32[1792]{0} parameter(59), metadata={op_name="1$start"}
  %param_58 = f32[1792]{0} parameter(58), metadata={op_name="1$start"}
  %get-tuple-element.213 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.175), index=1
  %fusion.174 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %param_59, f32[1792]{0} %param_58, f32[1792]{0} %get-tuple-element.213, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.2, f32[1792]{0} %reduce.191), kind=kLoop, calls=%fused_computation.174, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_60 = f32[1,1,1792,3584]{3,2,1,0} parameter(60), metadata={op_name="1$start"}
  %copy.3 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_60), metadata={op_name="1$start"}
  %cudnn-conv.2 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.174, f32[1,1,1792,3584]{1,0,2,3} %copy.3), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.3 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.2), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.310 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.3)
  %fusion.173 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.310), kind=kInput, calls=%fused_computation.173.clone
  %get-tuple-element.210 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.173), index=0
  %reduce.193 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.210, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/jvp(WideResNet)/BottleneckResNetBlock_8/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.211 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.173), index=1
  %param_4 = f32[3584]{0} parameter(4), metadata={op_name="1$start"}
  %param_67 = f32[3584]{0} parameter(67), metadata={op_name="1$start"}
  %fusion.168 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_5, f32[3584]{0} %param_68, f32[3584]{0} %reduce.193, f32[16,3584]{1,0} %get-tuple-element.211, f32[3584]{0} %param_4, /*index=5*/f32[3584]{0} %param_67), kind=kLoop, calls=%fused_computation.168, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(10)/add"}
  %get-tuple-element.230 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.168), index=2
  %get-tuple-element.231 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.168), index=0
  %param_7 = f32[896]{0} parameter(7), metadata={op_name="1$start"}
  %param_79 = f32[896]{0} parameter(79), metadata={op_name="1$start"}
  %param_62 = f32[3584]{0} parameter(62), metadata={op_name="1$start"}
  %param_61 = f32[3584]{0} parameter(61), metadata={op_name="1$start"}
  %get-tuple-element.208 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.168), index=1
  %fusion.166 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %fusion.188, f32[3584]{0} %param_62, f32[3584]{0} %param_61, f32[3584]{0} %get-tuple-element.208, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.3, /*index=5*/f32[3584]{0} %reduce.193), kind=kLoop, calls=%fused_computation.166, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_69 = f32[1,1,3584,896]{3,2,1,0} parameter(69), metadata={op_name="1$start"}
  %copy.4 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_69), metadata={op_name="1$start"}
  %cudnn-conv.3 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.166, f32[1,1,3584,896]{1,0,2,3} %copy.4), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.4 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.3), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.306 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.4)
  %fusion.165 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.306), kind=kInput, calls=%fused_computation.165.clone
  %get-tuple-element.205 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.165), index=0
  %reduce.195 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.205, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.206 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.165), index=1
  %param_6 = f32[896]{0} parameter(6), metadata={op_name="1$start"}
  %param_78 = f32[896]{0} parameter(78), metadata={op_name="1$start"}
  %fusion.160 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) fusion(f32[896]{0} %param_7, f32[896]{0} %param_79, f32[896]{0} %reduce.195, f32[16,896]{1,0} %get-tuple-element.206, f32[896]{0} %param_6, /*index=5*/f32[896]{0} %param_78), kind=kLoop, calls=%fused_computation.160, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  %get-tuple-element.232 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.160), index=2
  %get-tuple-element.233 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.160), index=0
  %param_9 = f32[1792]{0} parameter(9), metadata={op_name="1$start"}
  %param_81 = f32[1792]{0} parameter(81), metadata={op_name="1$start"}
  %param_71 = f32[896]{0} parameter(71), metadata={op_name="1$start"}
  %param_70 = f32[896]{0} parameter(70), metadata={op_name="1$start"}
  %get-tuple-element.203 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.160), index=1
  %fusion.159 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %param_71, f32[896]{0} %param_70, f32[896]{0} %get-tuple-element.203, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.4, f32[896]{0} %reduce.195), kind=kLoop, calls=%fused_computation.159, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_72 = f32[3,3,896,1792]{3,2,1,0} parameter(72), metadata={op_name="1$start"}
  %copy.5 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_72), metadata={op_name="1$start"}
  %cudnn-conv.4 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.159, f32[3,3,896,1792]{1,0,2,3} %copy.5), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.5 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.4), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.302 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.5)
  %fusion.158 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.302), kind=kInput, calls=%fused_computation.158.clone
  %get-tuple-element.200 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.158), index=0
  %reduce.197 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.200, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.201 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.158), index=1
  %param_8 = f32[1792]{0} parameter(8), metadata={op_name="1$start"}
  %param_80 = f32[1792]{0} parameter(80), metadata={op_name="1$start"}
  %fusion.153 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_9, f32[1792]{0} %param_81, f32[1792]{0} %reduce.197, f32[16,1792]{1,0} %get-tuple-element.201, f32[1792]{0} %param_8, /*index=5*/f32[1792]{0} %param_80), kind=kLoop, calls=%fused_computation.153, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  %get-tuple-element.234 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.153), index=2
  %get-tuple-element.235 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.153), index=0
  %param_11 = f32[3584]{0} parameter(11), metadata={op_name="1$start"}
  %param_83 = f32[3584]{0} parameter(83), metadata={op_name="1$start"}
  %param_74 = f32[1792]{0} parameter(74), metadata={op_name="1$start"}
  %param_73 = f32[1792]{0} parameter(73), metadata={op_name="1$start"}
  %get-tuple-element.198 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.153), index=1
  %fusion.152 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %param_74, f32[1792]{0} %param_73, f32[1792]{0} %get-tuple-element.198, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.5, f32[1792]{0} %reduce.197), kind=kLoop, calls=%fused_computation.152, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_75 = f32[1,1,1792,3584]{3,2,1,0} parameter(75), metadata={op_name="1$start"}
  %copy.6 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_75), metadata={op_name="1$start"}
  %cudnn-conv.5 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.152, f32[1,1,1792,3584]{1,0,2,3} %copy.6), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.6 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.5), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.298 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.6)
  %fusion.151 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.298), kind=kInput, calls=%fused_computation.151.clone
  %get-tuple-element.195 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.151), index=0
  %reduce.199 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.195, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.196 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.151), index=1
  %param_10 = f32[3584]{0} parameter(10), metadata={op_name="1$start"}
  %param_82 = f32[3584]{0} parameter(82), metadata={op_name="1$start"}
  %fusion.146 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_11, f32[3584]{0} %param_83, f32[3584]{0} %reduce.199, f32[16,3584]{1,0} %get-tuple-element.196, f32[3584]{0} %param_10, /*index=5*/f32[3584]{0} %param_82), kind=kLoop, calls=%fused_computation.146, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/add"}
  %get-tuple-element.236 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.146), index=2
  %get-tuple-element.237 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.146), index=0
  %param_13 = f32[896]{0} parameter(13), metadata={op_name="1$start"}
  %param_94 = f32[896]{0} parameter(94), metadata={op_name="1$start"}
  %param_77 = f32[3584]{0} parameter(77), metadata={op_name="1$start"}
  %param_76 = f32[3584]{0} parameter(76), metadata={op_name="1$start"}
  %get-tuple-element.193 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.146), index=1
  %fusion.145 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %fusion.166, f32[3584]{0} %param_77, f32[3584]{0} %param_76, f32[3584]{0} %get-tuple-element.193, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.6, /*index=5*/f32[3584]{0} %reduce.199), kind=kLoop, calls=%fused_computation.145, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(11)/jvp(WideResNet)/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_84 = f32[1,1,3584,896]{3,2,1,0} parameter(84), metadata={op_name="1$start"}
  %copy.7 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_84), metadata={op_name="1$start"}
  %cudnn-conv.6 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.145, f32[1,1,3584,896]{1,0,2,3} %copy.7), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.7 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.6), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.294 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.7)
  %fusion.144 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.294), kind=kInput, calls=%fused_computation.144.clone
  %get-tuple-element.188 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.144), index=0
  %reduce.201 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.188, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.189 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.144), index=1
  %param_12 = f32[896]{0} parameter(12), metadata={op_name="1$start"}
  %param_93 = f32[896]{0} parameter(93), metadata={op_name="1$start"}
  %fusion.139 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) fusion(f32[896]{0} %param_13, f32[896]{0} %param_94, f32[896]{0} %reduce.201, f32[16,896]{1,0} %get-tuple-element.189, f32[896]{0} %param_12, /*index=5*/f32[896]{0} %param_93), kind=kLoop, calls=%fused_computation.139, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  %get-tuple-element.238 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.139), index=2
  %get-tuple-element.239 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.139), index=0
  %param_15 = f32[1792]{0} parameter(15), metadata={op_name="1$start"}
  %param_96 = f32[1792]{0} parameter(96), metadata={op_name="1$start"}
  %param_86 = f32[896]{0} parameter(86), metadata={op_name="1$start"}
  %param_85 = f32[896]{0} parameter(85), metadata={op_name="1$start"}
  %get-tuple-element.186 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.139), index=1
  %fusion.138 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %param_86, f32[896]{0} %param_85, f32[896]{0} %get-tuple-element.186, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.7, f32[896]{0} %reduce.201), kind=kLoop, calls=%fused_computation.138, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_87 = f32[3,3,896,1792]{3,2,1,0} parameter(87), metadata={op_name="1$start"}
  %copy.8 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_87), metadata={op_name="1$start"}
  %cudnn-conv.7 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.138, f32[3,3,896,1792]{1,0,2,3} %copy.8), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.8 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.7), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.290 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.8)
  %fusion.137 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.290), kind=kInput, calls=%fused_computation.137.clone
  %get-tuple-element.183 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.137), index=0
  %reduce.203 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.183, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.184 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.137), index=1
  %param_14 = f32[1792]{0} parameter(14), metadata={op_name="1$start"}
  %param_95 = f32[1792]{0} parameter(95), metadata={op_name="1$start"}
  %fusion.132 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_15, f32[1792]{0} %param_96, f32[1792]{0} %reduce.203, f32[16,1792]{1,0} %get-tuple-element.184, f32[1792]{0} %param_14, /*index=5*/f32[1792]{0} %param_95), kind=kLoop, calls=%fused_computation.132, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  %get-tuple-element.240 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.132), index=2
  %get-tuple-element.241 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.132), index=0
  %param_17 = f32[3584]{0} parameter(17), metadata={op_name="1$start"}
  %param_98 = f32[3584]{0} parameter(98), metadata={op_name="1$start"}
  %param_89 = f32[1792]{0} parameter(89), metadata={op_name="1$start"}
  %param_88 = f32[1792]{0} parameter(88), metadata={op_name="1$start"}
  %get-tuple-element.181 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.132), index=1
  %fusion.131 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %param_89, f32[1792]{0} %param_88, f32[1792]{0} %get-tuple-element.181, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.8, f32[1792]{0} %reduce.203), kind=kLoop, calls=%fused_computation.131, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_90 = f32[1,1,1792,3584]{3,2,1,0} parameter(90), metadata={op_name="1$start"}
  %copy.9 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_90), metadata={op_name="1$start"}
  %cudnn-conv.8 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.131, f32[1,1,1792,3584]{1,0,2,3} %copy.9), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.9 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.286 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.9)
  %fusion.130 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.286), kind=kInput, calls=%fused_computation.130.clone
  %get-tuple-element.178 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.130), index=0
  %reduce.205 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.178, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.179 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.130), index=1
  %param_16 = f32[3584]{0} parameter(16), metadata={op_name="1$start"}
  %param_97 = f32[3584]{0} parameter(97), metadata={op_name="1$start"}
  %fusion.125 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_17, f32[3584]{0} %param_98, f32[3584]{0} %reduce.205, f32[16,3584]{1,0} %get-tuple-element.179, f32[3584]{0} %param_16, /*index=5*/f32[3584]{0} %param_97), kind=kLoop, calls=%fused_computation.125, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/add"}
  %get-tuple-element.242 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.125), index=2
  %get-tuple-element.243 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.125), index=0
  %param_19 = f32[896]{0} parameter(19), metadata={op_name="1$start"}
  %param_109 = f32[896]{0} parameter(109), metadata={op_name="1$start"}
  %param_92 = f32[3584]{0} parameter(92), metadata={op_name="1$start"}
  %param_91 = f32[3584]{0} parameter(91), metadata={op_name="1$start"}
  %get-tuple-element.176 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.125), index=1
  %fusion.124 = (f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %fusion.145, f32[3584]{0} %param_92, f32[3584]{0} %param_91, f32[3584]{0} %get-tuple-element.176, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.9, /*index=5*/f32[3584]{0} %reduce.205), kind=kLoop, calls=%fused_computation.124, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(12)/jvp(WideResNet)/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.190 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) %fusion.124), index=0
  %param_99 = f32[1,1,3584,896]{3,2,1,0} parameter(99), metadata={op_name="1$start"}
  %copy.10 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_99), metadata={op_name="1$start"}
  %cudnn-conv.9 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.190, f32[1,1,3584,896]{1,0,2,3} %copy.10), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.10 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.9), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.282 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.10)
  %fusion.123 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.282), kind=kInput, calls=%fused_computation.123.clone
  %get-tuple-element.171 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.123), index=0
  %reduce.207 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.171, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.172 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.123), index=1
  %param_18 = f32[896]{0} parameter(18), metadata={op_name="1$start"}
  %param_108 = f32[896]{0} parameter(108), metadata={op_name="1$start"}
  %fusion.118 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) fusion(f32[896]{0} %param_19, f32[896]{0} %param_109, f32[896]{0} %reduce.207, f32[16,896]{1,0} %get-tuple-element.172, f32[896]{0} %param_18, /*index=5*/f32[896]{0} %param_108), kind=kLoop, calls=%fused_computation.118, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  %get-tuple-element.244 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.118), index=2
  %get-tuple-element.245 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.118), index=0
  %param_21 = f32[1792]{0} parameter(21), metadata={op_name="1$start"}
  %param_111 = f32[1792]{0} parameter(111), metadata={op_name="1$start"}
  %param_101 = f32[896]{0} parameter(101), metadata={op_name="1$start"}
  %param_100 = f32[896]{0} parameter(100), metadata={op_name="1$start"}
  %get-tuple-element.169 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.118), index=1
  %fusion.117 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %param_101, f32[896]{0} %param_100, f32[896]{0} %get-tuple-element.169, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.10, f32[896]{0} %reduce.207), kind=kLoop, calls=%fused_computation.117, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_102 = f32[3,3,896,1792]{3,2,1,0} parameter(102), metadata={op_name="1$start"}
  %copy.11 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_102), metadata={op_name="1$start"}
  %cudnn-conv.10 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.117, f32[3,3,896,1792]{1,0,2,3} %copy.11), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.11 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.10), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.278 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.11)
  %fusion.116 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.278), kind=kInput, calls=%fused_computation.116.clone
  %get-tuple-element.166 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.116), index=0
  %reduce.209 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.166, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.167 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.116), index=1
  %param_20 = f32[1792]{0} parameter(20), metadata={op_name="1$start"}
  %param_110 = f32[1792]{0} parameter(110), metadata={op_name="1$start"}
  %fusion.111 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_21, f32[1792]{0} %param_111, f32[1792]{0} %reduce.209, f32[16,1792]{1,0} %get-tuple-element.167, f32[1792]{0} %param_20, /*index=5*/f32[1792]{0} %param_110), kind=kLoop, calls=%fused_computation.111, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  %get-tuple-element.246 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.111), index=2
  %get-tuple-element.247 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.111), index=0
  %param_23 = f32[3584]{0} parameter(23), metadata={op_name="1$start"}
  %param_113 = f32[3584]{0} parameter(113), metadata={op_name="1$start"}
  %param_104 = f32[1792]{0} parameter(104), metadata={op_name="1$start"}
  %param_103 = f32[1792]{0} parameter(103), metadata={op_name="1$start"}
  %get-tuple-element.164 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.111), index=1
  %fusion.110 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %param_104, f32[1792]{0} %param_103, f32[1792]{0} %get-tuple-element.164, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.11, f32[1792]{0} %reduce.209), kind=kLoop, calls=%fused_computation.110, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_105 = f32[1,1,1792,3584]{3,2,1,0} parameter(105), metadata={op_name="1$start"}
  %copy.12 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_105), metadata={op_name="1$start"}
  %cudnn-conv.11 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.110, f32[1,1,1792,3584]{1,0,2,3} %copy.12), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.12 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.11), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.274 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.12)
  %fusion.109 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.274), kind=kInput, calls=%fused_computation.109.clone
  %get-tuple-element.161 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.109), index=0
  %reduce.211 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.161, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.162 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.109), index=1
  %param_22 = f32[3584]{0} parameter(22), metadata={op_name="1$start"}
  %param_112 = f32[3584]{0} parameter(112), metadata={op_name="1$start"}
  %fusion.104 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_23, f32[3584]{0} %param_113, f32[3584]{0} %reduce.211, f32[16,3584]{1,0} %get-tuple-element.162, f32[3584]{0} %param_22, /*index=5*/f32[3584]{0} %param_112), kind=kLoop, calls=%fused_computation.104, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/add"}
  %get-tuple-element.248 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.104), index=2
  %get-tuple-element.249 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.104), index=0
  %param_25 = f32[896]{0} parameter(25), metadata={op_name="1$start"}
  %param_124 = f32[896]{0} parameter(124), metadata={op_name="1$start"}
  %param_107 = f32[3584]{0} parameter(107), metadata={op_name="1$start"}
  %param_106 = f32[3584]{0} parameter(106), metadata={op_name="1$start"}
  %get-tuple-element.159 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.104), index=1
  %fusion.103 = (f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.190, f32[3584]{0} %param_107, f32[3584]{0} %param_106, f32[3584]{0} %get-tuple-element.159, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.12, /*index=5*/f32[3584]{0} %reduce.211), kind=kLoop, calls=%fused_computation.103, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(13)/jvp(WideResNet)/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.173 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) %fusion.103), index=0
  %param_114 = f32[1,1,3584,896]{3,2,1,0} parameter(114), metadata={op_name="1$start"}
  %copy.13 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_114), metadata={op_name="1$start"}
  %cudnn-conv.12 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.173, f32[1,1,3584,896]{1,0,2,3} %copy.13), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.13 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.12), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.270 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.13)
  %fusion.102 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.270), kind=kInput, calls=%fused_computation.102.clone
  %get-tuple-element.155 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.102), index=0
  %reduce.213 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.155, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.156 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.102), index=1
  %param_24 = f32[896]{0} parameter(24), metadata={op_name="1$start"}
  %param_123 = f32[896]{0} parameter(123), metadata={op_name="1$start"}
  %fusion.97 = (f32[896]{0}, f32[896]{0}, f32[896]{0}) fusion(f32[896]{0} %param_25, f32[896]{0} %param_124, f32[896]{0} %reduce.213, f32[16,896]{1,0} %get-tuple-element.156, f32[896]{0} %param_24, /*index=5*/f32[896]{0} %param_123), kind=kLoop, calls=%fused_computation.97, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  %get-tuple-element.250 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.97), index=2
  %get-tuple-element.251 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.97), index=0
  %param_27 = f32[1792]{0} parameter(27), metadata={op_name="1$start"}
  %param_126 = f32[1792]{0} parameter(126), metadata={op_name="1$start"}
  %param_116 = f32[896]{0} parameter(116), metadata={op_name="1$start"}
  %param_115 = f32[896]{0} parameter(115), metadata={op_name="1$start"}
  %get-tuple-element.153 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}, f32[896]{0}) %fusion.97), index=1
  %fusion.96 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %param_116, f32[896]{0} %param_115, f32[896]{0} %get-tuple-element.153, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.13, f32[896]{0} %reduce.213), kind=kLoop, calls=%fused_computation.96, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_117 = f32[3,3,896,1792]{3,2,1,0} parameter(117), metadata={op_name="1$start"}
  %copy.14 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_117), metadata={op_name="1$start"}
  %cudnn-conv.13 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.96, f32[3,3,896,1792]{1,0,2,3} %copy.14), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.14 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.13), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.266 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.14)
  %fusion.95 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.266), kind=kInput, calls=%fused_computation.95.clone
  %get-tuple-element.150 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.95), index=0
  %reduce.215 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.150, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.151 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.95), index=1
  %param_26 = f32[1792]{0} parameter(26), metadata={op_name="1$start"}
  %param_125 = f32[1792]{0} parameter(125), metadata={op_name="1$start"}
  %fusion.90 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_27, f32[1792]{0} %param_126, f32[1792]{0} %reduce.215, f32[16,1792]{1,0} %get-tuple-element.151, f32[1792]{0} %param_26, /*index=5*/f32[1792]{0} %param_125), kind=kLoop, calls=%fused_computation.90, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  %get-tuple-element.252 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.90), index=2
  %get-tuple-element.253 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.90), index=0
  %param_29 = f32[3584]{0} parameter(29), metadata={op_name="1$start"}
  %param_128 = f32[3584]{0} parameter(128), metadata={op_name="1$start"}
  %param_119 = f32[1792]{0} parameter(119), metadata={op_name="1$start"}
  %param_118 = f32[1792]{0} parameter(118), metadata={op_name="1$start"}
  %get-tuple-element.148 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.90), index=1
  %fusion.89 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %param_119, f32[1792]{0} %param_118, f32[1792]{0} %get-tuple-element.148, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.14, f32[1792]{0} %reduce.215), kind=kLoop, calls=%fused_computation.89, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_120 = f32[1,1,1792,3584]{3,2,1,0} parameter(120), metadata={op_name="1$start"}
  %copy.15 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_120), metadata={op_name="1$start"}
  %cudnn-conv.14 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.89, f32[1,1,1792,3584]{1,0,2,3} %copy.15), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.15 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.14), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.262 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.15)
  %fusion.88 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.262), kind=kInput, calls=%fused_computation.88.clone
  %get-tuple-element.145 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.88), index=0
  %reduce.217 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.145, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/jvp(WideResNet)/BottleneckResNetBlock_12/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.146 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.88), index=1
  %param_28 = f32[3584]{0} parameter(28), metadata={op_name="1$start"}
  %param_127 = f32[3584]{0} parameter(127), metadata={op_name="1$start"}
  %fusion.83 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_29, f32[3584]{0} %param_128, f32[3584]{0} %reduce.217, f32[16,3584]{1,0} %get-tuple-element.146, f32[3584]{0} %param_28, /*index=5*/f32[3584]{0} %param_127), kind=kLoop, calls=%fused_computation.83, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(14)/add"}
  %get-tuple-element.254 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.83), index=2
  %get-tuple-element.255 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.83), index=0
  %param_31 = f32[1792]{0} parameter(31), metadata={op_name="1$start"}
  %param_142 = f32[1792]{0} parameter(142), metadata={op_name="1$start"}
  %param_122 = f32[3584]{0} parameter(122), metadata={op_name="1$start"}
  %param_121 = f32[3584]{0} parameter(121), metadata={op_name="1$start"}
  %get-tuple-element.143 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.83), index=1
  %fusion.192 = (f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.173, f32[3584]{0} %param_122, f32[3584]{0} %param_121, f32[3584]{0} %get-tuple-element.143, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.15, /*index=5*/f32[3584]{0} %reduce.217), kind=kInput, calls=%fused_computation.192, metadata={op_name="tuple.61"}
  %get-tuple-element.141 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) %fusion.192), index=1
  %param_129 = f32[1,1,3584,1792]{3,2,1,0} parameter(129), metadata={op_name="1$start"}
  %copy.16 = f32[1,1,3584,1792]{1,0,2,3} copy(f32[1,1,3584,1792]{3,2,1,0} %param_129), metadata={op_name="1$start"}
  %cudnn-conv.16 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.141, f32[1,1,3584,1792]{1,0,2,3} %copy.16), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.17 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.16), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.258 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.17)
  %fusion.81 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.258), kind=kInput, calls=%fused_computation.81.clone
  %get-tuple-element.138 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.81), index=0
  %reduce.221 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.138, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.139 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.81), index=1
  %param_30 = f32[1792]{0} parameter(30), metadata={op_name="1$start"}
  %param_141 = f32[1792]{0} parameter(141), metadata={op_name="1$start"}
  %fusion.76 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_31, f32[1792]{0} %param_142, f32[1792]{0} %reduce.221, f32[16,1792]{1,0} %get-tuple-element.139, f32[1792]{0} %param_30, /*index=5*/f32[1792]{0} %param_141), kind=kLoop, calls=%fused_computation.76, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  %get-tuple-element.256 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.76), index=2
  %get-tuple-element.257 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.76), index=0
  %param_33 = f32[3584]{0} parameter(33), metadata={op_name="1$start"}
  %param_144 = f32[3584]{0} parameter(144), metadata={op_name="1$start"}
  %param_131 = f32[1792]{0} parameter(131), metadata={op_name="1$start"}
  %param_130 = f32[1792]{0} parameter(130), metadata={op_name="1$start"}
  %get-tuple-element.136 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.76), index=1
  %fusion.75 = f32[16,15,15,1792]{2,1,3,0} fusion(f32[1792]{0} %param_131, f32[1792]{0} %param_130, f32[1792]{0} %get-tuple-element.136, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.17, f32[1792]{0} %reduce.221), kind=kLoop, calls=%fused_computation.75, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_132 = f32[3,3,1792,3584]{3,2,1,0} parameter(132), metadata={op_name="1$start"}
  %copy.17 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %param_132), metadata={op_name="1$start"}
  %cudnn-conv.17 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,15,15,1792]{2,1,3,0} %fusion.75, f32[3,3,1792,3584]{1,0,2,3} %copy.17), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.18 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.17), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.254 = f32[16,3584,49]{2,1,0} bitcast(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.18)
  %fusion.74 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,49]{2,1,0} %bitcast.254), kind=kInput, calls=%fused_computation.74.clone
  %get-tuple-element.133 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.74), index=0
  %reduce.223 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.133, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.134 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.74), index=1
  %param_32 = f32[3584]{0} parameter(32), metadata={op_name="1$start"}
  %param_143 = f32[3584]{0} parameter(143), metadata={op_name="1$start"}
  %fusion.69 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_33, f32[3584]{0} %param_144, f32[3584]{0} %reduce.223, f32[16,3584]{1,0} %get-tuple-element.134, f32[3584]{0} %param_32, /*index=5*/f32[3584]{0} %param_143), kind=kLoop, calls=%fused_computation.69, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  %get-tuple-element.258 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.69), index=2
  %get-tuple-element.259 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.69), index=0
  %param_35 = f32[7168]{0} parameter(35), metadata={op_name="1$start"}
  %param_146 = f32[7168]{0} parameter(146), metadata={op_name="1$start"}
  %param_134 = f32[3584]{0} parameter(134), metadata={op_name="1$start"}
  %param_133 = f32[3584]{0} parameter(133), metadata={op_name="1$start"}
  %get-tuple-element.131 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.69), index=1
  %fusion.68 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %param_134, f32[3584]{0} %param_133, f32[3584]{0} %get-tuple-element.131, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.18, f32[3584]{0} %reduce.223), kind=kLoop, calls=%fused_computation.68, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_135 = f32[1,1,3584,7168]{3,2,1,0} parameter(135), metadata={op_name="1$start"}
  %copy.18 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %param_135), metadata={op_name="1$start"}
  %cudnn-conv.18 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.68, f32[1,1,3584,7168]{1,0,2,3} %copy.18), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.19 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv.18), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.250 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.19)
  %fusion.67 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.250), kind=kInput, calls=%fused_computation.67.clone
  %get-tuple-element.128 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.67), index=0
  %reduce.225 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.128, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.129 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.67), index=1
  %param_34 = f32[7168]{0} parameter(34), metadata={op_name="1$start"}
  %param_145 = f32[7168]{0} parameter(145), metadata={op_name="1$start"}
  %fusion.62 = (f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) fusion(f32[7168]{0} %param_35, f32[7168]{0} %param_146, f32[7168]{0} %reduce.225, f32[16,7168]{1,0} %get-tuple-element.129, f32[7168]{0} %param_34, /*index=5*/f32[7168]{0} %param_145), kind=kLoop, calls=%fused_computation.62, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  %get-tuple-element.260 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.62), index=2
  %get-tuple-element.261 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.62), index=0
  %param_37 = f32[7168]{0} parameter(37), metadata={op_name="1$start"}
  %param_148 = f32[7168]{0} parameter(148), metadata={op_name="1$start"}
  %param_138 = f32[1,1,3584,7168]{3,2,1,0} parameter(138), metadata={op_name="1$start"}
  %copy.19 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %param_138), metadata={op_name="1$start"}
  %cudnn-conv.15 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.141, f32[1,1,3584,7168]{1,0,2,3} %copy.19), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.16 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv.15), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.246 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.16)
  %fusion.61 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.246), kind=kInput, calls=%fused_computation.61.clone
  %get-tuple-element.123 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.61), index=0
  %reduce.219 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.123, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/jvp(WideResNet)/BottleneckResNetBlock_13/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.124 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.61), index=1
  %param_36 = f32[7168]{0} parameter(36), metadata={op_name="1$start"}
  %param_147 = f32[7168]{0} parameter(147), metadata={op_name="1$start"}
  %fusion.56 = (f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) fusion(f32[7168]{0} %param_37, f32[7168]{0} %param_148, f32[7168]{0} %reduce.219, f32[16,7168]{1,0} %get-tuple-element.124, f32[7168]{0} %param_36, /*index=5*/f32[7168]{0} %param_147), kind=kLoop, calls=%fused_computation.56, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(15)/add"}
  %get-tuple-element.262 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.56), index=2
  %get-tuple-element.263 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.56), index=0
  %param_39 = f32[1792]{0} parameter(39), metadata={op_name="1$start"}
  %param_159 = f32[1792]{0} parameter(159), metadata={op_name="1$start"}
  %param_137 = f32[7168]{0} parameter(137), metadata={op_name="1$start"}
  %param_136 = f32[7168]{0} parameter(136), metadata={op_name="1$start"}
  %get-tuple-element.126 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.62), index=1
  %param_140 = f32[7168]{0} parameter(140), metadata={op_name="1$start"}
  %param_139 = f32[7168]{0} parameter(139), metadata={op_name="1$start"}
  %get-tuple-element.121 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.56), index=1
  %fusion.54 = f32[16,7,7,7168]{2,1,3,0} fusion(f32[7168]{0} %param_137, f32[7168]{0} %param_136, f32[7168]{0} %get-tuple-element.126, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.19, f32[7168]{0} %reduce.225, /*index=5*/f32[7168]{0} %param_140, f32[7168]{0} %param_139, f32[7168]{0} %get-tuple-element.121, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.16, f32[7168]{0} %reduce.219), kind=kLoop, calls=%fused_computation.54, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_149 = f32[1,1,7168,1792]{3,2,1,0} parameter(149), metadata={op_name="1$start"}
  %copy.20 = f32[1,1,7168,1792]{1,0,2,3} copy(f32[1,1,7168,1792]{3,2,1,0} %param_149), metadata={op_name="1$start"}
  %cudnn-conv.19 = (f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %fusion.54, f32[1,1,7168,1792]{1,0,2,3} %copy.20), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.20 = f32[16,7,7,1792]{2,1,3,0} get-tuple-element((f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.19), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.242 = f32[16,1792,49]{2,1,0} bitcast(f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.20)
  %fusion.53 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,49]{2,1,0} %bitcast.242), kind=kInput, calls=%fused_computation.53.clone
  %get-tuple-element.118 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.53), index=0
  %reduce.227 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.118, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.119 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.53), index=1
  %param_38 = f32[1792]{0} parameter(38), metadata={op_name="1$start"}
  %param_158 = f32[1792]{0} parameter(158), metadata={op_name="1$start"}
  %fusion.48 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_39, f32[1792]{0} %param_159, f32[1792]{0} %reduce.227, f32[16,1792]{1,0} %get-tuple-element.119, f32[1792]{0} %param_38, /*index=5*/f32[1792]{0} %param_158), kind=kLoop, calls=%fused_computation.48, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  %get-tuple-element.264 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.48), index=2
  %get-tuple-element.265 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.48), index=0
  %param_41 = f32[3584]{0} parameter(41), metadata={op_name="1$start"}
  %param_161 = f32[3584]{0} parameter(161), metadata={op_name="1$start"}
  %param_151 = f32[1792]{0} parameter(151), metadata={op_name="1$start"}
  %param_150 = f32[1792]{0} parameter(150), metadata={op_name="1$start"}
  %get-tuple-element.116 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.48), index=1
  %fusion.47 = f32[16,7,7,1792]{2,1,3,0} fusion(f32[1792]{0} %param_151, f32[1792]{0} %param_150, f32[1792]{0} %get-tuple-element.116, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.20, f32[1792]{0} %reduce.227), kind=kLoop, calls=%fused_computation.47, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_152 = f32[3,3,1792,3584]{3,2,1,0} parameter(152), metadata={op_name="1$start"}
  %copy.21 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %param_152), metadata={op_name="1$start"}
  %cudnn-conv.20 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,1792]{2,1,3,0} %fusion.47, f32[3,3,1792,3584]{1,0,2,3} %copy.21), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.21 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.20), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.238 = f32[16,3584,49]{2,1,0} bitcast(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.21)
  %fusion.46 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,49]{2,1,0} %bitcast.238), kind=kInput, calls=%fused_computation.46.clone
  %get-tuple-element.113 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.46), index=0
  %reduce.229 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.113, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.114 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.46), index=1
  %param_40 = f32[3584]{0} parameter(40), metadata={op_name="1$start"}
  %param_160 = f32[3584]{0} parameter(160), metadata={op_name="1$start"}
  %fusion.41 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_41, f32[3584]{0} %param_161, f32[3584]{0} %reduce.229, f32[16,3584]{1,0} %get-tuple-element.114, f32[3584]{0} %param_40, /*index=5*/f32[3584]{0} %param_160), kind=kLoop, calls=%fused_computation.41, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  %get-tuple-element.266 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.41), index=2
  %get-tuple-element.267 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.41), index=0
  %param_43 = f32[7168]{0} parameter(43), metadata={op_name="1$start"}
  %param_163 = f32[7168]{0} parameter(163), metadata={op_name="1$start"}
  %param_154 = f32[3584]{0} parameter(154), metadata={op_name="1$start"}
  %param_153 = f32[3584]{0} parameter(153), metadata={op_name="1$start"}
  %get-tuple-element.111 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.41), index=1
  %fusion.40 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %param_154, f32[3584]{0} %param_153, f32[3584]{0} %get-tuple-element.111, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.21, f32[3584]{0} %reduce.229), kind=kLoop, calls=%fused_computation.40, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_155 = f32[1,1,3584,7168]{3,2,1,0} parameter(155), metadata={op_name="1$start"}
  %copy.22 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %param_155), metadata={op_name="1$start"}
  %cudnn-conv.21 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.40, f32[1,1,3584,7168]{1,0,2,3} %copy.22), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.22 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv.21), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.234 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.22)
  %fusion.39 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.234), kind=kInput, calls=%fused_computation.39.clone
  %get-tuple-element.108 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.39), index=0
  %reduce.231 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.108, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/jvp(WideResNet)/BottleneckResNetBlock_14/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.109 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.39), index=1
  %param_42 = f32[7168]{0} parameter(42), metadata={op_name="1$start"}
  %param_162 = f32[7168]{0} parameter(162), metadata={op_name="1$start"}
  %fusion.34 = (f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) fusion(f32[7168]{0} %param_43, f32[7168]{0} %param_163, f32[7168]{0} %reduce.231, f32[16,7168]{1,0} %get-tuple-element.109, f32[7168]{0} %param_42, /*index=5*/f32[7168]{0} %param_162), kind=kLoop, calls=%fused_computation.34, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(16)/add"}
  %get-tuple-element.268 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.34), index=2
  %get-tuple-element.269 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.34), index=0
  %param_45 = f32[1792]{0} parameter(45), metadata={op_name="1$start"}
  %param_176 = f32[1792]{0} parameter(176), metadata={op_name="1$start"}
  %param_157 = f32[7168]{0} parameter(157), metadata={op_name="1$start"}
  %param_156 = f32[7168]{0} parameter(156), metadata={op_name="1$start"}
  %get-tuple-element.106 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.34), index=1
  %fusion.191 = (f32[16,7,7,7168]{3,2,1,0}, f32[16,7,7,7168]{2,1,3,0}) fusion(f32[16,7,7,7168]{2,1,3,0} %fusion.54, f32[7168]{0} %param_157, f32[7168]{0} %param_156, f32[7168]{0} %get-tuple-element.106, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.22, /*index=5*/f32[7168]{0} %reduce.231), kind=kInput, calls=%fused_computation.191, metadata={op_name="tuple.61"}
  %get-tuple-element.104 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[16,7,7,7168]{2,1,3,0}) %fusion.191), index=1
  %param_164 = f32[1,1,7168,1792]{3,2,1,0} parameter(164), metadata={op_name="1$start"}
  %copy.23 = f32[1,1,7168,1792]{1,0,2,3} copy(f32[1,1,7168,1792]{3,2,1,0} %param_164), metadata={op_name="1$start"}
  %cudnn-conv.22 = (f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.104, f32[1,1,7168,1792]{1,0,2,3} %copy.23), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.23 = f32[16,7,7,1792]{2,1,3,0} get-tuple-element((f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.22), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.230 = f32[16,1792,49]{2,1,0} bitcast(f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.23)
  %fusion.32 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,49]{2,1,0} %bitcast.230), kind=kInput, calls=%fused_computation.32.clone
  %get-tuple-element.101 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.32), index=0
  %reduce.233 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.101, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.102 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.32), index=1
  %param_44 = f32[1792]{0} parameter(44), metadata={op_name="1$start"}
  %param_175 = f32[1792]{0} parameter(175), metadata={op_name="1$start"}
  %fusion.27 = (f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_45, f32[1792]{0} %param_176, f32[1792]{0} %reduce.233, f32[16,1792]{1,0} %get-tuple-element.102, f32[1792]{0} %param_44, /*index=5*/f32[1792]{0} %param_175), kind=kLoop, calls=%fused_computation.27, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %get-tuple-element.270 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.27), index=2
  %get-tuple-element.271 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.27), index=0
  %param_47 = f32[3584]{0} parameter(47), metadata={op_name="1$start"}
  %param_178 = f32[3584]{0} parameter(178), metadata={op_name="1$start"}
  %param_166 = f32[1792]{0} parameter(166), metadata={op_name="1$start"}
  %param_165 = f32[1792]{0} parameter(165), metadata={op_name="1$start"}
  %get-tuple-element.99 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.27), index=1
  %fusion.26 = f32[16,7,7,1792]{2,1,3,0} fusion(f32[1792]{0} %param_166, f32[1792]{0} %param_165, f32[1792]{0} %get-tuple-element.99, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.23, f32[1792]{0} %reduce.233), kind=kLoop, calls=%fused_computation.26, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_167 = f32[3,3,1792,3584]{3,2,1,0} parameter(167), metadata={op_name="1$start"}
  %copy.24 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %param_167), metadata={op_name="1$start"}
  %cudnn-conv.23 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,1792]{2,1,3,0} %fusion.26, f32[3,3,1792,3584]{1,0,2,3} %copy.24), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.24 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.23), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.226 = f32[16,3584,49]{2,1,0} bitcast(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.24)
  %fusion.25 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,49]{2,1,0} %bitcast.226), kind=kInput, calls=%fused_computation.25.clone
  %get-tuple-element.96 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.25), index=0
  %reduce.235 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.96, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.97 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.25), index=1
  %param_46 = f32[3584]{0} parameter(46), metadata={op_name="1$start"}
  %param_177 = f32[3584]{0} parameter(177), metadata={op_name="1$start"}
  %fusion.20 = (f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_47, f32[3584]{0} %param_178, f32[3584]{0} %reduce.235, f32[16,3584]{1,0} %get-tuple-element.97, f32[3584]{0} %param_46, /*index=5*/f32[3584]{0} %param_177), kind=kLoop, calls=%fused_computation.20, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %get-tuple-element.272 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.20), index=2
  %get-tuple-element.273 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.20), index=0
  %param_49 = f32[7168]{0} parameter(49), metadata={op_name="1$start"}
  %param_180 = f32[7168]{0} parameter(180), metadata={op_name="1$start"}
  %param_169 = f32[3584]{0} parameter(169), metadata={op_name="1$start"}
  %param_168 = f32[3584]{0} parameter(168), metadata={op_name="1$start"}
  %get-tuple-element.94 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[3584]{0}) %fusion.20), index=1
  %fusion.19 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %param_169, f32[3584]{0} %param_168, f32[3584]{0} %get-tuple-element.94, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.24, f32[3584]{0} %reduce.235), kind=kLoop, calls=%fused_computation.19, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_170 = f32[1,1,3584,7168]{3,2,1,0} parameter(170), metadata={op_name="1$start"}
  %copy.25 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %param_170), metadata={op_name="1$start"}
  %cudnn-conv.24 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.19, f32[1,1,3584,7168]{1,0,2,3} %copy.25), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.25 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv.24), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.222 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.25)
  %fusion.18 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.222), kind=kInput, calls=%fused_computation.18.clone
  %get-tuple-element.91 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.18), index=0
  %reduce.237 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.91, f32[] %constant_535), dimensions={0}, to_apply=%region_0.1142.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/BottleneckResNetBlock_15/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.92 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.18), index=1
  %param_48 = f32[7168]{0} parameter(48), metadata={op_name="1$start"}
  %param_179 = f32[7168]{0} parameter(179), metadata={op_name="1$start"}
  %fusion.13 = (f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) fusion(f32[7168]{0} %param_49, f32[7168]{0} %param_180, f32[7168]{0} %reduce.237, f32[16,7168]{1,0} %get-tuple-element.92, f32[7168]{0} %param_48, /*index=5*/f32[7168]{0} %param_179), kind=kLoop, calls=%fused_computation.13, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %get-tuple-element.274 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.13), index=2
  %get-tuple-element.275 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.13), index=0
  %param_50 = f32[] parameter(50), metadata={op_name="1$start"}
  %bitcast.218 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.104)
  %param_172 = f32[7168]{0} parameter(172), metadata={op_name="1$start"}
  %param_171 = f32[7168]{0} parameter(171), metadata={op_name="1$start"}
  %get-tuple-element.89 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}, f32[7168]{0}) %fusion.13), index=1
  %bitcast.217 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.25)
  %fusion.12 = f32[16,7168]{1,0} fusion(f32[16,7168,49]{2,1,0} %bitcast.218, f32[7168]{0} %param_172, f32[7168]{0} %param_171, f32[7168]{0} %get-tuple-element.89, f32[16,7168,49]{2,1,0} %bitcast.217, /*index=5*/f32[7168]{0} %reduce.237), kind=kInput, calls=%fused_computation.12.clone, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/reduce_sum[axes=(1, 2)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
  %fusion.11 = f32[16,7168]{1,0} fusion(f32[16,7168]{1,0} %fusion.12), kind=kLoop, calls=%fused_computation.11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
  %param_173 = f32[7168,1024]{1,0} parameter(173), metadata={op_name="1$start"}
  %param_174 = f32[1024]{0} parameter(174), metadata={op_name="1$start"}
  %broadcast.1067 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %param_174), dimensions={1}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/Dense_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=200}
  %cublas-gemm.3 = f32[16,1024]{1,0} custom-call(f32[16,7168]{1,0} %fusion.11, f32[7168,1024]{1,0} %param_173, f32[16,1024]{1,0} %broadcast.1067), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/jvp(WideResNet)/Dense_0/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=196}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  %fusion.10 = (f32[16]{0}, s32[16]{0}) fusion(f32[16,1024]{1,0} %cublas-gemm.3), kind=kInput, calls=%fused_computation.10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce[computation=<function _compute_argminmax.<locals>.reducer_fn at 0x7f21c42cf5e0> consts=() dimensions=(1,)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %get-tuple-element = f32[16]{0} get-tuple-element((f32[16]{0}, s32[16]{0}) %fusion.10), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce_max[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %fusion.8 = f32[16]{0} fusion(f32[16,1024]{1,0} %cublas-gemm.3, f32[16]{0} %get-tuple-element), kind=kInput, calls=%fused_computation.8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce_sum[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %log.0 = f32[16]{0} log(f32[16]{0} %fusion.8), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/log" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %param_181 = s32[16]{0} parameter(181), metadata={op_name="1$start"}
  %fusion.7 = f32[16]{0} fusion(f32[16]{0} %log.0, s32[16]{0} %param_181, f32[16,1024]{1,0} %cublas-gemm.3, f32[16]{0} %get-tuple-element), kind=kInput, calls=%fused_computation.7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce_sum[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %get-tuple-element.330 = s32[16]{0} get-tuple-element((f32[16]{0}, s32[16]{0}) %fusion.10), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce[computation=<function _compute_argminmax.<locals>.reducer_fn at 0x7f21c42cf5e0> consts=() dimensions=(1,)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=183}
  %fusion.6 = (f32[], f32[]) fusion(f32[16]{0} %fusion.7, s32[16]{0} %get-tuple-element.330, s32[16]{0} %param_181), kind=kInput, calls=%fused_computation.6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/reduce_sum[axes=(0,)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=113}
  %get-tuple-element.224 = f32[] get-tuple-element((f32[], f32[]) %fusion.6), index=0
  %param_51 = f32[] parameter(51), metadata={op_name="1$start"}
  %get-tuple-element.225 = f32[] get-tuple-element((f32[], f32[]) %fusion.6), index=1
  %fusion.193 = (f32[1]{0}, f32[1]{0}) fusion(f32[] %param_50, f32[] %get-tuple-element.224, f32[] %param_51, f32[] %get-tuple-element.225), kind=kInput, calls=%horizontally_fused_computation, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %get-tuple-element.222 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}) %fusion.193), index=0
  %bitcast.204 = f32[] bitcast(f32[1]{0} %get-tuple-element.222), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %get-tuple-element.223 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}) %fusion.193), index=1
  %bitcast.205 = f32[] bitcast(f32[1]{0} %get-tuple-element.223), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %param_52 = f32[] parameter(52), metadata={op_name="1$start"}
  %param_182 = s32[] parameter(182), metadata={op_name="1$start"}
  %fusion.2 = f32[] fusion(f32[] %param_52, s32[] %param_182), kind=kLoop, calls=%fused_computation.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(1)/jit(17)/add"}
  %fusion.189 = f32[16,14,14,3584]{3,2,1,0} fusion(f32[16,14,14,3584]{2,1,3,0} %fusion.188, f32[3584]{0} %param_62, f32[3584]{0} %param_61, f32[3584]{0} %get-tuple-element.208, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.3, /*index=5*/f32[3584]{0} %reduce.193), kind=kInput, calls=%fused_computation.189, metadata={op_name="tuple.61"}
  %get-tuple-element.341 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) %fusion.124), index=1
  %get-tuple-element.342 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) %fusion.103), index=1
  %get-tuple-element.343 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) %fusion.192), index=2
  %get-tuple-element.344 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{3,2,1,0}) %fusion.192), index=0
  %fusion.190 = f32[16,7,7,7168]{3,2,1,0} fusion(f32[7168]{0} %param_137, f32[7168]{0} %param_136, f32[7168]{0} %get-tuple-element.126, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.19, f32[7168]{0} %reduce.225, /*index=5*/f32[7168]{0} %param_140, f32[7168]{0} %param_139, f32[7168]{0} %get-tuple-element.121, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.16, f32[7168]{0} %reduce.219), kind=kInput, calls=%fused_computation.190, metadata={op_name="tuple.61"}
  %get-tuple-element.346 = f32[16,7,7,7168]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[16,7,7,7168]{2,1,3,0}) %fusion.191), index=0
  ROOT %tuple.120 = (f32[896]{0}, f32[896]{0}, f32[1792]{0}, f32[1792]{0}, f32[3584]{0}, /*index=5*/f32[3584]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[3584]{0}, f32[3584]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[896]{0}, f32[896]{0}, /*index=20*/f32[1792]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[896]{0}, /*index=25*/f32[896]{0}, f32[1792]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, /*index=30*/f32[1792]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[7168]{0}, /*index=35*/f32[7168]{0}, f32[7168]{0}, f32[7168]{0}, f32[1792]{0}, f32[1792]{0}, /*index=40*/f32[3584]{0}, f32[3584]{0}, f32[7168]{0}, f32[7168]{0}, f32[1792]{0}, /*index=45*/f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[7168]{0}, f32[7168]{0}, /*index=50*/f32[], f32[], f32[], f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{3,2,1,0}, /*index=55*/f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{3,2,1,0}, f32[16,14,14,3584]{3,2,1,0}, f32[16,7,7,7168]{3,2,1,0}, f32[16,7,7,7168]{3,2,1,0}) tuple(f32[896]{0} %get-tuple-element.226, f32[896]{0} %get-tuple-element.227, f32[1792]{0} %get-tuple-element.228, f32[1792]{0} %get-tuple-element.229, f32[3584]{0} %get-tuple-element.230, /*index=5*/f32[3584]{0} %get-tuple-element.231, f32[896]{0} %get-tuple-element.232, f32[896]{0} %get-tuple-element.233, f32[1792]{0} %get-tuple-element.234, f32[1792]{0} %get-tuple-element.235, /*index=10*/f32[3584]{0} %get-tuple-element.236, f32[3584]{0} %get-tuple-element.237, f32[896]{0} %get-tuple-element.238, f32[896]{0} %get-tuple-element.239, f32[1792]{0} %get-tuple-element.240, /*index=15*/f32[1792]{0} %get-tuple-element.241, f32[3584]{0} %get-tuple-element.242, f32[3584]{0} %get-tuple-element.243, f32[896]{0} %get-tuple-element.244, f32[896]{0} %get-tuple-element.245, /*index=20*/f32[1792]{0} %get-tuple-element.246, f32[1792]{0} %get-tuple-element.247, f32[3584]{0} %get-tuple-element.248, f32[3584]{0} %get-tuple-element.249, f32[896]{0} %get-tuple-element.250, /*index=25*/f32[896]{0} %get-tuple-element.251, f32[1792]{0} %get-tuple-element.252, f32[1792]{0} %get-tuple-element.253, f32[3584]{0} %get-tuple-element.254, f32[3584]{0} %get-tuple-element.255, /*index=30*/f32[1792]{0} %get-tuple-element.256, f32[1792]{0} %get-tuple-element.257, f32[3584]{0} %get-tuple-element.258, f32[3584]{0} %get-tuple-element.259, f32[7168]{0} %get-tuple-element.260, /*index=35*/f32[7168]{0} %get-tuple-element.261, f32[7168]{0} %get-tuple-element.262, f32[7168]{0} %get-tuple-element.263, f32[1792]{0} %get-tuple-element.264, f32[1792]{0} %get-tuple-element.265, /*index=40*/f32[3584]{0} %get-tuple-element.266, f32[3584]{0} %get-tuple-element.267, f32[7168]{0} %get-tuple-element.268, f32[7168]{0} %get-tuple-element.269, f32[1792]{0} %get-tuple-element.270, /*index=45*/f32[1792]{0} %get-tuple-element.271, f32[3584]{0} %get-tuple-element.272, f32[3584]{0} %get-tuple-element.273, f32[7168]{0} %get-tuple-element.274, f32[7168]{0} %get-tuple-element.275, /*index=50*/f32[] %bitcast.204, f32[] %bitcast.205, f32[] %fusion.2, f32[16,14,14,3584]{3,2,1,0} %fusion.189, f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.341, /*index=55*/f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.342, f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.343, f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.344, f32[16,7,7,7168]{3,2,1,0} %fusion.190, f32[16,7,7,7168]{3,2,1,0} %get-tuple-element.346)
}

