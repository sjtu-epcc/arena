HloModule train_step_func_pipeshard_parallel_mesh_0-3, input_output_alias={ {0}: (0, {}, may-alias), {1}: (1, {}, may-alias), {2}: (2, {}, may-alias), {3}: (3, {}, may-alias), {4}: (4, {}, may-alias), {5}: (5, {}, may-alias), {6}: (6, {}, may-alias), {7}: (7, {}, may-alias), {8}: (8, {}, may-alias), {9}: (9, {}, may-alias), {10}: (10, {}, may-alias), {11}: (11, {}, may-alias), {12}: (12, {}, may-alias), {13}: (13, {}, may-alias), {14}: (14, {}, may-alias), {15}: (15, {}, may-alias), {16}: (16, {}, may-alias), {17}: (17, {}, may-alias), {18}: (18, {}, may-alias), {19}: (19, {}, may-alias), {20}: (20, {}, may-alias), {21}: (21, {}, may-alias), {22}: (22, {}, may-alias), {23}: (23, {}, may-alias), {24}: (24, {}, may-alias), {25}: (25, {}, may-alias), {26}: (26, {}, may-alias), {27}: (27, {}, may-alias), {28}: (28, {}, may-alias), {29}: (29, {}, may-alias), {30}: (30, {}, may-alias), {31}: (31, {}, may-alias), {32}: (32, {}, may-alias), {33}: (33, {}, may-alias), {34}: (34, {}, may-alias), {35}: (35, {}, may-alias), {36}: (36, {}, may-alias), {37}: (37, {}, may-alias), {38}: (38, {}, may-alias), {39}: (39, {}, may-alias), {40}: (40, {}, may-alias), {41}: (41, {}, may-alias), {42}: (42, {}, may-alias), {43}: (43, {}, may-alias), {44}: (44, {}, may-alias), {45}: (45, {}, may-alias), {46}: (46, {}, may-alias), {47}: (47, {}, may-alias), {48}: (48, {}, may-alias), {49}: (49, {}, may-alias), {50}: (50, {}, may-alias), {51}: (51, {}, may-alias), {52}: (52, {}, may-alias), {53}: (53, {}, may-alias), {54}: (54, {}, may-alias), {55}: (55, {}, may-alias), {56}: (56, {}, may-alias), {57}: (57, {}, may-alias), {58}: (58, {}, may-alias), {59}: (59, {}, may-alias), {60}: (60, {}, may-alias), {61}: (61, {}, may-alias), {62}: (62, {}, may-alias), {63}: (63, {}, may-alias), {64}: (64, {}, may-alias), {65}: (65, {}, may-alias), {66}: (66, {}, may-alias), {67}: (67, {}, may-alias), {68}: (68, {}, may-alias), {69}: (69, {}, may-alias), {70}: (70, {}, may-alias), {71}: (71, {}, may-alias), {72}: (72, {}, may-alias), {73}: (73, {}, may-alias), {74}: (74, {}, may-alias), {75}: (75, {}, may-alias), {76}: (76, {}, may-alias), {77}: (77, {}, may-alias), {78}: (78, {}, may-alias), {79}: (79, {}, may-alias), {80}: (80, {}, may-alias), {81}: (81, {}, may-alias), {82}: (82, {}, may-alias), {83}: (83, {}, may-alias) }, entry_computation_layout={(f32[1,1,1792,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,1792,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[3,3,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[3,3,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[3,3,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,896,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[3,3,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,896,224]{3,2,1,0},f32[224]{0},f32[224]{0},f32[3,3,224,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[1,1,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,224,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,224]{3,2,1,0},f32[224]{0},f32[224]{0},f32[3,3,224,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[1,1,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[7,7,3,224]{3,2,1,0},f32[224]{0},f32[224]{0},f32[1,1,224,224]{3,2,1,0},f32[224]{0},f32[224]{0},f32[3,3,224,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[16,14,14,3584]{3,2,1,0},f32[16,28,28,1792]{3,2,1,0},f32[1,1,1792,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[16,28,28,1792]{3,2,1,0},f32[1,1,1792,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[3,3,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[16,28,28,1792]{3,2,1,0},f32[1,1,1792,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[3,3,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[16,28,28,1792]{3,2,1,0},f32[1,1,1792,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[3,3,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[16,56,56,896]{3,2,1,0},f32[1,1,896,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[3,3,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[1,1,896,1792]{3,2,1,0},f32[1792]{0},f32[16,56,56,896]{3,2,1,0},f32[1,1,896,224]{3,2,1,0},f32[224]{0},f32[224]{0},f32[3,3,224,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[1,1,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[16,56,56,448]{3,2,1,0},f32[1,1,448,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[16,56,56,224]{3,2,1,0},f32[1,1,224,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[1,1,896,224]{3,2,1,0},f32[224]{0},f32[224]{0},f32[3,3,224,448]{3,2,1,0},f32[448]{0},f32[448]{0},f32[1,1,448,896]{3,2,1,0},f32[896]{0},s32[16,224,224,3]{3,2,1,0},f32[7,7,3,224]{3,2,1,0},f32[224]{0},f32[224]{0},f32[1,1,224,224]{3,2,1,0},f32[224]{0},f32[224]{0},f32[3,3,224,448]{3,2,1,0},f32[448]{0},f32[448]{0})->(f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[3584]{0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, /*index=15*/f32[3,3,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, /*index=20*/f32[1792]{0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=25*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=30*/f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, f32[896]{0}, /*index=35*/f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[1,1,896,448]{3,2,1,0}, /*index=40*/f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=45*/f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, /*index=50*/f32[1792]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=55*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=60*/f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, /*index=65*/f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=70*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=75*/f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=80*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0})}

%region_195.7208.3 (Arg_0.7209: f32[], Arg_1.7210: f32[]) -> pred[] {
  %Arg_0.7209 = f32[] parameter(0)
  %Arg_1.7210 = f32[] parameter(1)
  ROOT %compare.7211 = pred[] compare(f32[] %Arg_0.7209, f32[] %Arg_1.7210), direction=GE, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/ge" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
}

%region_63.4346.3 (Arg_0.4347: f32[], Arg_1.4348: f32[]) -> f32[] {
  %Arg_0.4347 = f32[] parameter(0)
  %Arg_1.4348 = f32[] parameter(1)
  ROOT %add.4349 = f32[] add(f32[] %Arg_0.4347, f32[] %Arg_1.4348), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.1 (param_0.1712: f32[16,56,56,448], param_1.2330: f32[448], param_2.1672: f32[448], param_3.1434: f32[448], param_4.1236: f32[16,56,56,448], param_5.1229: f32[448]) -> (f32[16,448], f32[16,448], f32[16,448]) {
  %param_4.1236 = f32[16,56,56,448]{2,1,3,0} parameter(4)
  %param_5.1229 = f32[448]{0} parameter(5)
  %constant_3167 = f32[] constant(1.99298465e-05)
  %broadcast.3924 = f32[448]{0} broadcast(f32[] %constant_3167), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2345 = f32[448]{0} multiply(f32[448]{0} %param_5.1229, f32[448]{0} %broadcast.3924), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3923 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.2345), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.421 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_4.1236, f32[16,56,56,448]{2,1,3,0} %broadcast.3923), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1434 = f32[448]{0} parameter(3)
  %constant_182 = f32[] constant(0)
  %broadcast.3922 = f32[448]{0} broadcast(f32[] %constant_182), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.789 = f32[448]{0} maximum(f32[448]{0} %param_3.1434, f32[448]{0} %broadcast.3922), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3165 = f32[] constant(1e-05)
  %broadcast.3921 = f32[448]{0} broadcast(f32[] %constant_3165), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1277 = f32[448]{0} add(f32[448]{0} %maximum.789, f32[448]{0} %broadcast.3921), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2324 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1277), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.521 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2324), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1672 = f32[448]{0} parameter(2)
  %bitcast.2323 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_2.1672), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2344 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.521, f32[1,1,1,448]{3,2,1,0} %bitcast.2323), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2322 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2344), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3920 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.2322), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2343 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.421, f32[16,56,56,448]{2,1,3,0} %broadcast.3920), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2330 = f32[448]{0} parameter(1)
  %broadcast.3919 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_1.2330), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1276 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2343, f32[16,56,56,448]{2,1,3,0} %broadcast.3919), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3918 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_182), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.305 = pred[16,56,56,448]{2,1,3,0} compare(f32[16,56,56,448]{2,1,3,0} %add.1276, f32[16,56,56,448]{2,1,3,0} %broadcast.3918), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1712 = f32[16,56,56,448]{2,1,3,0} parameter(0)
  %select.305 = f32[16,56,56,448]{2,1,3,0} select(pred[16,56,56,448]{2,1,3,0} %compare.305, f32[16,56,56,448]{2,1,3,0} %param_0.1712, f32[16,56,56,448]{2,1,3,0} %broadcast.3918), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %select.305), dimensions={0,3,1,2}
  %bitcast.594 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.686 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.594, f32[] %constant_182), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.2361.clone.1 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %select.305, f32[16,56,56,448]{2,1,3,0} %broadcast.3920), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.5.clone.1 = f32[16,56,56,448]{2,1,3,0} negate(f32[16,56,56,448]{2,1,3,0} %multiply.2361.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.1 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %negate.5.clone.1), dimensions={0,3,1,2}
  %bitcast.609.clone.1 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.697.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.609.clone.1, f32[] %constant_182), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.314.clone.1 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.421, f32[16,56,56,448]{2,1,3,0} %select.305), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.2 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %multiply.314.clone.1), dimensions={0,3,1,2}
  %bitcast.611.clone.1 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.2), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.699.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.611.clone.1, f32[] %constant_182), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.8 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.686, f32[16,448]{1,0} %reduce.697.clone.1, f32[16,448]{1,0} %reduce.699.clone.1)
}

%fused_computation.3 (param_0.7: f32[3,3,224,448], param_1.9: f32[3,3,224,448]) -> f32[3,3,224,448] {
  %param_1.9 = f32[3,3,224,448]{3,2,1,0} parameter(1)
  %copy.139 = f32[3,3,224,448]{1,0,2,3} copy(f32[3,3,224,448]{3,2,1,0} %param_1.9), metadata={op_name="3$start"}
  %param_0.7 = f32[3,3,224,448]{1,0,2,3} parameter(0)
  %add.30 = f32[3,3,224,448]{1,0,2,3} add(f32[3,3,224,448]{1,0,2,3} %copy.139, f32[3,3,224,448]{1,0,2,3} %param_0.7), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  ROOT %copy.138 = f32[3,3,224,448]{3,2,1,0} copy(f32[3,3,224,448]{1,0,2,3} %add.30), metadata={op_name="tuple.85"}
}

%fused_computation.5 (param_0.1723: f32[16,56,56,224], param_1.2348: f32[224], param_2.1697: f32[224], param_3.1465: f32[224], param_4.1270: f32[16,56,56,224], param_5.1272: f32[224]) -> (f32[16,224], f32[16,224], f32[16,224]) {
  %param_4.1270 = f32[16,56,56,224]{2,1,3,0} parameter(4)
  %param_5.1272 = f32[224]{0} parameter(5)
  %constant_3220 = f32[] constant(1.99298465e-05)
  %broadcast.4006 = f32[224]{0} broadcast(f32[] %constant_3220), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2383 = f32[224]{0} multiply(f32[224]{0} %param_5.1272, f32[224]{0} %broadcast.4006), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4005 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2383), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.431 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_4.1270, f32[16,56,56,224]{2,1,3,0} %broadcast.4005), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1465 = f32[224]{0} parameter(3)
  %constant_184 = f32[] constant(0)
  %broadcast.4004 = f32[224]{0} broadcast(f32[] %constant_184), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.803 = f32[224]{0} maximum(f32[224]{0} %param_3.1465, f32[224]{0} %broadcast.4004), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3218 = f32[] constant(1e-05)
  %broadcast.4003 = f32[224]{0} broadcast(f32[] %constant_3218), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1301 = f32[224]{0} add(f32[224]{0} %maximum.803, f32[224]{0} %broadcast.4003), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2366 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1301), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.535 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2366), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1697 = f32[224]{0} parameter(2)
  %bitcast.2365 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_2.1697), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2382 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.535, f32[1,1,1,224]{3,2,1,0} %bitcast.2365), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2364 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2382), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.4002 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2364), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2381 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.431, f32[16,56,56,224]{2,1,3,0} %broadcast.4002), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2348 = f32[224]{0} parameter(1)
  %broadcast.4001 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_1.2348), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1300 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2381, f32[16,56,56,224]{2,1,3,0} %broadcast.4001), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.4000 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_184), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.315 = pred[16,56,56,224]{2,1,3,0} compare(f32[16,56,56,224]{2,1,3,0} %add.1300, f32[16,56,56,224]{2,1,3,0} %broadcast.4000), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1723 = f32[16,56,56,224]{2,1,3,0} parameter(0)
  %select.315 = f32[16,56,56,224]{2,1,3,0} select(pred[16,56,56,224]{2,1,3,0} %compare.315, f32[16,56,56,224]{2,1,3,0} %param_0.1723, f32[16,56,56,224]{2,1,3,0} %broadcast.4000), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.3 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %select.315), dimensions={0,3,1,2}
  %bitcast.596 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.3), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.688 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.596, f32[] %constant_184), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.2399.clone.1 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %select.315, f32[16,56,56,224]{2,1,3,0} %broadcast.4002), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.3.clone.1 = f32[16,56,56,224]{2,1,3,0} negate(f32[16,56,56,224]{2,1,3,0} %multiply.2399.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.4 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %negate.3.clone.1), dimensions={0,3,1,2}
  %bitcast.605.clone.1 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.4), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.694.clone.1 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.605.clone.1, f32[] %constant_184), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.303.clone.1 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.431, f32[16,56,56,224]{2,1,3,0} %select.315), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.5 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %multiply.303.clone.1), dimensions={0,3,1,2}
  %bitcast.607.clone.1 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.5), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.696.clone.1 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.607.clone.1, f32[] %constant_184), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.6 = (f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) tuple(f32[16,224]{1,0} %reduce.688, f32[16,224]{1,0} %reduce.694.clone.1, f32[16,224]{1,0} %reduce.696.clone.1)
}

%fused_computation.7 (param_0.14: f32[1,1,224,224], param_1.18: f32[1,1,224,224]) -> f32[1,1,224,224] {
  %param_1.18 = f32[1,1,224,224]{3,2,1,0} parameter(1)
  %copy.141 = f32[1,1,224,224]{1,0,2,3} copy(f32[1,1,224,224]{3,2,1,0} %param_1.18), metadata={op_name="3$start"}
  %param_0.14 = f32[1,1,224,224]{1,0,2,3} parameter(0)
  %add.33 = f32[1,1,224,224]{1,0,2,3} add(f32[1,1,224,224]{1,0,2,3} %copy.141, f32[1,1,224,224]{1,0,2,3} %param_0.14), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  ROOT %copy.140 = f32[1,1,224,224]{3,2,1,0} copy(f32[1,1,224,224]{1,0,2,3} %add.33), metadata={op_name="tuple.85"}
}

%fused_computation.9 (param_0.1735: f32[16,113,113,224], param_1.2367: f32[224], param_2.1725: f32[224], param_3.1498: f32[224], param_4.1306: f32[16,112,112,224], param_5.1315: f32[224]) -> (f32[16,224], f32[16,224], f32[16,224]) {
  %param_4.1306 = f32[16,112,112,224]{2,1,3,0} parameter(4)
  %param_5.1315 = f32[224]{0} parameter(5)
  %constant_3273 = f32[] constant(4.98246163e-06)
  %broadcast.4088 = f32[224]{0} broadcast(f32[] %constant_3273), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2421 = f32[224]{0} multiply(f32[224]{0} %param_5.1315, f32[224]{0} %broadcast.4088), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4087 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2421), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.441 = f32[16,112,112,224]{2,1,3,0} subtract(f32[16,112,112,224]{2,1,3,0} %param_4.1306, f32[16,112,112,224]{2,1,3,0} %broadcast.4087), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1498 = f32[224]{0} parameter(3)
  %constant_186 = f32[] constant(0)
  %broadcast.4086 = f32[224]{0} broadcast(f32[] %constant_186), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.817 = f32[224]{0} maximum(f32[224]{0} %param_3.1498, f32[224]{0} %broadcast.4086), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3271 = f32[] constant(1e-05)
  %broadcast.4085 = f32[224]{0} broadcast(f32[] %constant_3271), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1325 = f32[224]{0} add(f32[224]{0} %maximum.817, f32[224]{0} %broadcast.4085), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2408 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1325), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.549 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2408), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1725 = f32[224]{0} parameter(2)
  %bitcast.2407 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_2.1725), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2420 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.549, f32[1,1,1,224]{3,2,1,0} %bitcast.2407), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2406 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2420), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.4084 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2406), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2419 = f32[16,112,112,224]{2,1,3,0} multiply(f32[16,112,112,224]{2,1,3,0} %subtract.441, f32[16,112,112,224]{2,1,3,0} %broadcast.4084), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2367 = f32[224]{0} parameter(1)
  %broadcast.4083 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %param_1.2367), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1324 = f32[16,112,112,224]{2,1,3,0} add(f32[16,112,112,224]{2,1,3,0} %multiply.2419, f32[16,112,112,224]{2,1,3,0} %broadcast.4083), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.4082 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[] %constant_186), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %compare.325 = pred[16,112,112,224]{2,1,3,0} compare(f32[16,112,112,224]{2,1,3,0} %add.1324, f32[16,112,112,224]{2,1,3,0} %broadcast.4082), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %param_0.1735 = f32[16,113,113,224]{2,1,3,0} parameter(0)
  %slice.31 = f32[16,112,112,224]{2,1,3,0} slice(f32[16,113,113,224]{2,1,3,0} %param_0.1735), slice={[0:16], [0:112], [0:112], [0:224]}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/slice[start_indices=(0, 0, 0, 0) limit_indices=(16, 112, 112, 224) strides=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
  %select.325 = f32[16,112,112,224]{2,1,3,0} select(pred[16,112,112,224]{2,1,3,0} %compare.325, f32[16,112,112,224]{2,1,3,0} %slice.31, f32[16,112,112,224]{2,1,3,0} %broadcast.4082), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %transpose.6 = f32[16,224,112,112]{3,2,1,0} transpose(f32[16,112,112,224]{2,1,3,0} %select.325), dimensions={0,3,1,2}
  %bitcast.598 = f32[16,224,12544]{2,1,0} bitcast(f32[16,224,112,112]{3,2,1,0} %transpose.6), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %reduce.690 = f32[16,224]{1,0} reduce(f32[16,224,12544]{2,1,0} %bitcast.598, f32[] %constant_186), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.2437.clone.1 = f32[16,112,112,224]{2,1,3,0} multiply(f32[16,112,112,224]{2,1,3,0} %select.325, f32[16,112,112,224]{2,1,3,0} %broadcast.4084), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.1.clone.1 = f32[16,112,112,224]{2,1,3,0} negate(f32[16,112,112,224]{2,1,3,0} %multiply.2437.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.7 = f32[16,224,112,112]{3,2,1,0} transpose(f32[16,112,112,224]{2,1,3,0} %negate.1.clone.1), dimensions={0,3,1,2}
  %bitcast.601.clone.1 = f32[16,224,12544]{2,1,0} bitcast(f32[16,224,112,112]{3,2,1,0} %transpose.7), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.691.clone.1 = f32[16,224]{1,0} reduce(f32[16,224,12544]{2,1,0} %bitcast.601.clone.1, f32[] %constant_186), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.292.clone.1 = f32[16,112,112,224]{2,1,3,0} multiply(f32[16,112,112,224]{2,1,3,0} %subtract.441, f32[16,112,112,224]{2,1,3,0} %select.325), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.8 = f32[16,224,112,112]{3,2,1,0} transpose(f32[16,112,112,224]{2,1,3,0} %multiply.292.clone.1), dimensions={0,3,1,2}
  %bitcast.603.clone.1 = f32[16,224,12544]{2,1,0} bitcast(f32[16,224,112,112]{3,2,1,0} %transpose.8), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.693.clone.1 = f32[16,224]{1,0} reduce(f32[16,224,12544]{2,1,0} %bitcast.603.clone.1, f32[] %constant_186), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.4 = (f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) tuple(f32[16,224]{1,0} %reduce.690, f32[16,224]{1,0} %reduce.691.clone.1, f32[16,224]{1,0} %reduce.693.clone.1)
}

%fused_computation.11 (param_0.21: f32[7,7,3,224], param_1.27: f32[7,7,3,224]) -> f32[7,7,3,224] {
  %param_1.27 = f32[7,7,3,224]{3,2,1,0} parameter(1)
  %copy.143 = f32[7,7,3,224]{1,0,2,3} copy(f32[7,7,3,224]{3,2,1,0} %param_1.27), metadata={op_name="3$start"}
  %param_0.21 = f32[7,7,3,224]{1,0,2,3} parameter(0)
  %add.36 = f32[7,7,3,224]{1,0,2,3} add(f32[7,7,3,224]{1,0,2,3} %copy.143, f32[7,7,3,224]{1,0,2,3} %param_0.21), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  ROOT %copy.142 = f32[7,7,3,224]{3,2,1,0} copy(f32[7,7,3,224]{1,0,2,3} %add.36), metadata={op_name="tuple.85"}
}

%fused_computation.12 (param_0.24: f32[224], param_1.33: f32[224], param_2.1727: f32[16,112,112,224], param_3.1500: f32[224], param_4.1308: f32[1,1,1,224], param_5.1317: f32[224], param_6.858: f32[16,113,113,224], param_7.934: f32[224]) -> f32[16,112,112,224] {
  %param_2.1727 = f32[16,112,112,224]{2,1,3,0} parameter(2)
  %param_1.33 = f32[224]{0} parameter(1)
  %constant_187 = f32[] constant(4.98246163e-06)
  %broadcast.4108 = f32[224]{0} broadcast(f32[] %constant_187), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2431 = f32[224]{0} multiply(f32[224]{0} %param_1.33, f32[224]{0} %broadcast.4108), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4107 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2431), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.443 = f32[16,112,112,224]{2,1,3,0} subtract(f32[16,112,112,224]{2,1,3,0} %param_2.1727, f32[16,112,112,224]{2,1,3,0} %broadcast.4107), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1500 = f32[224]{0} parameter(3)
  %constant_191 = f32[] constant(0)
  %broadcast.4106 = f32[224]{0} broadcast(f32[] %constant_191), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.821 = f32[224]{0} maximum(f32[224]{0} %param_3.1500, f32[224]{0} %broadcast.4106), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2992 = f32[] constant(1e-05)
  %broadcast.4105 = f32[224]{0} broadcast(f32[] %constant_2992), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1331 = f32[224]{0} add(f32[224]{0} %maximum.821, f32[224]{0} %broadcast.4105), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2420 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1331), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.553 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2420), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1317 = f32[224]{0} parameter(5)
  %bitcast.2419 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_5.1317), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2430 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.553, f32[1,1,1,224]{3,2,1,0} %bitcast.2419), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2418 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.4104 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2418), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2429 = f32[16,112,112,224]{2,1,3,0} multiply(f32[16,112,112,224]{2,1,3,0} %subtract.443, f32[16,112,112,224]{2,1,3,0} %broadcast.4104), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.934 = f32[224]{0} parameter(7)
  %broadcast.4103 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %param_7.934), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1330 = f32[16,112,112,224]{2,1,3,0} add(f32[16,112,112,224]{2,1,3,0} %multiply.2429, f32[16,112,112,224]{2,1,3,0} %broadcast.4103), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.4102 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[] %constant_191), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %compare.327 = pred[16,112,112,224]{2,1,3,0} compare(f32[16,112,112,224]{2,1,3,0} %add.1330, f32[16,112,112,224]{2,1,3,0} %broadcast.4102), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %param_6.858 = f32[16,113,113,224]{2,1,3,0} parameter(6)
  %slice.33 = f32[16,112,112,224]{2,1,3,0} slice(f32[16,113,113,224]{2,1,3,0} %param_6.858), slice={[0:16], [0:112], [0:112], [0:224]}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/slice[start_indices=(0, 0, 0, 0) limit_indices=(16, 112, 112, 224) strides=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
  %select.327 = f32[16,112,112,224]{2,1,3,0} select(pred[16,112,112,224]{2,1,3,0} %compare.327, f32[16,112,112,224]{2,1,3,0} %slice.33, f32[16,112,112,224]{2,1,3,0} %broadcast.4102), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %multiply.2427 = f32[16,112,112,224]{2,1,3,0} multiply(f32[16,112,112,224]{2,1,3,0} %select.327, f32[16,112,112,224]{2,1,3,0} %broadcast.4104), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1308 = f32[1,1,1,224]{3,2,1,0} parameter(4)
  %multiply.291 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %param_4.1308, f32[1,1,1,224]{3,2,1,0} %bitcast.2419), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.1 = f32[1,1,1,224]{3,2,1,0} divide(f32[1,1,1,224]{3,2,1,0} %rsqrt.553, f32[1,1,1,224]{3,2,1,0} %bitcast.2420), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_188 = f32[] constant(-0.5)
  %broadcast.316 = f32[1,1,1,224]{3,2,1,0} broadcast(f32[] %constant_188), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.290 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %divide.1, f32[1,1,1,224]{3,2,1,0} %broadcast.316), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.289 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %multiply.291, f32[1,1,1,224]{3,2,1,0} %multiply.290), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.600 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.289), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reshape[new_sizes=(224,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.1 = pred[224]{0} compare(f32[224]{0} %param_3.1500, f32[224]{0} %maximum.821), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_189 = f32[] constant(1)
  %broadcast.315 = f32[224]{0} broadcast(f32[] %constant_189), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/broadcast_in_dim[shape=(224,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.1 = f32[224]{0} select(pred[224]{0} %compare.1, f32[224]{0} %broadcast.315, f32[224]{0} %broadcast.4106), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.0 = pred[224]{0} compare(f32[224]{0} %broadcast.4106, f32[224]{0} %maximum.821), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_190 = f32[] constant(2)
  %broadcast.314 = f32[224]{0} broadcast(f32[] %constant_190), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.0 = f32[224]{0} select(pred[224]{0} %compare.0, f32[224]{0} %broadcast.314, f32[224]{0} %broadcast.315), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.0 = f32[224]{0} divide(f32[224]{0} %select.1, f32[224]{0} %select.0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.288 = f32[224]{0} multiply(f32[224]{0} %bitcast.600, f32[224]{0} %divide.0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_180 = f32[] constant(9.96492327e-06)
  %broadcast.312 = f32[224]{0} broadcast(f32[] %constant_180), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.287 = f32[224]{0} multiply(f32[224]{0} %multiply.288, f32[224]{0} %broadcast.312), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.311 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.287), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.286 = f32[16,112,112,224]{2,1,3,0} multiply(f32[16,112,112,224]{2,1,3,0} %param_2.1727, f32[16,112,112,224]{2,1,3,0} %broadcast.311), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.39 = f32[16,112,112,224]{2,1,3,0} add(f32[16,112,112,224]{2,1,3,0} %multiply.2427, f32[16,112,112,224]{2,1,3,0} %multiply.286), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.24 = f32[224]{0} parameter(0)
  %negate.0 = f32[224]{0} negate(f32[224]{0} %multiply.288), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.285 = f32[224]{0} multiply(f32[224]{0} %param_1.33, f32[224]{0} %broadcast.312), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.284 = f32[224]{0} multiply(f32[224]{0} %negate.0, f32[224]{0} %multiply.285), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.38 = f32[224]{0} add(f32[224]{0} %param_0.24, f32[224]{0} %multiply.284), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.283 = f32[224]{0} multiply(f32[224]{0} %add.38, f32[224]{0} %broadcast.4108), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.310 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.283), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/broadcast_in_dim[shape=(16, 112, 112, 224) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.37 = f32[16,112,112,224]{2,1,3,0} add(f32[16,112,112,224]{2,1,3,0} %add.39, f32[16,112,112,224]{2,1,3,0} %broadcast.310), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.14 (param_0.28: f32[16,224]) -> f32[1,1,1,224] {
  %param_0.28 = f32[16,224]{1,0} parameter(0)
  %constant_192 = f32[] constant(0)
  %reduce.692 = f32[224]{0} reduce(f32[16,224]{1,0} %param_0.28, f32[] %constant_192), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.602 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %reduce.692), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.18 (param_0.37: f32[224], param_1.52: f32[224], param_2.1699: f32[16,56,56,224], param_3.1467: f32[224], param_4.1272: f32[1,1,1,224], param_5.1274: f32[224], param_6.832: f32[16,56,56,224], param_7.915: f32[224]) -> f32[16,56,56,224] {
  %param_2.1699 = f32[16,56,56,224]{2,1,3,0} parameter(2)
  %param_1.52 = f32[224]{0} parameter(1)
  %constant_197 = f32[] constant(1.99298465e-05)
  %broadcast.4026 = f32[224]{0} broadcast(f32[] %constant_197), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2393 = f32[224]{0} multiply(f32[224]{0} %param_1.52, f32[224]{0} %broadcast.4026), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4025 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2393), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.433 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_2.1699, f32[16,56,56,224]{2,1,3,0} %broadcast.4025), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1467 = f32[224]{0} parameter(3)
  %constant_201 = f32[] constant(0)
  %broadcast.4024 = f32[224]{0} broadcast(f32[] %constant_201), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.807 = f32[224]{0} maximum(f32[224]{0} %param_3.1467, f32[224]{0} %broadcast.4024), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3067 = f32[] constant(1e-05)
  %broadcast.4023 = f32[224]{0} broadcast(f32[] %constant_3067), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1307 = f32[224]{0} add(f32[224]{0} %maximum.807, f32[224]{0} %broadcast.4023), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2378 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1307), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.539 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2378), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1274 = f32[224]{0} parameter(5)
  %bitcast.2377 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_5.1274), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2392 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.539, f32[1,1,1,224]{3,2,1,0} %bitcast.2377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2376 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.4022 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2376), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2391 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.433, f32[16,56,56,224]{2,1,3,0} %broadcast.4022), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.915 = f32[224]{0} parameter(7)
  %broadcast.4021 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_7.915), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1306 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2391, f32[16,56,56,224]{2,1,3,0} %broadcast.4021), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.4020 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_201), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.317 = pred[16,56,56,224]{2,1,3,0} compare(f32[16,56,56,224]{2,1,3,0} %add.1306, f32[16,56,56,224]{2,1,3,0} %broadcast.4020), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.832 = f32[16,56,56,224]{2,1,3,0} parameter(6)
  %select.317 = f32[16,56,56,224]{2,1,3,0} select(pred[16,56,56,224]{2,1,3,0} %compare.317, f32[16,56,56,224]{2,1,3,0} %param_6.832, f32[16,56,56,224]{2,1,3,0} %broadcast.4020), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.2389 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %select.317, f32[16,56,56,224]{2,1,3,0} %broadcast.4022), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1272 = f32[1,1,1,224]{3,2,1,0} parameter(4)
  %multiply.302 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %param_4.1272, f32[1,1,1,224]{3,2,1,0} %bitcast.2377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.3 = f32[1,1,1,224]{3,2,1,0} divide(f32[1,1,1,224]{3,2,1,0} %rsqrt.539, f32[1,1,1,224]{3,2,1,0} %bitcast.2378), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_198 = f32[] constant(-0.5)
  %broadcast.325 = f32[1,1,1,224]{3,2,1,0} broadcast(f32[] %constant_198), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.301 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %divide.3, f32[1,1,1,224]{3,2,1,0} %broadcast.325), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.300 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %multiply.302, f32[1,1,1,224]{3,2,1,0} %multiply.301), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.604 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.300), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reshape[new_sizes=(224,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.4 = pred[224]{0} compare(f32[224]{0} %param_3.1467, f32[224]{0} %maximum.807), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_199 = f32[] constant(1)
  %broadcast.324 = f32[224]{0} broadcast(f32[] %constant_199), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/broadcast_in_dim[shape=(224,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.4 = f32[224]{0} select(pred[224]{0} %compare.4, f32[224]{0} %broadcast.324, f32[224]{0} %broadcast.4024), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.3 = pred[224]{0} compare(f32[224]{0} %broadcast.4024, f32[224]{0} %maximum.807), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_200 = f32[] constant(2)
  %broadcast.323 = f32[224]{0} broadcast(f32[] %constant_200), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.3 = f32[224]{0} select(pred[224]{0} %compare.3, f32[224]{0} %broadcast.323, f32[224]{0} %broadcast.324), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.2 = f32[224]{0} divide(f32[224]{0} %select.4, f32[224]{0} %select.3), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.299 = f32[224]{0} multiply(f32[224]{0} %bitcast.604, f32[224]{0} %divide.2), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_196 = f32[] constant(3.98596931e-05)
  %broadcast.322 = f32[224]{0} broadcast(f32[] %constant_196), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.298 = f32[224]{0} multiply(f32[224]{0} %multiply.299, f32[224]{0} %broadcast.322), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.321 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.298), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.297 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %param_2.1699, f32[16,56,56,224]{2,1,3,0} %broadcast.321), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.42 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2389, f32[16,56,56,224]{2,1,3,0} %multiply.297), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.37 = f32[224]{0} parameter(0)
  %negate.2 = f32[224]{0} negate(f32[224]{0} %multiply.299), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.296 = f32[224]{0} multiply(f32[224]{0} %param_1.52, f32[224]{0} %broadcast.322), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.295 = f32[224]{0} multiply(f32[224]{0} %negate.2, f32[224]{0} %multiply.296), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.41 = f32[224]{0} add(f32[224]{0} %param_0.37, f32[224]{0} %multiply.295), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.294 = f32[224]{0} multiply(f32[224]{0} %add.41, f32[224]{0} %broadcast.4026), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.320 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.294), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/broadcast_in_dim[shape=(16, 56, 56, 224) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.40 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %add.42, f32[16,56,56,224]{2,1,3,0} %broadcast.320), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.20 (param_0.41: f32[16,224]) -> f32[1,1,1,224] {
  %param_0.41 = f32[16,224]{1,0} parameter(0)
  %constant_202 = f32[] constant(0)
  %reduce.695 = f32[224]{0} reduce(f32[16,224]{1,0} %param_0.41, f32[] %constant_202), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.606 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %reduce.695), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.24 (param_0.49: f32[448], param_1.70: f32[448], param_2.1674: f32[16,56,56,448], param_3.1436: f32[448], param_4.1238: f32[1,1,1,448], param_5.1231: f32[448], param_6.807: f32[16,56,56,448], param_7.897: f32[448]) -> f32[16,56,56,448] {
  %param_2.1674 = f32[16,56,56,448]{2,1,3,0} parameter(2)
  %param_1.70 = f32[448]{0} parameter(1)
  %constant_207 = f32[] constant(1.99298465e-05)
  %broadcast.3944 = f32[448]{0} broadcast(f32[] %constant_207), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2355 = f32[448]{0} multiply(f32[448]{0} %param_1.70, f32[448]{0} %broadcast.3944), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3943 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.2355), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.423 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_2.1674, f32[16,56,56,448]{2,1,3,0} %broadcast.3943), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1436 = f32[448]{0} parameter(3)
  %constant_211 = f32[] constant(0)
  %broadcast.3942 = f32[448]{0} broadcast(f32[] %constant_211), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.793 = f32[448]{0} maximum(f32[448]{0} %param_3.1436, f32[448]{0} %broadcast.3942), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3124 = f32[] constant(1e-05)
  %broadcast.3941 = f32[448]{0} broadcast(f32[] %constant_3124), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1283 = f32[448]{0} add(f32[448]{0} %maximum.793, f32[448]{0} %broadcast.3941), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2336 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1283), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.525 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2336), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1231 = f32[448]{0} parameter(5)
  %bitcast.2335 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_5.1231), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2354 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.525, f32[1,1,1,448]{3,2,1,0} %bitcast.2335), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2334 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2354), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3940 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.2334), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2353 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.423, f32[16,56,56,448]{2,1,3,0} %broadcast.3940), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.897 = f32[448]{0} parameter(7)
  %broadcast.3939 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_7.897), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1282 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2353, f32[16,56,56,448]{2,1,3,0} %broadcast.3939), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3938 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_211), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.307 = pred[16,56,56,448]{2,1,3,0} compare(f32[16,56,56,448]{2,1,3,0} %add.1282, f32[16,56,56,448]{2,1,3,0} %broadcast.3938), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.807 = f32[16,56,56,448]{2,1,3,0} parameter(6)
  %select.307 = f32[16,56,56,448]{2,1,3,0} select(pred[16,56,56,448]{2,1,3,0} %compare.307, f32[16,56,56,448]{2,1,3,0} %param_6.807, f32[16,56,56,448]{2,1,3,0} %broadcast.3938), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.2351 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %select.307, f32[16,56,56,448]{2,1,3,0} %broadcast.3940), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1238 = f32[1,1,1,448]{3,2,1,0} parameter(4)
  %multiply.313 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %param_4.1238, f32[1,1,1,448]{3,2,1,0} %bitcast.2335), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.5 = f32[1,1,1,448]{3,2,1,0} divide(f32[1,1,1,448]{3,2,1,0} %rsqrt.525, f32[1,1,1,448]{3,2,1,0} %bitcast.2336), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_208 = f32[] constant(-0.5)
  %broadcast.336 = f32[1,1,1,448]{3,2,1,0} broadcast(f32[] %constant_208), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.312 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %divide.5, f32[1,1,1,448]{3,2,1,0} %broadcast.336), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.311 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %multiply.313, f32[1,1,1,448]{3,2,1,0} %multiply.312), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.608 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.311), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.7 = pred[448]{0} compare(f32[448]{0} %param_3.1436, f32[448]{0} %maximum.793), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_209 = f32[] constant(1)
  %broadcast.335 = f32[448]{0} broadcast(f32[] %constant_209), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/broadcast_in_dim[shape=(448,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.7 = f32[448]{0} select(pred[448]{0} %compare.7, f32[448]{0} %broadcast.335, f32[448]{0} %broadcast.3942), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.6 = pred[448]{0} compare(f32[448]{0} %broadcast.3942, f32[448]{0} %maximum.793), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_210 = f32[] constant(2)
  %broadcast.334 = f32[448]{0} broadcast(f32[] %constant_210), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.6 = f32[448]{0} select(pred[448]{0} %compare.6, f32[448]{0} %broadcast.334, f32[448]{0} %broadcast.335), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.4 = f32[448]{0} divide(f32[448]{0} %select.7, f32[448]{0} %select.6), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.310 = f32[448]{0} multiply(f32[448]{0} %bitcast.608, f32[448]{0} %divide.4), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_206 = f32[] constant(3.98596931e-05)
  %broadcast.332 = f32[448]{0} broadcast(f32[] %constant_206), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.309 = f32[448]{0} multiply(f32[448]{0} %multiply.310, f32[448]{0} %broadcast.332), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.331 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.309), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.308 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %param_2.1674, f32[16,56,56,448]{2,1,3,0} %broadcast.331), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.45 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2351, f32[16,56,56,448]{2,1,3,0} %multiply.308), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.49 = f32[448]{0} parameter(0)
  %negate.4 = f32[448]{0} negate(f32[448]{0} %multiply.310), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.307 = f32[448]{0} multiply(f32[448]{0} %param_1.70, f32[448]{0} %broadcast.332), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.306 = f32[448]{0} multiply(f32[448]{0} %negate.4, f32[448]{0} %multiply.307), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.44 = f32[448]{0} add(f32[448]{0} %param_0.49, f32[448]{0} %multiply.306), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.305 = f32[448]{0} multiply(f32[448]{0} %add.44, f32[448]{0} %broadcast.3944), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.330 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.305), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/broadcast_in_dim[shape=(16, 56, 56, 448) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.43 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %add.45, f32[16,56,56,448]{2,1,3,0} %broadcast.330), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.26 (param_0.53: f32[16,448]) -> f32[1,1,1,448] {
  %param_0.53 = f32[16,448]{1,0} parameter(0)
  %constant_212 = f32[] constant(0)
  %reduce.698 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.53, f32[] %constant_212), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.610 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %reduce.698), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.33 (param_0.1694: f32[16,448], param_1.2307: f32[448]) -> f32[448] {
  %param_0.1694 = f32[16,448]{1,0} parameter(0)
  %constant_219 = f32[] constant(0)
  %reduce.700 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.1694, f32[] %constant_219), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_218 = f32[] constant(1.99298465e-05)
  %broadcast.344 = f32[448]{0} broadcast(f32[] %constant_218), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.319 = f32[448]{0} multiply(f32[448]{0} %reduce.700, f32[448]{0} %broadcast.344), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2307 = f32[448]{0} parameter(1)
  %multiply.2319 = f32[448]{0} multiply(f32[448]{0} %param_1.2307, f32[448]{0} %broadcast.344), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.318 = f32[448]{0} multiply(f32[448]{0} %multiply.2319, f32[448]{0} %multiply.2319), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.0 = f32[448]{0} subtract(f32[448]{0} %multiply.319, f32[448]{0} %multiply.318), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.38 (param_0.1691: f32[224], param_1.2305: f32[224], param_2.1636: f32[224], param_3.1403: f32[16,56,56,224], param_4.1205: f32[224]) -> f32[16,56,56,224] {
  %param_3.1403 = f32[16,56,56,224]{2,1,3,0} parameter(3)
  %param_4.1205 = f32[224]{0} parameter(4)
  %constant_3097 = f32[] constant(1.99298465e-05)
  %broadcast.3846 = f32[224]{0} broadcast(f32[] %constant_3097), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2315 = f32[224]{0} multiply(f32[224]{0} %param_4.1205, f32[224]{0} %broadcast.3846), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3845 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2315), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.411 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_3.1403, f32[16,56,56,224]{2,1,3,0} %broadcast.3845), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1636 = f32[224]{0} parameter(2)
  %constant_223 = f32[] constant(0)
  %broadcast.3844 = f32[224]{0} broadcast(f32[] %constant_223), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.769 = f32[224]{0} maximum(f32[224]{0} %param_2.1636, f32[224]{0} %broadcast.3844), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3095 = f32[] constant(1e-05)
  %broadcast.3843 = f32[224]{0} broadcast(f32[] %constant_3095), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1255 = f32[224]{0} add(f32[224]{0} %maximum.769, f32[224]{0} %broadcast.3843), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2288 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1255), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.511 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2288), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2305 = f32[224]{0} parameter(1)
  %bitcast.2287 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_1.2305), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2314 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.511, f32[1,1,1,224]{3,2,1,0} %bitcast.2287), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2286 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2314), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3842 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2286), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2313 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.411, f32[16,56,56,224]{2,1,3,0} %broadcast.3842), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1691 = f32[224]{0} parameter(0)
  %broadcast.3841 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_0.1691), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1254 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2313, f32[16,56,56,224]{2,1,3,0} %broadcast.3841), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.347 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_223), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.1 = f32[16,56,56,224]{2,1,3,0} maximum(f32[16,56,56,224]{2,1,3,0} %add.1254, f32[16,56,56,224]{2,1,3,0} %broadcast.347), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.43 (param_0.1676: f32[16,224], param_1.2282: f32[224]) -> f32[224] {
  %param_0.1676 = f32[16,224]{1,0} parameter(0)
  %constant_227 = f32[] constant(0)
  %reduce.703 = f32[224]{0} reduce(f32[16,224]{1,0} %param_0.1676, f32[] %constant_227), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_226 = f32[] constant(1.99298465e-05)
  %broadcast.352 = f32[224]{0} broadcast(f32[] %constant_226), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.325 = f32[224]{0} multiply(f32[224]{0} %reduce.703, f32[224]{0} %broadcast.352), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2282 = f32[224]{0} parameter(1)
  %multiply.2295 = f32[224]{0} multiply(f32[224]{0} %param_1.2282, f32[224]{0} %broadcast.352), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.324 = f32[224]{0} multiply(f32[224]{0} %multiply.2295, f32[224]{0} %multiply.2295), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.2 = f32[224]{0} subtract(f32[224]{0} %multiply.325, f32[224]{0} %multiply.324), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.53 (param_0.1652: f32[16,224], param_1.2247: f32[224]) -> f32[224] {
  %param_0.1652 = f32[16,224]{1,0} parameter(0)
  %constant_235 = f32[] constant(0)
  %reduce.706 = f32[224]{0} reduce(f32[16,224]{1,0} %param_0.1652, f32[] %constant_235), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_234 = f32[] constant(4.98246163e-06)
  %broadcast.360 = f32[224]{0} broadcast(f32[] %constant_234), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.331 = f32[224]{0} multiply(f32[224]{0} %reduce.706, f32[224]{0} %broadcast.360), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2247 = f32[224]{0} parameter(1)
  %multiply.2259 = f32[224]{0} multiply(f32[224]{0} %param_1.2247, f32[224]{0} %broadcast.360), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.330 = f32[224]{0} multiply(f32[224]{0} %multiply.2259, f32[224]{0} %multiply.2259), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.4 = f32[224]{0} subtract(f32[224]{0} %multiply.331, f32[224]{0} %multiply.330), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.58 (param_0.105: s32[16,224,224,3]) -> f32[16,224,224,3] {
  %param_0.105 = s32[16,224,224,3]{3,2,1,0} parameter(0)
  %convert.1 = f32[16,224,224,3]{3,2,1,0} convert(s32[16,224,224,3]{3,2,1,0} %param_0.105), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/conv_init/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/dtypes.py" source_line=97}
  ROOT %copy.144 = f32[16,224,224,3]{2,1,3,0} copy(f32[16,224,224,3]{3,2,1,0} %convert.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/conv_init/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/dtypes.py" source_line=97}
}

%fused_computation.61 (param_0.109: f32[896], param_1.1366: f32[1,1,1,896], param_2.1743: f32[896], param_3.1520: f32[16,896]) -> (f32[896], f32[896]) {
  %param_0.109 = f32[896]{0} parameter(0)
  %param_3.1520 = f32[16,896]{1,0} parameter(3)
  %constant_2829 = f32[] constant(0)
  %reduce.731.clone.1 = f32[896]{0} reduce(f32[16,896]{1,0} %param_3.1520, f32[] %constant_2829), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_2805_clone_1 = f32[] constant(1.99298465e-05)
  %broadcast.414.clone.1 = f32[896]{0} broadcast(f32[] %constant_2805_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.396.clone.1 = f32[896]{0} multiply(f32[896]{0} %reduce.731.clone.1, f32[896]{0} %broadcast.414.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1743 = f32[896]{0} parameter(2)
  %multiply.2153.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_2.1743, f32[896]{0} %broadcast.414.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.395.clone.1 = f32[896]{0} multiply(f32[896]{0} %multiply.2153.clone.1, f32[896]{0} %multiply.2153.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.7.clone.1 = f32[896]{0} subtract(f32[896]{0} %multiply.396.clone.1, f32[896]{0} %multiply.395.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.3498 = f32[896]{0} broadcast(f32[] %constant_2829), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.685 = f32[896]{0} maximum(f32[896]{0} %subtract.7.clone.1, f32[896]{0} %broadcast.3498), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2828 = f32[] constant(1e-05)
  %broadcast.3497 = f32[896]{0} broadcast(f32[] %constant_2828), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1151 = f32[896]{0} add(f32[896]{0} %maximum.685, f32[896]{0} %broadcast.3497), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2096 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1151), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.9 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2096), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1366 = f32[1,1,1,896]{3,2,1,0} parameter(1)
  %multiply.334 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.9, f32[1,1,1,896]{3,2,1,0} %param_1.1366), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.625 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.53 = f32[896]{0} add(f32[896]{0} %param_0.109, f32[896]{0} %bitcast.625), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  ROOT %tuple.22 = (f32[896]{0}, f32[896]{0}) tuple(f32[896]{0} %add.53, f32[896]{0} %subtract.7.clone.1)
}

%fused_computation.62 (param_0.112: f32[1,1,448,896], param_1.158: f32[1,1,448,896]) -> f32[1,1,448,896] {
  %param_1.158 = f32[1,1,448,896]{3,2,1,0} parameter(1)
  %copy.146 = f32[1,1,448,896]{1,0,2,3} copy(f32[1,1,448,896]{3,2,1,0} %param_1.158), metadata={op_name="3$start"}
  %param_0.112 = f32[1,1,448,896]{1,0,2,3} parameter(0)
  %add.54 = f32[1,1,448,896]{1,0,2,3} add(f32[1,1,448,896]{1,0,2,3} %copy.146, f32[1,1,448,896]{1,0,2,3} %param_0.112), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  ROOT %copy.145 = f32[1,1,448,896]{3,2,1,0} copy(f32[1,1,448,896]{1,0,2,3} %add.54), metadata={op_name="tuple.85"}
}

%fused_computation.64 (param_0.1628: f32[16,56,56,448], param_1.2205: f32[448], param_2.1500: f32[448], param_3.1274: f32[448], param_4.1093: f32[16,56,56,448], param_5.1087: f32[448]) -> (f32[16,448], f32[16,448], f32[16,448]) {
  %param_4.1093 = f32[16,56,56,448]{2,1,3,0} parameter(4)
  %param_5.1087 = f32[448]{0} parameter(5)
  %constant_2866 = f32[] constant(1.99298465e-05)
  %broadcast.3552 = f32[448]{0} broadcast(f32[] %constant_2866), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2181 = f32[448]{0} multiply(f32[448]{0} %param_5.1087, f32[448]{0} %broadcast.3552), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3551 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.2181), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.377 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_4.1093, f32[16,56,56,448]{2,1,3,0} %broadcast.3551), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1274 = f32[448]{0} parameter(3)
  %constant_242 = f32[] constant(0)
  %broadcast.3550 = f32[448]{0} broadcast(f32[] %constant_242), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.695 = f32[448]{0} maximum(f32[448]{0} %param_3.1274, f32[448]{0} %broadcast.3550), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2864 = f32[] constant(1e-05)
  %broadcast.3549 = f32[448]{0} broadcast(f32[] %constant_2864), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1167 = f32[448]{0} add(f32[448]{0} %maximum.695, f32[448]{0} %broadcast.3549), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2126 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1167), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.461 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2126), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1500 = f32[448]{0} parameter(2)
  %bitcast.2125 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_2.1500), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2180 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.461, f32[1,1,1,448]{3,2,1,0} %bitcast.2125), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2124 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2180), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3548 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.2124), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2179 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.377, f32[16,56,56,448]{2,1,3,0} %broadcast.3548), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2205 = f32[448]{0} parameter(1)
  %broadcast.3547 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_1.2205), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1166 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2179, f32[16,56,56,448]{2,1,3,0} %broadcast.3547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3546 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_242), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.285 = pred[16,56,56,448]{2,1,3,0} compare(f32[16,56,56,448]{2,1,3,0} %add.1166, f32[16,56,56,448]{2,1,3,0} %broadcast.3546), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1628 = f32[16,56,56,448]{2,1,3,0} parameter(0)
  %select.285 = f32[16,56,56,448]{2,1,3,0} select(pred[16,56,56,448]{2,1,3,0} %compare.285, f32[16,56,56,448]{2,1,3,0} %param_0.1628, f32[16,56,56,448]{2,1,3,0} %broadcast.3546), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.9 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %select.285), dimensions={0,3,1,2}
  %bitcast.626 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.9), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.712 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.626, f32[] %constant_242), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.2197.clone.1 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %select.285, f32[16,56,56,448]{2,1,3,0} %broadcast.3548), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.13.clone.1 = f32[16,56,56,448]{2,1,3,0} negate(f32[16,56,56,448]{2,1,3,0} %multiply.2197.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.10 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %negate.13.clone.1), dimensions={0,3,1,2}
  %bitcast.646.clone.1 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.10), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.725.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.646.clone.1, f32[] %constant_242), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.381.clone.1 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.377, f32[16,56,56,448]{2,1,3,0} %select.285), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.11 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %multiply.381.clone.1), dimensions={0,3,1,2}
  %bitcast.648.clone.1 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.11), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.727.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.648.clone.1, f32[] %constant_242), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.21 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.712, f32[16,448]{1,0} %reduce.725.clone.1, f32[16,448]{1,0} %reduce.727.clone.1)
}

%fused_computation.66 (param_0.119: f32[3,3,224,448], param_1.167: f32[3,3,224,448]) -> f32[3,3,224,448] {
  %param_1.167 = f32[3,3,224,448]{3,2,1,0} parameter(1)
  %copy.148 = f32[3,3,224,448]{1,0,2,3} copy(f32[3,3,224,448]{3,2,1,0} %param_1.167), metadata={op_name="3$start"}
  %param_0.119 = f32[3,3,224,448]{1,0,2,3} parameter(0)
  %add.57 = f32[3,3,224,448]{1,0,2,3} add(f32[3,3,224,448]{1,0,2,3} %copy.148, f32[3,3,224,448]{1,0,2,3} %param_0.119), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  ROOT %copy.147 = f32[3,3,224,448]{3,2,1,0} copy(f32[3,3,224,448]{1,0,2,3} %add.57), metadata={op_name="tuple.85"}
}

%fused_computation.68 (param_0.1639: f32[16,56,56,224], param_1.2223: f32[224], param_2.1525: f32[224], param_3.1305: f32[224], param_4.1127: f32[16,56,56,224], param_5.1130: f32[224]) -> (f32[16,224], f32[16,224], f32[16,224]) {
  %param_4.1127 = f32[16,56,56,224]{2,1,3,0} parameter(4)
  %param_5.1130 = f32[224]{0} parameter(5)
  %constant_2919 = f32[] constant(1.99298465e-05)
  %broadcast.3634 = f32[224]{0} broadcast(f32[] %constant_2919), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2219 = f32[224]{0} multiply(f32[224]{0} %param_5.1130, f32[224]{0} %broadcast.3634), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3633 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2219), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.387 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_4.1127, f32[16,56,56,224]{2,1,3,0} %broadcast.3633), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1305 = f32[224]{0} parameter(3)
  %constant_244 = f32[] constant(0)
  %broadcast.3632 = f32[224]{0} broadcast(f32[] %constant_244), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.709 = f32[224]{0} maximum(f32[224]{0} %param_3.1305, f32[224]{0} %broadcast.3632), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2917 = f32[] constant(1e-05)
  %broadcast.3631 = f32[224]{0} broadcast(f32[] %constant_2917), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1191 = f32[224]{0} add(f32[224]{0} %maximum.709, f32[224]{0} %broadcast.3631), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2168 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1191), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.475 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2168), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1525 = f32[224]{0} parameter(2)
  %bitcast.2167 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_2.1525), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2218 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.475, f32[1,1,1,224]{3,2,1,0} %bitcast.2167), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2166 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2218), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3630 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2166), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2217 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.387, f32[16,56,56,224]{2,1,3,0} %broadcast.3630), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2223 = f32[224]{0} parameter(1)
  %broadcast.3629 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_1.2223), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1190 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2217, f32[16,56,56,224]{2,1,3,0} %broadcast.3629), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3628 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_244), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.295 = pred[16,56,56,224]{2,1,3,0} compare(f32[16,56,56,224]{2,1,3,0} %add.1190, f32[16,56,56,224]{2,1,3,0} %broadcast.3628), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1639 = f32[16,56,56,224]{2,1,3,0} parameter(0)
  %select.295 = f32[16,56,56,224]{2,1,3,0} select(pred[16,56,56,224]{2,1,3,0} %compare.295, f32[16,56,56,224]{2,1,3,0} %param_0.1639, f32[16,56,56,224]{2,1,3,0} %broadcast.3628), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.12 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %select.295), dimensions={0,3,1,2}
  %bitcast.628 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.12), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.714 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.628, f32[] %constant_244), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.2235.clone.1 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %select.295, f32[16,56,56,224]{2,1,3,0} %broadcast.3630), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.11.clone.1 = f32[16,56,56,224]{2,1,3,0} negate(f32[16,56,56,224]{2,1,3,0} %multiply.2235.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.13 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %negate.11.clone.1), dimensions={0,3,1,2}
  %bitcast.642.clone.1 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.13), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.722.clone.1 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.642.clone.1, f32[] %constant_244), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.370.clone.1 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.387, f32[16,56,56,224]{2,1,3,0} %select.295), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.14 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %multiply.370.clone.1), dimensions={0,3,1,2}
  %bitcast.644.clone.1 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.14), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.724.clone.1 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.644.clone.1, f32[] %constant_244), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.19 = (f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) tuple(f32[16,224]{1,0} %reduce.714, f32[16,224]{1,0} %reduce.722.clone.1, f32[16,224]{1,0} %reduce.724.clone.1)
}

%fused_computation.70 (param_0.126: f32[1,1,896,224], param_1.176: f32[1,1,896,224]) -> f32[1,1,896,224] {
  %param_1.176 = f32[1,1,896,224]{3,2,1,0} parameter(1)
  %copy.150 = f32[1,1,896,224]{1,0,2,3} copy(f32[1,1,896,224]{3,2,1,0} %param_1.176), metadata={op_name="3$start"}
  %param_0.126 = f32[1,1,896,224]{1,0,2,3} parameter(0)
  %add.60 = f32[1,1,896,224]{1,0,2,3} add(f32[1,1,896,224]{1,0,2,3} %copy.150, f32[1,1,896,224]{1,0,2,3} %param_0.126), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  ROOT %copy.149 = f32[1,1,896,224]{3,2,1,0} copy(f32[1,1,896,224]{1,0,2,3} %add.60), metadata={op_name="tuple.85"}
}

%fused_computation.72 (param_0.130: f32[1,1,224,896], param_1.181: f32[1,1,224,896]) -> f32[1,1,224,896] {
  %param_1.181 = f32[1,1,224,896]{3,2,1,0} parameter(1)
  %copy.152 = f32[1,1,224,896]{1,0,2,3} copy(f32[1,1,224,896]{3,2,1,0} %param_1.181), metadata={op_name="3$start"}
  %param_0.130 = f32[1,1,224,896]{1,0,2,3} parameter(0)
  %add.62 = f32[1,1,224,896]{1,0,2,3} add(f32[1,1,224,896]{1,0,2,3} %copy.152, f32[1,1,224,896]{1,0,2,3} %param_0.130), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  ROOT %copy.151 = f32[1,1,224,896]{3,2,1,0} copy(f32[1,1,224,896]{1,0,2,3} %add.62), metadata={op_name="tuple.85"}
}

%fused_computation.75 (param_0.137: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.137 = f32[16,896]{1,0} parameter(0)
  %constant_251 = f32[] constant(0)
  %reduce.716 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.137, f32[] %constant_251), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.633 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.716), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.80 (param_0.146: f32[1,1,448,896], param_1.203: f32[1,1,448,896]) -> f32[1,1,448,896] {
  %param_1.203 = f32[1,1,448,896]{3,2,1,0} parameter(1)
  %copy.154 = f32[1,1,448,896]{1,0,2,3} copy(f32[1,1,448,896]{3,2,1,0} %param_1.203), metadata={op_name="3$start"}
  %param_0.146 = f32[1,1,448,896]{1,0,2,3} parameter(0)
  %add.67 = f32[1,1,448,896]{1,0,2,3} add(f32[1,1,448,896]{1,0,2,3} %copy.154, f32[1,1,448,896]{1,0,2,3} %param_0.146), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  ROOT %copy.153 = f32[1,1,448,896]{3,2,1,0} copy(f32[1,1,448,896]{1,0,2,3} %add.67), metadata={op_name="tuple.85"}
}

%fused_computation.81 (param_0.149: f32[896], param_1.209: f32[896], param_2.1538: f32[16,56,56,896], param_3.1318: f32[896], param_4.1138: f32[1,1,1,896], param_5.1146: f32[896], param_6.1218: f32[896], param_7.1533: f32[896], param_8.1160: f32[16,56,56,896], param_9.692: f32[896], param_10.525: f32[1,1,1,896], param_11.481: f32[896], param_12.409: f32[16,56,56,896], param_13.419: f32[896], param_14.309: f32[896]) -> (f32[16,56,56,896], f32[16,56,56,896]) {
  %param_8.1160 = f32[16,56,56,896]{2,1,3,0} parameter(8)
  %param_7.1533 = f32[896]{0} parameter(7)
  %constant_256 = f32[] constant(1.99298465e-05)
  %broadcast.4168 = f32[896]{0} broadcast(f32[] %constant_256), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2465 = f32[896]{0} multiply(f32[896]{0} %param_7.1533, f32[896]{0} %broadcast.4168), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4167 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2465), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.453 = f32[16,56,56,896]{2,1,3,0} subtract(f32[16,56,56,896]{2,1,3,0} %param_8.1160, f32[16,56,56,896]{2,1,3,0} %broadcast.4167), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_9.692 = f32[896]{0} parameter(9)
  %constant_260 = f32[] constant(0)
  %broadcast.4166 = f32[896]{0} broadcast(f32[] %constant_260), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.833 = f32[896]{0} maximum(f32[896]{0} %param_9.692, f32[896]{0} %broadcast.4166), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2603 = f32[] constant(1e-05)
  %broadcast.4165 = f32[896]{0} broadcast(f32[] %constant_2603), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1359 = f32[896]{0} add(f32[896]{0} %maximum.833, f32[896]{0} %broadcast.4165), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2456 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1359), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.565 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2456), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_11.481 = f32[896]{0} parameter(11)
  %bitcast.2455 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_11.481), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2464 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.565, f32[1,1,1,896]{3,2,1,0} %bitcast.2455), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2454 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.4164 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2454), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2463 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.453, f32[16,56,56,896]{2,1,3,0} %broadcast.4164), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_14.309 = f32[896]{0} parameter(14)
  %broadcast.4163 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %param_14.309), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1358 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2463, f32[16,56,56,896]{2,1,3,0} %broadcast.4163), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %param_2.1538 = f32[16,56,56,896]{2,1,3,0} parameter(2)
  %param_1.209 = f32[896]{0} parameter(1)
  %multiply.2462 = f32[896]{0} multiply(f32[896]{0} %param_1.209, f32[896]{0} %broadcast.4168), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4162 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2462), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.452 = f32[16,56,56,896]{2,1,3,0} subtract(f32[16,56,56,896]{2,1,3,0} %param_2.1538, f32[16,56,56,896]{2,1,3,0} %broadcast.4162), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1318 = f32[896]{0} parameter(3)
  %maximum.832 = f32[896]{0} maximum(f32[896]{0} %param_3.1318, f32[896]{0} %broadcast.4166), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1357 = f32[896]{0} add(f32[896]{0} %maximum.832, f32[896]{0} %broadcast.4165), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2453 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1357), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.564 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2453), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1146 = f32[896]{0} parameter(5)
  %bitcast.2452 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.1146), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2461 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.564, f32[1,1,1,896]{3,2,1,0} %bitcast.2452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2451 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.4161 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2451), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2460 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.452, f32[16,56,56,896]{2,1,3,0} %broadcast.4161), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_13.419 = f32[896]{0} parameter(13)
  %broadcast.4160 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %param_13.419), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1356 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2460, f32[16,56,56,896]{2,1,3,0} %broadcast.4160), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1355 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %add.1358, f32[16,56,56,896]{2,1,3,0} %add.1356), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.4159 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[] %constant_260), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.333 = pred[16,56,56,896]{2,1,3,0} compare(f32[16,56,56,896]{2,1,3,0} %add.1355, f32[16,56,56,896]{2,1,3,0} %broadcast.4159), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_12.409 = f32[16,56,56,896]{2,1,3,0} parameter(12)
  %select.333 = f32[16,56,56,896]{2,1,3,0} select(pred[16,56,56,896]{2,1,3,0} %compare.333, f32[16,56,56,896]{2,1,3,0} %param_12.409, f32[16,56,56,896]{2,1,3,0} %broadcast.4159), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %multiply.2242 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %select.333, f32[16,56,56,896]{2,1,3,0} %broadcast.4161), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1138 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.358 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.1138, f32[1,1,1,896]{3,2,1,0} %bitcast.2452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.9 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.564, f32[1,1,1,896]{3,2,1,0} %bitcast.2453), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_257 = f32[] constant(-0.5)
  %broadcast.378 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_257), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.357 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.9, f32[1,1,1,896]{3,2,1,0} %broadcast.378), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.356 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.358, f32[1,1,1,896]{3,2,1,0} %multiply.357), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.637 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.356), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.12 = pred[896]{0} compare(f32[896]{0} %param_3.1318, f32[896]{0} %maximum.832), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_258 = f32[] constant(1)
  %broadcast.377 = f32[896]{0} broadcast(f32[] %constant_258), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.12 = f32[896]{0} select(pred[896]{0} %compare.12, f32[896]{0} %broadcast.377, f32[896]{0} %broadcast.4166), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.11 = pred[896]{0} compare(f32[896]{0} %broadcast.4166, f32[896]{0} %maximum.832), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_259 = f32[] constant(2)
  %broadcast.376 = f32[896]{0} broadcast(f32[] %constant_259), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.11 = f32[896]{0} select(pred[896]{0} %compare.11, f32[896]{0} %broadcast.376, f32[896]{0} %broadcast.377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.8 = f32[896]{0} divide(f32[896]{0} %select.12, f32[896]{0} %select.11), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.355 = f32[896]{0} multiply(f32[896]{0} %bitcast.637, f32[896]{0} %divide.8), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_255 = f32[] constant(3.98596931e-05)
  %broadcast.374 = f32[896]{0} broadcast(f32[] %constant_255), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.354 = f32[896]{0} multiply(f32[896]{0} %multiply.355, f32[896]{0} %broadcast.374), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.373 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.354), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.353 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %param_2.1538, f32[16,56,56,896]{2,1,3,0} %broadcast.373), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.70 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2242, f32[16,56,56,896]{2,1,3,0} %multiply.353), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.149 = f32[896]{0} parameter(0)
  %negate.8 = f32[896]{0} negate(f32[896]{0} %multiply.355), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.352 = f32[896]{0} multiply(f32[896]{0} %param_1.209, f32[896]{0} %broadcast.374), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.351 = f32[896]{0} multiply(f32[896]{0} %negate.8, f32[896]{0} %multiply.352), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.69 = f32[896]{0} add(f32[896]{0} %param_0.149, f32[896]{0} %multiply.351), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.350 = f32[896]{0} multiply(f32[896]{0} %add.69, f32[896]{0} %broadcast.4168), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.372 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.350), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/broadcast_in_dim[shape=(16, 56, 56, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %add.68 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %add.70, f32[16,56,56,896]{2,1,3,0} %broadcast.372), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2250.clone.1 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %select.333, f32[16,56,56,896]{2,1,3,0} %broadcast.4164), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_10.525 = f32[1,1,1,896]{3,2,1,0} parameter(10)
  %multiply.346.clone.1 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_10.525, f32[1,1,1,896]{3,2,1,0} %bitcast.2455), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.7.clone.1 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.565, f32[1,1,1,896]{3,2,1,0} %bitcast.2456), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.345.clone.1 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.7.clone.1, f32[1,1,1,896]{3,2,1,0} %broadcast.378), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.344.clone.1 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.346.clone.1, f32[1,1,1,896]{3,2,1,0} %multiply.345.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.631.clone.1 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.344.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.10.clone.1 = pred[896]{0} compare(f32[896]{0} %param_9.692, f32[896]{0} %maximum.833), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.10.clone.1 = f32[896]{0} select(pred[896]{0} %compare.10.clone.1, f32[896]{0} %broadcast.377, f32[896]{0} %broadcast.4166), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.9.clone.1 = pred[896]{0} compare(f32[896]{0} %broadcast.4166, f32[896]{0} %maximum.833), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.9.clone.1 = f32[896]{0} select(pred[896]{0} %compare.9.clone.1, f32[896]{0} %broadcast.376, f32[896]{0} %broadcast.377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.6.clone.1 = f32[896]{0} divide(f32[896]{0} %select.10.clone.1, f32[896]{0} %select.9.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.343.clone.1 = f32[896]{0} multiply(f32[896]{0} %bitcast.631.clone.1, f32[896]{0} %divide.6.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.342.clone.1 = f32[896]{0} multiply(f32[896]{0} %multiply.343.clone.1, f32[896]{0} %broadcast.374), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.364.clone.1 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.342.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.341.clone.1 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %param_8.1160, f32[16,56,56,896]{2,1,3,0} %broadcast.364.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.65.clone.1 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2250.clone.1, f32[16,56,56,896]{2,1,3,0} %multiply.341.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_6.1218 = f32[896]{0} parameter(6)
  %negate.6.clone.1 = f32[896]{0} negate(f32[896]{0} %multiply.343.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.340.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_7.1533, f32[896]{0} %broadcast.374), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.339.clone.1 = f32[896]{0} multiply(f32[896]{0} %negate.6.clone.1, f32[896]{0} %multiply.340.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.64.clone.1 = f32[896]{0} add(f32[896]{0} %param_6.1218, f32[896]{0} %multiply.339.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.338.clone.1 = f32[896]{0} multiply(f32[896]{0} %add.64.clone.1, f32[896]{0} %broadcast.4168), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.363.clone.1 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.338.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/broadcast_in_dim[shape=(16, 56, 56, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %add.63.clone.1 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %add.65.clone.1, f32[16,56,56,896]{2,1,3,0} %broadcast.363.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %tuple.17 = (f32[16,56,56,896]{2,1,3,0}, f32[16,56,56,896]{2,1,3,0}) tuple(f32[16,56,56,896]{2,1,3,0} %add.68, f32[16,56,56,896]{2,1,3,0} %add.63.clone.1)
}

%fused_computation.82 (param_0.1745: f32[896], param_1.2433: f32[896], param_2.1783: f32[16,56,56,896], param_3.1587: f32[896], param_4.1391: f32[896], param_5.1364: f32[896], param_6.1216: f32[16,56,56,896], param_7.1531: f32[896], param_8.1158: f32[16,56,56,896], param_9.690: f32[896], param_10.523: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896], f32[16,896], f32[16,896]) {
  %param_6.1216 = f32[16,56,56,896]{2,1,3,0} parameter(6)
  %param_7.1531 = f32[896]{0} parameter(7)
  %constant_2588_clone_1 = f32[] constant(1.99298465e-05)
  %broadcast.4148 = f32[896]{0} broadcast(f32[] %constant_2588_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2453 = f32[896]{0} multiply(f32[896]{0} %param_7.1531, f32[896]{0} %broadcast.4148), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4147 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2453), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.449 = f32[16,56,56,896]{2,1,3,0} subtract(f32[16,56,56,896]{2,1,3,0} %param_6.1216, f32[16,56,56,896]{2,1,3,0} %broadcast.4147), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_5.1364 = f32[896]{0} parameter(5)
  %constant_263 = f32[] constant(0)
  %broadcast.4146 = f32[896]{0} broadcast(f32[] %constant_263), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.829 = f32[896]{0} maximum(f32[896]{0} %param_5.1364, f32[896]{0} %broadcast.4146), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2954 = f32[] constant(1e-05)
  %broadcast.4145 = f32[896]{0} broadcast(f32[] %constant_2954), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1349 = f32[896]{0} add(f32[896]{0} %maximum.829, f32[896]{0} %broadcast.4145), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2444 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1349), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.561 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2444), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_4.1391 = f32[896]{0} parameter(4)
  %bitcast.2443 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_4.1391), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2452 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.561, f32[1,1,1,896]{3,2,1,0} %bitcast.2443), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2442 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.4144 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2442), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2451 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.449, f32[16,56,56,896]{2,1,3,0} %broadcast.4144), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_10.523 = f32[896]{0} parameter(10)
  %broadcast.4143 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %param_10.523), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1348 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2451, f32[16,56,56,896]{2,1,3,0} %broadcast.4143), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %param_2.1783 = f32[16,56,56,896]{2,1,3,0} parameter(2)
  %param_3.1587 = f32[896]{0} parameter(3)
  %multiply.2450 = f32[896]{0} multiply(f32[896]{0} %param_3.1587, f32[896]{0} %broadcast.4148), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4142 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2450), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.448 = f32[16,56,56,896]{2,1,3,0} subtract(f32[16,56,56,896]{2,1,3,0} %param_2.1783, f32[16,56,56,896]{2,1,3,0} %broadcast.4142), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_1.2433 = f32[896]{0} parameter(1)
  %maximum.828 = f32[896]{0} maximum(f32[896]{0} %param_1.2433, f32[896]{0} %broadcast.4146), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1347 = f32[896]{0} add(f32[896]{0} %maximum.828, f32[896]{0} %broadcast.4145), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2441 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1347), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.560 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_0.1745 = f32[896]{0} parameter(0)
  %bitcast.2440 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_0.1745), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2449 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.560, f32[1,1,1,896]{3,2,1,0} %bitcast.2440), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2439 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2449), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.4141 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2439), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2448 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.448, f32[16,56,56,896]{2,1,3,0} %broadcast.4141), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_9.690 = f32[896]{0} parameter(9)
  %broadcast.4140 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %param_9.690), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1346 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2448, f32[16,56,56,896]{2,1,3,0} %broadcast.4140), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1345 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %add.1348, f32[16,56,56,896]{2,1,3,0} %add.1346), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.4139 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[] %constant_263), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.331 = pred[16,56,56,896]{2,1,3,0} compare(f32[16,56,56,896]{2,1,3,0} %add.1345, f32[16,56,56,896]{2,1,3,0} %broadcast.4139), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_8.1158 = f32[16,56,56,896]{2,1,3,0} parameter(8)
  %select.331 = f32[16,56,56,896]{2,1,3,0} select(pred[16,56,56,896]{2,1,3,0} %compare.331, f32[16,56,56,896]{2,1,3,0} %param_8.1158, f32[16,56,56,896]{2,1,3,0} %broadcast.4139), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %multiply.2246 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %select.331, f32[16,56,56,896]{2,1,3,0} %broadcast.4141), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.9 = f32[16,56,56,896]{2,1,3,0} negate(f32[16,56,56,896]{2,1,3,0} %multiply.2246), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.15 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %negate.9), dimensions={0,3,1,2}
  %bitcast.638 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.15), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.719 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.638, f32[] %constant_263), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.359.clone.1 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.448, f32[16,56,56,896]{2,1,3,0} %select.331), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.16 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %multiply.359.clone.1), dimensions={0,3,1,2}
  %bitcast.640.clone.1 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.16), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.721.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.640.clone.1, f32[] %constant_263), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.2254.clone.1 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %select.331, f32[16,56,56,896]{2,1,3,0} %broadcast.4144), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.7.clone.1 = f32[16,56,56,896]{2,1,3,0} negate(f32[16,56,56,896]{2,1,3,0} %multiply.2254.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.17 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %negate.7.clone.1), dimensions={0,3,1,2}
  %bitcast.632.clone.1 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.17), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.715.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.632.clone.1, f32[] %constant_263), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.347.clone.1 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.449, f32[16,56,56,896]{2,1,3,0} %select.331), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.18 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %multiply.347.clone.1), dimensions={0,3,1,2}
  %bitcast.634.clone.1 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.18), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.717.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.634.clone.1, f32[] %constant_263), dimensions={2}, to_apply=%region_63.4346.3
  %transpose.19 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %select.331), dimensions={0,3,1,2}
  %bitcast.635.clone.1 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.19), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.718.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.635.clone.1, f32[] %constant_263), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.16 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.719, f32[16,896]{1,0} %reduce.721.clone.1, f32[16,896]{1,0} %reduce.715.clone.1, f32[16,896]{1,0} %reduce.717.clone.1, f32[16,896]{1,0} %reduce.718.clone.1)
}

%fused_computation.83 (param_0.153: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.153 = f32[16,896]{1,0} parameter(0)
  %constant_261 = f32[] constant(0)
  %reduce.720 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.153, f32[] %constant_261), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.639 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.720), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.87 (param_0.161: f32[224], param_1.227: f32[224], param_2.1527: f32[16,56,56,224], param_3.1307: f32[224], param_4.1129: f32[1,1,1,224], param_5.1132: f32[224], param_6.762: f32[16,56,56,224], param_7.846: f32[224]) -> f32[16,56,56,224] {
  %param_2.1527 = f32[16,56,56,224]{2,1,3,0} parameter(2)
  %param_1.227 = f32[224]{0} parameter(1)
  %constant_266 = f32[] constant(1.99298465e-05)
  %broadcast.3654 = f32[224]{0} broadcast(f32[] %constant_266), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2229 = f32[224]{0} multiply(f32[224]{0} %param_1.227, f32[224]{0} %broadcast.3654), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3653 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2229), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.389 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_2.1527, f32[16,56,56,224]{2,1,3,0} %broadcast.3653), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1307 = f32[224]{0} parameter(3)
  %constant_270 = f32[] constant(0)
  %broadcast.3652 = f32[224]{0} broadcast(f32[] %constant_270), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.713 = f32[224]{0} maximum(f32[224]{0} %param_3.1307, f32[224]{0} %broadcast.3652), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2715 = f32[] constant(1e-05)
  %broadcast.3651 = f32[224]{0} broadcast(f32[] %constant_2715), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1197 = f32[224]{0} add(f32[224]{0} %maximum.713, f32[224]{0} %broadcast.3651), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2180 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1197), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.479 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2180), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1132 = f32[224]{0} parameter(5)
  %bitcast.2179 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_5.1132), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2228 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.479, f32[1,1,1,224]{3,2,1,0} %bitcast.2179), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2178 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2228), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3650 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2178), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2227 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.389, f32[16,56,56,224]{2,1,3,0} %broadcast.3650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.846 = f32[224]{0} parameter(7)
  %broadcast.3649 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_7.846), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1196 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2227, f32[16,56,56,224]{2,1,3,0} %broadcast.3649), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3648 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_270), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.297 = pred[16,56,56,224]{2,1,3,0} compare(f32[16,56,56,224]{2,1,3,0} %add.1196, f32[16,56,56,224]{2,1,3,0} %broadcast.3648), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.762 = f32[16,56,56,224]{2,1,3,0} parameter(6)
  %select.297 = f32[16,56,56,224]{2,1,3,0} select(pred[16,56,56,224]{2,1,3,0} %compare.297, f32[16,56,56,224]{2,1,3,0} %param_6.762, f32[16,56,56,224]{2,1,3,0} %broadcast.3648), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.2225 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %select.297, f32[16,56,56,224]{2,1,3,0} %broadcast.3650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1129 = f32[1,1,1,224]{3,2,1,0} parameter(4)
  %multiply.369 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %param_4.1129, f32[1,1,1,224]{3,2,1,0} %bitcast.2179), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.11 = f32[1,1,1,224]{3,2,1,0} divide(f32[1,1,1,224]{3,2,1,0} %rsqrt.479, f32[1,1,1,224]{3,2,1,0} %bitcast.2180), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_267 = f32[] constant(-0.5)
  %broadcast.387 = f32[1,1,1,224]{3,2,1,0} broadcast(f32[] %constant_267), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.368 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %divide.11, f32[1,1,1,224]{3,2,1,0} %broadcast.387), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.367 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %multiply.369, f32[1,1,1,224]{3,2,1,0} %multiply.368), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.641 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.367), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reshape[new_sizes=(224,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.15 = pred[224]{0} compare(f32[224]{0} %param_3.1307, f32[224]{0} %maximum.713), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_268 = f32[] constant(1)
  %broadcast.386 = f32[224]{0} broadcast(f32[] %constant_268), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/broadcast_in_dim[shape=(224,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.15 = f32[224]{0} select(pred[224]{0} %compare.15, f32[224]{0} %broadcast.386, f32[224]{0} %broadcast.3652), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.14 = pred[224]{0} compare(f32[224]{0} %broadcast.3652, f32[224]{0} %maximum.713), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_269 = f32[] constant(2)
  %broadcast.385 = f32[224]{0} broadcast(f32[] %constant_269), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.14 = f32[224]{0} select(pred[224]{0} %compare.14, f32[224]{0} %broadcast.385, f32[224]{0} %broadcast.386), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.10 = f32[224]{0} divide(f32[224]{0} %select.15, f32[224]{0} %select.14), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.366 = f32[224]{0} multiply(f32[224]{0} %bitcast.641, f32[224]{0} %divide.10), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_265 = f32[] constant(3.98596931e-05)
  %broadcast.384 = f32[224]{0} broadcast(f32[] %constant_265), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.365 = f32[224]{0} multiply(f32[224]{0} %multiply.366, f32[224]{0} %broadcast.384), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.383 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.365), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.364 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %param_2.1527, f32[16,56,56,224]{2,1,3,0} %broadcast.383), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.73 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2225, f32[16,56,56,224]{2,1,3,0} %multiply.364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.161 = f32[224]{0} parameter(0)
  %negate.10 = f32[224]{0} negate(f32[224]{0} %multiply.366), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.363 = f32[224]{0} multiply(f32[224]{0} %param_1.227, f32[224]{0} %broadcast.384), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.362 = f32[224]{0} multiply(f32[224]{0} %negate.10, f32[224]{0} %multiply.363), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.72 = f32[224]{0} add(f32[224]{0} %param_0.161, f32[224]{0} %multiply.362), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.361 = f32[224]{0} multiply(f32[224]{0} %add.72, f32[224]{0} %broadcast.3654), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.382 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.361), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/broadcast_in_dim[shape=(16, 56, 56, 224) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.71 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %add.73, f32[16,56,56,224]{2,1,3,0} %broadcast.382), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.89 (param_0.165: f32[16,224]) -> f32[1,1,1,224] {
  %param_0.165 = f32[16,224]{1,0} parameter(0)
  %constant_271 = f32[] constant(0)
  %reduce.723 = f32[224]{0} reduce(f32[16,224]{1,0} %param_0.165, f32[] %constant_271), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.643 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %reduce.723), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.93 (param_0.173: f32[448], param_1.245: f32[448], param_2.1502: f32[16,56,56,448], param_3.1276: f32[448], param_4.1095: f32[1,1,1,448], param_5.1089: f32[448], param_6.737: f32[16,56,56,448], param_7.828: f32[448]) -> f32[16,56,56,448] {
  %param_2.1502 = f32[16,56,56,448]{2,1,3,0} parameter(2)
  %param_1.245 = f32[448]{0} parameter(1)
  %constant_276 = f32[] constant(1.99298465e-05)
  %broadcast.3572 = f32[448]{0} broadcast(f32[] %constant_276), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2191 = f32[448]{0} multiply(f32[448]{0} %param_1.245, f32[448]{0} %broadcast.3572), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3571 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.2191), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.379 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_2.1502, f32[16,56,56,448]{2,1,3,0} %broadcast.3571), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1276 = f32[448]{0} parameter(3)
  %constant_280 = f32[] constant(0)
  %broadcast.3570 = f32[448]{0} broadcast(f32[] %constant_280), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.699 = f32[448]{0} maximum(f32[448]{0} %param_3.1276, f32[448]{0} %broadcast.3570), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2772 = f32[] constant(1e-05)
  %broadcast.3569 = f32[448]{0} broadcast(f32[] %constant_2772), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1173 = f32[448]{0} add(f32[448]{0} %maximum.699, f32[448]{0} %broadcast.3569), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2138 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1173), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.465 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2138), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1089 = f32[448]{0} parameter(5)
  %bitcast.2137 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_5.1089), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2190 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.465, f32[1,1,1,448]{3,2,1,0} %bitcast.2137), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2136 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2190), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3568 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.2136), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2189 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.379, f32[16,56,56,448]{2,1,3,0} %broadcast.3568), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.828 = f32[448]{0} parameter(7)
  %broadcast.3567 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_7.828), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1172 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2189, f32[16,56,56,448]{2,1,3,0} %broadcast.3567), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3566 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_280), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.287 = pred[16,56,56,448]{2,1,3,0} compare(f32[16,56,56,448]{2,1,3,0} %add.1172, f32[16,56,56,448]{2,1,3,0} %broadcast.3566), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.737 = f32[16,56,56,448]{2,1,3,0} parameter(6)
  %select.287 = f32[16,56,56,448]{2,1,3,0} select(pred[16,56,56,448]{2,1,3,0} %compare.287, f32[16,56,56,448]{2,1,3,0} %param_6.737, f32[16,56,56,448]{2,1,3,0} %broadcast.3566), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.2187 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %select.287, f32[16,56,56,448]{2,1,3,0} %broadcast.3568), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1095 = f32[1,1,1,448]{3,2,1,0} parameter(4)
  %multiply.380 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %param_4.1095, f32[1,1,1,448]{3,2,1,0} %bitcast.2137), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.13 = f32[1,1,1,448]{3,2,1,0} divide(f32[1,1,1,448]{3,2,1,0} %rsqrt.465, f32[1,1,1,448]{3,2,1,0} %bitcast.2138), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_277 = f32[] constant(-0.5)
  %broadcast.398 = f32[1,1,1,448]{3,2,1,0} broadcast(f32[] %constant_277), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.379 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %divide.13, f32[1,1,1,448]{3,2,1,0} %broadcast.398), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.378 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %multiply.380, f32[1,1,1,448]{3,2,1,0} %multiply.379), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.645 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.378), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.18 = pred[448]{0} compare(f32[448]{0} %param_3.1276, f32[448]{0} %maximum.699), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_278 = f32[] constant(1)
  %broadcast.397 = f32[448]{0} broadcast(f32[] %constant_278), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/broadcast_in_dim[shape=(448,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.18 = f32[448]{0} select(pred[448]{0} %compare.18, f32[448]{0} %broadcast.397, f32[448]{0} %broadcast.3570), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.17 = pred[448]{0} compare(f32[448]{0} %broadcast.3570, f32[448]{0} %maximum.699), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_279 = f32[] constant(2)
  %broadcast.396 = f32[448]{0} broadcast(f32[] %constant_279), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.17 = f32[448]{0} select(pred[448]{0} %compare.17, f32[448]{0} %broadcast.396, f32[448]{0} %broadcast.397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.12 = f32[448]{0} divide(f32[448]{0} %select.18, f32[448]{0} %select.17), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.377 = f32[448]{0} multiply(f32[448]{0} %bitcast.645, f32[448]{0} %divide.12), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_275 = f32[] constant(3.98596931e-05)
  %broadcast.394 = f32[448]{0} broadcast(f32[] %constant_275), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.376 = f32[448]{0} multiply(f32[448]{0} %multiply.377, f32[448]{0} %broadcast.394), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.393 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.376), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.375 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %param_2.1502, f32[16,56,56,448]{2,1,3,0} %broadcast.393), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.76 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2187, f32[16,56,56,448]{2,1,3,0} %multiply.375), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.173 = f32[448]{0} parameter(0)
  %negate.12 = f32[448]{0} negate(f32[448]{0} %multiply.377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.374 = f32[448]{0} multiply(f32[448]{0} %param_1.245, f32[448]{0} %broadcast.394), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.373 = f32[448]{0} multiply(f32[448]{0} %negate.12, f32[448]{0} %multiply.374), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.75 = f32[448]{0} add(f32[448]{0} %param_0.173, f32[448]{0} %multiply.373), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.372 = f32[448]{0} multiply(f32[448]{0} %add.75, f32[448]{0} %broadcast.3572), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.392 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.372), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/broadcast_in_dim[shape=(16, 56, 56, 448) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.74 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %add.76, f32[16,56,56,448]{2,1,3,0} %broadcast.392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.95 (param_0.177: f32[16,448]) -> f32[1,1,1,448] {
  %param_0.177 = f32[16,448]{1,0} parameter(0)
  %constant_281 = f32[] constant(0)
  %reduce.726 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.177, f32[] %constant_281), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.647 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %reduce.726), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.99 (param_0.185: f32[896], param_1.263: f32[896], param_2.1479: f32[16,56,56,896], param_3.1251: f32[896], param_4.1069: f32[1,1,1,896], param_5.1059: f32[896], param_6.717: f32[16,56,56,896]) -> f32[16,56,56,896] {
  %param_6.717 = f32[16,56,56,896]{2,1,3,0} parameter(6)
  %param_3.1251 = f32[896]{0} parameter(3)
  %constant_290 = f32[] constant(0)
  %broadcast.3504 = f32[896]{0} broadcast(f32[] %constant_290), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.687 = f32[896]{0} maximum(f32[896]{0} %param_3.1251, f32[896]{0} %broadcast.3504), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2823 = f32[] constant(1e-05)
  %broadcast.3503 = f32[896]{0} broadcast(f32[] %constant_2823), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1153 = f32[896]{0} add(f32[896]{0} %maximum.687, f32[896]{0} %broadcast.3503), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2102 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1153), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.453 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2102), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1059 = f32[896]{0} parameter(5)
  %bitcast.2101 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.1059), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2159 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.453, f32[1,1,1,896]{3,2,1,0} %bitcast.2101), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2100 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2159), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3502 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2100), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2158 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %param_6.717, f32[16,56,56,896]{2,1,3,0} %broadcast.3502), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.1479 = f32[16,56,56,896]{2,1,3,0} parameter(2)
  %param_4.1069 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.391 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.1069, f32[1,1,1,896]{3,2,1,0} %bitcast.2101), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.15 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.453, f32[1,1,1,896]{3,2,1,0} %bitcast.2102), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_287 = f32[] constant(-0.5)
  %broadcast.408 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_287), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.390 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.15, f32[1,1,1,896]{3,2,1,0} %broadcast.408), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.389 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.391, f32[1,1,1,896]{3,2,1,0} %multiply.390), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.649 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.389), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.21 = pred[896]{0} compare(f32[896]{0} %param_3.1251, f32[896]{0} %maximum.687), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_288 = f32[] constant(1)
  %broadcast.407 = f32[896]{0} broadcast(f32[] %constant_288), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.21 = f32[896]{0} select(pred[896]{0} %compare.21, f32[896]{0} %broadcast.407, f32[896]{0} %broadcast.3504), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.20 = pred[896]{0} compare(f32[896]{0} %broadcast.3504, f32[896]{0} %maximum.687), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_289 = f32[] constant(2)
  %broadcast.406 = f32[896]{0} broadcast(f32[] %constant_289), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.20 = f32[896]{0} select(pred[896]{0} %compare.20, f32[896]{0} %broadcast.406, f32[896]{0} %broadcast.407), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.14 = f32[896]{0} divide(f32[896]{0} %select.21, f32[896]{0} %select.20), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.388 = f32[896]{0} multiply(f32[896]{0} %bitcast.649, f32[896]{0} %divide.14), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_285 = f32[] constant(3.98596931e-05)
  %broadcast.404 = f32[896]{0} broadcast(f32[] %constant_285), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.387 = f32[896]{0} multiply(f32[896]{0} %multiply.388, f32[896]{0} %broadcast.404), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.403 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.387), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.386 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %param_2.1479, f32[16,56,56,896]{2,1,3,0} %broadcast.403), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.79 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2158, f32[16,56,56,896]{2,1,3,0} %multiply.386), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.185 = f32[896]{0} parameter(0)
  %negate.14 = f32[896]{0} negate(f32[896]{0} %multiply.388), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.263 = f32[896]{0} parameter(1)
  %multiply.385 = f32[896]{0} multiply(f32[896]{0} %param_1.263, f32[896]{0} %broadcast.404), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.384 = f32[896]{0} multiply(f32[896]{0} %negate.14, f32[896]{0} %multiply.385), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.78 = f32[896]{0} add(f32[896]{0} %param_0.185, f32[896]{0} %multiply.384), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_286 = f32[] constant(1.99298465e-05)
  %broadcast.405 = f32[896]{0} broadcast(f32[] %constant_286), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.383 = f32[896]{0} multiply(f32[896]{0} %add.78, f32[896]{0} %broadcast.405), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.402 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.383), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/broadcast_in_dim[shape=(16, 56, 56, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.77 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %add.79, f32[16,56,56,896]{2,1,3,0} %broadcast.402), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.100 (param_0.1621: f32[16,56,56,896], param_1.2195: f32[896], param_2.1486: f32[896]) -> (f32[16,896], f32[16,896]) {
  %param_0.1621 = f32[16,56,56,896]{2,1,3,0} parameter(0)
  %param_2.1486 = f32[896]{0} parameter(2)
  %constant_293 = f32[] constant(0)
  %broadcast.3510 = f32[896]{0} broadcast(f32[] %constant_293), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.689 = f32[896]{0} maximum(f32[896]{0} %param_2.1486, f32[896]{0} %broadcast.3510), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2838 = f32[] constant(1e-05)
  %broadcast.3509 = f32[896]{0} broadcast(f32[] %constant_2838), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1155 = f32[896]{0} add(f32[896]{0} %maximum.689, f32[896]{0} %broadcast.3509), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2108 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1155), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.455 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2108), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2195 = f32[896]{0} parameter(1)
  %bitcast.2107 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.2195), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2163 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.455, f32[1,1,1,896]{3,2,1,0} %bitcast.2107), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2106 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2163), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3508 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2106), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2162 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %param_0.1621, f32[16,56,56,896]{2,1,3,0} %broadcast.3508), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.15 = f32[16,56,56,896]{2,1,3,0} negate(f32[16,56,56,896]{2,1,3,0} %multiply.2162), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.20 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %negate.15), dimensions={0,3,1,2}
  %bitcast.650 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.20), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.728 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.650, f32[] %constant_293), dimensions={2}, to_apply=%region_63.4346.3
  %transpose.21 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %param_0.1621), dimensions={0,3,1,2}
  %bitcast.624.clone.1 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.21), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %reduce.710.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.624.clone.1, f32[] %constant_293), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.24 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.728, f32[16,896]{1,0} %reduce.710.clone.1)
}

%fused_computation.101 (param_0.189: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.189 = f32[16,896]{1,0} parameter(0)
  %constant_291 = f32[] constant(0)
  %reduce.729 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.189, f32[] %constant_291), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.651 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.729), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.110 (param_0.1609: f32[448], param_1.2185: f32[448], param_2.1468: f32[448], param_3.1240: f32[16,56,56,448], param_4.1067: f32[448]) -> f32[16,56,56,448] {
  %param_3.1240 = f32[16,56,56,448]{2,1,3,0} parameter(3)
  %param_4.1067 = f32[448]{0} parameter(4)
  %constant_2802 = f32[] constant(1.99298465e-05)
  %broadcast.3478 = f32[448]{0} broadcast(f32[] %constant_2802), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2151 = f32[448]{0} multiply(f32[448]{0} %param_4.1067, f32[448]{0} %broadcast.3478), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3477 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.2151), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.371 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_3.1240, f32[16,56,56,448]{2,1,3,0} %broadcast.3477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1468 = f32[448]{0} parameter(2)
  %constant_301 = f32[] constant(0)
  %broadcast.3476 = f32[448]{0} broadcast(f32[] %constant_301), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.675 = f32[448]{0} maximum(f32[448]{0} %param_2.1468, f32[448]{0} %broadcast.3476), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2800 = f32[] constant(1e-05)
  %broadcast.3475 = f32[448]{0} broadcast(f32[] %constant_2800), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1145 = f32[448]{0} add(f32[448]{0} %maximum.675, f32[448]{0} %broadcast.3475), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2090 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1145), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.451 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2090), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2185 = f32[448]{0} parameter(1)
  %bitcast.2089 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_1.2185), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2150 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.451, f32[1,1,1,448]{3,2,1,0} %bitcast.2089), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2088 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2150), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3474 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.2088), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2149 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.371, f32[16,56,56,448]{2,1,3,0} %broadcast.3474), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1609 = f32[448]{0} parameter(0)
  %broadcast.3473 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_0.1609), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1144 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2149, f32[16,56,56,448]{2,1,3,0} %broadcast.3473), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.416 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_301), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.6 = f32[16,56,56,448]{2,1,3,0} maximum(f32[16,56,56,448]{2,1,3,0} %add.1144, f32[16,56,56,448]{2,1,3,0} %broadcast.416), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.115 (param_0.1594: f32[16,448], param_1.2162: f32[448]) -> f32[448] {
  %param_0.1594 = f32[16,448]{1,0} parameter(0)
  %constant_305 = f32[] constant(0)
  %reduce.734 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.1594, f32[] %constant_305), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_304 = f32[] constant(1.99298465e-05)
  %broadcast.421 = f32[448]{0} broadcast(f32[] %constant_304), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.402 = f32[448]{0} multiply(f32[448]{0} %reduce.734, f32[448]{0} %broadcast.421), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2162 = f32[448]{0} parameter(1)
  %multiply.2131 = f32[448]{0} multiply(f32[448]{0} %param_1.2162, f32[448]{0} %broadcast.421), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.401 = f32[448]{0} multiply(f32[448]{0} %multiply.2131, f32[448]{0} %multiply.2131), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.8 = f32[448]{0} subtract(f32[448]{0} %multiply.402, f32[448]{0} %multiply.401), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.120 (param_0.1591: f32[224], param_1.2160: f32[224], param_2.1434: f32[224], param_3.1209: f32[16,56,56,224], param_4.1042: f32[224]) -> f32[16,56,56,224] {
  %param_3.1209 = f32[16,56,56,224]{2,1,3,0} parameter(3)
  %param_4.1042 = f32[224]{0} parameter(4)
  %constant_2745 = f32[] constant(1.99298465e-05)
  %broadcast.3418 = f32[224]{0} broadcast(f32[] %constant_2745), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2127 = f32[224]{0} multiply(f32[224]{0} %param_4.1042, f32[224]{0} %broadcast.3418), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3417 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2127), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.363 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_3.1209, f32[16,56,56,224]{2,1,3,0} %broadcast.3417), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1434 = f32[224]{0} parameter(2)
  %constant_309 = f32[] constant(0)
  %broadcast.3416 = f32[224]{0} broadcast(f32[] %constant_309), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.657 = f32[224]{0} maximum(f32[224]{0} %param_2.1434, f32[224]{0} %broadcast.3416), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2743 = f32[] constant(1e-05)
  %broadcast.3415 = f32[224]{0} broadcast(f32[] %constant_2743), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1127 = f32[224]{0} add(f32[224]{0} %maximum.657, f32[224]{0} %broadcast.3415), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2060 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1127), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.443 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2060), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2160 = f32[224]{0} parameter(1)
  %bitcast.2059 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_1.2160), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2126 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.443, f32[1,1,1,224]{3,2,1,0} %bitcast.2059), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2058 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2126), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3414 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2058), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2125 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.363, f32[16,56,56,224]{2,1,3,0} %broadcast.3414), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1591 = f32[224]{0} parameter(0)
  %broadcast.3413 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_0.1591), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1126 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2125, f32[16,56,56,224]{2,1,3,0} %broadcast.3413), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.424 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_309), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.8 = f32[16,56,56,224]{2,1,3,0} maximum(f32[16,56,56,224]{2,1,3,0} %add.1126, f32[16,56,56,224]{2,1,3,0} %broadcast.424), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.125 (param_0.1576: f32[16,224], param_1.2137: f32[224]) -> f32[224] {
  %param_0.1576 = f32[16,224]{1,0} parameter(0)
  %constant_313 = f32[] constant(0)
  %reduce.737 = f32[224]{0} reduce(f32[16,224]{1,0} %param_0.1576, f32[] %constant_313), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_312 = f32[] constant(1.99298465e-05)
  %broadcast.429 = f32[224]{0} broadcast(f32[] %constant_312), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.408 = f32[224]{0} multiply(f32[224]{0} %reduce.737, f32[224]{0} %broadcast.429), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2137 = f32[224]{0} parameter(1)
  %multiply.2107 = f32[224]{0} multiply(f32[224]{0} %param_1.2137, f32[224]{0} %broadcast.429), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.407 = f32[224]{0} multiply(f32[224]{0} %multiply.2107, f32[224]{0} %multiply.2107), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.10 = f32[224]{0} subtract(f32[224]{0} %multiply.408, f32[224]{0} %multiply.407), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.130 (param_0.1573: f32[896], param_1.2135: f32[896], param_2.1400: f32[896], param_3.1178: f32[16,56,56,896], param_4.1017: f32[896], param_5.1026: f32[896], param_6.706: f32[896], param_7.786: f32[896], param_8.708: f32[16,56,56,896], param_9.555: f32[896]) -> f32[16,56,56,896] {
  %param_8.708 = f32[16,56,56,896]{2,1,3,0} parameter(8)
  %param_9.555 = f32[896]{0} parameter(9)
  %constant_2685 = f32[] constant(1.99298465e-05)
  %broadcast.3358 = f32[896]{0} broadcast(f32[] %constant_2685), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2103 = f32[896]{0} multiply(f32[896]{0} %param_9.555, f32[896]{0} %broadcast.3358), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3357 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2103), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.355 = f32[16,56,56,896]{2,1,3,0} subtract(f32[16,56,56,896]{2,1,3,0} %param_8.708, f32[16,56,56,896]{2,1,3,0} %broadcast.3357), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_7.786 = f32[896]{0} parameter(7)
  %constant_317 = f32[] constant(0)
  %broadcast.3356 = f32[896]{0} broadcast(f32[] %constant_317), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.639 = f32[896]{0} maximum(f32[896]{0} %param_7.786, f32[896]{0} %broadcast.3356), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2683 = f32[] constant(1e-05)
  %broadcast.3355 = f32[896]{0} broadcast(f32[] %constant_2683), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1109 = f32[896]{0} add(f32[896]{0} %maximum.639, f32[896]{0} %broadcast.3355), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2030 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1109), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.435 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2030), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_6.706 = f32[896]{0} parameter(6)
  %bitcast.2029 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_6.706), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2102 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.435, f32[1,1,1,896]{3,2,1,0} %bitcast.2029), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2028 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2102), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3354 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2028), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2101 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.355, f32[16,56,56,896]{2,1,3,0} %broadcast.3354), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_5.1026 = f32[896]{0} parameter(5)
  %broadcast.3353 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %param_5.1026), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1108 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2101, f32[16,56,56,896]{2,1,3,0} %broadcast.3353), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %param_3.1178 = f32[16,56,56,896]{2,1,3,0} parameter(3)
  %param_4.1017 = f32[896]{0} parameter(4)
  %multiply.2100 = f32[896]{0} multiply(f32[896]{0} %param_4.1017, f32[896]{0} %broadcast.3358), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3351 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2100), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.354 = f32[16,56,56,896]{2,1,3,0} subtract(f32[16,56,56,896]{2,1,3,0} %param_3.1178, f32[16,56,56,896]{2,1,3,0} %broadcast.3351), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1400 = f32[896]{0} parameter(2)
  %maximum.638 = f32[896]{0} maximum(f32[896]{0} %param_2.1400, f32[896]{0} %broadcast.3356), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1107 = f32[896]{0} add(f32[896]{0} %maximum.638, f32[896]{0} %broadcast.3355), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2027 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1107), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.434 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2027), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2135 = f32[896]{0} parameter(1)
  %bitcast.2026 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.2135), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2099 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.434, f32[1,1,1,896]{3,2,1,0} %bitcast.2026), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2025 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2099), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3348 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2025), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2098 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.354, f32[16,56,56,896]{2,1,3,0} %broadcast.3348), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1573 = f32[896]{0} parameter(0)
  %broadcast.3347 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1573), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1106 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.2098, f32[16,56,56,896]{2,1,3,0} %broadcast.3347), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1105 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %add.1108, f32[16,56,56,896]{2,1,3,0} %add.1106), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.432 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[] %constant_317), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.10 = f32[16,56,56,896]{2,1,3,0} maximum(f32[16,56,56,896]{2,1,3,0} %add.1105, f32[16,56,56,896]{2,1,3,0} %broadcast.432), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.135 (param_0.1544: f32[16,896], param_1.2097: f32[896]) -> f32[896] {
  %param_0.1544 = f32[16,896]{1,0} parameter(0)
  %constant_328 = f32[] constant(0)
  %reduce.740 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1544, f32[] %constant_328), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_327 = f32[] constant(1.99298465e-05)
  %broadcast.439 = f32[896]{0} broadcast(f32[] %constant_327), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.415 = f32[896]{0} multiply(f32[896]{0} %reduce.740, f32[896]{0} %broadcast.439), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2097 = f32[896]{0} parameter(1)
  %multiply.2059 = f32[896]{0} multiply(f32[896]{0} %param_1.2097, f32[896]{0} %broadcast.439), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.414 = f32[896]{0} multiply(f32[896]{0} %multiply.2059, f32[896]{0} %multiply.2059), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.12 = f32[896]{0} subtract(f32[896]{0} %multiply.415, f32[896]{0} %multiply.414), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.143 (param_0.1558: f32[16,896], param_1.2114: f32[896]) -> f32[896] {
  %param_0.1558 = f32[16,896]{1,0} parameter(0)
  %constant_321 = f32[] constant(0)
  %reduce.743 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1558, f32[] %constant_321), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_320 = f32[] constant(1.99298465e-05)
  %broadcast.444 = f32[896]{0} broadcast(f32[] %constant_320), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.420 = f32[896]{0} multiply(f32[896]{0} %reduce.743, f32[896]{0} %broadcast.444), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2114 = f32[896]{0} parameter(1)
  %multiply.2071 = f32[896]{0} multiply(f32[896]{0} %param_1.2114, f32[896]{0} %broadcast.444), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.419 = f32[896]{0} multiply(f32[896]{0} %multiply.2071, f32[896]{0} %multiply.2071), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.14 = f32[896]{0} subtract(f32[896]{0} %multiply.420, f32[896]{0} %multiply.419), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.148 (param_0.265: f32[16,56,56,896], param_1.386: f32[16,56,56,896]) -> f32[16,56,56,896] {
  %param_1.386 = f32[16,56,56,896]{2,1,3,0} parameter(1)
  %constant_332 = f32[] constant(0)
  %broadcast.447 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[] %constant_332), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.22 = pred[16,56,56,896]{2,1,3,0} compare(f32[16,56,56,896]{2,1,3,0} %param_1.386, f32[16,56,56,896]{2,1,3,0} %broadcast.447), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.265 = f32[16,56,56,896]{2,1,3,0} parameter(0)
  ROOT %select.22 = f32[16,56,56,896]{2,1,3,0} select(pred[16,56,56,896]{2,1,3,0} %compare.22, f32[16,56,56,896]{2,1,3,0} %param_0.265, f32[16,56,56,896]{2,1,3,0} %broadcast.447), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.152 (param_0.272: f32[1,1,448,896], param_1.395: f32[1,1,448,896]) -> f32[1,1,448,896] {
  %param_1.395 = f32[1,1,448,896]{3,2,1,0} parameter(1)
  %copy.156 = f32[1,1,448,896]{1,0,2,3} copy(f32[1,1,448,896]{3,2,1,0} %param_1.395), metadata={op_name="3$start"}
  %param_0.272 = f32[1,1,448,896]{1,0,2,3} parameter(0)
  %add.92 = f32[1,1,448,896]{1,0,2,3} add(f32[1,1,448,896]{1,0,2,3} %copy.156, f32[1,1,448,896]{1,0,2,3} %param_0.272), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  ROOT %copy.155 = f32[1,1,448,896]{3,2,1,0} copy(f32[1,1,448,896]{1,0,2,3} %add.92), metadata={op_name="tuple.85"}
}

%fused_computation.154 (param_0.1526: f32[16,56,56,448], param_1.2069: f32[448], param_2.1309: f32[448], param_3.1097: f32[448], param_4.950: f32[16,56,56,448], param_5.941: f32[448]) -> (f32[16,448], f32[16,448], f32[16,448]) {
  %param_4.950 = f32[16,56,56,448]{2,1,3,0} parameter(4)
  %param_5.941 = f32[448]{0} parameter(5)
  %constant_2497 = f32[] constant(1.99298465e-05)
  %broadcast.3116 = f32[448]{0} broadcast(f32[] %constant_2497), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1997 = f32[448]{0} multiply(f32[448]{0} %param_5.941, f32[448]{0} %broadcast.3116), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3115 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1997), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.325 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_4.950, f32[16,56,56,448]{2,1,3,0} %broadcast.3115), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1097 = f32[448]{0} parameter(3)
  %constant_336 = f32[] constant(0)
  %broadcast.3114 = f32[448]{0} broadcast(f32[] %constant_336), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.581 = f32[448]{0} maximum(f32[448]{0} %param_3.1097, f32[448]{0} %broadcast.3114), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2495 = f32[] constant(1e-05)
  %broadcast.3113 = f32[448]{0} broadcast(f32[] %constant_2495), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1033 = f32[448]{0} add(f32[448]{0} %maximum.581, f32[448]{0} %broadcast.3113), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1904 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.397 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1904), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1309 = f32[448]{0} parameter(2)
  %bitcast.1903 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_2.1309), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1996 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.397, f32[1,1,1,448]{3,2,1,0} %bitcast.1903), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1902 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1996), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3112 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1902), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1995 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.325, f32[16,56,56,448]{2,1,3,0} %broadcast.3112), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2069 = f32[448]{0} parameter(1)
  %broadcast.3111 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_1.2069), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1032 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.1995, f32[16,56,56,448]{2,1,3,0} %broadcast.3111), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3110 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_336), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.265 = pred[16,56,56,448]{2,1,3,0} compare(f32[16,56,56,448]{2,1,3,0} %add.1032, f32[16,56,56,448]{2,1,3,0} %broadcast.3110), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1526 = f32[16,56,56,448]{2,1,3,0} parameter(0)
  %select.265 = f32[16,56,56,448]{2,1,3,0} select(pred[16,56,56,448]{2,1,3,0} %compare.265, f32[16,56,56,448]{2,1,3,0} %param_0.1526, f32[16,56,56,448]{2,1,3,0} %broadcast.3110), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.22 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %select.265), dimensions={0,3,1,2}
  %bitcast.675 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.22), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.749 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.675, f32[] %constant_336), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.2013.clone.1 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %select.265, f32[16,56,56,448]{2,1,3,0} %broadcast.3112), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.19.clone.1 = f32[16,56,56,448]{2,1,3,0} negate(f32[16,56,56,448]{2,1,3,0} %multiply.2013.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.23 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %negate.19.clone.1), dimensions={0,3,1,2}
  %bitcast.684.clone.1 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.23), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.755.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.684.clone.1, f32[] %constant_336), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.446.clone.1 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.325, f32[16,56,56,448]{2,1,3,0} %select.265), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.24 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %multiply.446.clone.1), dimensions={0,3,1,2}
  %bitcast.686.clone.1 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.24), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.757.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.686.clone.1, f32[] %constant_336), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.32 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.749, f32[16,448]{1,0} %reduce.755.clone.1, f32[16,448]{1,0} %reduce.757.clone.1)
}

%fused_computation.156 (param_0.279: f32[3,3,224,448], param_1.404: f32[3,3,224,448]) -> f32[3,3,224,448] {
  %param_1.404 = f32[3,3,224,448]{3,2,1,0} parameter(1)
  %copy.158 = f32[3,3,224,448]{1,0,2,3} copy(f32[3,3,224,448]{3,2,1,0} %param_1.404), metadata={op_name="3$start"}
  %param_0.279 = f32[3,3,224,448]{1,0,2,3} parameter(0)
  %add.95 = f32[3,3,224,448]{1,0,2,3} add(f32[3,3,224,448]{1,0,2,3} %copy.158, f32[3,3,224,448]{1,0,2,3} %param_0.279), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  ROOT %copy.157 = f32[3,3,224,448]{3,2,1,0} copy(f32[3,3,224,448]{1,0,2,3} %add.95), metadata={op_name="tuple.85"}
}

%fused_computation.158 (param_0.1537: f32[16,56,56,224], param_1.2087: f32[224], param_2.1334: f32[224], param_3.1128: f32[224], param_4.984: f32[16,56,56,224], param_5.984: f32[224]) -> (f32[16,224], f32[16,224], f32[16,224]) {
  %param_4.984 = f32[16,56,56,224]{2,1,3,0} parameter(4)
  %param_5.984 = f32[224]{0} parameter(5)
  %constant_2550 = f32[] constant(1.99298465e-05)
  %broadcast.3198 = f32[224]{0} broadcast(f32[] %constant_2550), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2035 = f32[224]{0} multiply(f32[224]{0} %param_5.984, f32[224]{0} %broadcast.3198), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3197 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2035), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.335 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_4.984, f32[16,56,56,224]{2,1,3,0} %broadcast.3197), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1128 = f32[224]{0} parameter(3)
  %constant_338 = f32[] constant(0)
  %broadcast.3196 = f32[224]{0} broadcast(f32[] %constant_338), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.595 = f32[224]{0} maximum(f32[224]{0} %param_3.1128, f32[224]{0} %broadcast.3196), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2548 = f32[] constant(1e-05)
  %broadcast.3195 = f32[224]{0} broadcast(f32[] %constant_2548), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1057 = f32[224]{0} add(f32[224]{0} %maximum.595, f32[224]{0} %broadcast.3195), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1946 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1057), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.411 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.1946), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1334 = f32[224]{0} parameter(2)
  %bitcast.1945 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_2.1334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2034 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.411, f32[1,1,1,224]{3,2,1,0} %bitcast.1945), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1944 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2034), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3194 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.1944), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2033 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.335, f32[16,56,56,224]{2,1,3,0} %broadcast.3194), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2087 = f32[224]{0} parameter(1)
  %broadcast.3193 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_1.2087), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1056 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2033, f32[16,56,56,224]{2,1,3,0} %broadcast.3193), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3192 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_338), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.275 = pred[16,56,56,224]{2,1,3,0} compare(f32[16,56,56,224]{2,1,3,0} %add.1056, f32[16,56,56,224]{2,1,3,0} %broadcast.3192), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1537 = f32[16,56,56,224]{2,1,3,0} parameter(0)
  %select.275 = f32[16,56,56,224]{2,1,3,0} select(pred[16,56,56,224]{2,1,3,0} %compare.275, f32[16,56,56,224]{2,1,3,0} %param_0.1537, f32[16,56,56,224]{2,1,3,0} %broadcast.3192), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.25 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %select.275), dimensions={0,3,1,2}
  %bitcast.677 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.25), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.751 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.677, f32[] %constant_338), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.2051.clone.1 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %select.275, f32[16,56,56,224]{2,1,3,0} %broadcast.3194), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.17.clone.1 = f32[16,56,56,224]{2,1,3,0} negate(f32[16,56,56,224]{2,1,3,0} %multiply.2051.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.26 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %negate.17.clone.1), dimensions={0,3,1,2}
  %bitcast.680.clone.1 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.26), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.752.clone.1 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.680.clone.1, f32[] %constant_338), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.435.clone.1 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.335, f32[16,56,56,224]{2,1,3,0} %select.275), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.27 = f32[16,224,56,56]{3,2,1,0} transpose(f32[16,56,56,224]{2,1,3,0} %multiply.435.clone.1), dimensions={0,3,1,2}
  %bitcast.682.clone.1 = f32[16,224,3136]{2,1,0} bitcast(f32[16,224,56,56]{3,2,1,0} %transpose.27), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.754.clone.1 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %bitcast.682.clone.1, f32[] %constant_338), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.30 = (f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) tuple(f32[16,224]{1,0} %reduce.751, f32[16,224]{1,0} %reduce.752.clone.1, f32[16,224]{1,0} %reduce.754.clone.1)
}

%fused_computation.160 (param_0.286: f32[1,1,896,224], param_1.413: f32[1,1,896,224]) -> f32[1,1,896,224] {
  %param_1.413 = f32[1,1,896,224]{3,2,1,0} parameter(1)
  %copy.160 = f32[1,1,896,224]{1,0,2,3} copy(f32[1,1,896,224]{3,2,1,0} %param_1.413), metadata={op_name="3$start"}
  %param_0.286 = f32[1,1,896,224]{1,0,2,3} parameter(0)
  %add.98 = f32[1,1,896,224]{1,0,2,3} add(f32[1,1,896,224]{1,0,2,3} %copy.160, f32[1,1,896,224]{1,0,2,3} %param_0.286), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  ROOT %copy.159 = f32[1,1,896,224]{3,2,1,0} copy(f32[1,1,896,224]{1,0,2,3} %add.98), metadata={op_name="tuple.85"}
}

%fused_computation.161 (param_0.289: f32[224], param_1.419: f32[224], param_2.1336: f32[16,56,56,224], param_3.1130: f32[224], param_4.986: f32[1,1,1,224], param_5.986: f32[224], param_6.672: f32[16,56,56,224], param_7.752: f32[224]) -> f32[16,56,56,224] {
  %param_2.1336 = f32[16,56,56,224]{2,1,3,0} parameter(2)
  %param_1.419 = f32[224]{0} parameter(1)
  %constant_340 = f32[] constant(1.99298465e-05)
  %broadcast.3218 = f32[224]{0} broadcast(f32[] %constant_340), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2045 = f32[224]{0} multiply(f32[224]{0} %param_1.419, f32[224]{0} %broadcast.3218), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3217 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2045), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.337 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_2.1336, f32[16,56,56,224]{2,1,3,0} %broadcast.3217), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1130 = f32[224]{0} parameter(3)
  %constant_344 = f32[] constant(0)
  %broadcast.3216 = f32[224]{0} broadcast(f32[] %constant_344), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.599 = f32[224]{0} maximum(f32[224]{0} %param_3.1130, f32[224]{0} %broadcast.3216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2330 = f32[] constant(1e-05)
  %broadcast.3215 = f32[224]{0} broadcast(f32[] %constant_2330), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1063 = f32[224]{0} add(f32[224]{0} %maximum.599, f32[224]{0} %broadcast.3215), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1958 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1063), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.415 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.1958), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.986 = f32[224]{0} parameter(5)
  %bitcast.1957 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_5.986), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2044 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.415, f32[1,1,1,224]{3,2,1,0} %bitcast.1957), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1956 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2044), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3214 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.1956), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2043 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.337, f32[16,56,56,224]{2,1,3,0} %broadcast.3214), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.752 = f32[224]{0} parameter(7)
  %broadcast.3213 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_7.752), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1062 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2043, f32[16,56,56,224]{2,1,3,0} %broadcast.3213), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3212 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_344), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.277 = pred[16,56,56,224]{2,1,3,0} compare(f32[16,56,56,224]{2,1,3,0} %add.1062, f32[16,56,56,224]{2,1,3,0} %broadcast.3212), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.672 = f32[16,56,56,224]{2,1,3,0} parameter(6)
  %select.277 = f32[16,56,56,224]{2,1,3,0} select(pred[16,56,56,224]{2,1,3,0} %compare.277, f32[16,56,56,224]{2,1,3,0} %param_6.672, f32[16,56,56,224]{2,1,3,0} %broadcast.3212), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.2041 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %select.277, f32[16,56,56,224]{2,1,3,0} %broadcast.3214), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.986 = f32[1,1,1,224]{3,2,1,0} parameter(4)
  %multiply.434 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %param_4.986, f32[1,1,1,224]{3,2,1,0} %bitcast.1957), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.17 = f32[1,1,1,224]{3,2,1,0} divide(f32[1,1,1,224]{3,2,1,0} %rsqrt.415, f32[1,1,1,224]{3,2,1,0} %bitcast.1958), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_341 = f32[] constant(-0.5)
  %broadcast.453 = f32[1,1,1,224]{3,2,1,0} broadcast(f32[] %constant_341), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.433 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %divide.17, f32[1,1,1,224]{3,2,1,0} %broadcast.453), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.432 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %multiply.434, f32[1,1,1,224]{3,2,1,0} %multiply.433), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.679 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.432), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reshape[new_sizes=(224,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.24 = pred[224]{0} compare(f32[224]{0} %param_3.1130, f32[224]{0} %maximum.599), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_342 = f32[] constant(1)
  %broadcast.452 = f32[224]{0} broadcast(f32[] %constant_342), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/broadcast_in_dim[shape=(224,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.24 = f32[224]{0} select(pred[224]{0} %compare.24, f32[224]{0} %broadcast.452, f32[224]{0} %broadcast.3216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.23 = pred[224]{0} compare(f32[224]{0} %broadcast.3216, f32[224]{0} %maximum.599), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_343 = f32[] constant(2)
  %broadcast.451 = f32[224]{0} broadcast(f32[] %constant_343), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.23 = f32[224]{0} select(pred[224]{0} %compare.23, f32[224]{0} %broadcast.451, f32[224]{0} %broadcast.452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.16 = f32[224]{0} divide(f32[224]{0} %select.24, f32[224]{0} %select.23), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.431 = f32[224]{0} multiply(f32[224]{0} %bitcast.679, f32[224]{0} %divide.16), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_339 = f32[] constant(3.98596931e-05)
  %broadcast.450 = f32[224]{0} broadcast(f32[] %constant_339), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.430 = f32[224]{0} multiply(f32[224]{0} %multiply.431, f32[224]{0} %broadcast.450), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.449 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.430), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.429 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %param_2.1336, f32[16,56,56,224]{2,1,3,0} %broadcast.449), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.101 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.2041, f32[16,56,56,224]{2,1,3,0} %multiply.429), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.289 = f32[224]{0} parameter(0)
  %negate.16 = f32[224]{0} negate(f32[224]{0} %multiply.431), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.428 = f32[224]{0} multiply(f32[224]{0} %param_1.419, f32[224]{0} %broadcast.450), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.427 = f32[224]{0} multiply(f32[224]{0} %negate.16, f32[224]{0} %multiply.428), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.100 = f32[224]{0} add(f32[224]{0} %param_0.289, f32[224]{0} %multiply.427), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.426 = f32[224]{0} multiply(f32[224]{0} %add.100, f32[224]{0} %broadcast.3218), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.448 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.426), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/broadcast_in_dim[shape=(16, 56, 56, 224) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.99 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %add.101, f32[16,56,56,224]{2,1,3,0} %broadcast.448), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.163 (param_0.293: f32[16,224]) -> f32[1,1,1,224] {
  %param_0.293 = f32[16,224]{1,0} parameter(0)
  %constant_345 = f32[] constant(0)
  %reduce.753 = f32[224]{0} reduce(f32[16,224]{1,0} %param_0.293, f32[] %constant_345), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.681 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %reduce.753), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.167 (param_0.301: f32[448], param_1.437: f32[448], param_2.1311: f32[16,56,56,448], param_3.1099: f32[448], param_4.952: f32[1,1,1,448], param_5.943: f32[448], param_6.647: f32[16,56,56,448], param_7.734: f32[448]) -> f32[16,56,56,448] {
  %param_2.1311 = f32[16,56,56,448]{2,1,3,0} parameter(2)
  %param_1.437 = f32[448]{0} parameter(1)
  %constant_350 = f32[] constant(1.99298465e-05)
  %broadcast.3136 = f32[448]{0} broadcast(f32[] %constant_350), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2007 = f32[448]{0} multiply(f32[448]{0} %param_1.437, f32[448]{0} %broadcast.3136), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3135 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.2007), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.327 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_2.1311, f32[16,56,56,448]{2,1,3,0} %broadcast.3135), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1099 = f32[448]{0} parameter(3)
  %constant_354 = f32[] constant(0)
  %broadcast.3134 = f32[448]{0} broadcast(f32[] %constant_354), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.585 = f32[448]{0} maximum(f32[448]{0} %param_3.1099, f32[448]{0} %broadcast.3134), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2387 = f32[] constant(1e-05)
  %broadcast.3133 = f32[448]{0} broadcast(f32[] %constant_2387), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1039 = f32[448]{0} add(f32[448]{0} %maximum.585, f32[448]{0} %broadcast.3133), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1916 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1039), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.401 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1916), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.943 = f32[448]{0} parameter(5)
  %bitcast.1915 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_5.943), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2006 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.401, f32[1,1,1,448]{3,2,1,0} %bitcast.1915), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1914 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2006), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3132 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1914), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2005 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.327, f32[16,56,56,448]{2,1,3,0} %broadcast.3132), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.734 = f32[448]{0} parameter(7)
  %broadcast.3131 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_7.734), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1038 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2005, f32[16,56,56,448]{2,1,3,0} %broadcast.3131), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3130 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_354), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.267 = pred[16,56,56,448]{2,1,3,0} compare(f32[16,56,56,448]{2,1,3,0} %add.1038, f32[16,56,56,448]{2,1,3,0} %broadcast.3130), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.647 = f32[16,56,56,448]{2,1,3,0} parameter(6)
  %select.267 = f32[16,56,56,448]{2,1,3,0} select(pred[16,56,56,448]{2,1,3,0} %compare.267, f32[16,56,56,448]{2,1,3,0} %param_6.647, f32[16,56,56,448]{2,1,3,0} %broadcast.3130), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.2003 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %select.267, f32[16,56,56,448]{2,1,3,0} %broadcast.3132), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.952 = f32[1,1,1,448]{3,2,1,0} parameter(4)
  %multiply.445 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %param_4.952, f32[1,1,1,448]{3,2,1,0} %bitcast.1915), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.19 = f32[1,1,1,448]{3,2,1,0} divide(f32[1,1,1,448]{3,2,1,0} %rsqrt.401, f32[1,1,1,448]{3,2,1,0} %bitcast.1916), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_351 = f32[] constant(-0.5)
  %broadcast.464 = f32[1,1,1,448]{3,2,1,0} broadcast(f32[] %constant_351), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.444 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %divide.19, f32[1,1,1,448]{3,2,1,0} %broadcast.464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.443 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %multiply.445, f32[1,1,1,448]{3,2,1,0} %multiply.444), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.683 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.443), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.27 = pred[448]{0} compare(f32[448]{0} %param_3.1099, f32[448]{0} %maximum.585), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_352 = f32[] constant(1)
  %broadcast.463 = f32[448]{0} broadcast(f32[] %constant_352), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/broadcast_in_dim[shape=(448,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.27 = f32[448]{0} select(pred[448]{0} %compare.27, f32[448]{0} %broadcast.463, f32[448]{0} %broadcast.3134), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.26 = pred[448]{0} compare(f32[448]{0} %broadcast.3134, f32[448]{0} %maximum.585), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_353 = f32[] constant(2)
  %broadcast.462 = f32[448]{0} broadcast(f32[] %constant_353), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.26 = f32[448]{0} select(pred[448]{0} %compare.26, f32[448]{0} %broadcast.462, f32[448]{0} %broadcast.463), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.18 = f32[448]{0} divide(f32[448]{0} %select.27, f32[448]{0} %select.26), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.442 = f32[448]{0} multiply(f32[448]{0} %bitcast.683, f32[448]{0} %divide.18), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_349 = f32[] constant(3.98596931e-05)
  %broadcast.460 = f32[448]{0} broadcast(f32[] %constant_349), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.441 = f32[448]{0} multiply(f32[448]{0} %multiply.442, f32[448]{0} %broadcast.460), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.459 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.441), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.440 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %param_2.1311, f32[16,56,56,448]{2,1,3,0} %broadcast.459), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.104 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.2003, f32[16,56,56,448]{2,1,3,0} %multiply.440), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.301 = f32[448]{0} parameter(0)
  %negate.18 = f32[448]{0} negate(f32[448]{0} %multiply.442), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.439 = f32[448]{0} multiply(f32[448]{0} %param_1.437, f32[448]{0} %broadcast.460), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.438 = f32[448]{0} multiply(f32[448]{0} %negate.18, f32[448]{0} %multiply.439), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.103 = f32[448]{0} add(f32[448]{0} %param_0.301, f32[448]{0} %multiply.438), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.437 = f32[448]{0} multiply(f32[448]{0} %add.103, f32[448]{0} %broadcast.3136), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.458 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.437), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/broadcast_in_dim[shape=(16, 56, 56, 448) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.102 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %add.104, f32[16,56,56,448]{2,1,3,0} %broadcast.458), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.169 (param_0.305: f32[16,448]) -> f32[1,1,1,448] {
  %param_0.305 = f32[16,448]{1,0} parameter(0)
  %constant_355 = f32[] constant(0)
  %reduce.756 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.305, f32[] %constant_355), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.685 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %reduce.756), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.173 (param_0.313: f32[896], param_1.455: f32[896], param_2.1288: f32[16,56,56,896], param_3.1074: f32[896], param_4.926: f32[1,1,1,896], param_5.913: f32[896], param_6.627: f32[16,56,56,896]) -> f32[16,56,56,896] {
  %param_6.627 = f32[16,56,56,896]{2,1,3,0} parameter(6)
  %param_3.1074 = f32[896]{0} parameter(3)
  %constant_364 = f32[] constant(0)
  %broadcast.3068 = f32[896]{0} broadcast(f32[] %constant_364), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.573 = f32[896]{0} maximum(f32[896]{0} %param_3.1074, f32[896]{0} %broadcast.3068), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2444 = f32[] constant(1e-05)
  %broadcast.3067 = f32[896]{0} broadcast(f32[] %constant_2444), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1019 = f32[896]{0} add(f32[896]{0} %maximum.573, f32[896]{0} %broadcast.3067), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1880 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1019), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.389 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1880), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.913 = f32[896]{0} parameter(5)
  %bitcast.1879 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.913), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1975 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.389, f32[1,1,1,896]{3,2,1,0} %bitcast.1879), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1878 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1975), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3066 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1878), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1974 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %param_6.627, f32[16,56,56,896]{2,1,3,0} %broadcast.3066), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.1288 = f32[16,56,56,896]{2,1,3,0} parameter(2)
  %param_4.926 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.456 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.926, f32[1,1,1,896]{3,2,1,0} %bitcast.1879), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.21 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.389, f32[1,1,1,896]{3,2,1,0} %bitcast.1880), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_361 = f32[] constant(-0.5)
  %broadcast.474 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_361), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.455 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.21, f32[1,1,1,896]{3,2,1,0} %broadcast.474), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.454 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.456, f32[1,1,1,896]{3,2,1,0} %multiply.455), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.687 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.454), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.30 = pred[896]{0} compare(f32[896]{0} %param_3.1074, f32[896]{0} %maximum.573), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_362 = f32[] constant(1)
  %broadcast.473 = f32[896]{0} broadcast(f32[] %constant_362), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.30 = f32[896]{0} select(pred[896]{0} %compare.30, f32[896]{0} %broadcast.473, f32[896]{0} %broadcast.3068), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.29 = pred[896]{0} compare(f32[896]{0} %broadcast.3068, f32[896]{0} %maximum.573), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_363 = f32[] constant(2)
  %broadcast.472 = f32[896]{0} broadcast(f32[] %constant_363), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.29 = f32[896]{0} select(pred[896]{0} %compare.29, f32[896]{0} %broadcast.472, f32[896]{0} %broadcast.473), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.20 = f32[896]{0} divide(f32[896]{0} %select.30, f32[896]{0} %select.29), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.453 = f32[896]{0} multiply(f32[896]{0} %bitcast.687, f32[896]{0} %divide.20), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_359 = f32[] constant(3.98596931e-05)
  %broadcast.470 = f32[896]{0} broadcast(f32[] %constant_359), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.452 = f32[896]{0} multiply(f32[896]{0} %multiply.453, f32[896]{0} %broadcast.470), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.469 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.452), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.451 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %param_2.1288, f32[16,56,56,896]{2,1,3,0} %broadcast.469), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.107 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.1974, f32[16,56,56,896]{2,1,3,0} %multiply.451), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.313 = f32[896]{0} parameter(0)
  %negate.20 = f32[896]{0} negate(f32[896]{0} %multiply.453), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.455 = f32[896]{0} parameter(1)
  %multiply.450 = f32[896]{0} multiply(f32[896]{0} %param_1.455, f32[896]{0} %broadcast.470), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.449 = f32[896]{0} multiply(f32[896]{0} %negate.20, f32[896]{0} %multiply.450), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.106 = f32[896]{0} add(f32[896]{0} %param_0.313, f32[896]{0} %multiply.449), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_360 = f32[] constant(1.99298465e-05)
  %broadcast.471 = f32[896]{0} broadcast(f32[] %constant_360), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.448 = f32[896]{0} multiply(f32[896]{0} %add.106, f32[896]{0} %broadcast.471), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.468 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.448), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/broadcast_in_dim[shape=(16, 56, 56, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.105 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %add.107, f32[16,56,56,896]{2,1,3,0} %broadcast.468), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.174 (param_0.1519: f32[16,56,56,896], param_1.2059: f32[896], param_2.1295: f32[896], param_3.1525: f32[16,56,56,896], param_4.1331: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_0.1519 = f32[16,56,56,896]{2,1,3,0} parameter(0)
  %param_2.1295 = f32[896]{0} parameter(2)
  %constant_367 = f32[] constant(0)
  %broadcast.3074 = f32[896]{0} broadcast(f32[] %constant_367), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.575 = f32[896]{0} maximum(f32[896]{0} %param_2.1295, f32[896]{0} %broadcast.3074), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2469 = f32[] constant(1e-05)
  %broadcast.3073 = f32[896]{0} broadcast(f32[] %constant_2469), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1021 = f32[896]{0} add(f32[896]{0} %maximum.575, f32[896]{0} %broadcast.3073), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1886 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1021), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.391 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1886), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2059 = f32[896]{0} parameter(1)
  %bitcast.1885 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.2059), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1979 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.391, f32[1,1,1,896]{3,2,1,0} %bitcast.1885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1884 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1979), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3072 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1884), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1978 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %param_0.1519, f32[16,56,56,896]{2,1,3,0} %broadcast.3072), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.21 = f32[16,56,56,896]{2,1,3,0} negate(f32[16,56,56,896]{2,1,3,0} %multiply.1978), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.28 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %negate.21), dimensions={0,3,1,2}
  %bitcast.688 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.28), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.758 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.688, f32[] %constant_367), dimensions={2}, to_apply=%region_63.4346.3
  %param_3.1525 = f32[16,56,56,896]{2,1,3,0} parameter(3)
  %param_4.1331 = f32[896]{0} parameter(4)
  %constant_2429_clone_1 = f32[] constant(1.99298465e-05)
  %broadcast.3038.clone.1 = f32[896]{0} broadcast(f32[] %constant_2429_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1967.clone.1 = f32[896]{0} multiply(f32[896]{0} %param_4.1331, f32[896]{0} %broadcast.3038.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3037.clone.1 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1967.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.319.clone.1 = f32[16,56,56,896]{2,1,3,0} subtract(f32[16,56,56,896]{2,1,3,0} %param_3.1525, f32[16,56,56,896]{2,1,3,0} %broadcast.3037.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.457.clone.1 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.319.clone.1, f32[16,56,56,896]{2,1,3,0} %param_0.1519), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.29 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %multiply.457.clone.1), dimensions={0,3,1,2}
  %bitcast.690.clone.1 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.29), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.760.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.690.clone.1, f32[] %constant_367), dimensions={2}, to_apply=%region_63.4346.3
  %transpose.30 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %param_0.1519), dimensions={0,3,1,2}
  %bitcast.673.clone.1 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.30), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.747.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %bitcast.673.clone.1, f32[] %constant_367), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.34 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.758, f32[16,896]{1,0} %reduce.760.clone.1, f32[16,896]{1,0} %reduce.747.clone.1)
}

%fused_computation.175 (param_0.317: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.317 = f32[16,896]{1,0} parameter(0)
  %constant_365 = f32[] constant(0)
  %reduce.759 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.317, f32[] %constant_365), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.689 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.759), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.178 (param_0.322: f32[16,56,56,896], param_1.467: f32[16,56,56,896], param_2.147: f32[896], param_3.1069: f32[16,56,56,896], param_4.925: f32[896], param_5.912: f32[896], param_6.626: f32[896]) -> f32[16,56,56,896] {
  %param_1.467 = f32[16,56,56,896]{2,1,3,0} parameter(1)
  %param_3.1069 = f32[16,56,56,896]{2,1,3,0} parameter(3)
  %param_4.925 = f32[896]{0} parameter(4)
  %constant_2426 = f32[] constant(1.99298465e-05)
  %broadcast.3034 = f32[896]{0} broadcast(f32[] %constant_2426), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1965 = f32[896]{0} multiply(f32[896]{0} %param_4.925, f32[896]{0} %broadcast.3034), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3033 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1965), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.317 = f32[16,56,56,896]{2,1,3,0} subtract(f32[16,56,56,896]{2,1,3,0} %param_3.1069, f32[16,56,56,896]{2,1,3,0} %broadcast.3033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_6.626 = f32[896]{0} parameter(6)
  %constant_368 = f32[] constant(0)
  %broadcast.3058 = f32[896]{0} broadcast(f32[] %constant_368), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.569 = f32[896]{0} maximum(f32[896]{0} %param_6.626, f32[896]{0} %broadcast.3058), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2454 = f32[] constant(1e-05)
  %broadcast.3057 = f32[896]{0} broadcast(f32[] %constant_2454), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1015 = f32[896]{0} add(f32[896]{0} %maximum.569, f32[896]{0} %broadcast.3057), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1868 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1015), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.385 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1868), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.912 = f32[896]{0} parameter(5)
  %bitcast.1867 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.912), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1969 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.385, f32[1,1,1,896]{3,2,1,0} %bitcast.1867), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1866 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1969), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.478 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1866), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.459 = f32[16,56,56,896]{2,1,3,0} multiply(f32[16,56,56,896]{2,1,3,0} %subtract.317, f32[16,56,56,896]{2,1,3,0} %broadcast.478), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.147 = f32[896]{0} parameter(2)
  %broadcast.477 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %param_2.147), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.109 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %multiply.459, f32[16,56,56,896]{2,1,3,0} %broadcast.477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.108 = f32[16,56,56,896]{2,1,3,0} add(f32[16,56,56,896]{2,1,3,0} %param_1.467, f32[16,56,56,896]{2,1,3,0} %add.109), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.479 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[] %constant_368), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.31 = pred[16,56,56,896]{2,1,3,0} compare(f32[16,56,56,896]{2,1,3,0} %add.108, f32[16,56,56,896]{2,1,3,0} %broadcast.479), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.322 = f32[16,56,56,896]{2,1,3,0} parameter(0)
  ROOT %select.31 = f32[16,56,56,896]{2,1,3,0} select(pred[16,56,56,896]{2,1,3,0} %compare.31, f32[16,56,56,896]{2,1,3,0} %param_0.322, f32[16,56,56,896]{2,1,3,0} %broadcast.479), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.182 (param_0.1505: f32[16,896], param_1.2039: f32[896]) -> f32[896] {
  %param_0.1505 = f32[16,896]{1,0} parameter(0)
  %constant_372 = f32[] constant(0)
  %reduce.761 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1505, f32[] %constant_372), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_371 = f32[] constant(1.99298465e-05)
  %broadcast.482 = f32[896]{0} broadcast(f32[] %constant_371), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.462 = f32[896]{0} multiply(f32[896]{0} %reduce.761, f32[896]{0} %broadcast.482), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2039 = f32[896]{0} parameter(1)
  %multiply.1963 = f32[896]{0} multiply(f32[896]{0} %param_1.2039, f32[896]{0} %broadcast.482), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.461 = f32[896]{0} multiply(f32[896]{0} %multiply.1963, f32[896]{0} %multiply.1963), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.16 = f32[896]{0} subtract(f32[896]{0} %multiply.462, f32[896]{0} %multiply.461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.187 (param_0.1501: f32[448], param_1.2034: f32[448], param_2.1261: f32[448], param_3.1054: f32[16,56,56,448], param_4.914: f32[448]) -> f32[16,56,56,448] {
  %param_3.1054 = f32[16,56,56,448]{2,1,3,0} parameter(3)
  %param_4.914 = f32[448]{0} parameter(4)
  %constant_2410 = f32[] constant(1.99298465e-05)
  %broadcast.3014 = f32[448]{0} broadcast(f32[] %constant_2410), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1953 = f32[448]{0} multiply(f32[448]{0} %param_4.914, f32[448]{0} %broadcast.3014), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3013 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1953), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.313 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_3.1054, f32[16,56,56,448]{2,1,3,0} %broadcast.3013), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1261 = f32[448]{0} parameter(2)
  %constant_376 = f32[] constant(0)
  %broadcast.3012 = f32[448]{0} broadcast(f32[] %constant_376), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.555 = f32[448]{0} maximum(f32[448]{0} %param_2.1261, f32[448]{0} %broadcast.3012), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2408 = f32[] constant(1e-05)
  %broadcast.3011 = f32[448]{0} broadcast(f32[] %constant_2408), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1003 = f32[448]{0} add(f32[448]{0} %maximum.555, f32[448]{0} %broadcast.3011), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1850 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1003), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.381 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1850), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2034 = f32[448]{0} parameter(1)
  %bitcast.1849 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_1.2034), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1952 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.381, f32[1,1,1,448]{3,2,1,0} %bitcast.1849), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1848 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1952), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3010 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1848), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1951 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.313, f32[16,56,56,448]{2,1,3,0} %broadcast.3010), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1501 = f32[448]{0} parameter(0)
  %broadcast.3009 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_0.1501), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1002 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.1951, f32[16,56,56,448]{2,1,3,0} %broadcast.3009), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.485 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_376), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.14 = f32[16,56,56,448]{2,1,3,0} maximum(f32[16,56,56,448]{2,1,3,0} %add.1002, f32[16,56,56,448]{2,1,3,0} %broadcast.485), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.192 (param_0.1487: f32[16,448], param_1.2014: f32[448]) -> f32[448] {
  %param_0.1487 = f32[16,448]{1,0} parameter(0)
  %constant_380 = f32[] constant(0)
  %reduce.764 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.1487, f32[] %constant_380), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_379 = f32[] constant(1.99298465e-05)
  %broadcast.490 = f32[448]{0} broadcast(f32[] %constant_379), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.468 = f32[448]{0} multiply(f32[448]{0} %reduce.764, f32[448]{0} %broadcast.490), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2014 = f32[448]{0} parameter(1)
  %multiply.1939 = f32[448]{0} multiply(f32[448]{0} %param_1.2014, f32[448]{0} %broadcast.490), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.467 = f32[448]{0} multiply(f32[448]{0} %multiply.1939, f32[448]{0} %multiply.1939), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.18 = f32[448]{0} subtract(f32[448]{0} %multiply.468, f32[448]{0} %multiply.467), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.197 (param_0.1483: f32[224], param_1.2009: f32[224], param_2.1227: f32[224], param_3.1023: f32[16,56,56,224], param_4.889: f32[224]) -> f32[16,56,56,224] {
  %param_3.1023 = f32[16,56,56,224]{2,1,3,0} parameter(3)
  %param_4.889 = f32[224]{0} parameter(4)
  %constant_2353 = f32[] constant(1.99298465e-05)
  %broadcast.2954 = f32[224]{0} broadcast(f32[] %constant_2353), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1929 = f32[224]{0} multiply(f32[224]{0} %param_4.889, f32[224]{0} %broadcast.2954), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2953 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.1929), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.305 = f32[16,56,56,224]{2,1,3,0} subtract(f32[16,56,56,224]{2,1,3,0} %param_3.1023, f32[16,56,56,224]{2,1,3,0} %broadcast.2953), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1227 = f32[224]{0} parameter(2)
  %constant_384 = f32[] constant(0)
  %broadcast.2952 = f32[224]{0} broadcast(f32[] %constant_384), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.537 = f32[224]{0} maximum(f32[224]{0} %param_2.1227, f32[224]{0} %broadcast.2952), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2351 = f32[] constant(1e-05)
  %broadcast.2951 = f32[224]{0} broadcast(f32[] %constant_2351), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.985 = f32[224]{0} add(f32[224]{0} %maximum.537, f32[224]{0} %broadcast.2951), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1820 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.985), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.373 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.1820), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2009 = f32[224]{0} parameter(1)
  %bitcast.1819 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_1.2009), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1928 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.373, f32[1,1,1,224]{3,2,1,0} %bitcast.1819), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1818 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.1928), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2950 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.1818), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1927 = f32[16,56,56,224]{2,1,3,0} multiply(f32[16,56,56,224]{2,1,3,0} %subtract.305, f32[16,56,56,224]{2,1,3,0} %broadcast.2950), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1483 = f32[224]{0} parameter(0)
  %broadcast.2949 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[224]{0} %param_0.1483), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.984 = f32[16,56,56,224]{2,1,3,0} add(f32[16,56,56,224]{2,1,3,0} %multiply.1927, f32[16,56,56,224]{2,1,3,0} %broadcast.2949), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.493 = f32[16,56,56,224]{2,1,3,0} broadcast(f32[] %constant_384), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.16 = f32[16,56,56,224]{2,1,3,0} maximum(f32[16,56,56,224]{2,1,3,0} %add.984, f32[16,56,56,224]{2,1,3,0} %broadcast.493), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.202 (param_0.1469: f32[16,224], param_1.1989: f32[224]) -> f32[224] {
  %param_0.1469 = f32[16,224]{1,0} parameter(0)
  %constant_388 = f32[] constant(0)
  %reduce.767 = f32[224]{0} reduce(f32[16,224]{1,0} %param_0.1469, f32[] %constant_388), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_387 = f32[] constant(1.99298465e-05)
  %broadcast.498 = f32[224]{0} broadcast(f32[] %constant_387), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.474 = f32[224]{0} multiply(f32[224]{0} %reduce.767, f32[224]{0} %broadcast.498), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1989 = f32[224]{0} parameter(1)
  %multiply.1915 = f32[224]{0} multiply(f32[224]{0} %param_1.1989, f32[224]{0} %broadcast.498), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.473 = f32[224]{0} multiply(f32[224]{0} %multiply.1915, f32[224]{0} %multiply.1915), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.20 = f32[224]{0} subtract(f32[224]{0} %multiply.474, f32[224]{0} %multiply.473), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.207 (param_0.368: f32[16,56,56,896]) -> f32[16,56,56,896] {
  %param_0.368 = f32[16,56,56,896]{2,1,3,0} parameter(0)
  %constant_392 = f32[] constant(0)
  %broadcast.501 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[] %constant_392), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.18 = f32[16,56,56,896]{2,1,3,0} maximum(f32[16,56,56,896]{2,1,3,0} %param_0.368, f32[16,56,56,896]{2,1,3,0} %broadcast.501), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.208 (param_0.369: f32[1792], param_1.1397: f32[1,1,1,1792], param_2.1753: f32[1792], param_3.1530: f32[16,1792]) -> (f32[1792], f32[1792]) {
  %param_0.369 = f32[1792]{0} parameter(0)
  %param_3.1530 = f32[16,1792]{1,0} parameter(3)
  %constant_2293 = f32[] constant(0)
  %reduce.773.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.1530, f32[] %constant_2293), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_2269_clone_1 = f32[] constant(7.97193861e-05)
  %broadcast.514.clone.1 = f32[1792]{0} broadcast(f32[] %constant_2269_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.491.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.773.clone.1, f32[1792]{0} %broadcast.514.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1753 = f32[1792]{0} parameter(2)
  %multiply.1901.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.1753, f32[1792]{0} %broadcast.514.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.490.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1901.clone.1, f32[1792]{0} %multiply.1901.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.23.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.491.clone.1, f32[1792]{0} %multiply.490.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.2894 = f32[1792]{0} broadcast(f32[] %constant_2293), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.517 = f32[1792]{0} maximum(f32[1792]{0} %subtract.23.clone.1, f32[1792]{0} %broadcast.2894), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2292 = f32[] constant(1e-05)
  %broadcast.2893 = f32[1792]{0} broadcast(f32[] %constant_2292), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.967 = f32[1792]{0} add(f32[1792]{0} %maximum.517, f32[1792]{0} %broadcast.2893), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1784 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.967), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.33 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1784), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1397 = f32[1,1,1,1792]{3,2,1,0} parameter(1)
  %multiply.477 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.33, f32[1,1,1,1792]{3,2,1,0} %param_1.1397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.703 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.115 = f32[1792]{0} add(f32[1792]{0} %param_0.369, f32[1792]{0} %bitcast.703), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  ROOT %tuple.38 = (f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.115, f32[1792]{0} %subtract.23.clone.1)
}

%fused_computation.209 (param_0.372: f32[1,1,896,1792], param_1.541: f32[1,1,896,1792]) -> f32[1,1,896,1792] {
  %param_1.541 = f32[1,1,896,1792]{3,2,1,0} parameter(1)
  %copy.162 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %param_1.541), metadata={op_name="3$start"}
  %param_0.372 = f32[1,1,896,1792]{1,0,2,3} parameter(0)
  %add.116 = f32[1,1,896,1792]{1,0,2,3} add(f32[1,1,896,1792]{1,0,2,3} %copy.162, f32[1,1,896,1792]{1,0,2,3} %param_0.372), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  ROOT %copy.161 = f32[1,1,896,1792]{3,2,1,0} copy(f32[1,1,896,1792]{1,0,2,3} %add.116), metadata={op_name="tuple.85"}
}

%fused_computation.211 (param_0.1466: f32[16,28,28,1792], param_1.1987: f32[1792], param_2.1198: f32[1792], param_3.1543: f32[1792], param_4.1348: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_0.1466 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  %param_2.1198 = f32[1792]{0} parameter(2)
  %constant_401 = f32[] constant(0)
  %broadcast.2906 = f32[1792]{0} broadcast(f32[] %constant_401), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.521 = f32[1792]{0} maximum(f32[1792]{0} %param_2.1198, f32[1792]{0} %broadcast.2906), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2302 = f32[] constant(1e-05)
  %broadcast.2905 = f32[1792]{0} broadcast(f32[] %constant_2302), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.971 = f32[1792]{0} add(f32[1792]{0} %maximum.521, f32[1792]{0} %broadcast.2905), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1796 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.971), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.367 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1796), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1987 = f32[1792]{0} parameter(1)
  %bitcast.1795 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1987), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1911 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.367, f32[1,1,1,1792]{3,2,1,0} %bitcast.1795), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1794 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1911), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2904 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1794), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1910 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_0.1466, f32[16,28,28,1792]{2,1,3,0} %broadcast.2904), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.23 = f32[16,28,28,1792]{2,1,3,0} negate(f32[16,28,28,1792]{2,1,3,0} %multiply.1910), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.31 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %negate.23), dimensions={0,3,1,2}
  %bitcast.705 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.31), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.770 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.705, f32[] %constant_401), dimensions={2}, to_apply=%region_63.4346.3
  %param_4.1348 = f32[1792]{0} parameter(4)
  %maximum.479.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %param_4.1348, f32[1792]{0} %broadcast.2906), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.913.clone.1 = f32[1792]{0} add(f32[1792]{0} %maximum.479.clone.1, f32[1792]{0} %broadcast.2905), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1694.clone.1 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.913.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.335.clone.1 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1694.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_3.1543 = f32[1792]{0} parameter(3)
  %bitcast.1693.clone.1 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_3.1543), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1823.clone.1 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.335.clone.1, f32[1,1,1,1792]{3,2,1,0} %bitcast.1693.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1692.clone.1 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1823.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2708.clone.1 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1692.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1822.clone.1 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_0.1466, f32[16,28,28,1792]{2,1,3,0} %broadcast.2708.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.29.clone.1 = f32[16,28,28,1792]{2,1,3,0} negate(f32[16,28,28,1792]{2,1,3,0} %multiply.1822.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.32 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %negate.29.clone.1), dimensions={0,3,1,2}
  %bitcast.727.clone.1 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.32), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.787.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.727.clone.1, f32[] %constant_401), dimensions={2}, to_apply=%region_63.4346.3
  %transpose.33 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %param_0.1466), dimensions={0,3,1,2}
  %bitcast.712.clone.1 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.33), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %reduce.776.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.712.clone.1, f32[] %constant_401), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.67 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.770, f32[16,1792]{1,0} %reduce.787.clone.1, f32[16,1792]{1,0} %reduce.776.clone.1)
}

%fused_computation.212 (param_0.379: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.379 = f32[16,1792]{1,0} parameter(0)
  %constant_399 = f32[] constant(0)
  %reduce.771 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.379, f32[] %constant_399), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.706 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.771), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.222 (param_0.395: f32[1792], param_1.1400: f32[1,1,1,1792], param_2.1757: f32[1792], param_3.1535: f32[16,1792]) -> (f32[1792], f32[1792]) {
  %param_0.395 = f32[1792]{0} parameter(0)
  %param_3.1535 = f32[16,1792]{1,0} parameter(3)
  %constant_2150 = f32[] constant(0)
  %reduce.790.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.1535, f32[] %constant_2150), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_2126_clone_1 = f32[] constant(7.97193861e-05)
  %broadcast.548.clone.1 = f32[1792]{0} broadcast(f32[] %constant_2126_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.532.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.790.clone.1, f32[1792]{0} %broadcast.548.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1757 = f32[1792]{0} parameter(2)
  %multiply.1813.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.1757, f32[1792]{0} %broadcast.548.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.531.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1813.clone.1, f32[1792]{0} %multiply.1813.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.25.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.532.clone.1, f32[1792]{0} %multiply.531.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.2698 = f32[1792]{0} broadcast(f32[] %constant_2150), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.475 = f32[1792]{0} maximum(f32[1792]{0} %subtract.25.clone.1, f32[1792]{0} %broadcast.2698), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2149 = f32[] constant(1e-05)
  %broadcast.2697 = f32[1792]{0} broadcast(f32[] %constant_2149), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.909 = f32[1792]{0} add(f32[1792]{0} %maximum.475, f32[1792]{0} %broadcast.2697), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1682 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.909), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.36 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1682), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1400 = f32[1,1,1,1792]{3,2,1,0} parameter(1)
  %multiply.494 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.36, f32[1,1,1,1792]{3,2,1,0} %param_1.1400), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.713 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.494), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.121 = f32[1792]{0} add(f32[1792]{0} %param_0.395, f32[1792]{0} %bitcast.713), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  ROOT %tuple.64 = (f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.121, f32[1792]{0} %subtract.25.clone.1)
}

%fused_computation.223 (param_0.398: f32[1,1,896,1792], param_1.582: f32[1,1,896,1792]) -> f32[1,1,896,1792] {
  %param_1.582 = f32[1,1,896,1792]{3,2,1,0} parameter(1)
  %copy.164 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %param_1.582), metadata={op_name="3$start"}
  %param_0.398 = f32[1,1,896,1792]{1,0,2,3} parameter(0)
  %add.122 = f32[1,1,896,1792]{1,0,2,3} add(f32[1,1,896,1792]{1,0,2,3} %copy.164, f32[1,1,896,1792]{1,0,2,3} %param_0.398), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  ROOT %copy.163 = f32[1,1,896,1792]{3,2,1,0} copy(f32[1,1,896,1792]{1,0,2,3} %add.122), metadata={op_name="tuple.85"}
}

%fused_computation.225 (param_0.1438: f32[16,28,28,896], param_1.1950: f32[896], param_2.1140: f32[896], param_3.938: f32[896], param_4.823: f32[16,28,28,896], param_5.813: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.823 = f32[16,28,28,896]{2,1,3,0} parameter(4)
  %param_5.813 = f32[896]{0} parameter(5)
  %constant_2187 = f32[] constant(7.97193861e-05)
  %broadcast.2752 = f32[896]{0} broadcast(f32[] %constant_2187), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1841 = f32[896]{0} multiply(f32[896]{0} %param_5.813, f32[896]{0} %broadcast.2752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2751 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1841), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.285 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_4.823, f32[16,28,28,896]{2,1,3,0} %broadcast.2751), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.938 = f32[896]{0} parameter(3)
  %constant_411 = f32[] constant(0)
  %broadcast.2750 = f32[896]{0} broadcast(f32[] %constant_411), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.485 = f32[896]{0} maximum(f32[896]{0} %param_3.938, f32[896]{0} %broadcast.2750), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2185 = f32[] constant(1e-05)
  %broadcast.2749 = f32[896]{0} broadcast(f32[] %constant_2185), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.925 = f32[896]{0} add(f32[896]{0} %maximum.485, f32[896]{0} %broadcast.2749), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1712 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.925), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.341 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1712), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1140 = f32[896]{0} parameter(2)
  %bitcast.1711 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.1140), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1840 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.341, f32[1,1,1,896]{3,2,1,0} %bitcast.1711), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1710 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1840), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2748 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1710), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1839 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.285, f32[16,28,28,896]{2,1,3,0} %broadcast.2748), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1950 = f32[896]{0} parameter(1)
  %broadcast.2747 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.1950), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.924 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1839, f32[16,28,28,896]{2,1,3,0} %broadcast.2747), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2746 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_411), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.245 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.924, f32[16,28,28,896]{2,1,3,0} %broadcast.2746), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1438 = f32[16,28,28,896]{2,1,3,0} parameter(0)
  %select.245 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.245, f32[16,28,28,896]{2,1,3,0} %param_0.1438, f32[16,28,28,896]{2,1,3,0} %broadcast.2746), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.34 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %select.245), dimensions={0,3,1,2}
  %bitcast.714 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.34), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.778 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.714, f32[] %constant_411), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1857.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.245, f32[16,28,28,896]{2,1,3,0} %broadcast.2748), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.27.clone.1 = f32[16,28,28,896]{2,1,3,0} negate(f32[16,28,28,896]{2,1,3,0} %multiply.1857.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.35 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %negate.27.clone.1), dimensions={0,3,1,2}
  %bitcast.723.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.35), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.784.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.723.clone.1, f32[] %constant_411), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.517.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.285, f32[16,28,28,896]{2,1,3,0} %select.245), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.36 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %multiply.517.clone.1), dimensions={0,3,1,2}
  %bitcast.725.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.36), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.786.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.725.clone.1, f32[] %constant_411), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.63 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.778, f32[16,896]{1,0} %reduce.784.clone.1, f32[16,896]{1,0} %reduce.786.clone.1)
}

%fused_computation.227 (param_0.405: f32[3,3,448,896], param_1.591: f32[3,3,448,896]) -> f32[3,3,448,896] {
  %param_1.591 = f32[3,3,448,896]{3,2,1,0} parameter(1)
  %copy.166 = f32[3,3,448,896]{1,0,2,3} copy(f32[3,3,448,896]{3,2,1,0} %param_1.591), metadata={op_name="3$start"}
  %param_0.405 = f32[3,3,448,896]{1,0,2,3} parameter(0)
  %add.125 = f32[3,3,448,896]{1,0,2,3} add(f32[3,3,448,896]{1,0,2,3} %copy.166, f32[3,3,448,896]{1,0,2,3} %param_0.405), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  ROOT %copy.165 = f32[3,3,448,896]{3,2,1,0} copy(f32[3,3,448,896]{1,0,2,3} %add.125), metadata={op_name="tuple.85"}
}

%fused_computation.229 (param_0.1450: f32[16,57,57,448], param_1.1969: f32[448], param_2.1168: f32[448], param_3.971: f32[448], param_4.859: f32[16,56,56,448], param_5.856: f32[448]) -> (f32[16,448], f32[16,448], f32[16,448]) {
  %param_4.859 = f32[16,56,56,448]{2,1,3,0} parameter(4)
  %param_5.856 = f32[448]{0} parameter(5)
  %constant_2240 = f32[] constant(1.99298465e-05)
  %broadcast.2834 = f32[448]{0} broadcast(f32[] %constant_2240), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1879 = f32[448]{0} multiply(f32[448]{0} %param_5.856, f32[448]{0} %broadcast.2834), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2833 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1879), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.295 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_4.859, f32[16,56,56,448]{2,1,3,0} %broadcast.2833), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.971 = f32[448]{0} parameter(3)
  %constant_413 = f32[] constant(0)
  %broadcast.2832 = f32[448]{0} broadcast(f32[] %constant_413), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.499 = f32[448]{0} maximum(f32[448]{0} %param_3.971, f32[448]{0} %broadcast.2832), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2238 = f32[] constant(1e-05)
  %broadcast.2831 = f32[448]{0} broadcast(f32[] %constant_2238), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.949 = f32[448]{0} add(f32[448]{0} %maximum.499, f32[448]{0} %broadcast.2831), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1754 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.949), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.355 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1754), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1168 = f32[448]{0} parameter(2)
  %bitcast.1753 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_2.1168), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1878 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.355, f32[1,1,1,448]{3,2,1,0} %bitcast.1753), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1752 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1878), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2830 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1752), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1877 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.295, f32[16,56,56,448]{2,1,3,0} %broadcast.2830), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1969 = f32[448]{0} parameter(1)
  %broadcast.2829 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_1.1969), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.948 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.1877, f32[16,56,56,448]{2,1,3,0} %broadcast.2829), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2828 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_413), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.255 = pred[16,56,56,448]{2,1,3,0} compare(f32[16,56,56,448]{2,1,3,0} %add.948, f32[16,56,56,448]{2,1,3,0} %broadcast.2828), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1450 = f32[16,57,57,448]{2,1,3,0} parameter(0)
  %slice.21 = f32[16,56,56,448]{2,1,3,0} slice(f32[16,57,57,448]{2,1,3,0} %param_0.1450), slice={[0:16], [0:56], [0:56], [0:448]}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %select.255 = f32[16,56,56,448]{2,1,3,0} select(pred[16,56,56,448]{2,1,3,0} %compare.255, f32[16,56,56,448]{2,1,3,0} %slice.21, f32[16,56,56,448]{2,1,3,0} %broadcast.2828), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.37 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %select.255), dimensions={0,3,1,2}
  %bitcast.716 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.37), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.780 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.716, f32[] %constant_413), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1895.clone.1 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %select.255, f32[16,56,56,448]{2,1,3,0} %broadcast.2830), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.25.clone.1 = f32[16,56,56,448]{2,1,3,0} negate(f32[16,56,56,448]{2,1,3,0} %multiply.1895.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.38 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %negate.25.clone.1), dimensions={0,3,1,2}
  %bitcast.719.clone.1 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.38), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.781.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.719.clone.1, f32[] %constant_413), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.506.clone.1 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.295, f32[16,56,56,448]{2,1,3,0} %select.255), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.39 = f32[16,448,56,56]{3,2,1,0} transpose(f32[16,56,56,448]{2,1,3,0} %multiply.506.clone.1), dimensions={0,3,1,2}
  %bitcast.721.clone.1 = f32[16,448,3136]{2,1,0} bitcast(f32[16,448,56,56]{3,2,1,0} %transpose.39), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.783.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %bitcast.721.clone.1, f32[] %constant_413), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.42 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.780, f32[16,448]{1,0} %reduce.781.clone.1, f32[16,448]{1,0} %reduce.783.clone.1)
}

%fused_computation.231 (param_0.412: f32[1,1,896,448], param_1.600: f32[1,1,896,448]) -> f32[1,1,896,448] {
  %param_1.600 = f32[1,1,896,448]{3,2,1,0} parameter(1)
  %copy.168 = f32[1,1,896,448]{1,0,2,3} copy(f32[1,1,896,448]{3,2,1,0} %param_1.600), metadata={op_name="3$start"}
  %param_0.412 = f32[1,1,896,448]{1,0,2,3} parameter(0)
  %add.128 = f32[1,1,896,448]{1,0,2,3} add(f32[1,1,896,448]{1,0,2,3} %copy.168, f32[1,1,896,448]{1,0,2,3} %param_0.412), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  ROOT %copy.167 = f32[1,1,896,448]{3,2,1,0} copy(f32[1,1,896,448]{1,0,2,3} %add.128), metadata={op_name="tuple.85"}
}

%fused_computation.232 (param_0.415: f32[448], param_1.606: f32[448], param_2.1170: f32[16,56,56,448], param_3.973: f32[448], param_4.861: f32[1,1,1,448], param_5.858: f32[448], param_6.600: f32[16,57,57,448], param_7.674: f32[448]) -> f32[16,56,56,448] {
  %param_2.1170 = f32[16,56,56,448]{2,1,3,0} parameter(2)
  %param_1.606 = f32[448]{0} parameter(1)
  %constant_415 = f32[] constant(1.99298465e-05)
  %broadcast.2854 = f32[448]{0} broadcast(f32[] %constant_415), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1889 = f32[448]{0} multiply(f32[448]{0} %param_1.606, f32[448]{0} %broadcast.2854), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2853 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1889), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.297 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_2.1170, f32[16,56,56,448]{2,1,3,0} %broadcast.2853), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.973 = f32[448]{0} parameter(3)
  %constant_419 = f32[] constant(0)
  %broadcast.2852 = f32[448]{0} broadcast(f32[] %constant_419), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.503 = f32[448]{0} maximum(f32[448]{0} %param_3.973, f32[448]{0} %broadcast.2852), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2036 = f32[] constant(1e-05)
  %broadcast.2851 = f32[448]{0} broadcast(f32[] %constant_2036), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.955 = f32[448]{0} add(f32[448]{0} %maximum.503, f32[448]{0} %broadcast.2851), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1766 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.955), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.359 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1766), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.858 = f32[448]{0} parameter(5)
  %bitcast.1765 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_5.858), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1888 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.359, f32[1,1,1,448]{3,2,1,0} %bitcast.1765), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1764 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2850 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1764), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1887 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.297, f32[16,56,56,448]{2,1,3,0} %broadcast.2850), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.674 = f32[448]{0} parameter(7)
  %broadcast.2849 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_7.674), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.954 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.1887, f32[16,56,56,448]{2,1,3,0} %broadcast.2849), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2848 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_419), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.257 = pred[16,56,56,448]{2,1,3,0} compare(f32[16,56,56,448]{2,1,3,0} %add.954, f32[16,56,56,448]{2,1,3,0} %broadcast.2848), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.600 = f32[16,57,57,448]{2,1,3,0} parameter(6)
  %slice.23 = f32[16,56,56,448]{2,1,3,0} slice(f32[16,57,57,448]{2,1,3,0} %param_6.600), slice={[0:16], [0:56], [0:56], [0:448]}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %select.257 = f32[16,56,56,448]{2,1,3,0} select(pred[16,56,56,448]{2,1,3,0} %compare.257, f32[16,56,56,448]{2,1,3,0} %slice.23, f32[16,56,56,448]{2,1,3,0} %broadcast.2848), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1885 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %select.257, f32[16,56,56,448]{2,1,3,0} %broadcast.2850), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.861 = f32[1,1,1,448]{3,2,1,0} parameter(4)
  %multiply.505 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %param_4.861, f32[1,1,1,448]{3,2,1,0} %bitcast.1765), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.25 = f32[1,1,1,448]{3,2,1,0} divide(f32[1,1,1,448]{3,2,1,0} %rsqrt.359, f32[1,1,1,448]{3,2,1,0} %bitcast.1766), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_416 = f32[] constant(-0.5)
  %broadcast.522 = f32[1,1,1,448]{3,2,1,0} broadcast(f32[] %constant_416), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.504 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %divide.25, f32[1,1,1,448]{3,2,1,0} %broadcast.522), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.503 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %multiply.505, f32[1,1,1,448]{3,2,1,0} %multiply.504), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.718 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.503), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.35 = pred[448]{0} compare(f32[448]{0} %param_3.973, f32[448]{0} %maximum.503), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_417 = f32[] constant(1)
  %broadcast.521 = f32[448]{0} broadcast(f32[] %constant_417), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/broadcast_in_dim[shape=(448,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.35 = f32[448]{0} select(pred[448]{0} %compare.35, f32[448]{0} %broadcast.521, f32[448]{0} %broadcast.2852), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.34 = pred[448]{0} compare(f32[448]{0} %broadcast.2852, f32[448]{0} %maximum.503), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_418 = f32[] constant(2)
  %broadcast.520 = f32[448]{0} broadcast(f32[] %constant_418), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.34 = f32[448]{0} select(pred[448]{0} %compare.34, f32[448]{0} %broadcast.520, f32[448]{0} %broadcast.521), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.24 = f32[448]{0} divide(f32[448]{0} %select.35, f32[448]{0} %select.34), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.502 = f32[448]{0} multiply(f32[448]{0} %bitcast.718, f32[448]{0} %divide.24), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_414 = f32[] constant(3.98596931e-05)
  %broadcast.518 = f32[448]{0} broadcast(f32[] %constant_414), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.501 = f32[448]{0} multiply(f32[448]{0} %multiply.502, f32[448]{0} %broadcast.518), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.517 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.501), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.500 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %param_2.1170, f32[16,56,56,448]{2,1,3,0} %broadcast.517), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.131 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.1885, f32[16,56,56,448]{2,1,3,0} %multiply.500), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.415 = f32[448]{0} parameter(0)
  %negate.24 = f32[448]{0} negate(f32[448]{0} %multiply.502), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.499 = f32[448]{0} multiply(f32[448]{0} %param_1.606, f32[448]{0} %broadcast.518), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.498 = f32[448]{0} multiply(f32[448]{0} %negate.24, f32[448]{0} %multiply.499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.130 = f32[448]{0} add(f32[448]{0} %param_0.415, f32[448]{0} %multiply.498), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.497 = f32[448]{0} multiply(f32[448]{0} %add.130, f32[448]{0} %broadcast.2854), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.516 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.497), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/broadcast_in_dim[shape=(16, 56, 56, 448) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.129 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %add.131, f32[16,56,56,448]{2,1,3,0} %broadcast.516), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.234 (param_0.419: f32[16,448]) -> f32[1,1,1,448] {
  %param_0.419 = f32[16,448]{1,0} parameter(0)
  %constant_420 = f32[] constant(0)
  %reduce.782 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.419, f32[] %constant_420), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.720 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %reduce.782), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.238 (param_0.428: f32[896], param_1.625: f32[896], param_2.1142: f32[16,28,28,896], param_3.940: f32[896], param_4.825: f32[1,1,1,896], param_5.815: f32[896], param_6.574: f32[16,28,28,896], param_7.655: f32[896]) -> f32[16,28,28,896] {
  %param_2.1142 = f32[16,28,28,896]{2,1,3,0} parameter(2)
  %param_1.625 = f32[896]{0} parameter(1)
  %constant_428 = f32[] constant(7.97193861e-05)
  %broadcast.2772 = f32[896]{0} broadcast(f32[] %constant_428), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1851 = f32[896]{0} multiply(f32[896]{0} %param_1.625, f32[896]{0} %broadcast.2772), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2771 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1851), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.287 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_2.1142, f32[16,28,28,896]{2,1,3,0} %broadcast.2771), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.940 = f32[896]{0} parameter(3)
  %constant_429 = f32[] constant(0)
  %broadcast.2770 = f32[896]{0} broadcast(f32[] %constant_429), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.489 = f32[896]{0} maximum(f32[896]{0} %param_3.940, f32[896]{0} %broadcast.2770), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2093 = f32[] constant(1e-05)
  %broadcast.2769 = f32[896]{0} broadcast(f32[] %constant_2093), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.931 = f32[896]{0} add(f32[896]{0} %maximum.489, f32[896]{0} %broadcast.2769), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1724 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.931), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.345 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1724), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.815 = f32[896]{0} parameter(5)
  %bitcast.1723 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.815), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1850 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.345, f32[1,1,1,896]{3,2,1,0} %bitcast.1723), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1722 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1850), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2768 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1722), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1849 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.287, f32[16,28,28,896]{2,1,3,0} %broadcast.2768), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.655 = f32[896]{0} parameter(7)
  %broadcast.2767 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.655), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.930 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1849, f32[16,28,28,896]{2,1,3,0} %broadcast.2767), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2766 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_429), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.247 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.930, f32[16,28,28,896]{2,1,3,0} %broadcast.2766), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.574 = f32[16,28,28,896]{2,1,3,0} parameter(6)
  %select.247 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.247, f32[16,28,28,896]{2,1,3,0} %param_6.574, f32[16,28,28,896]{2,1,3,0} %broadcast.2766), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1847 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.247, f32[16,28,28,896]{2,1,3,0} %broadcast.2768), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.825 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.516 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.825, f32[1,1,1,896]{3,2,1,0} %bitcast.1723), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.27 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.345, f32[1,1,1,896]{3,2,1,0} %bitcast.1724), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_425 = f32[] constant(-0.5)
  %broadcast.531 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_425), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.515 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.27, f32[1,1,1,896]{3,2,1,0} %broadcast.531), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.514 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.516, f32[1,1,1,896]{3,2,1,0} %multiply.515), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.722 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.514), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.38 = pred[896]{0} compare(f32[896]{0} %param_3.940, f32[896]{0} %maximum.489), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_426 = f32[] constant(1)
  %broadcast.530 = f32[896]{0} broadcast(f32[] %constant_426), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.38 = f32[896]{0} select(pred[896]{0} %compare.38, f32[896]{0} %broadcast.530, f32[896]{0} %broadcast.2770), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.37 = pred[896]{0} compare(f32[896]{0} %broadcast.2770, f32[896]{0} %maximum.489), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_427 = f32[] constant(2)
  %broadcast.529 = f32[896]{0} broadcast(f32[] %constant_427), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.37 = f32[896]{0} select(pred[896]{0} %compare.37, f32[896]{0} %broadcast.529, f32[896]{0} %broadcast.530), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.26 = f32[896]{0} divide(f32[896]{0} %select.38, f32[896]{0} %select.37), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.513 = f32[896]{0} multiply(f32[896]{0} %bitcast.722, f32[896]{0} %divide.26), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_424 = f32[] constant(0.000159438772)
  %broadcast.528 = f32[896]{0} broadcast(f32[] %constant_424), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.512 = f32[896]{0} multiply(f32[896]{0} %multiply.513, f32[896]{0} %broadcast.528), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.527 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.512), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.511 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %param_2.1142, f32[16,28,28,896]{2,1,3,0} %broadcast.527), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.134 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1847, f32[16,28,28,896]{2,1,3,0} %multiply.511), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.428 = f32[896]{0} parameter(0)
  %negate.26 = f32[896]{0} negate(f32[896]{0} %multiply.513), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.510 = f32[896]{0} multiply(f32[896]{0} %param_1.625, f32[896]{0} %broadcast.528), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.509 = f32[896]{0} multiply(f32[896]{0} %negate.26, f32[896]{0} %multiply.510), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.133 = f32[896]{0} add(f32[896]{0} %param_0.428, f32[896]{0} %multiply.509), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.508 = f32[896]{0} multiply(f32[896]{0} %add.133, f32[896]{0} %broadcast.2772), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.526 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.508), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/broadcast_in_dim[shape=(16, 28, 28, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.132 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %add.134, f32[16,28,28,896]{2,1,3,0} %broadcast.526), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.240 (param_0.432: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.432 = f32[16,896]{1,0} parameter(0)
  %constant_430 = f32[] constant(0)
  %reduce.785 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.432, f32[] %constant_430), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.724 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.785), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.244 (param_0.440: f32[1792], param_1.643: f32[1792], param_2.1119: f32[16,28,28,1792], param_3.915: f32[1792], param_4.799: f32[1,1,1,1792], param_5.785: f32[1792], param_6.554: f32[16,28,28,1792], param_7.1254: f32[1792], param_8.996: f32[1792], param_9.650: f32[16,28,28,1792], param_10.508: f32[1792], param_11.465: f32[1,1,1,1792], param_12.385: f32[1792]) -> (f32[16,28,28,1792], f32[16,28,28,1792]) {
  %param_6.554 = f32[16,28,28,1792]{2,1,3,0} parameter(6)
  %param_3.915 = f32[1792]{0} parameter(3)
  %constant_439 = f32[] constant(0)
  %broadcast.2704 = f32[1792]{0} broadcast(f32[] %constant_439), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.477 = f32[1792]{0} maximum(f32[1792]{0} %param_3.915, f32[1792]{0} %broadcast.2704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2144 = f32[] constant(1e-05)
  %broadcast.2703 = f32[1792]{0} broadcast(f32[] %constant_2144), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.911 = f32[1792]{0} add(f32[1792]{0} %maximum.477, f32[1792]{0} %broadcast.2703), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1688 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.911), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.333 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1688), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.785 = f32[1792]{0} parameter(5)
  %bitcast.1687 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.785), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1819 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.333, f32[1,1,1,1792]{3,2,1,0} %bitcast.1687), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1686 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1819), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2702 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1686), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1818 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_6.554, f32[16,28,28,1792]{2,1,3,0} %broadcast.2702), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.1119 = f32[16,28,28,1792]{2,1,3,0} parameter(2)
  %param_4.799 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.527 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.799, f32[1,1,1,1792]{3,2,1,0} %bitcast.1687), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.29 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.333, f32[1,1,1,1792]{3,2,1,0} %bitcast.1688), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_435 = f32[] constant(-0.5)
  %broadcast.542 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_435), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.526 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.29, f32[1,1,1,1792]{3,2,1,0} %broadcast.542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.525 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.527, f32[1,1,1,1792]{3,2,1,0} %multiply.526), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.726 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.525), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.41 = pred[1792]{0} compare(f32[1792]{0} %param_3.915, f32[1792]{0} %maximum.477), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_436 = f32[] constant(1)
  %broadcast.541 = f32[1792]{0} broadcast(f32[] %constant_436), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.41 = f32[1792]{0} select(pred[1792]{0} %compare.41, f32[1792]{0} %broadcast.541, f32[1792]{0} %broadcast.2704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.40 = pred[1792]{0} compare(f32[1792]{0} %broadcast.2704, f32[1792]{0} %maximum.477), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_437 = f32[] constant(2)
  %broadcast.540 = f32[1792]{0} broadcast(f32[] %constant_437), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.40 = f32[1792]{0} select(pred[1792]{0} %compare.40, f32[1792]{0} %broadcast.540, f32[1792]{0} %broadcast.541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.28 = f32[1792]{0} divide(f32[1792]{0} %select.41, f32[1792]{0} %select.40), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.524 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.726, f32[1792]{0} %divide.28), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_434 = f32[] constant(0.000159438772)
  %broadcast.538 = f32[1792]{0} broadcast(f32[] %constant_434), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.523 = f32[1792]{0} multiply(f32[1792]{0} %multiply.524, f32[1792]{0} %broadcast.538), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.537 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.523), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.522 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_2.1119, f32[16,28,28,1792]{2,1,3,0} %broadcast.537), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.137 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %multiply.1818, f32[16,28,28,1792]{2,1,3,0} %multiply.522), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.440 = f32[1792]{0} parameter(0)
  %negate.28 = f32[1792]{0} negate(f32[1792]{0} %multiply.524), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.643 = f32[1792]{0} parameter(1)
  %multiply.521 = f32[1792]{0} multiply(f32[1792]{0} %param_1.643, f32[1792]{0} %broadcast.538), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.520 = f32[1792]{0} multiply(f32[1792]{0} %negate.28, f32[1792]{0} %multiply.521), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.136 = f32[1792]{0} add(f32[1792]{0} %param_0.440, f32[1792]{0} %multiply.520), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_438 = f32[] constant(7.97193861e-05)
  %broadcast.539 = f32[1792]{0} broadcast(f32[] %constant_438), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.519 = f32[1792]{0} multiply(f32[1792]{0} %add.136, f32[1792]{0} %broadcast.539), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.536 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.519), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/broadcast_in_dim[shape=(16, 28, 28, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %add.135 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %add.137, f32[16,28,28,1792]{2,1,3,0} %broadcast.536), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %param_10.508 = f32[1792]{0} parameter(10)
  %maximum.519.clone.1 = f32[1792]{0} maximum(f32[1792]{0} %param_10.508, f32[1792]{0} %broadcast.2704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.969.clone.1 = f32[1792]{0} add(f32[1792]{0} %maximum.519.clone.1, f32[1792]{0} %broadcast.2703), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1790.clone.1 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.969.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.365.clone.1 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1790.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_12.385 = f32[1792]{0} parameter(12)
  %bitcast.1789.clone.1 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_12.385), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1907.clone.1 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.365.clone.1, f32[1,1,1,1792]{3,2,1,0} %bitcast.1789.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1788.clone.1 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1907.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2898.clone.1 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1788.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1906.clone.1 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_6.554, f32[16,28,28,1792]{2,1,3,0} %broadcast.2898.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_9.650 = f32[16,28,28,1792]{2,1,3,0} parameter(9)
  %param_11.465 = f32[1,1,1,1792]{3,2,1,0} parameter(11)
  %multiply.486.clone.1 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_11.465, f32[1,1,1,1792]{3,2,1,0} %bitcast.1789.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.23.clone.1 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.365.clone.1, f32[1,1,1,1792]{3,2,1,0} %bitcast.1790.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.485.clone.1 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.23.clone.1, f32[1,1,1,1792]{3,2,1,0} %broadcast.542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.484.clone.1 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.486.clone.1, f32[1,1,1,1792]{3,2,1,0} %multiply.485.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.704.clone.1 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.484.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.33.clone.1 = pred[1792]{0} compare(f32[1792]{0} %param_10.508, f32[1792]{0} %maximum.519.clone.1), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.33.clone.1 = f32[1792]{0} select(pred[1792]{0} %compare.33.clone.1, f32[1792]{0} %broadcast.541, f32[1792]{0} %broadcast.2704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.32.clone.1 = pred[1792]{0} compare(f32[1792]{0} %broadcast.2704, f32[1792]{0} %maximum.519.clone.1), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.32.clone.1 = f32[1792]{0} select(pred[1792]{0} %compare.32.clone.1, f32[1792]{0} %broadcast.540, f32[1792]{0} %broadcast.541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.22.clone.1 = f32[1792]{0} divide(f32[1792]{0} %select.33.clone.1, f32[1792]{0} %select.32.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.483.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.704.clone.1, f32[1792]{0} %divide.22.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.482.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.483.clone.1, f32[1792]{0} %broadcast.538), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.503.clone.1 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.482.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.481.clone.1 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_9.650, f32[16,28,28,1792]{2,1,3,0} %broadcast.503.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.119.clone.1 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %multiply.1906.clone.1, f32[16,28,28,1792]{2,1,3,0} %multiply.481.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_7.1254 = f32[1792]{0} parameter(7)
  %negate.22.clone.1 = f32[1792]{0} negate(f32[1792]{0} %multiply.483.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_8.996 = f32[1792]{0} parameter(8)
  %multiply.480.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_8.996, f32[1792]{0} %broadcast.538), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.479.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %negate.22.clone.1, f32[1792]{0} %multiply.480.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.118.clone.1 = f32[1792]{0} add(f32[1792]{0} %param_7.1254, f32[1792]{0} %multiply.479.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.478.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %add.118.clone.1, f32[1792]{0} %broadcast.539), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.502.clone.1 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.478.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/broadcast_in_dim[shape=(16, 28, 28, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %add.117.clone.1 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %add.119.clone.1, f32[16,28,28,1792]{2,1,3,0} %broadcast.502.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %tuple.69 = (f32[16,28,28,1792]{2,1,3,0}, f32[16,28,28,1792]{2,1,3,0}) tuple(f32[16,28,28,1792]{2,1,3,0} %add.135, f32[16,28,28,1792]{2,1,3,0} %add.117.clone.1)
}

%fused_computation.246 (param_0.444: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.444 = f32[16,1792]{1,0} parameter(0)
  %constant_440 = f32[] constant(0)
  %reduce.788 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.444, f32[] %constant_440), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.728 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.788), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.255 (param_0.1419: f32[896], param_1.1930: f32[896], param_2.1108: f32[896], param_3.904: f32[16,28,28,896], param_4.797: f32[896]) -> f32[16,28,28,896] {
  %param_3.904 = f32[16,28,28,896]{2,1,3,0} parameter(3)
  %param_4.797 = f32[896]{0} parameter(4)
  %constant_2123 = f32[] constant(7.97193861e-05)
  %broadcast.2678 = f32[896]{0} broadcast(f32[] %constant_2123), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1811 = f32[896]{0} multiply(f32[896]{0} %param_4.797, f32[896]{0} %broadcast.2678), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2677 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1811), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.279 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_3.904, f32[16,28,28,896]{2,1,3,0} %broadcast.2677), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1108 = f32[896]{0} parameter(2)
  %constant_450 = f32[] constant(0)
  %broadcast.2676 = f32[896]{0} broadcast(f32[] %constant_450), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.465 = f32[896]{0} maximum(f32[896]{0} %param_2.1108, f32[896]{0} %broadcast.2676), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2121 = f32[] constant(1e-05)
  %broadcast.2675 = f32[896]{0} broadcast(f32[] %constant_2121), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.903 = f32[896]{0} add(f32[896]{0} %maximum.465, f32[896]{0} %broadcast.2675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1676 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.903), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.331 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1676), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1930 = f32[896]{0} parameter(1)
  %bitcast.1675 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.1930), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1810 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.331, f32[1,1,1,896]{3,2,1,0} %bitcast.1675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1674 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1810), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2674 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1674), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1809 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.279, f32[16,28,28,896]{2,1,3,0} %broadcast.2674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1419 = f32[896]{0} parameter(0)
  %broadcast.2673 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1419), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.902 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1809, f32[16,28,28,896]{2,1,3,0} %broadcast.2673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.550 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_450), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.21 = f32[16,28,28,896]{2,1,3,0} maximum(f32[16,28,28,896]{2,1,3,0} %add.902, f32[16,28,28,896]{2,1,3,0} %broadcast.550), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.260 (param_0.1404: f32[16,896], param_1.1907: f32[896]) -> f32[896] {
  %param_0.1404 = f32[16,896]{1,0} parameter(0)
  %constant_454 = f32[] constant(0)
  %reduce.793 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1404, f32[] %constant_454), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_453 = f32[] constant(7.97193861e-05)
  %broadcast.555 = f32[896]{0} broadcast(f32[] %constant_453), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.538 = f32[896]{0} multiply(f32[896]{0} %reduce.793, f32[896]{0} %broadcast.555), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1907 = f32[896]{0} parameter(1)
  %multiply.1791 = f32[896]{0} multiply(f32[896]{0} %param_1.1907, f32[896]{0} %broadcast.555), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.537 = f32[896]{0} multiply(f32[896]{0} %multiply.1791, f32[896]{0} %multiply.1791), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.26 = f32[896]{0} subtract(f32[896]{0} %multiply.538, f32[896]{0} %multiply.537), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.265 (param_0.1401: f32[448], param_1.1905: f32[448], param_2.1074: f32[448], param_3.873: f32[16,56,56,448], param_4.772: f32[448]) -> f32[16,57,57,448] {
  %param_3.873 = f32[16,56,56,448]{2,1,3,0} parameter(3)
  %param_4.772 = f32[448]{0} parameter(4)
  %constant_2066 = f32[] constant(1.99298465e-05)
  %broadcast.2618 = f32[448]{0} broadcast(f32[] %constant_2066), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1787 = f32[448]{0} multiply(f32[448]{0} %param_4.772, f32[448]{0} %broadcast.2618), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2617 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1787), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.271 = f32[16,56,56,448]{2,1,3,0} subtract(f32[16,56,56,448]{2,1,3,0} %param_3.873, f32[16,56,56,448]{2,1,3,0} %broadcast.2617), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1074 = f32[448]{0} parameter(2)
  %constant_458 = f32[] constant(0)
  %broadcast.2616 = f32[448]{0} broadcast(f32[] %constant_458), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.447 = f32[448]{0} maximum(f32[448]{0} %param_2.1074, f32[448]{0} %broadcast.2616), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2064 = f32[] constant(1e-05)
  %broadcast.2615 = f32[448]{0} broadcast(f32[] %constant_2064), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.885 = f32[448]{0} add(f32[448]{0} %maximum.447, f32[448]{0} %broadcast.2615), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1646 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.323 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1646), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1905 = f32[448]{0} parameter(1)
  %bitcast.1645 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_1.1905), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1786 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.323, f32[1,1,1,448]{3,2,1,0} %bitcast.1645), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1644 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1786), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2614 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1644), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1785 = f32[16,56,56,448]{2,1,3,0} multiply(f32[16,56,56,448]{2,1,3,0} %subtract.271, f32[16,56,56,448]{2,1,3,0} %broadcast.2614), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1401 = f32[448]{0} parameter(0)
  %broadcast.2613 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[448]{0} %param_0.1401), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.884 = f32[16,56,56,448]{2,1,3,0} add(f32[16,56,56,448]{2,1,3,0} %multiply.1785, f32[16,56,56,448]{2,1,3,0} %broadcast.2613), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.558 = f32[16,56,56,448]{2,1,3,0} broadcast(f32[] %constant_458), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %maximum.23 = f32[16,56,56,448]{2,1,3,0} maximum(f32[16,56,56,448]{2,1,3,0} %add.884, f32[16,56,56,448]{2,1,3,0} %broadcast.558), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %pad.5 = f32[16,57,57,448]{2,1,3,0} pad(f32[16,56,56,448]{2,1,3,0} %maximum.23, f32[] %constant_458), padding=0_0x0_1x0_1x0_0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.270 (param_0.1386: f32[16,448], param_1.1882: f32[448]) -> f32[448] {
  %param_0.1386 = f32[16,448]{1,0} parameter(0)
  %constant_462 = f32[] constant(0)
  %reduce.796 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.1386, f32[] %constant_462), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_461 = f32[] constant(1.99298465e-05)
  %broadcast.563 = f32[448]{0} broadcast(f32[] %constant_461), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.544 = f32[448]{0} multiply(f32[448]{0} %reduce.796, f32[448]{0} %broadcast.563), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1882 = f32[448]{0} parameter(1)
  %multiply.1767 = f32[448]{0} multiply(f32[448]{0} %param_1.1882, f32[448]{0} %broadcast.563), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.543 = f32[448]{0} multiply(f32[448]{0} %multiply.1767, f32[448]{0} %multiply.1767), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.28 = f32[448]{0} subtract(f32[448]{0} %multiply.544, f32[448]{0} %multiply.543), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.275 (param_0.492: f32[16,28,28,1792], param_1.722: f32[16,28,28,1792]) -> f32[16,28,28,1792] {
  %param_1.722 = f32[16,28,28,1792]{2,1,3,0} parameter(1)
  %constant_466 = f32[] constant(0)
  %broadcast.566 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[] %constant_466), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.42 = pred[16,28,28,1792]{2,1,3,0} compare(f32[16,28,28,1792]{2,1,3,0} %param_1.722, f32[16,28,28,1792]{2,1,3,0} %broadcast.566), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.492 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  ROOT %select.42 = f32[16,28,28,1792]{2,1,3,0} select(pred[16,28,28,1792]{2,1,3,0} %compare.42, f32[16,28,28,1792]{2,1,3,0} %param_0.492, f32[16,28,28,1792]{2,1,3,0} %broadcast.566), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.278 (param_0.496: f32[1792], param_1.1411: f32[1,1,1,1792], param_2.1762: f32[1792], param_3.1552: f32[16,1792]) -> (f32[1792], f32[1792]) {
  %param_0.496 = f32[1792]{0} parameter(0)
  %param_3.1552 = f32[16,1792]{1,0} parameter(3)
  %constant_1893 = f32[] constant(0)
  %reduce.814.clone.1 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3.1552, f32[] %constant_1893), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_1869_clone_1 = f32[] constant(7.97193861e-05)
  %broadcast.599.clone.1 = f32[1792]{0} broadcast(f32[] %constant_1869_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.585.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %reduce.814.clone.1, f32[1792]{0} %broadcast.599.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1762 = f32[1792]{0} parameter(2)
  %multiply.1677.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_2.1762, f32[1792]{0} %broadcast.599.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.584.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1677.clone.1, f32[1792]{0} %multiply.1677.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.31.clone.1 = f32[1792]{0} subtract(f32[1792]{0} %multiply.585.clone.1, f32[1792]{0} %multiply.584.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.2382 = f32[1792]{0} broadcast(f32[] %constant_1893), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.397 = f32[1792]{0} maximum(f32[1792]{0} %subtract.31.clone.1, f32[1792]{0} %broadcast.2382), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1892 = f32[] constant(1e-05)
  %broadcast.2381 = f32[1792]{0} broadcast(f32[] %constant_1892), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.815 = f32[1792]{0} add(f32[1792]{0} %maximum.397, f32[1792]{0} %broadcast.2381), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1520 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.815), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.45 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1520), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1411 = f32[1,1,1,1792]{3,2,1,0} parameter(1)
  %multiply.547 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.45, f32[1,1,1,1792]{3,2,1,0} %param_1.1411), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.743 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.144 = f32[1792]{0} add(f32[1792]{0} %param_0.496, f32[1792]{0} %bitcast.743), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  ROOT %tuple.76 = (f32[1792]{0}, f32[1792]{0}) tuple(f32[1792]{0} %add.144, f32[1792]{0} %subtract.31.clone.1)
}

%fused_computation.279 (param_0.499: f32[1,1,896,1792], param_1.731: f32[1,1,896,1792]) -> f32[1,1,896,1792] {
  %param_1.731 = f32[1,1,896,1792]{3,2,1,0} parameter(1)
  %copy.170 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %param_1.731), metadata={op_name="3$start"}
  %param_0.499 = f32[1,1,896,1792]{1,0,2,3} parameter(0)
  %add.145 = f32[1,1,896,1792]{1,0,2,3} add(f32[1,1,896,1792]{1,0,2,3} %copy.170, f32[1,1,896,1792]{1,0,2,3} %param_0.499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  ROOT %copy.169 = f32[1,1,896,1792]{3,2,1,0} copy(f32[1,1,896,1792]{1,0,2,3} %add.145), metadata={op_name="tuple.85"}
}

%fused_computation.281 (param_0.1368: f32[16,28,28,896], param_1.1854: f32[896], param_2.1004: f32[896], param_3.799: f32[896], param_4.703: f32[16,28,28,896], param_5.694: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.703 = f32[16,28,28,896]{2,1,3,0} parameter(4)
  %param_5.694 = f32[896]{0} parameter(5)
  %constant_1930 = f32[] constant(7.97193861e-05)
  %broadcast.2436 = f32[896]{0} broadcast(f32[] %constant_1930), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1705 = f32[896]{0} multiply(f32[896]{0} %param_5.694, f32[896]{0} %broadcast.2436), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2435 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1705), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.249 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_4.703, f32[16,28,28,896]{2,1,3,0} %broadcast.2435), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.799 = f32[896]{0} parameter(3)
  %constant_470 = f32[] constant(0)
  %broadcast.2434 = f32[896]{0} broadcast(f32[] %constant_470), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.407 = f32[896]{0} maximum(f32[896]{0} %param_3.799, f32[896]{0} %broadcast.2434), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1928 = f32[] constant(1e-05)
  %broadcast.2433 = f32[896]{0} broadcast(f32[] %constant_1928), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.831 = f32[896]{0} add(f32[896]{0} %maximum.407, f32[896]{0} %broadcast.2433), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1550 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.831), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.293 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1550), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1004 = f32[896]{0} parameter(2)
  %bitcast.1549 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.1004), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1704 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.293, f32[1,1,1,896]{3,2,1,0} %bitcast.1549), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1548 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2432 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1548), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1703 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.249, f32[16,28,28,896]{2,1,3,0} %broadcast.2432), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1854 = f32[896]{0} parameter(1)
  %broadcast.2431 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.1854), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.830 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1703, f32[16,28,28,896]{2,1,3,0} %broadcast.2431), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2430 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_470), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.225 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.830, f32[16,28,28,896]{2,1,3,0} %broadcast.2430), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1368 = f32[16,28,28,896]{2,1,3,0} parameter(0)
  %select.225 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.225, f32[16,28,28,896]{2,1,3,0} %param_0.1368, f32[16,28,28,896]{2,1,3,0} %broadcast.2430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.40 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %select.225), dimensions={0,3,1,2}
  %bitcast.744 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.40), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.802 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.744, f32[] %constant_470), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1721.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.225, f32[16,28,28,896]{2,1,3,0} %broadcast.2432), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.33.clone.1 = f32[16,28,28,896]{2,1,3,0} negate(f32[16,28,28,896]{2,1,3,0} %multiply.1721.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.41 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %negate.33.clone.1), dimensions={0,3,1,2}
  %bitcast.753.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.41), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.808.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.753.clone.1, f32[] %constant_470), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.570.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.249, f32[16,28,28,896]{2,1,3,0} %select.225), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.42 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %multiply.570.clone.1), dimensions={0,3,1,2}
  %bitcast.755.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.42), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.810.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.755.clone.1, f32[] %constant_470), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.75 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.802, f32[16,896]{1,0} %reduce.808.clone.1, f32[16,896]{1,0} %reduce.810.clone.1)
}

%fused_computation.283 (param_0.506: f32[3,3,448,896], param_1.740: f32[3,3,448,896]) -> f32[3,3,448,896] {
  %param_1.740 = f32[3,3,448,896]{3,2,1,0} parameter(1)
  %copy.172 = f32[3,3,448,896]{1,0,2,3} copy(f32[3,3,448,896]{3,2,1,0} %param_1.740), metadata={op_name="3$start"}
  %param_0.506 = f32[3,3,448,896]{1,0,2,3} parameter(0)
  %add.148 = f32[3,3,448,896]{1,0,2,3} add(f32[3,3,448,896]{1,0,2,3} %copy.172, f32[3,3,448,896]{1,0,2,3} %param_0.506), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  ROOT %copy.171 = f32[3,3,448,896]{3,2,1,0} copy(f32[3,3,448,896]{1,0,2,3} %add.148), metadata={op_name="tuple.85"}
}

%fused_computation.285 (param_0.1379: f32[16,28,28,448], param_1.1872: f32[448], param_2.1029: f32[448], param_3.830: f32[448], param_4.737: f32[16,28,28,448], param_5.737: f32[448]) -> (f32[16,448], f32[16,448], f32[16,448]) {
  %param_4.737 = f32[16,28,28,448]{2,1,3,0} parameter(4)
  %param_5.737 = f32[448]{0} parameter(5)
  %constant_1983 = f32[] constant(7.97193861e-05)
  %broadcast.2518 = f32[448]{0} broadcast(f32[] %constant_1983), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1743 = f32[448]{0} multiply(f32[448]{0} %param_5.737, f32[448]{0} %broadcast.2518), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2517 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1743), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.259 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_4.737, f32[16,28,28,448]{2,1,3,0} %broadcast.2517), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.830 = f32[448]{0} parameter(3)
  %constant_472 = f32[] constant(0)
  %broadcast.2516 = f32[448]{0} broadcast(f32[] %constant_472), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.421 = f32[448]{0} maximum(f32[448]{0} %param_3.830, f32[448]{0} %broadcast.2516), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1981 = f32[] constant(1e-05)
  %broadcast.2515 = f32[448]{0} broadcast(f32[] %constant_1981), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.855 = f32[448]{0} add(f32[448]{0} %maximum.421, f32[448]{0} %broadcast.2515), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1592 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.855), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.307 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1592), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1029 = f32[448]{0} parameter(2)
  %bitcast.1591 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_2.1029), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1742 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.307, f32[1,1,1,448]{3,2,1,0} %bitcast.1591), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1590 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1742), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2514 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1590), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1741 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.259, f32[16,28,28,448]{2,1,3,0} %broadcast.2514), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1872 = f32[448]{0} parameter(1)
  %broadcast.2513 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_1.1872), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.854 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1741, f32[16,28,28,448]{2,1,3,0} %broadcast.2513), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2512 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_472), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.235 = pred[16,28,28,448]{2,1,3,0} compare(f32[16,28,28,448]{2,1,3,0} %add.854, f32[16,28,28,448]{2,1,3,0} %broadcast.2512), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1379 = f32[16,28,28,448]{2,1,3,0} parameter(0)
  %select.235 = f32[16,28,28,448]{2,1,3,0} select(pred[16,28,28,448]{2,1,3,0} %compare.235, f32[16,28,28,448]{2,1,3,0} %param_0.1379, f32[16,28,28,448]{2,1,3,0} %broadcast.2512), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.43 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %select.235), dimensions={0,3,1,2}
  %bitcast.746 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.43), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.804 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.746, f32[] %constant_472), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1759.clone.1 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %select.235, f32[16,28,28,448]{2,1,3,0} %broadcast.2514), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.31.clone.1 = f32[16,28,28,448]{2,1,3,0} negate(f32[16,28,28,448]{2,1,3,0} %multiply.1759.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.44 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %negate.31.clone.1), dimensions={0,3,1,2}
  %bitcast.749.clone.1 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.44), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.805.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.749.clone.1, f32[] %constant_472), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.559.clone.1 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.259, f32[16,28,28,448]{2,1,3,0} %select.235), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.45 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %multiply.559.clone.1), dimensions={0,3,1,2}
  %bitcast.751.clone.1 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.45), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.807.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.751.clone.1, f32[] %constant_472), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.73 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.804, f32[16,448]{1,0} %reduce.805.clone.1, f32[16,448]{1,0} %reduce.807.clone.1)
}

%fused_computation.287 (param_0.513: f32[1,1,1792,448], param_1.749: f32[1,1,1792,448]) -> f32[1,1,1792,448] {
  %param_1.749 = f32[1,1,1792,448]{3,2,1,0} parameter(1)
  %copy.174 = f32[1,1,1792,448]{1,0,2,3} copy(f32[1,1,1792,448]{3,2,1,0} %param_1.749), metadata={op_name="3$start"}
  %param_0.513 = f32[1,1,1792,448]{1,0,2,3} parameter(0)
  %add.151 = f32[1,1,1792,448]{1,0,2,3} add(f32[1,1,1792,448]{1,0,2,3} %copy.174, f32[1,1,1792,448]{1,0,2,3} %param_0.513), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  ROOT %copy.173 = f32[1,1,1792,448]{3,2,1,0} copy(f32[1,1,1792,448]{1,0,2,3} %add.151), metadata={op_name="tuple.85"}
}

%fused_computation.288 (param_0.516: f32[448], param_1.755: f32[448], param_2.1031: f32[16,28,28,448], param_3.832: f32[448], param_4.739: f32[1,1,1,448], param_5.739: f32[448], param_6.538: f32[16,28,28,448], param_7.613: f32[448]) -> f32[16,28,28,448] {
  %param_2.1031 = f32[16,28,28,448]{2,1,3,0} parameter(2)
  %param_1.755 = f32[448]{0} parameter(1)
  %constant_477 = f32[] constant(7.97193861e-05)
  %broadcast.2538 = f32[448]{0} broadcast(f32[] %constant_477), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1753 = f32[448]{0} multiply(f32[448]{0} %param_1.755, f32[448]{0} %broadcast.2538), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2537 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1753), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.261 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_2.1031, f32[16,28,28,448]{2,1,3,0} %broadcast.2537), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.832 = f32[448]{0} parameter(3)
  %constant_478 = f32[] constant(0)
  %broadcast.2536 = f32[448]{0} broadcast(f32[] %constant_478), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.425 = f32[448]{0} maximum(f32[448]{0} %param_3.832, f32[448]{0} %broadcast.2536), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1779 = f32[] constant(1e-05)
  %broadcast.2535 = f32[448]{0} broadcast(f32[] %constant_1779), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.861 = f32[448]{0} add(f32[448]{0} %maximum.425, f32[448]{0} %broadcast.2535), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1604 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.861), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.311 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1604), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.739 = f32[448]{0} parameter(5)
  %bitcast.1603 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_5.739), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1752 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.311, f32[1,1,1,448]{3,2,1,0} %bitcast.1603), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1602 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2534 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1602), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1751 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.261, f32[16,28,28,448]{2,1,3,0} %broadcast.2534), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.613 = f32[448]{0} parameter(7)
  %broadcast.2533 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_7.613), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.860 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1751, f32[16,28,28,448]{2,1,3,0} %broadcast.2533), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2532 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_478), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.237 = pred[16,28,28,448]{2,1,3,0} compare(f32[16,28,28,448]{2,1,3,0} %add.860, f32[16,28,28,448]{2,1,3,0} %broadcast.2532), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.538 = f32[16,28,28,448]{2,1,3,0} parameter(6)
  %select.237 = f32[16,28,28,448]{2,1,3,0} select(pred[16,28,28,448]{2,1,3,0} %compare.237, f32[16,28,28,448]{2,1,3,0} %param_6.538, f32[16,28,28,448]{2,1,3,0} %broadcast.2532), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1749 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %select.237, f32[16,28,28,448]{2,1,3,0} %broadcast.2534), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.739 = f32[1,1,1,448]{3,2,1,0} parameter(4)
  %multiply.558 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %param_4.739, f32[1,1,1,448]{3,2,1,0} %bitcast.1603), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.31 = f32[1,1,1,448]{3,2,1,0} divide(f32[1,1,1,448]{3,2,1,0} %rsqrt.311, f32[1,1,1,448]{3,2,1,0} %bitcast.1604), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_474 = f32[] constant(-0.5)
  %broadcast.572 = f32[1,1,1,448]{3,2,1,0} broadcast(f32[] %constant_474), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.557 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %divide.31, f32[1,1,1,448]{3,2,1,0} %broadcast.572), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.556 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %multiply.558, f32[1,1,1,448]{3,2,1,0} %multiply.557), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.748 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.556), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.44 = pred[448]{0} compare(f32[448]{0} %param_3.832, f32[448]{0} %maximum.425), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_475 = f32[] constant(1)
  %broadcast.571 = f32[448]{0} broadcast(f32[] %constant_475), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/broadcast_in_dim[shape=(448,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.44 = f32[448]{0} select(pred[448]{0} %compare.44, f32[448]{0} %broadcast.571, f32[448]{0} %broadcast.2536), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.43 = pred[448]{0} compare(f32[448]{0} %broadcast.2536, f32[448]{0} %maximum.425), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_476 = f32[] constant(2)
  %broadcast.570 = f32[448]{0} broadcast(f32[] %constant_476), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.43 = f32[448]{0} select(pred[448]{0} %compare.43, f32[448]{0} %broadcast.570, f32[448]{0} %broadcast.571), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.30 = f32[448]{0} divide(f32[448]{0} %select.44, f32[448]{0} %select.43), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.555 = f32[448]{0} multiply(f32[448]{0} %bitcast.748, f32[448]{0} %divide.30), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_473 = f32[] constant(0.000159438772)
  %broadcast.569 = f32[448]{0} broadcast(f32[] %constant_473), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.554 = f32[448]{0} multiply(f32[448]{0} %multiply.555, f32[448]{0} %broadcast.569), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.568 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.554), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.553 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %param_2.1031, f32[16,28,28,448]{2,1,3,0} %broadcast.568), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.154 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1749, f32[16,28,28,448]{2,1,3,0} %multiply.553), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.516 = f32[448]{0} parameter(0)
  %negate.30 = f32[448]{0} negate(f32[448]{0} %multiply.555), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.552 = f32[448]{0} multiply(f32[448]{0} %param_1.755, f32[448]{0} %broadcast.569), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.551 = f32[448]{0} multiply(f32[448]{0} %negate.30, f32[448]{0} %multiply.552), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.153 = f32[448]{0} add(f32[448]{0} %param_0.516, f32[448]{0} %multiply.551), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.550 = f32[448]{0} multiply(f32[448]{0} %add.153, f32[448]{0} %broadcast.2538), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.567 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.550), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/broadcast_in_dim[shape=(16, 28, 28, 448) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.152 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %add.154, f32[16,28,28,448]{2,1,3,0} %broadcast.567), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.290 (param_0.520: f32[16,448]) -> f32[1,1,1,448] {
  %param_0.520 = f32[16,448]{1,0} parameter(0)
  %constant_479 = f32[] constant(0)
  %reduce.806 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.520, f32[] %constant_479), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.750 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %reduce.806), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.294 (param_0.528: f32[896], param_1.773: f32[896], param_2.1006: f32[16,28,28,896], param_3.801: f32[896], param_4.705: f32[1,1,1,896], param_5.696: f32[896], param_6.513: f32[16,28,28,896], param_7.595: f32[896]) -> f32[16,28,28,896] {
  %param_2.1006 = f32[16,28,28,896]{2,1,3,0} parameter(2)
  %param_1.773 = f32[896]{0} parameter(1)
  %constant_487 = f32[] constant(7.97193861e-05)
  %broadcast.2456 = f32[896]{0} broadcast(f32[] %constant_487), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1715 = f32[896]{0} multiply(f32[896]{0} %param_1.773, f32[896]{0} %broadcast.2456), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2455 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1715), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.251 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_2.1006, f32[16,28,28,896]{2,1,3,0} %broadcast.2455), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.801 = f32[896]{0} parameter(3)
  %constant_488 = f32[] constant(0)
  %broadcast.2454 = f32[896]{0} broadcast(f32[] %constant_488), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.411 = f32[896]{0} maximum(f32[896]{0} %param_3.801, f32[896]{0} %broadcast.2454), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1836 = f32[] constant(1e-05)
  %broadcast.2453 = f32[896]{0} broadcast(f32[] %constant_1836), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.837 = f32[896]{0} add(f32[896]{0} %maximum.411, f32[896]{0} %broadcast.2453), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1562 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.837), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.297 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1562), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.696 = f32[896]{0} parameter(5)
  %bitcast.1561 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.696), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1714 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.297, f32[1,1,1,896]{3,2,1,0} %bitcast.1561), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1560 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1714), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2452 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1560), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1713 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.251, f32[16,28,28,896]{2,1,3,0} %broadcast.2452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.595 = f32[896]{0} parameter(7)
  %broadcast.2451 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.595), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.836 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1713, f32[16,28,28,896]{2,1,3,0} %broadcast.2451), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2450 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_488), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.227 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.836, f32[16,28,28,896]{2,1,3,0} %broadcast.2450), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.513 = f32[16,28,28,896]{2,1,3,0} parameter(6)
  %select.227 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.227, f32[16,28,28,896]{2,1,3,0} %param_6.513, f32[16,28,28,896]{2,1,3,0} %broadcast.2450), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1711 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.227, f32[16,28,28,896]{2,1,3,0} %broadcast.2452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.705 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.569 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.705, f32[1,1,1,896]{3,2,1,0} %bitcast.1561), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.33 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.297, f32[1,1,1,896]{3,2,1,0} %bitcast.1562), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_484 = f32[] constant(-0.5)
  %broadcast.582 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_484), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.568 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.33, f32[1,1,1,896]{3,2,1,0} %broadcast.582), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.567 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.569, f32[1,1,1,896]{3,2,1,0} %multiply.568), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.752 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.567), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.47 = pred[896]{0} compare(f32[896]{0} %param_3.801, f32[896]{0} %maximum.411), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_485 = f32[] constant(1)
  %broadcast.581 = f32[896]{0} broadcast(f32[] %constant_485), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.47 = f32[896]{0} select(pred[896]{0} %compare.47, f32[896]{0} %broadcast.581, f32[896]{0} %broadcast.2454), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.46 = pred[896]{0} compare(f32[896]{0} %broadcast.2454, f32[896]{0} %maximum.411), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_486 = f32[] constant(2)
  %broadcast.580 = f32[896]{0} broadcast(f32[] %constant_486), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.46 = f32[896]{0} select(pred[896]{0} %compare.46, f32[896]{0} %broadcast.580, f32[896]{0} %broadcast.581), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.32 = f32[896]{0} divide(f32[896]{0} %select.47, f32[896]{0} %select.46), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.566 = f32[896]{0} multiply(f32[896]{0} %bitcast.752, f32[896]{0} %divide.32), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_483 = f32[] constant(0.000159438772)
  %broadcast.579 = f32[896]{0} broadcast(f32[] %constant_483), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.565 = f32[896]{0} multiply(f32[896]{0} %multiply.566, f32[896]{0} %broadcast.579), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.578 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.565), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.564 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %param_2.1006, f32[16,28,28,896]{2,1,3,0} %broadcast.578), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.157 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1711, f32[16,28,28,896]{2,1,3,0} %multiply.564), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.528 = f32[896]{0} parameter(0)
  %negate.32 = f32[896]{0} negate(f32[896]{0} %multiply.566), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.563 = f32[896]{0} multiply(f32[896]{0} %param_1.773, f32[896]{0} %broadcast.579), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.562 = f32[896]{0} multiply(f32[896]{0} %negate.32, f32[896]{0} %multiply.563), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.156 = f32[896]{0} add(f32[896]{0} %param_0.528, f32[896]{0} %multiply.562), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.561 = f32[896]{0} multiply(f32[896]{0} %add.156, f32[896]{0} %broadcast.2456), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.577 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.561), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/broadcast_in_dim[shape=(16, 28, 28, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.155 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %add.157, f32[16,28,28,896]{2,1,3,0} %broadcast.577), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.296 (param_0.532: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.532 = f32[16,896]{1,0} parameter(0)
  %constant_489 = f32[] constant(0)
  %reduce.809 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.532, f32[] %constant_489), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.754 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.809), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.300 (param_0.540: f32[1792], param_1.791: f32[1792], param_2.983: f32[16,28,28,1792], param_3.776: f32[1792], param_4.679: f32[1,1,1,1792], param_5.666: f32[1792], param_6.493: f32[16,28,28,1792]) -> f32[16,28,28,1792] {
  %param_6.493 = f32[16,28,28,1792]{2,1,3,0} parameter(6)
  %param_3.776 = f32[1792]{0} parameter(3)
  %constant_498 = f32[] constant(0)
  %broadcast.2388 = f32[1792]{0} broadcast(f32[] %constant_498), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.399 = f32[1792]{0} maximum(f32[1792]{0} %param_3.776, f32[1792]{0} %broadcast.2388), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1887 = f32[] constant(1e-05)
  %broadcast.2387 = f32[1792]{0} broadcast(f32[] %constant_1887), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.817 = f32[1792]{0} add(f32[1792]{0} %maximum.399, f32[1792]{0} %broadcast.2387), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1526 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.817), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.285 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1526), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.666 = f32[1792]{0} parameter(5)
  %bitcast.1525 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.666), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1683 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.285, f32[1,1,1,1792]{3,2,1,0} %bitcast.1525), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1524 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1683), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2386 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1524), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1682 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_6.493, f32[16,28,28,1792]{2,1,3,0} %broadcast.2386), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.983 = f32[16,28,28,1792]{2,1,3,0} parameter(2)
  %param_4.679 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.580 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.679, f32[1,1,1,1792]{3,2,1,0} %bitcast.1525), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.35 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.285, f32[1,1,1,1792]{3,2,1,0} %bitcast.1526), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_494 = f32[] constant(-0.5)
  %broadcast.593 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_494), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.579 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.35, f32[1,1,1,1792]{3,2,1,0} %broadcast.593), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.578 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.580, f32[1,1,1,1792]{3,2,1,0} %multiply.579), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.756 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.578), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.50 = pred[1792]{0} compare(f32[1792]{0} %param_3.776, f32[1792]{0} %maximum.399), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_495 = f32[] constant(1)
  %broadcast.592 = f32[1792]{0} broadcast(f32[] %constant_495), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.50 = f32[1792]{0} select(pred[1792]{0} %compare.50, f32[1792]{0} %broadcast.592, f32[1792]{0} %broadcast.2388), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.49 = pred[1792]{0} compare(f32[1792]{0} %broadcast.2388, f32[1792]{0} %maximum.399), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_496 = f32[] constant(2)
  %broadcast.591 = f32[1792]{0} broadcast(f32[] %constant_496), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.49 = f32[1792]{0} select(pred[1792]{0} %compare.49, f32[1792]{0} %broadcast.591, f32[1792]{0} %broadcast.592), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.34 = f32[1792]{0} divide(f32[1792]{0} %select.50, f32[1792]{0} %select.49), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.577 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.756, f32[1792]{0} %divide.34), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_493 = f32[] constant(0.000159438772)
  %broadcast.589 = f32[1792]{0} broadcast(f32[] %constant_493), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.576 = f32[1792]{0} multiply(f32[1792]{0} %multiply.577, f32[1792]{0} %broadcast.589), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.588 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.576), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.575 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_2.983, f32[16,28,28,1792]{2,1,3,0} %broadcast.588), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.160 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %multiply.1682, f32[16,28,28,1792]{2,1,3,0} %multiply.575), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.540 = f32[1792]{0} parameter(0)
  %negate.34 = f32[1792]{0} negate(f32[1792]{0} %multiply.577), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.791 = f32[1792]{0} parameter(1)
  %multiply.574 = f32[1792]{0} multiply(f32[1792]{0} %param_1.791, f32[1792]{0} %broadcast.589), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.573 = f32[1792]{0} multiply(f32[1792]{0} %negate.34, f32[1792]{0} %multiply.574), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.159 = f32[1792]{0} add(f32[1792]{0} %param_0.540, f32[1792]{0} %multiply.573), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_497 = f32[] constant(7.97193861e-05)
  %broadcast.590 = f32[1792]{0} broadcast(f32[] %constant_497), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.572 = f32[1792]{0} multiply(f32[1792]{0} %add.159, f32[1792]{0} %broadcast.590), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.587 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.572), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/broadcast_in_dim[shape=(16, 28, 28, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.158 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %add.160, f32[16,28,28,1792]{2,1,3,0} %broadcast.587), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.301 (param_0.1361: f32[16,28,28,1792], param_1.1844: f32[1792], param_2.990: f32[1792]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1361 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  %param_2.990 = f32[1792]{0} parameter(2)
  %constant_501 = f32[] constant(0)
  %broadcast.2394 = f32[1792]{0} broadcast(f32[] %constant_501), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.401 = f32[1792]{0} maximum(f32[1792]{0} %param_2.990, f32[1792]{0} %broadcast.2394), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1902 = f32[] constant(1e-05)
  %broadcast.2393 = f32[1792]{0} broadcast(f32[] %constant_1902), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.819 = f32[1792]{0} add(f32[1792]{0} %maximum.401, f32[1792]{0} %broadcast.2393), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1532 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.819), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.287 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1532), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1844 = f32[1792]{0} parameter(1)
  %bitcast.1531 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1844), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1687 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.287, f32[1,1,1,1792]{3,2,1,0} %bitcast.1531), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1530 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1687), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2392 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1530), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1686 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_0.1361, f32[16,28,28,1792]{2,1,3,0} %broadcast.2392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.35 = f32[16,28,28,1792]{2,1,3,0} negate(f32[16,28,28,1792]{2,1,3,0} %multiply.1686), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.46 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %negate.35), dimensions={0,3,1,2}
  %bitcast.757 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.46), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.811 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.757, f32[] %constant_501), dimensions={2}, to_apply=%region_63.4346.3
  %transpose.47 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %param_0.1361), dimensions={0,3,1,2}
  %bitcast.742.clone.1 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.47), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %reduce.800.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.742.clone.1, f32[] %constant_501), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.78 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.811, f32[16,1792]{1,0} %reduce.800.clone.1)
}

%fused_computation.302 (param_0.544: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.544 = f32[16,1792]{1,0} parameter(0)
  %constant_499 = f32[] constant(0)
  %reduce.812 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.544, f32[] %constant_499), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.758 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.812), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.311 (param_0.1349: f32[896], param_1.1834: f32[896], param_2.972: f32[896], param_3.765: f32[16,28,28,896], param_4.677: f32[896]) -> f32[16,28,28,896] {
  %param_3.765 = f32[16,28,28,896]{2,1,3,0} parameter(3)
  %param_4.677 = f32[896]{0} parameter(4)
  %constant_1866 = f32[] constant(7.97193861e-05)
  %broadcast.2362 = f32[896]{0} broadcast(f32[] %constant_1866), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1675 = f32[896]{0} multiply(f32[896]{0} %param_4.677, f32[896]{0} %broadcast.2362), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2361 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1675), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.243 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_3.765, f32[16,28,28,896]{2,1,3,0} %broadcast.2361), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.972 = f32[896]{0} parameter(2)
  %constant_509 = f32[] constant(0)
  %broadcast.2360 = f32[896]{0} broadcast(f32[] %constant_509), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.387 = f32[896]{0} maximum(f32[896]{0} %param_2.972, f32[896]{0} %broadcast.2360), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1864 = f32[] constant(1e-05)
  %broadcast.2359 = f32[896]{0} broadcast(f32[] %constant_1864), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.579 = f32[896]{0} add(f32[896]{0} %maximum.387, f32[896]{0} %broadcast.2359), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1514 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.579), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.283 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1514), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1834 = f32[896]{0} parameter(1)
  %bitcast.1513 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.1834), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1674 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.283, f32[1,1,1,896]{3,2,1,0} %bitcast.1513), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1512 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2358 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1512), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1673 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.243, f32[16,28,28,896]{2,1,3,0} %broadcast.2358), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1349 = f32[896]{0} parameter(0)
  %broadcast.2357 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1349), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.578 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1673, f32[16,28,28,896]{2,1,3,0} %broadcast.2357), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.601 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_509), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.26 = f32[16,28,28,896]{2,1,3,0} maximum(f32[16,28,28,896]{2,1,3,0} %add.578, f32[16,28,28,896]{2,1,3,0} %broadcast.601), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.316 (param_0.1334: f32[16,896], param_1.1811: f32[896]) -> f32[896] {
  %param_0.1334 = f32[16,896]{1,0} parameter(0)
  %constant_513 = f32[] constant(0)
  %reduce.817 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1334, f32[] %constant_513), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_512 = f32[] constant(7.97193861e-05)
  %broadcast.606 = f32[896]{0} broadcast(f32[] %constant_512), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.591 = f32[896]{0} multiply(f32[896]{0} %reduce.817, f32[896]{0} %broadcast.606), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1811 = f32[896]{0} parameter(1)
  %multiply.1655 = f32[896]{0} multiply(f32[896]{0} %param_1.1811, f32[896]{0} %broadcast.606), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.590 = f32[896]{0} multiply(f32[896]{0} %multiply.1655, f32[896]{0} %multiply.1655), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.32 = f32[896]{0} subtract(f32[896]{0} %multiply.591, f32[896]{0} %multiply.590), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.321 (param_0.1331: f32[448], param_1.1809: f32[448], param_2.938: f32[448], param_3.734: f32[16,28,28,448], param_4.652: f32[448]) -> f32[16,28,28,448] {
  %param_3.734 = f32[16,28,28,448]{2,1,3,0} parameter(3)
  %param_4.652 = f32[448]{0} parameter(4)
  %constant_1809 = f32[] constant(7.97193861e-05)
  %broadcast.2302 = f32[448]{0} broadcast(f32[] %constant_1809), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1651 = f32[448]{0} multiply(f32[448]{0} %param_4.652, f32[448]{0} %broadcast.2302), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2301 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1651), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.235 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_3.734, f32[16,28,28,448]{2,1,3,0} %broadcast.2301), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.938 = f32[448]{0} parameter(2)
  %constant_517 = f32[] constant(0)
  %broadcast.2300 = f32[448]{0} broadcast(f32[] %constant_517), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.369 = f32[448]{0} maximum(f32[448]{0} %param_2.938, f32[448]{0} %broadcast.2300), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1807 = f32[] constant(1e-05)
  %broadcast.2299 = f32[448]{0} broadcast(f32[] %constant_1807), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.561 = f32[448]{0} add(f32[448]{0} %maximum.369, f32[448]{0} %broadcast.2299), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1484 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.561), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.275 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1484), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1809 = f32[448]{0} parameter(1)
  %bitcast.1483 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_1.1809), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1650 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.275, f32[1,1,1,448]{3,2,1,0} %bitcast.1483), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1482 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2298 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1482), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1649 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.235, f32[16,28,28,448]{2,1,3,0} %broadcast.2298), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1331 = f32[448]{0} parameter(0)
  %broadcast.2297 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_0.1331), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.560 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1649, f32[16,28,28,448]{2,1,3,0} %broadcast.2297), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.609 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_517), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.28 = f32[16,28,28,448]{2,1,3,0} maximum(f32[16,28,28,448]{2,1,3,0} %add.560, f32[16,28,28,448]{2,1,3,0} %broadcast.609), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.326 (param_0.1316: f32[16,448], param_1.1786: f32[448]) -> f32[448] {
  %param_0.1316 = f32[16,448]{1,0} parameter(0)
  %constant_521 = f32[] constant(0)
  %reduce.820 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.1316, f32[] %constant_521), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_520 = f32[] constant(7.97193861e-05)
  %broadcast.614 = f32[448]{0} broadcast(f32[] %constant_520), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.597 = f32[448]{0} multiply(f32[448]{0} %reduce.820, f32[448]{0} %broadcast.614), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1786 = f32[448]{0} parameter(1)
  %multiply.1631 = f32[448]{0} multiply(f32[448]{0} %param_1.1786, f32[448]{0} %broadcast.614), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.596 = f32[448]{0} multiply(f32[448]{0} %multiply.1631, f32[448]{0} %multiply.1631), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.34 = f32[448]{0} subtract(f32[448]{0} %multiply.597, f32[448]{0} %multiply.596), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.331 (param_0.590: f32[16,28,28,1792]) -> f32[16,28,28,1792] {
  %param_0.590 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  %constant_525 = f32[] constant(0)
  %broadcast.617 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[] %constant_525), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.30 = f32[16,28,28,1792]{2,1,3,0} maximum(f32[16,28,28,1792]{2,1,3,0} %param_0.590, f32[16,28,28,1792]{2,1,3,0} %broadcast.617), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.332 (param_0.592: f32[16,28,28,1792], param_1.872: f32[16,28,28,1792]) -> f32[16,28,28,1792] {
  %param_1.872 = f32[16,28,28,1792]{2,1,3,0} parameter(1)
  %constant_526 = f32[] constant(0)
  %broadcast.618 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[] %constant_526), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.51 = pred[16,28,28,1792]{2,1,3,0} compare(f32[16,28,28,1792]{2,1,3,0} %param_1.872, f32[16,28,28,1792]{2,1,3,0} %broadcast.618), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.592 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  ROOT %select.51 = f32[16,28,28,1792]{2,1,3,0} select(pred[16,28,28,1792]{2,1,3,0} %compare.51, f32[16,28,28,1792]{2,1,3,0} %param_0.592, f32[16,28,28,1792]{2,1,3,0} %broadcast.618), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.336 (param_0.599: f32[1,1,896,1792], param_1.881: f32[1,1,896,1792]) -> f32[1,1,896,1792] {
  %param_1.881 = f32[1,1,896,1792]{3,2,1,0} parameter(1)
  %copy.176 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %param_1.881), metadata={op_name="3$start"}
  %param_0.599 = f32[1,1,896,1792]{1,0,2,3} parameter(0)
  %add.168 = f32[1,1,896,1792]{1,0,2,3} add(f32[1,1,896,1792]{1,0,2,3} %copy.176, f32[1,1,896,1792]{1,0,2,3} %param_0.599), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  ROOT %copy.175 = f32[1,1,896,1792]{3,2,1,0} copy(f32[1,1,896,1792]{1,0,2,3} %add.168), metadata={op_name="tuple.85"}
}

%fused_computation.338 (param_0.1298: f32[16,28,28,896], param_1.1758: f32[896], param_2.868: f32[896], param_3.660: f32[896], param_4.583: f32[16,28,28,896], param_5.575: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.583 = f32[16,28,28,896]{2,1,3,0} parameter(4)
  %param_5.575 = f32[896]{0} parameter(5)
  %constant_1673 = f32[] constant(7.97193861e-05)
  %broadcast.2120 = f32[896]{0} broadcast(f32[] %constant_1673), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1569 = f32[896]{0} multiply(f32[896]{0} %param_5.575, f32[896]{0} %broadcast.2120), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2119 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1569), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.157 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_4.583, f32[16,28,28,896]{2,1,3,0} %broadcast.2119), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.660 = f32[896]{0} parameter(3)
  %constant_530 = f32[] constant(0)
  %broadcast.2118 = f32[896]{0} broadcast(f32[] %constant_530), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.329 = f32[896]{0} maximum(f32[896]{0} %param_3.660, f32[896]{0} %broadcast.2118), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1671 = f32[] constant(1e-05)
  %broadcast.2117 = f32[896]{0} broadcast(f32[] %constant_1671), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.507 = f32[896]{0} add(f32[896]{0} %maximum.329, f32[896]{0} %broadcast.2117), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1388 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.507), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.245 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1388), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.868 = f32[896]{0} parameter(2)
  %bitcast.1387 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.868), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1568 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.245, f32[1,1,1,896]{3,2,1,0} %bitcast.1387), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1386 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1568), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2116 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1386), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1567 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.157, f32[16,28,28,896]{2,1,3,0} %broadcast.2116), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1758 = f32[896]{0} parameter(1)
  %broadcast.2115 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.1758), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.506 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1567, f32[16,28,28,896]{2,1,3,0} %broadcast.2115), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2114 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_530), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.205 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.506, f32[16,28,28,896]{2,1,3,0} %broadcast.2114), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1298 = f32[16,28,28,896]{2,1,3,0} parameter(0)
  %select.205 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.205, f32[16,28,28,896]{2,1,3,0} %param_0.1298, f32[16,28,28,896]{2,1,3,0} %broadcast.2114), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.48 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %select.205), dimensions={0,3,1,2}
  %bitcast.774 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.48), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.826 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.774, f32[] %constant_530), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1585.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.205, f32[16,28,28,896]{2,1,3,0} %broadcast.2116), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.39.clone.1 = f32[16,28,28,896]{2,1,3,0} negate(f32[16,28,28,896]{2,1,3,0} %multiply.1585.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.49 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %negate.39.clone.1), dimensions={0,3,1,2}
  %bitcast.783.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.49), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.832.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.783.clone.1, f32[] %constant_530), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.623.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.157, f32[16,28,28,896]{2,1,3,0} %select.205), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.50 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %multiply.623.clone.1), dimensions={0,3,1,2}
  %bitcast.785.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.50), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.834.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.785.clone.1, f32[] %constant_530), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.84 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.826, f32[16,896]{1,0} %reduce.832.clone.1, f32[16,896]{1,0} %reduce.834.clone.1)
}

%fused_computation.340 (param_0.606: f32[3,3,448,896], param_1.890: f32[3,3,448,896]) -> f32[3,3,448,896] {
  %param_1.890 = f32[3,3,448,896]{3,2,1,0} parameter(1)
  %copy.178 = f32[3,3,448,896]{1,0,2,3} copy(f32[3,3,448,896]{3,2,1,0} %param_1.890), metadata={op_name="3$start"}
  %param_0.606 = f32[3,3,448,896]{1,0,2,3} parameter(0)
  %add.171 = f32[3,3,448,896]{1,0,2,3} add(f32[3,3,448,896]{1,0,2,3} %copy.178, f32[3,3,448,896]{1,0,2,3} %param_0.606), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  ROOT %copy.177 = f32[3,3,448,896]{3,2,1,0} copy(f32[3,3,448,896]{1,0,2,3} %add.171), metadata={op_name="tuple.85"}
}

%fused_computation.342 (param_0.1309: f32[16,28,28,448], param_1.1776: f32[448], param_2.893: f32[448], param_3.691: f32[448], param_4.617: f32[16,28,28,448], param_5.618: f32[448]) -> (f32[16,448], f32[16,448], f32[16,448]) {
  %param_4.617 = f32[16,28,28,448]{2,1,3,0} parameter(4)
  %param_5.618 = f32[448]{0} parameter(5)
  %constant_1726 = f32[] constant(7.97193861e-05)
  %broadcast.2202 = f32[448]{0} broadcast(f32[] %constant_1726), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1607 = f32[448]{0} multiply(f32[448]{0} %param_5.618, f32[448]{0} %broadcast.2202), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2201 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1607), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.167 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_4.617, f32[16,28,28,448]{2,1,3,0} %broadcast.2201), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.691 = f32[448]{0} parameter(3)
  %constant_532 = f32[] constant(0)
  %broadcast.2200 = f32[448]{0} broadcast(f32[] %constant_532), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.343 = f32[448]{0} maximum(f32[448]{0} %param_3.691, f32[448]{0} %broadcast.2200), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1724 = f32[] constant(1e-05)
  %broadcast.2199 = f32[448]{0} broadcast(f32[] %constant_1724), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.531 = f32[448]{0} add(f32[448]{0} %maximum.343, f32[448]{0} %broadcast.2199), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1430 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.531), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.259 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.893 = f32[448]{0} parameter(2)
  %bitcast.1429 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_2.893), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1606 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.259, f32[1,1,1,448]{3,2,1,0} %bitcast.1429), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1428 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1606), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2198 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1428), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1605 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.167, f32[16,28,28,448]{2,1,3,0} %broadcast.2198), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1776 = f32[448]{0} parameter(1)
  %broadcast.2197 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_1.1776), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.530 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1605, f32[16,28,28,448]{2,1,3,0} %broadcast.2197), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2196 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_532), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.215 = pred[16,28,28,448]{2,1,3,0} compare(f32[16,28,28,448]{2,1,3,0} %add.530, f32[16,28,28,448]{2,1,3,0} %broadcast.2196), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1309 = f32[16,28,28,448]{2,1,3,0} parameter(0)
  %select.215 = f32[16,28,28,448]{2,1,3,0} select(pred[16,28,28,448]{2,1,3,0} %compare.215, f32[16,28,28,448]{2,1,3,0} %param_0.1309, f32[16,28,28,448]{2,1,3,0} %broadcast.2196), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.51 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %select.215), dimensions={0,3,1,2}
  %bitcast.776 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.51), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.828 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.776, f32[] %constant_532), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1623.clone.1 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %select.215, f32[16,28,28,448]{2,1,3,0} %broadcast.2198), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.37.clone.1 = f32[16,28,28,448]{2,1,3,0} negate(f32[16,28,28,448]{2,1,3,0} %multiply.1623.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.52 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %negate.37.clone.1), dimensions={0,3,1,2}
  %bitcast.779.clone.1 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.52), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.829.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.779.clone.1, f32[] %constant_532), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.612.clone.1 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.167, f32[16,28,28,448]{2,1,3,0} %select.215), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.53 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %multiply.612.clone.1), dimensions={0,3,1,2}
  %bitcast.781.clone.1 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.53), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.831.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.781.clone.1, f32[] %constant_532), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.82 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.828, f32[16,448]{1,0} %reduce.829.clone.1, f32[16,448]{1,0} %reduce.831.clone.1)
}

%fused_computation.344 (param_0.613: f32[1,1,1792,448], param_1.899: f32[1,1,1792,448]) -> f32[1,1,1792,448] {
  %param_1.899 = f32[1,1,1792,448]{3,2,1,0} parameter(1)
  %copy.180 = f32[1,1,1792,448]{1,0,2,3} copy(f32[1,1,1792,448]{3,2,1,0} %param_1.899), metadata={op_name="3$start"}
  %param_0.613 = f32[1,1,1792,448]{1,0,2,3} parameter(0)
  %add.174 = f32[1,1,1792,448]{1,0,2,3} add(f32[1,1,1792,448]{1,0,2,3} %copy.180, f32[1,1,1792,448]{1,0,2,3} %param_0.613), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  ROOT %copy.179 = f32[1,1,1792,448]{3,2,1,0} copy(f32[1,1,1792,448]{1,0,2,3} %add.174), metadata={op_name="tuple.85"}
}

%fused_computation.345 (param_0.616: f32[448], param_1.905: f32[448], param_2.895: f32[16,28,28,448], param_3.693: f32[448], param_4.619: f32[1,1,1,448], param_5.620: f32[448], param_6.477: f32[16,28,28,448], param_7.553: f32[448]) -> f32[16,28,28,448] {
  %param_2.895 = f32[16,28,28,448]{2,1,3,0} parameter(2)
  %param_1.905 = f32[448]{0} parameter(1)
  %constant_731 = f32[] constant(7.97193861e-05)
  %broadcast.2222 = f32[448]{0} broadcast(f32[] %constant_731), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1617 = f32[448]{0} multiply(f32[448]{0} %param_1.905, f32[448]{0} %broadcast.2222), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2221 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1617), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.225 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_2.895, f32[16,28,28,448]{2,1,3,0} %broadcast.2221), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.693 = f32[448]{0} parameter(3)
  %constant_732 = f32[] constant(0)
  %broadcast.2220 = f32[448]{0} broadcast(f32[] %constant_732), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.347 = f32[448]{0} maximum(f32[448]{0} %param_3.693, f32[448]{0} %broadcast.2220), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1506 = f32[] constant(1e-05)
  %broadcast.2219 = f32[448]{0} broadcast(f32[] %constant_1506), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.537 = f32[448]{0} add(f32[448]{0} %maximum.347, f32[448]{0} %broadcast.2219), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1442 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.537), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.263 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1442), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.620 = f32[448]{0} parameter(5)
  %bitcast.1441 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_5.620), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1616 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.263, f32[1,1,1,448]{3,2,1,0} %bitcast.1441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1440 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1616), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2218 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1440), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1615 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.225, f32[16,28,28,448]{2,1,3,0} %broadcast.2218), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.553 = f32[448]{0} parameter(7)
  %broadcast.2217 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_7.553), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.536 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1615, f32[16,28,28,448]{2,1,3,0} %broadcast.2217), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2216 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_732), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.217 = pred[16,28,28,448]{2,1,3,0} compare(f32[16,28,28,448]{2,1,3,0} %add.536, f32[16,28,28,448]{2,1,3,0} %broadcast.2216), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.477 = f32[16,28,28,448]{2,1,3,0} parameter(6)
  %select.217 = f32[16,28,28,448]{2,1,3,0} select(pred[16,28,28,448]{2,1,3,0} %compare.217, f32[16,28,28,448]{2,1,3,0} %param_6.477, f32[16,28,28,448]{2,1,3,0} %broadcast.2216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1613 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %select.217, f32[16,28,28,448]{2,1,3,0} %broadcast.2218), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.619 = f32[1,1,1,448]{3,2,1,0} parameter(4)
  %multiply.611 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %param_4.619, f32[1,1,1,448]{3,2,1,0} %bitcast.1441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.37 = f32[1,1,1,448]{3,2,1,0} divide(f32[1,1,1,448]{3,2,1,0} %rsqrt.263, f32[1,1,1,448]{3,2,1,0} %bitcast.1442), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_534 = f32[] constant(-0.5)
  %broadcast.624 = f32[1,1,1,448]{3,2,1,0} broadcast(f32[] %constant_534), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.610 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %divide.37, f32[1,1,1,448]{3,2,1,0} %broadcast.624), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.609 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %multiply.611, f32[1,1,1,448]{3,2,1,0} %multiply.610), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.778 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.609), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.53 = pred[448]{0} compare(f32[448]{0} %param_3.693, f32[448]{0} %maximum.347), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_729 = f32[] constant(1)
  %broadcast.623 = f32[448]{0} broadcast(f32[] %constant_729), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/broadcast_in_dim[shape=(448,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.53 = f32[448]{0} select(pred[448]{0} %compare.53, f32[448]{0} %broadcast.623, f32[448]{0} %broadcast.2220), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.52 = pred[448]{0} compare(f32[448]{0} %broadcast.2220, f32[448]{0} %maximum.347), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_730 = f32[] constant(2)
  %broadcast.622 = f32[448]{0} broadcast(f32[] %constant_730), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.52 = f32[448]{0} select(pred[448]{0} %compare.52, f32[448]{0} %broadcast.622, f32[448]{0} %broadcast.623), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.36 = f32[448]{0} divide(f32[448]{0} %select.53, f32[448]{0} %select.52), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.608 = f32[448]{0} multiply(f32[448]{0} %bitcast.778, f32[448]{0} %divide.36), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_533 = f32[] constant(0.000159438772)
  %broadcast.621 = f32[448]{0} broadcast(f32[] %constant_533), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.607 = f32[448]{0} multiply(f32[448]{0} %multiply.608, f32[448]{0} %broadcast.621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.620 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.607), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.606 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %param_2.895, f32[16,28,28,448]{2,1,3,0} %broadcast.620), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.177 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1613, f32[16,28,28,448]{2,1,3,0} %multiply.606), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.616 = f32[448]{0} parameter(0)
  %negate.36 = f32[448]{0} negate(f32[448]{0} %multiply.608), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.605 = f32[448]{0} multiply(f32[448]{0} %param_1.905, f32[448]{0} %broadcast.621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.604 = f32[448]{0} multiply(f32[448]{0} %negate.36, f32[448]{0} %multiply.605), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.176 = f32[448]{0} add(f32[448]{0} %param_0.616, f32[448]{0} %multiply.604), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.603 = f32[448]{0} multiply(f32[448]{0} %add.176, f32[448]{0} %broadcast.2222), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.619 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.603), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/broadcast_in_dim[shape=(16, 28, 28, 448) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.175 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %add.177, f32[16,28,28,448]{2,1,3,0} %broadcast.619), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.347 (param_0.620: f32[16,448]) -> f32[1,1,1,448] {
  %param_0.620 = f32[16,448]{1,0} parameter(0)
  %constant_733 = f32[] constant(0)
  %reduce.830 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.620, f32[] %constant_733), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.780 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %reduce.830), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.351 (param_0.628: f32[896], param_1.923: f32[896], param_2.870: f32[16,28,28,896], param_3.662: f32[896], param_4.585: f32[1,1,1,896], param_5.577: f32[896], param_6.452: f32[16,28,28,896], param_7.535: f32[896]) -> f32[16,28,28,896] {
  %param_2.870 = f32[16,28,28,896]{2,1,3,0} parameter(2)
  %param_1.923 = f32[896]{0} parameter(1)
  %constant_741 = f32[] constant(7.97193861e-05)
  %broadcast.2140 = f32[896]{0} broadcast(f32[] %constant_741), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1579 = f32[896]{0} multiply(f32[896]{0} %param_1.923, f32[896]{0} %broadcast.2140), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2139 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1579), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.159 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_2.870, f32[16,28,28,896]{2,1,3,0} %broadcast.2139), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.662 = f32[896]{0} parameter(3)
  %constant_742 = f32[] constant(0)
  %broadcast.2138 = f32[896]{0} broadcast(f32[] %constant_742), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.333 = f32[896]{0} maximum(f32[896]{0} %param_3.662, f32[896]{0} %broadcast.2138), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1563 = f32[] constant(1e-05)
  %broadcast.2137 = f32[896]{0} broadcast(f32[] %constant_1563), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.513 = f32[896]{0} add(f32[896]{0} %maximum.333, f32[896]{0} %broadcast.2137), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1400 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.513), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.249 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1400), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.577 = f32[896]{0} parameter(5)
  %bitcast.1399 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.577), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1578 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.249, f32[1,1,1,896]{3,2,1,0} %bitcast.1399), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1398 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1578), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2136 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1398), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1577 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.159, f32[16,28,28,896]{2,1,3,0} %broadcast.2136), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.535 = f32[896]{0} parameter(7)
  %broadcast.2135 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.535), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.512 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1577, f32[16,28,28,896]{2,1,3,0} %broadcast.2135), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2134 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_742), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.207 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.512, f32[16,28,28,896]{2,1,3,0} %broadcast.2134), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.452 = f32[16,28,28,896]{2,1,3,0} parameter(6)
  %select.207 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.207, f32[16,28,28,896]{2,1,3,0} %param_6.452, f32[16,28,28,896]{2,1,3,0} %broadcast.2134), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1575 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.207, f32[16,28,28,896]{2,1,3,0} %broadcast.2136), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.585 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.622 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.585, f32[1,1,1,896]{3,2,1,0} %bitcast.1399), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.39 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.249, f32[1,1,1,896]{3,2,1,0} %bitcast.1400), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_738 = f32[] constant(-0.5)
  %broadcast.634 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_738), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.621 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.39, f32[1,1,1,896]{3,2,1,0} %broadcast.634), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.620 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.622, f32[1,1,1,896]{3,2,1,0} %multiply.621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.782 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.620), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.56 = pred[896]{0} compare(f32[896]{0} %param_3.662, f32[896]{0} %maximum.333), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_739 = f32[] constant(1)
  %broadcast.633 = f32[896]{0} broadcast(f32[] %constant_739), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.56 = f32[896]{0} select(pred[896]{0} %compare.56, f32[896]{0} %broadcast.633, f32[896]{0} %broadcast.2138), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.55 = pred[896]{0} compare(f32[896]{0} %broadcast.2138, f32[896]{0} %maximum.333), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_740 = f32[] constant(2)
  %broadcast.632 = f32[896]{0} broadcast(f32[] %constant_740), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.55 = f32[896]{0} select(pred[896]{0} %compare.55, f32[896]{0} %broadcast.632, f32[896]{0} %broadcast.633), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.38 = f32[896]{0} divide(f32[896]{0} %select.56, f32[896]{0} %select.55), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.619 = f32[896]{0} multiply(f32[896]{0} %bitcast.782, f32[896]{0} %divide.38), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_737 = f32[] constant(0.000159438772)
  %broadcast.631 = f32[896]{0} broadcast(f32[] %constant_737), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.618 = f32[896]{0} multiply(f32[896]{0} %multiply.619, f32[896]{0} %broadcast.631), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.630 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.618), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.617 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %param_2.870, f32[16,28,28,896]{2,1,3,0} %broadcast.630), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.180 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1575, f32[16,28,28,896]{2,1,3,0} %multiply.617), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.628 = f32[896]{0} parameter(0)
  %negate.38 = f32[896]{0} negate(f32[896]{0} %multiply.619), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.616 = f32[896]{0} multiply(f32[896]{0} %param_1.923, f32[896]{0} %broadcast.631), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.615 = f32[896]{0} multiply(f32[896]{0} %negate.38, f32[896]{0} %multiply.616), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.179 = f32[896]{0} add(f32[896]{0} %param_0.628, f32[896]{0} %multiply.615), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.614 = f32[896]{0} multiply(f32[896]{0} %add.179, f32[896]{0} %broadcast.2140), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.629 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.614), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/broadcast_in_dim[shape=(16, 28, 28, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.178 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %add.180, f32[16,28,28,896]{2,1,3,0} %broadcast.629), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.353 (param_0.632: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.632 = f32[16,896]{1,0} parameter(0)
  %constant_743 = f32[] constant(0)
  %reduce.833 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.632, f32[] %constant_743), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.784 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.833), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.357 (param_0.640: f32[1792], param_1.941: f32[1792], param_2.847: f32[16,28,28,1792], param_3.637: f32[1792], param_4.559: f32[1,1,1,1792], param_5.547: f32[1792], param_6.432: f32[16,28,28,1792]) -> f32[16,28,28,1792] {
  %param_6.432 = f32[16,28,28,1792]{2,1,3,0} parameter(6)
  %param_3.637 = f32[1792]{0} parameter(3)
  %constant_752 = f32[] constant(0)
  %broadcast.2072 = f32[1792]{0} broadcast(f32[] %constant_752), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.321 = f32[1792]{0} maximum(f32[1792]{0} %param_3.637, f32[1792]{0} %broadcast.2072), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1620 = f32[] constant(1e-05)
  %broadcast.2071 = f32[1792]{0} broadcast(f32[] %constant_1620), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.493 = f32[1792]{0} add(f32[1792]{0} %maximum.321, f32[1792]{0} %broadcast.2071), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1364 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.493), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.237 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.547 = f32[1792]{0} parameter(5)
  %bitcast.1363 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1547 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.237, f32[1,1,1,1792]{3,2,1,0} %bitcast.1363), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1362 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2070 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1362), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1546 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_6.432, f32[16,28,28,1792]{2,1,3,0} %broadcast.2070), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.847 = f32[16,28,28,1792]{2,1,3,0} parameter(2)
  %param_4.559 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.633 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.559, f32[1,1,1,1792]{3,2,1,0} %bitcast.1363), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.41 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.237, f32[1,1,1,1792]{3,2,1,0} %bitcast.1364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_748 = f32[] constant(-0.5)
  %broadcast.645 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_748), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.632 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.41, f32[1,1,1,1792]{3,2,1,0} %broadcast.645), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.631 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.633, f32[1,1,1,1792]{3,2,1,0} %multiply.632), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.786 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.631), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.59 = pred[1792]{0} compare(f32[1792]{0} %param_3.637, f32[1792]{0} %maximum.321), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_749 = f32[] constant(1)
  %broadcast.644 = f32[1792]{0} broadcast(f32[] %constant_749), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.59 = f32[1792]{0} select(pred[1792]{0} %compare.59, f32[1792]{0} %broadcast.644, f32[1792]{0} %broadcast.2072), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.58 = pred[1792]{0} compare(f32[1792]{0} %broadcast.2072, f32[1792]{0} %maximum.321), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_750 = f32[] constant(2)
  %broadcast.643 = f32[1792]{0} broadcast(f32[] %constant_750), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.58 = f32[1792]{0} select(pred[1792]{0} %compare.58, f32[1792]{0} %broadcast.643, f32[1792]{0} %broadcast.644), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.40 = f32[1792]{0} divide(f32[1792]{0} %select.59, f32[1792]{0} %select.58), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.630 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.786, f32[1792]{0} %divide.40), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_747 = f32[] constant(0.000159438772)
  %broadcast.641 = f32[1792]{0} broadcast(f32[] %constant_747), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.629 = f32[1792]{0} multiply(f32[1792]{0} %multiply.630, f32[1792]{0} %broadcast.641), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.640 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.629), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.628 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_2.847, f32[16,28,28,1792]{2,1,3,0} %broadcast.640), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.183 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %multiply.1546, f32[16,28,28,1792]{2,1,3,0} %multiply.628), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.640 = f32[1792]{0} parameter(0)
  %negate.40 = f32[1792]{0} negate(f32[1792]{0} %multiply.630), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.941 = f32[1792]{0} parameter(1)
  %multiply.627 = f32[1792]{0} multiply(f32[1792]{0} %param_1.941, f32[1792]{0} %broadcast.641), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.626 = f32[1792]{0} multiply(f32[1792]{0} %negate.40, f32[1792]{0} %multiply.627), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.182 = f32[1792]{0} add(f32[1792]{0} %param_0.640, f32[1792]{0} %multiply.626), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_751 = f32[] constant(7.97193861e-05)
  %broadcast.642 = f32[1792]{0} broadcast(f32[] %constant_751), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.625 = f32[1792]{0} multiply(f32[1792]{0} %add.182, f32[1792]{0} %broadcast.642), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.639 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.625), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/broadcast_in_dim[shape=(16, 28, 28, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.181 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %add.183, f32[16,28,28,1792]{2,1,3,0} %broadcast.639), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.358 (param_0.1291: f32[16,28,28,1792], param_1.1748: f32[1792], param_2.854: f32[1792], param_3.1557: f32[16,28,28,1792], param_4.1362: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_0.1291 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  %param_2.854 = f32[1792]{0} parameter(2)
  %constant_755 = f32[] constant(0)
  %broadcast.2078 = f32[1792]{0} broadcast(f32[] %constant_755), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.323 = f32[1792]{0} maximum(f32[1792]{0} %param_2.854, f32[1792]{0} %broadcast.2078), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1645 = f32[] constant(1e-05)
  %broadcast.2077 = f32[1792]{0} broadcast(f32[] %constant_1645), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.495 = f32[1792]{0} add(f32[1792]{0} %maximum.323, f32[1792]{0} %broadcast.2077), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1370 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.495), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.239 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1370), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1748 = f32[1792]{0} parameter(1)
  %bitcast.1369 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1748), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1551 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.239, f32[1,1,1,1792]{3,2,1,0} %bitcast.1369), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1368 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1551), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2076 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1368), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1550 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_0.1291, f32[16,28,28,1792]{2,1,3,0} %broadcast.2076), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.41 = f32[16,28,28,1792]{2,1,3,0} negate(f32[16,28,28,1792]{2,1,3,0} %multiply.1550), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.54 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %negate.41), dimensions={0,3,1,2}
  %bitcast.787 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.54), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.835 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.787, f32[] %constant_755), dimensions={2}, to_apply=%region_63.4346.3
  %param_3.1557 = f32[16,28,28,1792]{2,1,3,0} parameter(3)
  %param_4.1362 = f32[1792]{0} parameter(4)
  %constant_1605_clone_1 = f32[] constant(7.97193861e-05)
  %broadcast.2042.clone.1 = f32[1792]{0} broadcast(f32[] %constant_1605_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1539.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_4.1362, f32[1792]{0} %broadcast.2042.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2041.clone.1 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1539.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.151.clone.1 = f32[16,28,28,1792]{2,1,3,0} subtract(f32[16,28,28,1792]{2,1,3,0} %param_3.1557, f32[16,28,28,1792]{2,1,3,0} %broadcast.2041.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.634.clone.1 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %subtract.151.clone.1, f32[16,28,28,1792]{2,1,3,0} %param_0.1291), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.55 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %multiply.634.clone.1), dimensions={0,3,1,2}
  %bitcast.789.clone.1 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.55), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.837.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.789.clone.1, f32[] %constant_755), dimensions={2}, to_apply=%region_63.4346.3
  %transpose.56 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %param_0.1291), dimensions={0,3,1,2}
  %bitcast.772.clone.1 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.56), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.824.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.772.clone.1, f32[] %constant_755), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.86 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.835, f32[16,1792]{1,0} %reduce.837.clone.1, f32[16,1792]{1,0} %reduce.824.clone.1)
}

%fused_computation.359 (param_0.644: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.644 = f32[16,1792]{1,0} parameter(0)
  %constant_753 = f32[] constant(0)
  %reduce.836 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.644, f32[] %constant_753), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.788 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.836), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.362 (param_0.649: f32[16,28,28,1792], param_1.953: f32[16,28,28,1792], param_2.293: f32[1792], param_3.632: f32[16,28,28,1792], param_4.558: f32[1792], param_5.546: f32[1792], param_6.431: f32[1792]) -> f32[16,28,28,1792] {
  %param_1.953 = f32[16,28,28,1792]{2,1,3,0} parameter(1)
  %param_3.632 = f32[16,28,28,1792]{2,1,3,0} parameter(3)
  %param_4.558 = f32[1792]{0} parameter(4)
  %constant_1602 = f32[] constant(7.97193861e-05)
  %broadcast.2038 = f32[1792]{0} broadcast(f32[] %constant_1602), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1537 = f32[1792]{0} multiply(f32[1792]{0} %param_4.558, f32[1792]{0} %broadcast.2038), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2037 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1537), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.149 = f32[16,28,28,1792]{2,1,3,0} subtract(f32[16,28,28,1792]{2,1,3,0} %param_3.632, f32[16,28,28,1792]{2,1,3,0} %broadcast.2037), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_6.431 = f32[1792]{0} parameter(6)
  %constant_756 = f32[] constant(0)
  %broadcast.2062 = f32[1792]{0} broadcast(f32[] %constant_756), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.317 = f32[1792]{0} maximum(f32[1792]{0} %param_6.431, f32[1792]{0} %broadcast.2062), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1630 = f32[] constant(1e-05)
  %broadcast.2061 = f32[1792]{0} broadcast(f32[] %constant_1630), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.489 = f32[1792]{0} add(f32[1792]{0} %maximum.317, f32[1792]{0} %broadcast.2061), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1352 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.489), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.233 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1352), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.546 = f32[1792]{0} parameter(5)
  %bitcast.1351 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.546), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1541 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.233, f32[1,1,1,1792]{3,2,1,0} %bitcast.1351), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1350 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.649 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1350), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.636 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %subtract.149, f32[16,28,28,1792]{2,1,3,0} %broadcast.649), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.293 = f32[1792]{0} parameter(2)
  %broadcast.648 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_2.293), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.185 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %multiply.636, f32[16,28,28,1792]{2,1,3,0} %broadcast.648), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.184 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %param_1.953, f32[16,28,28,1792]{2,1,3,0} %add.185), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.650 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[] %constant_756), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.60 = pred[16,28,28,1792]{2,1,3,0} compare(f32[16,28,28,1792]{2,1,3,0} %add.184, f32[16,28,28,1792]{2,1,3,0} %broadcast.650), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.649 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  ROOT %select.60 = f32[16,28,28,1792]{2,1,3,0} select(pred[16,28,28,1792]{2,1,3,0} %compare.60, f32[16,28,28,1792]{2,1,3,0} %param_0.649, f32[16,28,28,1792]{2,1,3,0} %broadcast.650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.366 (param_0.1277: f32[16,1792], param_1.1728: f32[1792]) -> f32[1792] {
  %param_0.1277 = f32[16,1792]{1,0} parameter(0)
  %constant_760 = f32[] constant(0)
  %reduce.838 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1277, f32[] %constant_760), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_759 = f32[] constant(7.97193861e-05)
  %broadcast.653 = f32[1792]{0} broadcast(f32[] %constant_759), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.639 = f32[1792]{0} multiply(f32[1792]{0} %reduce.838, f32[1792]{0} %broadcast.653), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1728 = f32[1792]{0} parameter(1)
  %multiply.1535 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1728, f32[1792]{0} %broadcast.653), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.638 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1535, f32[1792]{0} %multiply.1535), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.36 = f32[1792]{0} subtract(f32[1792]{0} %multiply.639, f32[1792]{0} %multiply.638), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.371 (param_0.1273: f32[896], param_1.1723: f32[896], param_2.820: f32[896], param_3.617: f32[16,28,28,896], param_4.547: f32[896]) -> f32[16,28,28,896] {
  %param_3.617 = f32[16,28,28,896]{2,1,3,0} parameter(3)
  %param_4.547 = f32[896]{0} parameter(4)
  %constant_1586 = f32[] constant(7.97193861e-05)
  %broadcast.2018 = f32[896]{0} broadcast(f32[] %constant_1586), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1525 = f32[896]{0} multiply(f32[896]{0} %param_4.547, f32[896]{0} %broadcast.2018), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2017 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1525), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.145 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_3.617, f32[16,28,28,896]{2,1,3,0} %broadcast.2017), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.820 = f32[896]{0} parameter(2)
  %constant_764 = f32[] constant(0)
  %broadcast.2016 = f32[896]{0} broadcast(f32[] %constant_764), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.303 = f32[896]{0} maximum(f32[896]{0} %param_2.820, f32[896]{0} %broadcast.2016), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1584 = f32[] constant(1e-05)
  %broadcast.2015 = f32[896]{0} broadcast(f32[] %constant_1584), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.477 = f32[896]{0} add(f32[896]{0} %maximum.303, f32[896]{0} %broadcast.2015), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1334 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.229 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1723 = f32[896]{0} parameter(1)
  %bitcast.1333 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.1723), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1524 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.229, f32[1,1,1,896]{3,2,1,0} %bitcast.1333), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1332 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1524), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2014 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1332), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1523 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.145, f32[16,28,28,896]{2,1,3,0} %broadcast.2014), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1273 = f32[896]{0} parameter(0)
  %broadcast.2013 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1273), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.476 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1523, f32[16,28,28,896]{2,1,3,0} %broadcast.2013), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.656 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_764), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.32 = f32[16,28,28,896]{2,1,3,0} maximum(f32[16,28,28,896]{2,1,3,0} %add.476, f32[16,28,28,896]{2,1,3,0} %broadcast.656), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.376 (param_0.1259: f32[16,896], param_1.1703: f32[896]) -> f32[896] {
  %param_0.1259 = f32[16,896]{1,0} parameter(0)
  %constant_768 = f32[] constant(0)
  %reduce.841 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1259, f32[] %constant_768), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_767 = f32[] constant(7.97193861e-05)
  %broadcast.661 = f32[896]{0} broadcast(f32[] %constant_767), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.645 = f32[896]{0} multiply(f32[896]{0} %reduce.841, f32[896]{0} %broadcast.661), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1703 = f32[896]{0} parameter(1)
  %multiply.1511 = f32[896]{0} multiply(f32[896]{0} %param_1.1703, f32[896]{0} %broadcast.661), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.644 = f32[896]{0} multiply(f32[896]{0} %multiply.1511, f32[896]{0} %multiply.1511), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.38 = f32[896]{0} subtract(f32[896]{0} %multiply.645, f32[896]{0} %multiply.644), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.381 (param_0.1255: f32[448], param_1.1698: f32[448], param_2.786: f32[448], param_3.586: f32[16,28,28,448], param_4.522: f32[448]) -> f32[16,28,28,448] {
  %param_3.586 = f32[16,28,28,448]{2,1,3,0} parameter(3)
  %param_4.522 = f32[448]{0} parameter(4)
  %constant_1529 = f32[] constant(7.97193861e-05)
  %broadcast.1958 = f32[448]{0} broadcast(f32[] %constant_1529), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1501 = f32[448]{0} multiply(f32[448]{0} %param_4.522, f32[448]{0} %broadcast.1958), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1957 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1501), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.137 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_3.586, f32[16,28,28,448]{2,1,3,0} %broadcast.1957), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.786 = f32[448]{0} parameter(2)
  %constant_772 = f32[] constant(0)
  %broadcast.1956 = f32[448]{0} broadcast(f32[] %constant_772), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.285 = f32[448]{0} maximum(f32[448]{0} %param_2.786, f32[448]{0} %broadcast.1956), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1527 = f32[] constant(1e-05)
  %broadcast.1955 = f32[448]{0} broadcast(f32[] %constant_1527), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.459 = f32[448]{0} add(f32[448]{0} %maximum.285, f32[448]{0} %broadcast.1955), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1304 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.459), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.221 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1304), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1698 = f32[448]{0} parameter(1)
  %bitcast.1303 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_1.1698), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1500 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.221, f32[1,1,1,448]{3,2,1,0} %bitcast.1303), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1302 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1500), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1954 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1302), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1499 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.137, f32[16,28,28,448]{2,1,3,0} %broadcast.1954), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1255 = f32[448]{0} parameter(0)
  %broadcast.1953 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_0.1255), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.458 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1499, f32[16,28,28,448]{2,1,3,0} %broadcast.1953), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.664 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_772), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.34 = f32[16,28,28,448]{2,1,3,0} maximum(f32[16,28,28,448]{2,1,3,0} %add.458, f32[16,28,28,448]{2,1,3,0} %broadcast.664), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.386 (param_0.1241: f32[16,448], param_1.1678: f32[448]) -> f32[448] {
  %param_0.1241 = f32[16,448]{1,0} parameter(0)
  %constant_776 = f32[] constant(0)
  %reduce.844 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.1241, f32[] %constant_776), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_775 = f32[] constant(7.97193861e-05)
  %broadcast.669 = f32[448]{0} broadcast(f32[] %constant_775), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.651 = f32[448]{0} multiply(f32[448]{0} %reduce.844, f32[448]{0} %broadcast.669), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1678 = f32[448]{0} parameter(1)
  %multiply.1487 = f32[448]{0} multiply(f32[448]{0} %param_1.1678, f32[448]{0} %broadcast.669), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.650 = f32[448]{0} multiply(f32[448]{0} %multiply.1487, f32[448]{0} %multiply.1487), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.40 = f32[448]{0} subtract(f32[448]{0} %multiply.651, f32[448]{0} %multiply.650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.391 (param_0.695: f32[16,28,28,1792]) -> f32[16,28,28,1792] {
  %param_0.695 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  %constant_780 = f32[] constant(0)
  %broadcast.672 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[] %constant_780), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.36 = f32[16,28,28,1792]{2,1,3,0} maximum(f32[16,28,28,1792]{2,1,3,0} %param_0.695, f32[16,28,28,1792]{2,1,3,0} %broadcast.672), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.395 (param_0.702: f32[1,1,896,1792], param_1.1031: f32[1,1,896,1792]) -> f32[1,1,896,1792] {
  %param_1.1031 = f32[1,1,896,1792]{3,2,1,0} parameter(1)
  %copy.182 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %param_1.1031), metadata={op_name="3$start"}
  %param_0.702 = f32[1,1,896,1792]{1,0,2,3} parameter(0)
  %add.193 = f32[1,1,896,1792]{1,0,2,3} add(f32[1,1,896,1792]{1,0,2,3} %copy.182, f32[1,1,896,1792]{1,0,2,3} %param_0.702), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  ROOT %copy.181 = f32[1,1,896,1792]{3,2,1,0} copy(f32[1,1,896,1792]{1,0,2,3} %add.193), metadata={op_name="tuple.85"}
}

%fused_computation.397 (param_0.1223: f32[16,28,28,896], param_1.1650: f32[896], param_2.721: f32[896], param_3.519: f32[896], param_4.461: f32[16,28,28,896], param_5.450: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.461 = f32[16,28,28,896]{2,1,3,0} parameter(4)
  %param_5.450 = f32[896]{0} parameter(5)
  %constant_1400 = f32[] constant(7.97193861e-05)
  %broadcast.1788 = f32[896]{0} broadcast(f32[] %constant_1400), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1425 = f32[896]{0} multiply(f32[896]{0} %param_5.450, f32[896]{0} %broadcast.1788), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1787 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1425), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.117 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_4.461, f32[16,28,28,896]{2,1,3,0} %broadcast.1787), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.519 = f32[896]{0} parameter(3)
  %constant_784 = f32[] constant(0)
  %broadcast.1786 = f32[896]{0} broadcast(f32[] %constant_784), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.247 = f32[896]{0} maximum(f32[896]{0} %param_3.519, f32[896]{0} %broadcast.1786), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1398 = f32[] constant(1e-05)
  %broadcast.1785 = f32[896]{0} broadcast(f32[] %constant_1398), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.409 = f32[896]{0} add(f32[896]{0} %maximum.247, f32[896]{0} %broadcast.1785), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1214 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.409), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.193 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1214), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.721 = f32[896]{0} parameter(2)
  %bitcast.1213 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.721), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1424 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.193, f32[1,1,1,896]{3,2,1,0} %bitcast.1213), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1212 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1424), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1784 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1212), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1423 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.117, f32[16,28,28,896]{2,1,3,0} %broadcast.1784), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1650 = f32[896]{0} parameter(1)
  %broadcast.1783 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.1650), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.408 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1423, f32[16,28,28,896]{2,1,3,0} %broadcast.1783), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1782 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_784), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.185 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.408, f32[16,28,28,896]{2,1,3,0} %broadcast.1782), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1223 = f32[16,28,28,896]{2,1,3,0} parameter(0)
  %select.185 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.185, f32[16,28,28,896]{2,1,3,0} %param_0.1223, f32[16,28,28,896]{2,1,3,0} %broadcast.1782), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.57 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %select.185), dimensions={0,3,1,2}
  %bitcast.804 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.57), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.850 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.804, f32[] %constant_784), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1441.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.185, f32[16,28,28,896]{2,1,3,0} %broadcast.1784), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.45.clone.1 = f32[16,28,28,896]{2,1,3,0} negate(f32[16,28,28,896]{2,1,3,0} %multiply.1441.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.58 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %negate.45.clone.1), dimensions={0,3,1,2}
  %bitcast.813.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.58), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.856.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.813.clone.1, f32[] %constant_784), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.677.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.117, f32[16,28,28,896]{2,1,3,0} %select.185), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.59 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %multiply.677.clone.1), dimensions={0,3,1,2}
  %bitcast.815.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.59), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.858.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.815.clone.1, f32[] %constant_784), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.93 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.850, f32[16,896]{1,0} %reduce.856.clone.1, f32[16,896]{1,0} %reduce.858.clone.1)
}

%fused_computation.399 (param_0.709: f32[3,3,448,896], param_1.1040: f32[3,3,448,896]) -> f32[3,3,448,896] {
  %param_1.1040 = f32[3,3,448,896]{3,2,1,0} parameter(1)
  %copy.184 = f32[3,3,448,896]{1,0,2,3} copy(f32[3,3,448,896]{3,2,1,0} %param_1.1040), metadata={op_name="3$start"}
  %param_0.709 = f32[3,3,448,896]{1,0,2,3} parameter(0)
  %add.196 = f32[3,3,448,896]{1,0,2,3} add(f32[3,3,448,896]{1,0,2,3} %copy.184, f32[3,3,448,896]{1,0,2,3} %param_0.709), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  ROOT %copy.183 = f32[3,3,448,896]{3,2,1,0} copy(f32[3,3,448,896]{1,0,2,3} %add.196), metadata={op_name="tuple.85"}
}

%fused_computation.401 (param_0.1234: f32[16,28,28,448], param_1.1668: f32[448], param_2.746: f32[448], param_3.550: f32[448], param_4.495: f32[16,28,28,448], param_5.493: f32[448]) -> (f32[16,448], f32[16,448], f32[16,448]) {
  %param_4.495 = f32[16,28,28,448]{2,1,3,0} parameter(4)
  %param_5.493 = f32[448]{0} parameter(5)
  %constant_1453 = f32[] constant(7.97193861e-05)
  %broadcast.1870 = f32[448]{0} broadcast(f32[] %constant_1453), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1463 = f32[448]{0} multiply(f32[448]{0} %param_5.493, f32[448]{0} %broadcast.1870), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1869 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1463), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.127 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_4.495, f32[16,28,28,448]{2,1,3,0} %broadcast.1869), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.550 = f32[448]{0} parameter(3)
  %constant_786 = f32[] constant(0)
  %broadcast.1868 = f32[448]{0} broadcast(f32[] %constant_786), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.261 = f32[448]{0} maximum(f32[448]{0} %param_3.550, f32[448]{0} %broadcast.1868), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1451 = f32[] constant(1e-05)
  %broadcast.1867 = f32[448]{0} broadcast(f32[] %constant_1451), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.433 = f32[448]{0} add(f32[448]{0} %maximum.261, f32[448]{0} %broadcast.1867), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1256 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.433), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.207 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1256), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.746 = f32[448]{0} parameter(2)
  %bitcast.1255 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_2.746), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1462 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.207, f32[1,1,1,448]{3,2,1,0} %bitcast.1255), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1254 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1462), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1866 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1254), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1461 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.127, f32[16,28,28,448]{2,1,3,0} %broadcast.1866), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1668 = f32[448]{0} parameter(1)
  %broadcast.1865 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_1.1668), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.432 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1461, f32[16,28,28,448]{2,1,3,0} %broadcast.1865), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1864 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_786), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.195 = pred[16,28,28,448]{2,1,3,0} compare(f32[16,28,28,448]{2,1,3,0} %add.432, f32[16,28,28,448]{2,1,3,0} %broadcast.1864), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1234 = f32[16,28,28,448]{2,1,3,0} parameter(0)
  %select.195 = f32[16,28,28,448]{2,1,3,0} select(pred[16,28,28,448]{2,1,3,0} %compare.195, f32[16,28,28,448]{2,1,3,0} %param_0.1234, f32[16,28,28,448]{2,1,3,0} %broadcast.1864), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.60 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %select.195), dimensions={0,3,1,2}
  %bitcast.806 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.60), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.852 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.806, f32[] %constant_786), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1479.clone.1 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %select.195, f32[16,28,28,448]{2,1,3,0} %broadcast.1866), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.43.clone.1 = f32[16,28,28,448]{2,1,3,0} negate(f32[16,28,28,448]{2,1,3,0} %multiply.1479.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.61 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %negate.43.clone.1), dimensions={0,3,1,2}
  %bitcast.809.clone.1 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.61), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.853.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.809.clone.1, f32[] %constant_786), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.666.clone.1 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.127, f32[16,28,28,448]{2,1,3,0} %select.195), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.62 = f32[16,448,28,28]{3,2,1,0} transpose(f32[16,28,28,448]{2,1,3,0} %multiply.666.clone.1), dimensions={0,3,1,2}
  %bitcast.811.clone.1 = f32[16,448,784]{2,1,0} bitcast(f32[16,448,28,28]{3,2,1,0} %transpose.62), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.855.clone.1 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %bitcast.811.clone.1, f32[] %constant_786), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.91 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.852, f32[16,448]{1,0} %reduce.853.clone.1, f32[16,448]{1,0} %reduce.855.clone.1)
}

%fused_computation.403 (param_0.716: f32[1,1,1792,448], param_1.1049: f32[1,1,1792,448]) -> f32[1,1,1792,448] {
  %param_1.1049 = f32[1,1,1792,448]{3,2,1,0} parameter(1)
  %copy.186 = f32[1,1,1792,448]{1,0,2,3} copy(f32[1,1,1792,448]{3,2,1,0} %param_1.1049), metadata={op_name="3$start"}
  %param_0.716 = f32[1,1,1792,448]{1,0,2,3} parameter(0)
  %add.199 = f32[1,1,1792,448]{1,0,2,3} add(f32[1,1,1792,448]{1,0,2,3} %copy.186, f32[1,1,1792,448]{1,0,2,3} %param_0.716), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  ROOT %copy.185 = f32[1,1,1792,448]{3,2,1,0} copy(f32[1,1,1792,448]{1,0,2,3} %add.199), metadata={op_name="tuple.85"}
}

%fused_computation.404 (param_0.719: f32[448], param_1.1055: f32[448], param_2.748: f32[16,28,28,448], param_3.552: f32[448], param_4.497: f32[1,1,1,448], param_5.495: f32[448], param_6.408: f32[16,28,28,448], param_7.489: f32[448]) -> f32[16,28,28,448] {
  %param_2.748 = f32[16,28,28,448]{2,1,3,0} parameter(2)
  %param_1.1055 = f32[448]{0} parameter(1)
  %constant_791 = f32[] constant(7.97193861e-05)
  %broadcast.1890 = f32[448]{0} broadcast(f32[] %constant_791), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1473 = f32[448]{0} multiply(f32[448]{0} %param_1.1055, f32[448]{0} %broadcast.1890), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1889 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1473), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.129 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_2.748, f32[16,28,28,448]{2,1,3,0} %broadcast.1889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.552 = f32[448]{0} parameter(3)
  %constant_792 = f32[] constant(0)
  %broadcast.1888 = f32[448]{0} broadcast(f32[] %constant_792), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.265 = f32[448]{0} maximum(f32[448]{0} %param_3.552, f32[448]{0} %broadcast.1888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1233 = f32[] constant(1e-05)
  %broadcast.1887 = f32[448]{0} broadcast(f32[] %constant_1233), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.439 = f32[448]{0} add(f32[448]{0} %maximum.265, f32[448]{0} %broadcast.1887), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1268 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.439), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.211 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1268), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.495 = f32[448]{0} parameter(5)
  %bitcast.1267 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_5.495), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1472 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.211, f32[1,1,1,448]{3,2,1,0} %bitcast.1267), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1266 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1472), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1886 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1266), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1471 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.129, f32[16,28,28,448]{2,1,3,0} %broadcast.1886), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.489 = f32[448]{0} parameter(7)
  %broadcast.1885 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_7.489), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.438 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1471, f32[16,28,28,448]{2,1,3,0} %broadcast.1885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1884 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_792), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.197 = pred[16,28,28,448]{2,1,3,0} compare(f32[16,28,28,448]{2,1,3,0} %add.438, f32[16,28,28,448]{2,1,3,0} %broadcast.1884), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.408 = f32[16,28,28,448]{2,1,3,0} parameter(6)
  %select.197 = f32[16,28,28,448]{2,1,3,0} select(pred[16,28,28,448]{2,1,3,0} %compare.197, f32[16,28,28,448]{2,1,3,0} %param_6.408, f32[16,28,28,448]{2,1,3,0} %broadcast.1884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1469 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %select.197, f32[16,28,28,448]{2,1,3,0} %broadcast.1886), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.497 = f32[1,1,1,448]{3,2,1,0} parameter(4)
  %multiply.665 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %param_4.497, f32[1,1,1,448]{3,2,1,0} %bitcast.1267), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.43 = f32[1,1,1,448]{3,2,1,0} divide(f32[1,1,1,448]{3,2,1,0} %rsqrt.211, f32[1,1,1,448]{3,2,1,0} %bitcast.1268), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_788 = f32[] constant(-0.5)
  %broadcast.678 = f32[1,1,1,448]{3,2,1,0} broadcast(f32[] %constant_788), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.664 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %divide.43, f32[1,1,1,448]{3,2,1,0} %broadcast.678), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.663 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %multiply.665, f32[1,1,1,448]{3,2,1,0} %multiply.664), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.808 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.663), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.62 = pred[448]{0} compare(f32[448]{0} %param_3.552, f32[448]{0} %maximum.265), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_789 = f32[] constant(1)
  %broadcast.677 = f32[448]{0} broadcast(f32[] %constant_789), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/broadcast_in_dim[shape=(448,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.62 = f32[448]{0} select(pred[448]{0} %compare.62, f32[448]{0} %broadcast.677, f32[448]{0} %broadcast.1888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.61 = pred[448]{0} compare(f32[448]{0} %broadcast.1888, f32[448]{0} %maximum.265), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_790 = f32[] constant(2)
  %broadcast.676 = f32[448]{0} broadcast(f32[] %constant_790), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.61 = f32[448]{0} select(pred[448]{0} %compare.61, f32[448]{0} %broadcast.676, f32[448]{0} %broadcast.677), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.42 = f32[448]{0} divide(f32[448]{0} %select.62, f32[448]{0} %select.61), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.662 = f32[448]{0} multiply(f32[448]{0} %bitcast.808, f32[448]{0} %divide.42), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_787 = f32[] constant(0.000159438772)
  %broadcast.675 = f32[448]{0} broadcast(f32[] %constant_787), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.661 = f32[448]{0} multiply(f32[448]{0} %multiply.662, f32[448]{0} %broadcast.675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.674 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.661), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.660 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %param_2.748, f32[16,28,28,448]{2,1,3,0} %broadcast.674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.202 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1469, f32[16,28,28,448]{2,1,3,0} %multiply.660), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.719 = f32[448]{0} parameter(0)
  %negate.42 = f32[448]{0} negate(f32[448]{0} %multiply.662), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.659 = f32[448]{0} multiply(f32[448]{0} %param_1.1055, f32[448]{0} %broadcast.675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.658 = f32[448]{0} multiply(f32[448]{0} %negate.42, f32[448]{0} %multiply.659), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.201 = f32[448]{0} add(f32[448]{0} %param_0.719, f32[448]{0} %multiply.658), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.657 = f32[448]{0} multiply(f32[448]{0} %add.201, f32[448]{0} %broadcast.1890), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.673 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.657), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/broadcast_in_dim[shape=(16, 28, 28, 448) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.200 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %add.202, f32[16,28,28,448]{2,1,3,0} %broadcast.673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.406 (param_0.723: f32[16,448]) -> f32[1,1,1,448] {
  %param_0.723 = f32[16,448]{1,0} parameter(0)
  %constant_793 = f32[] constant(0)
  %reduce.854 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.723, f32[] %constant_793), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.810 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %reduce.854), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.410 (param_0.731: f32[896], param_1.1073: f32[896], param_2.723: f32[16,28,28,896], param_3.521: f32[896], param_4.463: f32[1,1,1,896], param_5.452: f32[896], param_6.383: f32[16,28,28,896], param_7.471: f32[896]) -> f32[16,28,28,896] {
  %param_2.723 = f32[16,28,28,896]{2,1,3,0} parameter(2)
  %param_1.1073 = f32[896]{0} parameter(1)
  %constant_801 = f32[] constant(7.97193861e-05)
  %broadcast.1808 = f32[896]{0} broadcast(f32[] %constant_801), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1435 = f32[896]{0} multiply(f32[896]{0} %param_1.1073, f32[896]{0} %broadcast.1808), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1807 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1435), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.119 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_2.723, f32[16,28,28,896]{2,1,3,0} %broadcast.1807), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.521 = f32[896]{0} parameter(3)
  %constant_802 = f32[] constant(0)
  %broadcast.1806 = f32[896]{0} broadcast(f32[] %constant_802), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.251 = f32[896]{0} maximum(f32[896]{0} %param_3.521, f32[896]{0} %broadcast.1806), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1290 = f32[] constant(1e-05)
  %broadcast.1805 = f32[896]{0} broadcast(f32[] %constant_1290), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.415 = f32[896]{0} add(f32[896]{0} %maximum.251, f32[896]{0} %broadcast.1805), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1226 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.415), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.197 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1226), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.452 = f32[896]{0} parameter(5)
  %bitcast.1225 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1434 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.197, f32[1,1,1,896]{3,2,1,0} %bitcast.1225), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1224 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1434), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1804 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1224), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1433 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.119, f32[16,28,28,896]{2,1,3,0} %broadcast.1804), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.471 = f32[896]{0} parameter(7)
  %broadcast.1803 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.471), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.414 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1433, f32[16,28,28,896]{2,1,3,0} %broadcast.1803), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1802 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_802), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.187 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.414, f32[16,28,28,896]{2,1,3,0} %broadcast.1802), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.383 = f32[16,28,28,896]{2,1,3,0} parameter(6)
  %select.187 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.187, f32[16,28,28,896]{2,1,3,0} %param_6.383, f32[16,28,28,896]{2,1,3,0} %broadcast.1802), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1431 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.187, f32[16,28,28,896]{2,1,3,0} %broadcast.1804), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.463 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.676 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.463, f32[1,1,1,896]{3,2,1,0} %bitcast.1225), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.45 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.197, f32[1,1,1,896]{3,2,1,0} %bitcast.1226), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_798 = f32[] constant(-0.5)
  %broadcast.688 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_798), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.675 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.45, f32[1,1,1,896]{3,2,1,0} %broadcast.688), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.674 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.676, f32[1,1,1,896]{3,2,1,0} %multiply.675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.812 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.65 = pred[896]{0} compare(f32[896]{0} %param_3.521, f32[896]{0} %maximum.251), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_799 = f32[] constant(1)
  %broadcast.687 = f32[896]{0} broadcast(f32[] %constant_799), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.65 = f32[896]{0} select(pred[896]{0} %compare.65, f32[896]{0} %broadcast.687, f32[896]{0} %broadcast.1806), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.64 = pred[896]{0} compare(f32[896]{0} %broadcast.1806, f32[896]{0} %maximum.251), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_800 = f32[] constant(2)
  %broadcast.686 = f32[896]{0} broadcast(f32[] %constant_800), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.64 = f32[896]{0} select(pred[896]{0} %compare.64, f32[896]{0} %broadcast.686, f32[896]{0} %broadcast.687), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.44 = f32[896]{0} divide(f32[896]{0} %select.65, f32[896]{0} %select.64), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.673 = f32[896]{0} multiply(f32[896]{0} %bitcast.812, f32[896]{0} %divide.44), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_797 = f32[] constant(0.000159438772)
  %broadcast.685 = f32[896]{0} broadcast(f32[] %constant_797), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.672 = f32[896]{0} multiply(f32[896]{0} %multiply.673, f32[896]{0} %broadcast.685), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.684 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.672), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.671 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %param_2.723, f32[16,28,28,896]{2,1,3,0} %broadcast.684), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.205 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1431, f32[16,28,28,896]{2,1,3,0} %multiply.671), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.731 = f32[896]{0} parameter(0)
  %negate.44 = f32[896]{0} negate(f32[896]{0} %multiply.673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.670 = f32[896]{0} multiply(f32[896]{0} %param_1.1073, f32[896]{0} %broadcast.685), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.669 = f32[896]{0} multiply(f32[896]{0} %negate.44, f32[896]{0} %multiply.670), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.204 = f32[896]{0} add(f32[896]{0} %param_0.731, f32[896]{0} %multiply.669), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.668 = f32[896]{0} multiply(f32[896]{0} %add.204, f32[896]{0} %broadcast.1808), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.683 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.668), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/broadcast_in_dim[shape=(16, 28, 28, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.203 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %add.205, f32[16,28,28,896]{2,1,3,0} %broadcast.683), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.412 (param_0.735: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.735 = f32[16,896]{1,0} parameter(0)
  %constant_803 = f32[] constant(0)
  %reduce.857 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.735, f32[] %constant_803), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.814 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.857), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.416 (param_0.743: f32[1792], param_1.1091: f32[1792], param_2.700: f32[16,28,28,1792], param_3.496: f32[1792], param_4.437: f32[1,1,1,1792], param_5.422: f32[1792], param_6.363: f32[16,28,28,1792]) -> f32[16,28,28,1792] {
  %param_6.363 = f32[16,28,28,1792]{2,1,3,0} parameter(6)
  %param_3.496 = f32[1792]{0} parameter(3)
  %constant_812 = f32[] constant(0)
  %broadcast.1740 = f32[1792]{0} broadcast(f32[] %constant_812), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.239 = f32[1792]{0} maximum(f32[1792]{0} %param_3.496, f32[1792]{0} %broadcast.1740), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1347 = f32[] constant(1e-05)
  %broadcast.1739 = f32[1792]{0} broadcast(f32[] %constant_1347), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.395 = f32[1792]{0} add(f32[1792]{0} %maximum.239, f32[1792]{0} %broadcast.1739), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1190 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.395), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.185 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1190), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.422 = f32[1792]{0} parameter(5)
  %bitcast.1189 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.422), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1403 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.185, f32[1,1,1,1792]{3,2,1,0} %bitcast.1189), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1188 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1403), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1738 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1188), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1402 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_6.363, f32[16,28,28,1792]{2,1,3,0} %broadcast.1738), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.700 = f32[16,28,28,1792]{2,1,3,0} parameter(2)
  %param_4.437 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.687 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.437, f32[1,1,1,1792]{3,2,1,0} %bitcast.1189), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.47 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.185, f32[1,1,1,1792]{3,2,1,0} %bitcast.1190), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_808 = f32[] constant(-0.5)
  %broadcast.699 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_808), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.686 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.47, f32[1,1,1,1792]{3,2,1,0} %broadcast.699), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.685 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.687, f32[1,1,1,1792]{3,2,1,0} %multiply.686), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.816 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.685), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.68 = pred[1792]{0} compare(f32[1792]{0} %param_3.496, f32[1792]{0} %maximum.239), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_809 = f32[] constant(1)
  %broadcast.698 = f32[1792]{0} broadcast(f32[] %constant_809), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.68 = f32[1792]{0} select(pred[1792]{0} %compare.68, f32[1792]{0} %broadcast.698, f32[1792]{0} %broadcast.1740), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.67 = pred[1792]{0} compare(f32[1792]{0} %broadcast.1740, f32[1792]{0} %maximum.239), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_810 = f32[] constant(2)
  %broadcast.697 = f32[1792]{0} broadcast(f32[] %constant_810), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.67 = f32[1792]{0} select(pred[1792]{0} %compare.67, f32[1792]{0} %broadcast.697, f32[1792]{0} %broadcast.698), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.46 = f32[1792]{0} divide(f32[1792]{0} %select.68, f32[1792]{0} %select.67), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.684 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.816, f32[1792]{0} %divide.46), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_807 = f32[] constant(0.000159438772)
  %broadcast.695 = f32[1792]{0} broadcast(f32[] %constant_807), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.683 = f32[1792]{0} multiply(f32[1792]{0} %multiply.684, f32[1792]{0} %broadcast.695), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.694 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.683), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.682 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_2.700, f32[16,28,28,1792]{2,1,3,0} %broadcast.694), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.208 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %multiply.1402, f32[16,28,28,1792]{2,1,3,0} %multiply.682), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.743 = f32[1792]{0} parameter(0)
  %negate.46 = f32[1792]{0} negate(f32[1792]{0} %multiply.684), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.1091 = f32[1792]{0} parameter(1)
  %multiply.681 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1091, f32[1792]{0} %broadcast.695), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.680 = f32[1792]{0} multiply(f32[1792]{0} %negate.46, f32[1792]{0} %multiply.681), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.207 = f32[1792]{0} add(f32[1792]{0} %param_0.743, f32[1792]{0} %multiply.680), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_811 = f32[] constant(7.97193861e-05)
  %broadcast.696 = f32[1792]{0} broadcast(f32[] %constant_811), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.679 = f32[1792]{0} multiply(f32[1792]{0} %add.207, f32[1792]{0} %broadcast.696), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.693 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.679), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/broadcast_in_dim[shape=(16, 28, 28, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.206 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %add.208, f32[16,28,28,1792]{2,1,3,0} %broadcast.693), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.417 (param_0.1216: f32[16,28,28,1792], param_1.1640: f32[1792], param_2.707: f32[1792], param_3.1561: f32[16,28,28,1792], param_4.1366: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_0.1216 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  %param_2.707 = f32[1792]{0} parameter(2)
  %constant_815 = f32[] constant(0)
  %broadcast.1746 = f32[1792]{0} broadcast(f32[] %constant_815), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.241 = f32[1792]{0} maximum(f32[1792]{0} %param_2.707, f32[1792]{0} %broadcast.1746), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1372 = f32[] constant(1e-05)
  %broadcast.1745 = f32[1792]{0} broadcast(f32[] %constant_1372), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.397 = f32[1792]{0} add(f32[1792]{0} %maximum.241, f32[1792]{0} %broadcast.1745), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1196 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.187 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1196), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1640 = f32[1792]{0} parameter(1)
  %bitcast.1195 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1640), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1407 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.187, f32[1,1,1,1792]{3,2,1,0} %bitcast.1195), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1194 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1407), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1744 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1194), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1406 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %param_0.1216, f32[16,28,28,1792]{2,1,3,0} %broadcast.1744), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.47 = f32[16,28,28,1792]{2,1,3,0} negate(f32[16,28,28,1792]{2,1,3,0} %multiply.1406), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.63 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %negate.47), dimensions={0,3,1,2}
  %bitcast.817 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.63), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.859 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.817, f32[] %constant_815), dimensions={2}, to_apply=%region_63.4346.3
  %param_3.1561 = f32[16,28,28,1792]{2,1,3,0} parameter(3)
  %param_4.1366 = f32[1792]{0} parameter(4)
  %constant_1332_clone_1 = f32[] constant(7.97193861e-05)
  %broadcast.1710.clone.1 = f32[1792]{0} broadcast(f32[] %constant_1332_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1395.clone.1 = f32[1792]{0} multiply(f32[1792]{0} %param_4.1366, f32[1792]{0} %broadcast.1710.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1709.clone.1 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1395.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.111.clone.1 = f32[16,28,28,1792]{2,1,3,0} subtract(f32[16,28,28,1792]{2,1,3,0} %param_3.1561, f32[16,28,28,1792]{2,1,3,0} %broadcast.1709.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.688.clone.1 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %subtract.111.clone.1, f32[16,28,28,1792]{2,1,3,0} %param_0.1216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.64 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %multiply.688.clone.1), dimensions={0,3,1,2}
  %bitcast.819.clone.1 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.64), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.861.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.819.clone.1, f32[] %constant_815), dimensions={2}, to_apply=%region_63.4346.3
  %transpose.65 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %param_0.1216), dimensions={0,3,1,2}
  %bitcast.802.clone.1 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.65), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.848.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %bitcast.802.clone.1, f32[] %constant_815), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.95 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.859, f32[16,1792]{1,0} %reduce.861.clone.1, f32[16,1792]{1,0} %reduce.848.clone.1)
}

%fused_computation.418 (param_0.747: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.747 = f32[16,1792]{1,0} parameter(0)
  %constant_813 = f32[] constant(0)
  %reduce.860 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.747, f32[] %constant_813), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.818 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.860), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.421 (param_0.752: f32[16,28,28,1792], param_1.1440: f32[16,28,28,1792], param_2.441: f32[1792], param_3.491: f32[16,28,28,1792], param_4.436: f32[1792], param_5.421: f32[1792], param_6.362: f32[1792]) -> f32[16,28,28,1792] {
  %param_1.1440 = f32[16,28,28,1792]{2,1,3,0} parameter(1)
  %param_3.491 = f32[16,28,28,1792]{2,1,3,0} parameter(3)
  %param_4.436 = f32[1792]{0} parameter(4)
  %constant_1329 = f32[] constant(7.97193861e-05)
  %broadcast.1706 = f32[1792]{0} broadcast(f32[] %constant_1329), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1393 = f32[1792]{0} multiply(f32[1792]{0} %param_4.436, f32[1792]{0} %broadcast.1706), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1705 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1393), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.109 = f32[16,28,28,1792]{2,1,3,0} subtract(f32[16,28,28,1792]{2,1,3,0} %param_3.491, f32[16,28,28,1792]{2,1,3,0} %broadcast.1705), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_6.362 = f32[1792]{0} parameter(6)
  %constant_816 = f32[] constant(0)
  %broadcast.1730 = f32[1792]{0} broadcast(f32[] %constant_816), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.235 = f32[1792]{0} maximum(f32[1792]{0} %param_6.362, f32[1792]{0} %broadcast.1730), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1357 = f32[] constant(1e-05)
  %broadcast.1729 = f32[1792]{0} broadcast(f32[] %constant_1357), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.391 = f32[1792]{0} add(f32[1792]{0} %maximum.235, f32[1792]{0} %broadcast.1729), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1178 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.391), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.181 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1178), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.421 = f32[1792]{0} parameter(5)
  %bitcast.1177 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.421), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1397 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.181, f32[1,1,1,1792]{3,2,1,0} %bitcast.1177), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1176 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.704 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1176), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.690 = f32[16,28,28,1792]{2,1,3,0} multiply(f32[16,28,28,1792]{2,1,3,0} %subtract.109, f32[16,28,28,1792]{2,1,3,0} %broadcast.704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.441 = f32[1792]{0} parameter(2)
  %broadcast.703 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_2.441), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.210 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %multiply.690, f32[16,28,28,1792]{2,1,3,0} %broadcast.703), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.209 = f32[16,28,28,1792]{2,1,3,0} add(f32[16,28,28,1792]{2,1,3,0} %param_1.1440, f32[16,28,28,1792]{2,1,3,0} %add.210), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.702 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[] %constant_816), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.69 = pred[16,28,28,1792]{2,1,3,0} compare(f32[16,28,28,1792]{2,1,3,0} %add.209, f32[16,28,28,1792]{2,1,3,0} %broadcast.702), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.752 = f32[16,28,28,1792]{2,1,3,0} parameter(0)
  ROOT %select.69 = f32[16,28,28,1792]{2,1,3,0} select(pred[16,28,28,1792]{2,1,3,0} %compare.69, f32[16,28,28,1792]{2,1,3,0} %param_0.752, f32[16,28,28,1792]{2,1,3,0} %broadcast.702), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.425 (param_0.1202: f32[16,1792], param_1.1620: f32[1792]) -> f32[1792] {
  %param_0.1202 = f32[16,1792]{1,0} parameter(0)
  %constant_820 = f32[] constant(0)
  %reduce.862 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1202, f32[] %constant_820), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_819 = f32[] constant(7.97193861e-05)
  %broadcast.707 = f32[1792]{0} broadcast(f32[] %constant_819), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.693 = f32[1792]{0} multiply(f32[1792]{0} %reduce.862, f32[1792]{0} %broadcast.707), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1620 = f32[1792]{0} parameter(1)
  %multiply.1391 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1620, f32[1792]{0} %broadcast.707), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.692 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1391, f32[1792]{0} %multiply.1391), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.42 = f32[1792]{0} subtract(f32[1792]{0} %multiply.693, f32[1792]{0} %multiply.692), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.430 (param_0.1198: f32[896], param_1.1615: f32[896], param_2.673: f32[896], param_3.476: f32[16,28,28,896], param_4.425: f32[896]) -> f32[16,28,28,896] {
  %param_3.476 = f32[16,28,28,896]{2,1,3,0} parameter(3)
  %param_4.425 = f32[896]{0} parameter(4)
  %constant_1313 = f32[] constant(7.97193861e-05)
  %broadcast.1686 = f32[896]{0} broadcast(f32[] %constant_1313), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1381 = f32[896]{0} multiply(f32[896]{0} %param_4.425, f32[896]{0} %broadcast.1686), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1685 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1381), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.105 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_3.476, f32[16,28,28,896]{2,1,3,0} %broadcast.1685), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.673 = f32[896]{0} parameter(2)
  %constant_824 = f32[] constant(0)
  %broadcast.1684 = f32[896]{0} broadcast(f32[] %constant_824), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.221 = f32[896]{0} maximum(f32[896]{0} %param_2.673, f32[896]{0} %broadcast.1684), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1311 = f32[] constant(1e-05)
  %broadcast.1683 = f32[896]{0} broadcast(f32[] %constant_1311), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.379 = f32[896]{0} add(f32[896]{0} %maximum.221, f32[896]{0} %broadcast.1683), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1160 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.379), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.177 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1160), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1615 = f32[896]{0} parameter(1)
  %bitcast.1159 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.1615), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1380 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.177, f32[1,1,1,896]{3,2,1,0} %bitcast.1159), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1158 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1380), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1682 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1158), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1379 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.105, f32[16,28,28,896]{2,1,3,0} %broadcast.1682), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1198 = f32[896]{0} parameter(0)
  %broadcast.1681 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1198), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.378 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1379, f32[16,28,28,896]{2,1,3,0} %broadcast.1681), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.710 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_824), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.38 = f32[16,28,28,896]{2,1,3,0} maximum(f32[16,28,28,896]{2,1,3,0} %add.378, f32[16,28,28,896]{2,1,3,0} %broadcast.710), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.435 (param_0.1184: f32[16,896], param_1.1595: f32[896]) -> f32[896] {
  %param_0.1184 = f32[16,896]{1,0} parameter(0)
  %constant_828 = f32[] constant(0)
  %reduce.865 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1184, f32[] %constant_828), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_827 = f32[] constant(7.97193861e-05)
  %broadcast.715 = f32[896]{0} broadcast(f32[] %constant_827), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.699 = f32[896]{0} multiply(f32[896]{0} %reduce.865, f32[896]{0} %broadcast.715), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1595 = f32[896]{0} parameter(1)
  %multiply.1367 = f32[896]{0} multiply(f32[896]{0} %param_1.1595, f32[896]{0} %broadcast.715), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.698 = f32[896]{0} multiply(f32[896]{0} %multiply.1367, f32[896]{0} %multiply.1367), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.44 = f32[896]{0} subtract(f32[896]{0} %multiply.699, f32[896]{0} %multiply.698), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.440 (param_0.1180: f32[448], param_1.1590: f32[448], param_2.639: f32[448], param_3.445: f32[16,28,28,448], param_4.400: f32[448]) -> f32[16,28,28,448] {
  %param_3.445 = f32[16,28,28,448]{2,1,3,0} parameter(3)
  %param_4.400 = f32[448]{0} parameter(4)
  %constant_1256 = f32[] constant(7.97193861e-05)
  %broadcast.1626 = f32[448]{0} broadcast(f32[] %constant_1256), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1357 = f32[448]{0} multiply(f32[448]{0} %param_4.400, f32[448]{0} %broadcast.1626), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1625 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %multiply.1357), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.97 = f32[16,28,28,448]{2,1,3,0} subtract(f32[16,28,28,448]{2,1,3,0} %param_3.445, f32[16,28,28,448]{2,1,3,0} %broadcast.1625), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.639 = f32[448]{0} parameter(2)
  %constant_832 = f32[] constant(0)
  %broadcast.1624 = f32[448]{0} broadcast(f32[] %constant_832), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.203 = f32[448]{0} maximum(f32[448]{0} %param_2.639, f32[448]{0} %broadcast.1624), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1254 = f32[] constant(1e-05)
  %broadcast.1623 = f32[448]{0} broadcast(f32[] %constant_1254), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.361 = f32[448]{0} add(f32[448]{0} %maximum.203, f32[448]{0} %broadcast.1623), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1130 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.361), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.169 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.1130), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1590 = f32[448]{0} parameter(1)
  %bitcast.1129 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %param_1.1590), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1356 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.169, f32[1,1,1,448]{3,2,1,0} %bitcast.1129), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1128 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.1356), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1622 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %bitcast.1128), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1355 = f32[16,28,28,448]{2,1,3,0} multiply(f32[16,28,28,448]{2,1,3,0} %subtract.97, f32[16,28,28,448]{2,1,3,0} %broadcast.1622), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1180 = f32[448]{0} parameter(0)
  %broadcast.1621 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[448]{0} %param_0.1180), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.360 = f32[16,28,28,448]{2,1,3,0} add(f32[16,28,28,448]{2,1,3,0} %multiply.1355, f32[16,28,28,448]{2,1,3,0} %broadcast.1621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.718 = f32[16,28,28,448]{2,1,3,0} broadcast(f32[] %constant_832), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.40 = f32[16,28,28,448]{2,1,3,0} maximum(f32[16,28,28,448]{2,1,3,0} %add.360, f32[16,28,28,448]{2,1,3,0} %broadcast.718), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.445 (param_0.1166: f32[16,448], param_1.1570: f32[448]) -> f32[448] {
  %param_0.1166 = f32[16,448]{1,0} parameter(0)
  %constant_836 = f32[] constant(0)
  %reduce.868 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0.1166, f32[] %constant_836), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_835 = f32[] constant(7.97193861e-05)
  %broadcast.723 = f32[448]{0} broadcast(f32[] %constant_835), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.705 = f32[448]{0} multiply(f32[448]{0} %reduce.868, f32[448]{0} %broadcast.723), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1570 = f32[448]{0} parameter(1)
  %multiply.1343 = f32[448]{0} multiply(f32[448]{0} %param_1.1570, f32[448]{0} %broadcast.723), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.704 = f32[448]{0} multiply(f32[448]{0} %multiply.1343, f32[448]{0} %multiply.1343), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.46 = f32[448]{0} subtract(f32[448]{0} %multiply.705, f32[448]{0} %multiply.704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.450 (param_0.798: f32[3584], param_1.1447: f32[1,1,1,3584], param_2.1773: f32[3584], param_3.1566: f32[16,3584]) -> (f32[3584], f32[3584]) {
  %param_0.798 = f32[3584]{0} parameter(0)
  %param_3.1566 = f32[16,3584]{1,0} parameter(3)
  %constant_1196 = f32[] constant(0)
  %reduce.874.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.1566, f32[] %constant_1196), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_1172_clone_1 = f32[] constant(0.000318877544)
  %broadcast.738.clone.1 = f32[3584]{0} broadcast(f32[] %constant_1172_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.722.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.874.clone.1, f32[3584]{0} %broadcast.738.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1773 = f32[3584]{0} parameter(2)
  %multiply.1329.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.1773, f32[3584]{0} %broadcast.738.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.721.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.1329.clone.1, f32[3584]{0} %multiply.1329.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.49.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.722.clone.1, f32[3584]{0} %multiply.721.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.1528 = f32[3584]{0} broadcast(f32[] %constant_1196), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.135 = f32[3584]{0} maximum(f32[3584]{0} %subtract.49.clone.1, f32[3584]{0} %broadcast.1528), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1195 = f32[] constant(1e-05)
  %broadcast.1526 = f32[3584]{0} broadcast(f32[] %constant_1195), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.343 = f32[3584]{0} add(f32[3584]{0} %maximum.135, f32[3584]{0} %broadcast.1526), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1094 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.343), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.72 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1094), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1447 = f32[1,1,1,3584]{3,2,1,0} parameter(1)
  %multiply.708 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.72, f32[1,1,1,3584]{3,2,1,0} %param_1.1447), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.832 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.708), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.216 = f32[3584]{0} add(f32[3584]{0} %param_0.798, f32[3584]{0} %bitcast.832), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  ROOT %tuple.99 = (f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.216, f32[3584]{0} %subtract.49.clone.1)
}

%fused_computation.451 (param_0.801: f32[1,1,1792,3584], param_1.1176: f32[1,1,1792,3584]) -> f32[1,1,1792,3584] {
  %param_1.1176 = f32[1,1,1792,3584]{3,2,1,0} parameter(1)
  %copy.188 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_1.1176), metadata={op_name="3$start"}
  %param_0.801 = f32[1,1,1792,3584]{1,0,2,3} parameter(0)
  %add.217 = f32[1,1,1792,3584]{1,0,2,3} add(f32[1,1,1792,3584]{1,0,2,3} %copy.188, f32[1,1,1792,3584]{1,0,2,3} %param_0.801), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  ROOT %copy.187 = f32[1,1,1792,3584]{3,2,1,0} copy(f32[1,1,1792,3584]{1,0,2,3} %add.217), metadata={op_name="tuple.85"}
}

%fused_computation.454 (param_0.808: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.808 = f32[16,3584]{1,0} parameter(0)
  %constant_846 = f32[] constant(0)
  %reduce.872 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.808, f32[] %constant_846), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.835 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.872), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.464 (param_0.824: f32[3584], param_1.1450: f32[1,1,1,3584], param_2.1776: f32[3584], param_3.1571: f32[16,3584]) -> (f32[3584], f32[3584]) {
  %param_0.824 = f32[3584]{0} parameter(0)
  %param_3.1571 = f32[16,3584]{1,0} parameter(3)
  %constant_1053 = f32[] constant(0)
  %reduce.891.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.1571, f32[] %constant_1053), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_1029_clone_1 = f32[] constant(0.000318877544)
  %broadcast.772.clone.1 = f32[3584]{0} broadcast(f32[] %constant_1029_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.763.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.891.clone.1, f32[3584]{0} %broadcast.772.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1776 = f32[3584]{0} parameter(2)
  %multiply.827.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.1776, f32[3584]{0} %broadcast.772.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.762.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.827.clone.1, f32[3584]{0} %multiply.827.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.51.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.763.clone.1, f32[3584]{0} %multiply.762.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.929 = f32[3584]{0} broadcast(f32[] %constant_1053), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.93 = f32[3584]{0} maximum(f32[3584]{0} %subtract.51.clone.1, f32[3584]{0} %broadcast.929), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1052 = f32[] constant(1e-05)
  %broadcast.928 = f32[3584]{0} broadcast(f32[] %constant_1052), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.285 = f32[3584]{0} add(f32[3584]{0} %maximum.93, f32[3584]{0} %broadcast.928), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.992 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.285), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.75 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.992), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1450 = f32[1,1,1,3584]{3,2,1,0} parameter(1)
  %multiply.725 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.75, f32[1,1,1,3584]{3,2,1,0} %param_1.1450), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.842 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.725), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.222 = f32[3584]{0} add(f32[3584]{0} %param_0.824, f32[3584]{0} %bitcast.842), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  ROOT %tuple.105 = (f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.222, f32[3584]{0} %subtract.51.clone.1)
}

%fused_computation.465 (param_0.827: f32[1,1,1792,3584], param_1.1217: f32[1,1,1792,3584]) -> f32[1,1,1792,3584] {
  %param_1.1217 = f32[1,1,1792,3584]{3,2,1,0} parameter(1)
  %copy.190 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_1.1217), metadata={op_name="3$start"}
  %param_0.827 = f32[1,1,1792,3584]{1,0,2,3} parameter(0)
  %add.223 = f32[1,1,1792,3584]{1,0,2,3} add(f32[1,1,1792,3584]{1,0,2,3} %copy.190, f32[1,1,1792,3584]{1,0,2,3} %param_0.827), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  ROOT %copy.189 = f32[1,1,1792,3584]{3,2,1,0} copy(f32[1,1,1792,3584]{1,0,2,3} %add.223), metadata={op_name="tuple.85"}
}

%fused_computation.467 (param_0.1135: f32[16,14,14,1792], param_1.1531: f32[1792], param_2.552: f32[1792], param_3.360: f32[1792], param_4.334: f32[16,14,14,1792], param_5.322: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.334 = f32[16,14,14,1792]{2,1,3,0} parameter(4)
  %param_5.322 = f32[1792]{0} parameter(5)
  %constant_1090 = f32[] constant(0.000318877544)
  %broadcast.983 = f32[1792]{0} broadcast(f32[] %constant_1090), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.855 = f32[1792]{0} multiply(f32[1792]{0} %param_5.322, f32[1792]{0} %broadcast.983), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.982 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.855), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.77 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_4.334, f32[16,14,14,1792]{2,1,3,0} %broadcast.982), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.360 = f32[1792]{0} parameter(3)
  %constant_858 = f32[] constant(0)
  %broadcast.981 = f32[1792]{0} broadcast(f32[] %constant_858), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.103 = f32[1792]{0} maximum(f32[1792]{0} %param_3.360, f32[1792]{0} %broadcast.981), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1088 = f32[] constant(1e-05)
  %broadcast.980 = f32[1792]{0} broadcast(f32[] %constant_1088), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.301 = f32[1792]{0} add(f32[1792]{0} %maximum.103, f32[1792]{0} %broadcast.980), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1022 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.301), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.137 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1022), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.552 = f32[1792]{0} parameter(2)
  %bitcast.1021 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.552), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.854 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.137, f32[1,1,1,1792]{3,2,1,0} %bitcast.1021), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1020 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.854), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.979 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1020), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.853 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.77, f32[16,14,14,1792]{2,1,3,0} %broadcast.979), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1531 = f32[1792]{0} parameter(1)
  %broadcast.978 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.1531), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.300 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.853, f32[16,14,14,1792]{2,1,3,0} %broadcast.978), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.977 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_858), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %compare.165 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.300, f32[16,14,14,1792]{2,1,3,0} %broadcast.977), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1135 = f32[16,14,14,1792]{2,1,3,0} parameter(0)
  %select.165 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.165, f32[16,14,14,1792]{2,1,3,0} %param_0.1135, f32[16,14,14,1792]{2,1,3,0} %broadcast.977), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.66 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %select.165), dimensions={0,3,1,2}
  %bitcast.843 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.66), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.879 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.843, f32[] %constant_858), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1285.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.165, f32[16,14,14,1792]{2,1,3,0} %broadcast.979), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.53.clone.1 = f32[16,14,14,1792]{2,1,3,0} negate(f32[16,14,14,1792]{2,1,3,0} %multiply.1285.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.67 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %negate.53.clone.1), dimensions={0,3,1,2}
  %bitcast.852.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.67), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.885.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.852.clone.1, f32[] %constant_858), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.748.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.77, f32[16,14,14,1792]{2,1,3,0} %select.165), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.68 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %multiply.748.clone.1), dimensions={0,3,1,2}
  %bitcast.854.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.68), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.887.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.854.clone.1, f32[] %constant_858), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.104 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.879, f32[16,1792]{1,0} %reduce.885.clone.1, f32[16,1792]{1,0} %reduce.887.clone.1)
}

%fused_computation.469 (param_0.834: f32[3,3,896,1792], param_1.1226: f32[3,3,896,1792]) -> f32[3,3,896,1792] {
  %param_1.1226 = f32[3,3,896,1792]{3,2,1,0} parameter(1)
  %copy.192 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_1.1226), metadata={op_name="3$start"}
  %param_0.834 = f32[3,3,896,1792]{1,0,2,3} parameter(0)
  %add.226 = f32[3,3,896,1792]{1,0,2,3} add(f32[3,3,896,1792]{1,0,2,3} %copy.192, f32[3,3,896,1792]{1,0,2,3} %param_0.834), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  ROOT %copy.191 = f32[3,3,896,1792]{3,2,1,0} copy(f32[3,3,896,1792]{1,0,2,3} %add.226), metadata={op_name="tuple.85"}
}

%fused_computation.471 (param_0.1147: f32[16,29,29,896], param_1.1550: f32[896], param_2.580: f32[896], param_3.393: f32[896], param_4.370: f32[16,28,28,896], param_5.365: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.370 = f32[16,28,28,896]{2,1,3,0} parameter(4)
  %param_5.365 = f32[896]{0} parameter(5)
  %constant_1143 = f32[] constant(7.97193861e-05)
  %broadcast.1065 = f32[896]{0} broadcast(f32[] %constant_1143), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1307 = f32[896]{0} multiply(f32[896]{0} %param_5.365, f32[896]{0} %broadcast.1065), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1064 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1307), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.87 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_4.370, f32[16,28,28,896]{2,1,3,0} %broadcast.1064), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.393 = f32[896]{0} parameter(3)
  %constant_860 = f32[] constant(0)
  %broadcast.1063 = f32[896]{0} broadcast(f32[] %constant_860), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.117 = f32[896]{0} maximum(f32[896]{0} %param_3.393, f32[896]{0} %broadcast.1063), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1141 = f32[] constant(1e-05)
  %broadcast.1062 = f32[896]{0} broadcast(f32[] %constant_1141), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.325 = f32[896]{0} add(f32[896]{0} %maximum.117, f32[896]{0} %broadcast.1062), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1064 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.325), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.151 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1064), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.580 = f32[896]{0} parameter(2)
  %bitcast.1063 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.580), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1306 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.151, f32[1,1,1,896]{3,2,1,0} %bitcast.1063), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1062 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1306), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1061 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1062), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1305 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.87, f32[16,28,28,896]{2,1,3,0} %broadcast.1061), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1550 = f32[896]{0} parameter(1)
  %broadcast.1060 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.1550), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.324 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1305, f32[16,28,28,896]{2,1,3,0} %broadcast.1060), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1059 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_860), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.175 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.324, f32[16,28,28,896]{2,1,3,0} %broadcast.1059), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1147 = f32[16,29,29,896]{2,1,3,0} parameter(0)
  %slice.11 = f32[16,28,28,896]{2,1,3,0} slice(f32[16,29,29,896]{2,1,3,0} %param_0.1147), slice={[0:16], [0:28], [0:28], [0:896]}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %select.175 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.175, f32[16,28,28,896]{2,1,3,0} %slice.11, f32[16,28,28,896]{2,1,3,0} %broadcast.1059), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.69 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %select.175), dimensions={0,3,1,2}
  %bitcast.845 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.69), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.881 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.845, f32[] %constant_860), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.1323.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.175, f32[16,28,28,896]{2,1,3,0} %broadcast.1061), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.51.clone.1 = f32[16,28,28,896]{2,1,3,0} negate(f32[16,28,28,896]{2,1,3,0} %multiply.1323.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.70 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %negate.51.clone.1), dimensions={0,3,1,2}
  %bitcast.848.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.70), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.882.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.848.clone.1, f32[] %constant_860), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.737.clone.1 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.87, f32[16,28,28,896]{2,1,3,0} %select.175), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.71 = f32[16,896,28,28]{3,2,1,0} transpose(f32[16,28,28,896]{2,1,3,0} %multiply.737.clone.1), dimensions={0,3,1,2}
  %bitcast.850.clone.1 = f32[16,896,784]{2,1,0} bitcast(f32[16,896,28,28]{3,2,1,0} %transpose.71), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.884.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %bitcast.850.clone.1, f32[] %constant_860), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.102 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.881, f32[16,896]{1,0} %reduce.882.clone.1, f32[16,896]{1,0} %reduce.884.clone.1)
}

%fused_computation.473 (param_0.841: f32[1,1,1792,896], param_1.1235: f32[1,1,1792,896]) -> f32[1,1,1792,896] {
  %param_1.1235 = f32[1,1,1792,896]{3,2,1,0} parameter(1)
  %copy.194 = f32[1,1,1792,896]{1,0,2,3} copy(f32[1,1,1792,896]{3,2,1,0} %param_1.1235), metadata={op_name="3$start"}
  %param_0.841 = f32[1,1,1792,896]{1,0,2,3} parameter(0)
  %add.229 = f32[1,1,1792,896]{1,0,2,3} add(f32[1,1,1792,896]{1,0,2,3} %copy.194, f32[1,1,1792,896]{1,0,2,3} %param_0.841), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  ROOT %copy.193 = f32[1,1,1792,896]{3,2,1,0} copy(f32[1,1,1792,896]{1,0,2,3} %add.229), metadata={op_name="tuple.85"}
}

%fused_computation.474 (param_0.844: f32[896], param_1.1241: f32[896], param_2.582: f32[16,28,28,896], param_3.395: f32[896], param_4.372: f32[1,1,1,896], param_5.367: f32[896], param_6.336: f32[16,29,29,896], param_7.411: f32[896]) -> f32[16,28,28,896] {
  %param_2.582 = f32[16,28,28,896]{2,1,3,0} parameter(2)
  %param_1.1241 = f32[896]{0} parameter(1)
  %constant_865 = f32[] constant(7.97193861e-05)
  %broadcast.1085 = f32[896]{0} broadcast(f32[] %constant_865), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1317 = f32[896]{0} multiply(f32[896]{0} %param_1.1241, f32[896]{0} %broadcast.1085), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1084 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1317), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.89 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_2.582, f32[16,28,28,896]{2,1,3,0} %broadcast.1084), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.395 = f32[896]{0} parameter(3)
  %constant_866 = f32[] constant(0)
  %broadcast.1083 = f32[896]{0} broadcast(f32[] %constant_866), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.121 = f32[896]{0} maximum(f32[896]{0} %param_3.395, f32[896]{0} %broadcast.1083), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_939 = f32[] constant(1e-05)
  %broadcast.1082 = f32[896]{0} broadcast(f32[] %constant_939), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.331 = f32[896]{0} add(f32[896]{0} %maximum.121, f32[896]{0} %broadcast.1082), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1076 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.331), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.155 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1076), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.367 = f32[896]{0} parameter(5)
  %bitcast.1075 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.367), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1316 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.155, f32[1,1,1,896]{3,2,1,0} %bitcast.1075), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1074 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1316), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1081 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1074), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1315 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.89, f32[16,28,28,896]{2,1,3,0} %broadcast.1081), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.411 = f32[896]{0} parameter(7)
  %broadcast.1080 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.411), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.330 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1315, f32[16,28,28,896]{2,1,3,0} %broadcast.1080), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1079 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_866), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.177 = pred[16,28,28,896]{2,1,3,0} compare(f32[16,28,28,896]{2,1,3,0} %add.330, f32[16,28,28,896]{2,1,3,0} %broadcast.1079), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.336 = f32[16,29,29,896]{2,1,3,0} parameter(6)
  %slice.13 = f32[16,28,28,896]{2,1,3,0} slice(f32[16,29,29,896]{2,1,3,0} %param_6.336), slice={[0:16], [0:28], [0:28], [0:896]}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %select.177 = f32[16,28,28,896]{2,1,3,0} select(pred[16,28,28,896]{2,1,3,0} %compare.177, f32[16,28,28,896]{2,1,3,0} %slice.13, f32[16,28,28,896]{2,1,3,0} %broadcast.1079), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1313 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %select.177, f32[16,28,28,896]{2,1,3,0} %broadcast.1081), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.372 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.736 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.372, f32[1,1,1,896]{3,2,1,0} %bitcast.1075), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.51 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.155, f32[1,1,1,896]{3,2,1,0} %bitcast.1076), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_862 = f32[] constant(-0.5)
  %broadcast.745 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_862), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.735 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.51, f32[1,1,1,896]{3,2,1,0} %broadcast.745), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.734 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.736, f32[1,1,1,896]{3,2,1,0} %multiply.735), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.847 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.734), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.73 = pred[896]{0} compare(f32[896]{0} %param_3.395, f32[896]{0} %maximum.121), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_863 = f32[] constant(1)
  %broadcast.744 = f32[896]{0} broadcast(f32[] %constant_863), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.73 = f32[896]{0} select(pred[896]{0} %compare.73, f32[896]{0} %broadcast.744, f32[896]{0} %broadcast.1083), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.72 = pred[896]{0} compare(f32[896]{0} %broadcast.1083, f32[896]{0} %maximum.121), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_864 = f32[] constant(2)
  %broadcast.743 = f32[896]{0} broadcast(f32[] %constant_864), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.72 = f32[896]{0} select(pred[896]{0} %compare.72, f32[896]{0} %broadcast.743, f32[896]{0} %broadcast.744), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.50 = f32[896]{0} divide(f32[896]{0} %select.73, f32[896]{0} %select.72), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.733 = f32[896]{0} multiply(f32[896]{0} %bitcast.847, f32[896]{0} %divide.50), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_861 = f32[] constant(0.000159438772)
  %broadcast.742 = f32[896]{0} broadcast(f32[] %constant_861), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.732 = f32[896]{0} multiply(f32[896]{0} %multiply.733, f32[896]{0} %broadcast.742), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.741 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.732), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.731 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %param_2.582, f32[16,28,28,896]{2,1,3,0} %broadcast.741), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.232 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.1313, f32[16,28,28,896]{2,1,3,0} %multiply.731), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.844 = f32[896]{0} parameter(0)
  %negate.50 = f32[896]{0} negate(f32[896]{0} %multiply.733), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.730 = f32[896]{0} multiply(f32[896]{0} %param_1.1241, f32[896]{0} %broadcast.742), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.729 = f32[896]{0} multiply(f32[896]{0} %negate.50, f32[896]{0} %multiply.730), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.231 = f32[896]{0} add(f32[896]{0} %param_0.844, f32[896]{0} %multiply.729), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.728 = f32[896]{0} multiply(f32[896]{0} %add.231, f32[896]{0} %broadcast.1085), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.740 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.728), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/broadcast_in_dim[shape=(16, 28, 28, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.230 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %add.232, f32[16,28,28,896]{2,1,3,0} %broadcast.740), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.476 (param_0.848: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.848 = f32[16,896]{1,0} parameter(0)
  %constant_867 = f32[] constant(0)
  %reduce.883 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.848, f32[] %constant_867), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.849 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.883), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.480 (param_0.857: f32[1792], param_1.1260: f32[1792], param_2.554: f32[16,14,14,1792], param_3.362: f32[1792], param_4.336: f32[1,1,1,1792], param_5.324: f32[1792], param_6.310: f32[16,14,14,1792], param_7.392: f32[1792]) -> f32[16,14,14,1792] {
  %param_2.554 = f32[16,14,14,1792]{2,1,3,0} parameter(2)
  %param_1.1260 = f32[1792]{0} parameter(1)
  %constant_875 = f32[] constant(0.000318877544)
  %broadcast.1003 = f32[1792]{0} broadcast(f32[] %constant_875), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1279 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1260, f32[1792]{0} %broadcast.1003), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1002 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1279), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.79 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_2.554, f32[16,14,14,1792]{2,1,3,0} %broadcast.1002), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.362 = f32[1792]{0} parameter(3)
  %constant_876 = f32[] constant(0)
  %broadcast.1001 = f32[1792]{0} broadcast(f32[] %constant_876), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.107 = f32[1792]{0} maximum(f32[1792]{0} %param_3.362, f32[1792]{0} %broadcast.1001), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_996 = f32[] constant(1e-05)
  %broadcast.1000 = f32[1792]{0} broadcast(f32[] %constant_996), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.307 = f32[1792]{0} add(f32[1792]{0} %maximum.107, f32[1792]{0} %broadcast.1000), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1034 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.307), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.141 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1034), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.324 = f32[1792]{0} parameter(5)
  %bitcast.1033 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.324), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1278 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.141, f32[1,1,1,1792]{3,2,1,0} %bitcast.1033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1032 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1278), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.999 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1032), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1277 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.79, f32[16,14,14,1792]{2,1,3,0} %broadcast.999), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.392 = f32[1792]{0} parameter(7)
  %broadcast.998 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.392), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.306 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1277, f32[16,14,14,1792]{2,1,3,0} %broadcast.998), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.997 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_876), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %compare.167 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.306, f32[16,14,14,1792]{2,1,3,0} %broadcast.997), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.310 = f32[16,14,14,1792]{2,1,3,0} parameter(6)
  %select.167 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.167, f32[16,14,14,1792]{2,1,3,0} %param_6.310, f32[16,14,14,1792]{2,1,3,0} %broadcast.997), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.861 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.167, f32[16,14,14,1792]{2,1,3,0} %broadcast.999), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.336 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.747 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.336, f32[1,1,1,1792]{3,2,1,0} %bitcast.1033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.53 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.141, f32[1,1,1,1792]{3,2,1,0} %bitcast.1034), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_871 = f32[] constant(-0.5)
  %broadcast.755 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_871), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.746 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.53, f32[1,1,1,1792]{3,2,1,0} %broadcast.755), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.745 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.747, f32[1,1,1,1792]{3,2,1,0} %multiply.746), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.851 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.745), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.76 = pred[1792]{0} compare(f32[1792]{0} %param_3.362, f32[1792]{0} %maximum.107), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_872 = f32[] constant(1)
  %broadcast.754 = f32[1792]{0} broadcast(f32[] %constant_872), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.76 = f32[1792]{0} select(pred[1792]{0} %compare.76, f32[1792]{0} %broadcast.754, f32[1792]{0} %broadcast.1001), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.75 = pred[1792]{0} compare(f32[1792]{0} %broadcast.1001, f32[1792]{0} %maximum.107), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_873 = f32[] constant(2)
  %broadcast.753 = f32[1792]{0} broadcast(f32[] %constant_873), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.75 = f32[1792]{0} select(pred[1792]{0} %compare.75, f32[1792]{0} %broadcast.753, f32[1792]{0} %broadcast.754), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.52 = f32[1792]{0} divide(f32[1792]{0} %select.76, f32[1792]{0} %select.75), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.744 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.851, f32[1792]{0} %divide.52), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_874 = f32[] constant(0.000637755089)
  %broadcast.752 = f32[1792]{0} broadcast(f32[] %constant_874), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.743 = f32[1792]{0} multiply(f32[1792]{0} %multiply.744, f32[1792]{0} %broadcast.752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.751 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.743), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.742 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %param_2.554, f32[16,14,14,1792]{2,1,3,0} %broadcast.751), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.235 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.861, f32[16,14,14,1792]{2,1,3,0} %multiply.742), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.857 = f32[1792]{0} parameter(0)
  %negate.52 = f32[1792]{0} negate(f32[1792]{0} %multiply.744), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.741 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1260, f32[1792]{0} %broadcast.752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.740 = f32[1792]{0} multiply(f32[1792]{0} %negate.52, f32[1792]{0} %multiply.741), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.234 = f32[1792]{0} add(f32[1792]{0} %param_0.857, f32[1792]{0} %multiply.740), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.739 = f32[1792]{0} multiply(f32[1792]{0} %add.234, f32[1792]{0} %broadcast.1003), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.750 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.739), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/broadcast_in_dim[shape=(16, 14, 14, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.233 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %add.235, f32[16,14,14,1792]{2,1,3,0} %broadcast.750), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.482 (param_0.861: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.861 = f32[16,1792]{1,0} parameter(0)
  %constant_877 = f32[] constant(0)
  %reduce.886 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.861, f32[] %constant_877), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.853 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.886), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.486 (param_0.869: f32[3584], param_1.1278: f32[3584], param_2.531: f32[16,14,14,3584], param_3.337: f32[3584], param_4.310: f32[1,1,1,3584], param_5.294: f32[3584], param_6.290: f32[16,14,14,3584], param_7.1529: f32[3584], param_8.1155: f32[3584], param_9.684: f32[16,14,14,3584], param_10.515: f32[3584], param_11.472: f32[1,1,1,3584], param_12.397: f32[3584]) -> (f32[16,14,14,3584], f32[16,14,14,3584]) {
  %param_6.290 = f32[16,14,14,3584]{2,1,3,0} parameter(6)
  %param_3.337 = f32[3584]{0} parameter(3)
  %constant_886 = f32[] constant(0)
  %broadcast.935 = f32[3584]{0} broadcast(f32[] %constant_886), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.95 = f32[3584]{0} maximum(f32[3584]{0} %param_3.337, f32[3584]{0} %broadcast.935), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1047 = f32[] constant(1e-05)
  %broadcast.934 = f32[3584]{0} broadcast(f32[] %constant_1047), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.287 = f32[3584]{0} add(f32[3584]{0} %maximum.95, f32[3584]{0} %broadcast.934), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.998 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.287), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.129 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.998), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.294 = f32[3584]{0} parameter(5)
  %bitcast.997 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.294), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.833 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.129, f32[1,1,1,3584]{3,2,1,0} %bitcast.997), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.996 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.833), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.933 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.996), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.832 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_6.290, f32[16,14,14,3584]{2,1,3,0} %broadcast.933), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.531 = f32[16,14,14,3584]{2,1,3,0} parameter(2)
  %param_4.310 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.758 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.310, f32[1,1,1,3584]{3,2,1,0} %bitcast.997), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.55 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.129, f32[1,1,1,3584]{3,2,1,0} %bitcast.998), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_881 = f32[] constant(-0.5)
  %broadcast.765 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_881), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.757 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.55, f32[1,1,1,3584]{3,2,1,0} %broadcast.765), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.756 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.758, f32[1,1,1,3584]{3,2,1,0} %multiply.757), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.855 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.756), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.79 = pred[3584]{0} compare(f32[3584]{0} %param_3.337, f32[3584]{0} %maximum.95), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_882 = f32[] constant(1)
  %broadcast.764 = f32[3584]{0} broadcast(f32[] %constant_882), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.79 = f32[3584]{0} select(pred[3584]{0} %compare.79, f32[3584]{0} %broadcast.764, f32[3584]{0} %broadcast.935), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.78 = pred[3584]{0} compare(f32[3584]{0} %broadcast.935, f32[3584]{0} %maximum.95), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_883 = f32[] constant(2)
  %broadcast.763 = f32[3584]{0} broadcast(f32[] %constant_883), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.78 = f32[3584]{0} select(pred[3584]{0} %compare.78, f32[3584]{0} %broadcast.763, f32[3584]{0} %broadcast.764), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.54 = f32[3584]{0} divide(f32[3584]{0} %select.79, f32[3584]{0} %select.78), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.755 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.855, f32[3584]{0} %divide.54), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_884 = f32[] constant(0.000637755089)
  %broadcast.762 = f32[3584]{0} broadcast(f32[] %constant_884), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.754 = f32[3584]{0} multiply(f32[3584]{0} %multiply.755, f32[3584]{0} %broadcast.762), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.761 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.754), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.753 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_2.531, f32[16,14,14,3584]{2,1,3,0} %broadcast.761), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.238 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.832, f32[16,14,14,3584]{2,1,3,0} %multiply.753), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.869 = f32[3584]{0} parameter(0)
  %negate.54 = f32[3584]{0} negate(f32[3584]{0} %multiply.755), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.1278 = f32[3584]{0} parameter(1)
  %multiply.752 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1278, f32[3584]{0} %broadcast.762), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.751 = f32[3584]{0} multiply(f32[3584]{0} %negate.54, f32[3584]{0} %multiply.752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.237 = f32[3584]{0} add(f32[3584]{0} %param_0.869, f32[3584]{0} %multiply.751), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_885 = f32[] constant(0.000318877544)
  %broadcast.767 = f32[3584]{0} broadcast(f32[] %constant_885), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.750 = f32[3584]{0} multiply(f32[3584]{0} %add.237, f32[3584]{0} %broadcast.767), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.760 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.750), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/broadcast_in_dim[shape=(16, 14, 14, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %add.236 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %add.238, f32[16,14,14,3584]{2,1,3,0} %broadcast.760), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %param_10.515 = f32[3584]{0} parameter(10)
  %maximum.137.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %param_10.515, f32[3584]{0} %broadcast.935), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.345.clone.1 = f32[3584]{0} add(f32[3584]{0} %maximum.137.clone.1, f32[3584]{0} %broadcast.934), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1100.clone.1 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.345.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.161.clone.1 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1100.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_12.397 = f32[3584]{0} parameter(12)
  %bitcast.1099.clone.1 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_12.397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1335.clone.1 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.161.clone.1, f32[1,1,1,3584]{3,2,1,0} %bitcast.1099.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1098.clone.1 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1335.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1536.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1098.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1334.clone.1 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_6.290, f32[16,14,14,3584]{2,1,3,0} %broadcast.1536.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_9.684 = f32[16,14,14,3584]{2,1,3,0} parameter(9)
  %param_11.472 = f32[1,1,1,3584]{3,2,1,0} parameter(11)
  %multiply.717.clone.1 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_11.472, f32[1,1,1,3584]{3,2,1,0} %bitcast.1099.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.49.clone.1 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.161.clone.1, f32[1,1,1,3584]{3,2,1,0} %bitcast.1100.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.716.clone.1 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.49.clone.1, f32[1,1,1,3584]{3,2,1,0} %broadcast.765), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.715.clone.1 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.717.clone.1, f32[1,1,1,3584]{3,2,1,0} %multiply.716.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.833.clone.1 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.715.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.71.clone.1 = pred[3584]{0} compare(f32[3584]{0} %param_10.515, f32[3584]{0} %maximum.137.clone.1), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.71.clone.1 = f32[3584]{0} select(pred[3584]{0} %compare.71.clone.1, f32[3584]{0} %broadcast.764, f32[3584]{0} %broadcast.935), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.70.clone.1 = pred[3584]{0} compare(f32[3584]{0} %broadcast.935, f32[3584]{0} %maximum.137.clone.1), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.70.clone.1 = f32[3584]{0} select(pred[3584]{0} %compare.70.clone.1, f32[3584]{0} %broadcast.763, f32[3584]{0} %broadcast.764), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.48.clone.1 = f32[3584]{0} divide(f32[3584]{0} %select.71.clone.1, f32[3584]{0} %select.70.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.714.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.833.clone.1, f32[3584]{0} %divide.48.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.713.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.714.clone.1, f32[3584]{0} %broadcast.762), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.727.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.713.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.712.clone.1 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_9.684, f32[16,14,14,3584]{2,1,3,0} %broadcast.727.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.220.clone.1 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.1334.clone.1, f32[16,14,14,3584]{2,1,3,0} %multiply.712.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_7.1529 = f32[3584]{0} parameter(7)
  %negate.48.clone.1 = f32[3584]{0} negate(f32[3584]{0} %multiply.714.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_8.1155 = f32[3584]{0} parameter(8)
  %multiply.711.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_8.1155, f32[3584]{0} %broadcast.762), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.710.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %negate.48.clone.1, f32[3584]{0} %multiply.711.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.219.clone.1 = f32[3584]{0} add(f32[3584]{0} %param_7.1529, f32[3584]{0} %multiply.710.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.709.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %add.219.clone.1, f32[3584]{0} %broadcast.767), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.726.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.709.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/broadcast_in_dim[shape=(16, 14, 14, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %add.218.clone.1 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %add.220.clone.1, f32[16,14,14,3584]{2,1,3,0} %broadcast.726.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %tuple.109 = (f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{2,1,3,0}) tuple(f32[16,14,14,3584]{2,1,3,0} %add.236, f32[16,14,14,3584]{2,1,3,0} %add.218.clone.1)
}

%fused_computation.487 (param_0.1128: f32[16,14,14,3584], param_1.1521: f32[3584], param_2.538: f32[3584], param_3.1579: f32[3584], param_4.1383: f32[3584]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1128 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_2.538 = f32[3584]{0} parameter(2)
  %constant_889 = f32[] constant(0)
  %broadcast.941 = f32[3584]{0} broadcast(f32[] %constant_889), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.97 = f32[3584]{0} maximum(f32[3584]{0} %param_2.538, f32[3584]{0} %broadcast.941), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1062 = f32[] constant(1e-05)
  %broadcast.940 = f32[3584]{0} broadcast(f32[] %constant_1062), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.289 = f32[3584]{0} add(f32[3584]{0} %maximum.97, f32[3584]{0} %broadcast.940), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1004 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.289), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.131 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1004), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1521 = f32[3584]{0} parameter(1)
  %bitcast.1003 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.1521), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.837 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.131, f32[1,1,1,3584]{3,2,1,0} %bitcast.1003), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1002 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.837), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.939 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1002), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.836 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_0.1128, f32[16,14,14,3584]{2,1,3,0} %broadcast.939), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.55 = f32[16,14,14,3584]{2,1,3,0} negate(f32[16,14,14,3584]{2,1,3,0} %multiply.836), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.72 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %negate.55), dimensions={0,3,1,2}
  %bitcast.856 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.72), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.888 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.856, f32[] %constant_889), dimensions={2}, to_apply=%region_63.4346.3
  %param_4.1383 = f32[3584]{0} parameter(4)
  %maximum.139.clone.1 = f32[3584]{0} maximum(f32[3584]{0} %param_4.1383, f32[3584]{0} %broadcast.941), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.347.clone.1 = f32[3584]{0} add(f32[3584]{0} %maximum.139.clone.1, f32[3584]{0} %broadcast.940), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1106.clone.1 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.347.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.163.clone.1 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1106.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_3.1579 = f32[3584]{0} parameter(3)
  %bitcast.1105.clone.1 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_3.1579), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1339.clone.1 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.163.clone.1, f32[1,1,1,3584]{3,2,1,0} %bitcast.1105.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1104.clone.1 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1339.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1548.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1104.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1338.clone.1 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_0.1128, f32[16,14,14,3584]{2,1,3,0} %broadcast.1548.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.49.clone.1 = f32[16,14,14,3584]{2,1,3,0} negate(f32[16,14,14,3584]{2,1,3,0} %multiply.1338.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.73 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %negate.49.clone.1), dimensions={0,3,1,2}
  %bitcast.834.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.73), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.871.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.834.clone.1, f32[] %constant_889), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.107 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.888, f32[16,3584]{1,0} %reduce.871.clone.1)
}

%fused_computation.488 (param_0.873: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.873 = f32[16,3584]{1,0} parameter(0)
  %constant_887 = f32[] constant(0)
  %reduce.889 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.873, f32[] %constant_887), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.857 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.497 (param_0.1116: f32[1792], param_1.1511: f32[1792], param_2.520: f32[1792], param_3.326: f32[16,14,14,1792], param_4.308: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.326 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.308 = f32[1792]{0} parameter(4)
  %constant_1026 = f32[] constant(0.000318877544)
  %broadcast.909 = f32[1792]{0} broadcast(f32[] %constant_1026), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.825 = f32[1792]{0} multiply(f32[1792]{0} %param_4.308, f32[1792]{0} %broadcast.909), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.908 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.825), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.71 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.326, f32[16,14,14,1792]{2,1,3,0} %broadcast.908), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.520 = f32[1792]{0} parameter(2)
  %constant_897 = f32[] constant(0)
  %broadcast.907 = f32[1792]{0} broadcast(f32[] %constant_897), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.83 = f32[1792]{0} maximum(f32[1792]{0} %param_2.520, f32[1792]{0} %broadcast.907), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1024 = f32[] constant(1e-05)
  %broadcast.906 = f32[1792]{0} broadcast(f32[] %constant_1024), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.279 = f32[1792]{0} add(f32[1792]{0} %maximum.83, f32[1792]{0} %broadcast.906), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.986 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.279), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.127 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.986), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1511 = f32[1792]{0} parameter(1)
  %bitcast.985 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1511), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.824 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.127, f32[1,1,1,1792]{3,2,1,0} %bitcast.985), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.984 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.824), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.905 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.984), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.823 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.71, f32[16,14,14,1792]{2,1,3,0} %broadcast.905), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1116 = f32[1792]{0} parameter(0)
  %broadcast.904 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1116), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.278 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.823, f32[16,14,14,1792]{2,1,3,0} %broadcast.904), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.774 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_897), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.44 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.278, f32[16,14,14,1792]{2,1,3,0} %broadcast.774), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.502 (param_0.1101: f32[16,1792], param_1.1488: f32[1792]) -> f32[1792] {
  %param_0.1101 = f32[16,1792]{1,0} parameter(0)
  %constant_901 = f32[] constant(0)
  %reduce.894 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1101, f32[] %constant_901), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_900 = f32[] constant(0.000318877544)
  %broadcast.779 = f32[1792]{0} broadcast(f32[] %constant_900), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.769 = f32[1792]{0} multiply(f32[1792]{0} %reduce.894, f32[1792]{0} %broadcast.779), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1488 = f32[1792]{0} parameter(1)
  %multiply.805 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1488, f32[1792]{0} %broadcast.779), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.768 = f32[1792]{0} multiply(f32[1792]{0} %multiply.805, f32[1792]{0} %multiply.805), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.52 = f32[1792]{0} subtract(f32[1792]{0} %multiply.769, f32[1792]{0} %multiply.768), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.507 (param_0.1098: f32[896], param_1.1486: f32[896], param_2.486: f32[896], param_3.295: f32[16,28,28,896], param_4.283: f32[896]) -> f32[16,29,29,896] {
  %param_3.295 = f32[16,28,28,896]{2,1,3,0} parameter(3)
  %param_4.283 = f32[896]{0} parameter(4)
  %constant_969 = f32[] constant(7.97193861e-05)
  %broadcast.849 = f32[896]{0} broadcast(f32[] %constant_969), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.801 = f32[896]{0} multiply(f32[896]{0} %param_4.283, f32[896]{0} %broadcast.849), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.848 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.801), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.63 = f32[16,28,28,896]{2,1,3,0} subtract(f32[16,28,28,896]{2,1,3,0} %param_3.295, f32[16,28,28,896]{2,1,3,0} %broadcast.848), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.486 = f32[896]{0} parameter(2)
  %constant_905 = f32[] constant(0)
  %broadcast.847 = f32[896]{0} broadcast(f32[] %constant_905), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.65 = f32[896]{0} maximum(f32[896]{0} %param_2.486, f32[896]{0} %broadcast.847), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_967 = f32[] constant(1e-05)
  %broadcast.846 = f32[896]{0} broadcast(f32[] %constant_967), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.261 = f32[896]{0} add(f32[896]{0} %maximum.65, f32[896]{0} %broadcast.846), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.956 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.261), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.119 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.956), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1486 = f32[896]{0} parameter(1)
  %bitcast.955 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.1486), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.800 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.119, f32[1,1,1,896]{3,2,1,0} %bitcast.955), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.954 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.800), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.845 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.954), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.799 = f32[16,28,28,896]{2,1,3,0} multiply(f32[16,28,28,896]{2,1,3,0} %subtract.63, f32[16,28,28,896]{2,1,3,0} %broadcast.845), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1098 = f32[896]{0} parameter(0)
  %broadcast.844 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1098), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.260 = f32[16,28,28,896]{2,1,3,0} add(f32[16,28,28,896]{2,1,3,0} %multiply.799, f32[16,28,28,896]{2,1,3,0} %broadcast.844), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.782 = f32[16,28,28,896]{2,1,3,0} broadcast(f32[] %constant_905), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %maximum.46 = f32[16,28,28,896]{2,1,3,0} maximum(f32[16,28,28,896]{2,1,3,0} %add.260, f32[16,28,28,896]{2,1,3,0} %broadcast.782), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %pad.6 = f32[16,29,29,896]{2,1,3,0} pad(f32[16,28,28,896]{2,1,3,0} %maximum.46, f32[] %constant_905), padding=0_0x0_1x0_1x0_0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.512 (param_0.1083: f32[16,896], param_1.1463: f32[896]) -> f32[896] {
  %param_0.1083 = f32[16,896]{1,0} parameter(0)
  %constant_909 = f32[] constant(0)
  %reduce.897 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1083, f32[] %constant_909), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_908 = f32[] constant(7.97193861e-05)
  %broadcast.787 = f32[896]{0} broadcast(f32[] %constant_908), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.775 = f32[896]{0} multiply(f32[896]{0} %reduce.897, f32[896]{0} %broadcast.787), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1463 = f32[896]{0} parameter(1)
  %multiply.781 = f32[896]{0} multiply(f32[896]{0} %param_1.1463, f32[896]{0} %broadcast.787), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.774 = f32[896]{0} multiply(f32[896]{0} %multiply.781, f32[896]{0} %multiply.781), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.54 = f32[896]{0} subtract(f32[896]{0} %multiply.775, f32[896]{0} %multiply.774), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.517 (param_0.1743: f32[224], param_1.2431: f32[224], param_2.1781: f32[224], param_3.1585: f32[16,112,112,224], param_4.1389: f32[224]) -> f32[16,113,113,224] {
  %param_3.1585 = f32[16,112,112,224]{2,1,3,0} parameter(3)
  %param_4.1389 = f32[224]{0} parameter(4)
  %constant_3031 = f32[] constant(4.98246163e-06)
  %broadcast.3772 = f32[224]{0} broadcast(f32[] %constant_3031), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2285 = f32[224]{0} multiply(f32[224]{0} %param_4.1389, f32[224]{0} %broadcast.3772), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3771 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2285), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.401 = f32[16,112,112,224]{2,1,3,0} subtract(f32[16,112,112,224]{2,1,3,0} %param_3.1585, f32[16,112,112,224]{2,1,3,0} %broadcast.3771), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1781 = f32[224]{0} parameter(2)
  %constant_3028 = f32[] constant(0)
  %broadcast.3770 = f32[224]{0} broadcast(f32[] %constant_3028), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.747 = f32[224]{0} maximum(f32[224]{0} %param_2.1781, f32[224]{0} %broadcast.3770), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3029 = f32[] constant(1e-05)
  %broadcast.3769 = f32[224]{0} broadcast(f32[] %constant_3029), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1233 = f32[224]{0} add(f32[224]{0} %maximum.747, f32[224]{0} %broadcast.3769), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2252 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1233), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.501 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2252), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2431 = f32[224]{0} parameter(1)
  %bitcast.2251 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_1.2431), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2284 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.501, f32[1,1,1,224]{3,2,1,0} %bitcast.2251), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2250 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2284), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3768 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2250), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2283 = f32[16,112,112,224]{2,1,3,0} multiply(f32[16,112,112,224]{2,1,3,0} %subtract.401, f32[16,112,112,224]{2,1,3,0} %broadcast.3768), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1743 = f32[224]{0} parameter(0)
  %broadcast.3767 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %param_0.1743), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1232 = f32[16,112,112,224]{2,1,3,0} add(f32[16,112,112,224]{2,1,3,0} %multiply.2283, f32[16,112,112,224]{2,1,3,0} %broadcast.3767), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3766 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[] %constant_3028), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %maximum.746 = f32[16,112,112,224]{2,1,3,0} maximum(f32[16,112,112,224]{2,1,3,0} %add.1232, f32[16,112,112,224]{2,1,3,0} %broadcast.3766), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %constant_3301 = f32[] constant(-inf)
  ROOT %pad.7 = f32[16,113,113,224]{2,1,3,0} pad(f32[16,112,112,224]{2,1,3,0} %maximum.746, f32[] %constant_3301), padding=0_0x0_1x0_1x0_0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/pad[padding_config=((0, 0, 0), (0, 1, 0), (0, 1, 0), (0, 0, 0))]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
}

%region_184.7164.3 (Arg_0.7165: f32[], Arg_1.7166: f32[]) -> f32[] {
  %Arg_0.7165 = f32[] parameter(0)
  %Arg_1.7166 = f32[] parameter(1)
  ROOT %maximum.7167 = f32[] maximum(f32[] %Arg_0.7165, f32[] %Arg_1.7166), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/reduce_window_max[window_dimensions=(1, 3, 3, 1) window_strides=(1, 2, 2, 1) padding=((0, 0), (0, 1), (0, 1), (0, 0)) base_dilation=(1, 1, 1, 1) window_dilation=(1, 1, 1, 1)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
}

%fused_computation.518 (param_0.1742: f32[224], param_1.2430: f32[224], param_2.1780: f32[224], param_3.1584: f32[16,112,112,224], param_4.1388: f32[224]) -> f32[16,56,56,224] {
  %param_3.1584 = f32[16,112,112,224]{2,1,3,0} parameter(3)
  %param_4.1388 = f32[224]{0} parameter(4)
  %constant_3040 = f32[] constant(4.98246163e-06)
  %broadcast.3786 = f32[224]{0} broadcast(f32[] %constant_3040), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2291 = f32[224]{0} multiply(f32[224]{0} %param_4.1388, f32[224]{0} %broadcast.3786), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3785 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %multiply.2291), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.403 = f32[16,112,112,224]{2,1,3,0} subtract(f32[16,112,112,224]{2,1,3,0} %param_3.1584, f32[16,112,112,224]{2,1,3,0} %broadcast.3785), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1780 = f32[224]{0} parameter(2)
  %constant_3037 = f32[] constant(0)
  %broadcast.3784 = f32[224]{0} broadcast(f32[] %constant_3037), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.751 = f32[224]{0} maximum(f32[224]{0} %param_2.1780, f32[224]{0} %broadcast.3784), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3038 = f32[] constant(1e-05)
  %broadcast.3783 = f32[224]{0} broadcast(f32[] %constant_3038), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1237 = f32[224]{0} add(f32[224]{0} %maximum.751, f32[224]{0} %broadcast.3783), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2258 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1237), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.503 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2258), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2430 = f32[224]{0} parameter(1)
  %bitcast.2257 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %param_1.2430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2290 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.503, f32[1,1,1,224]{3,2,1,0} %bitcast.2257), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2256 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2290), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3782 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %bitcast.2256), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2289 = f32[16,112,112,224]{2,1,3,0} multiply(f32[16,112,112,224]{2,1,3,0} %subtract.403, f32[16,112,112,224]{2,1,3,0} %broadcast.3782), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1742 = f32[224]{0} parameter(0)
  %broadcast.3781 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[224]{0} %param_0.1742), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1236 = f32[16,112,112,224]{2,1,3,0} add(f32[16,112,112,224]{2,1,3,0} %multiply.2289, f32[16,112,112,224]{2,1,3,0} %broadcast.3781), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3780 = f32[16,112,112,224]{2,1,3,0} broadcast(f32[] %constant_3037), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %maximum.750 = f32[16,112,112,224]{2,1,3,0} maximum(f32[16,112,112,224]{2,1,3,0} %add.1236, f32[16,112,112,224]{2,1,3,0} %broadcast.3780), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=124}
  %constant_3300 = f32[] constant(-inf)
  ROOT %reduce-window.0 = f32[16,56,56,224]{2,1,3,0} reduce-window(f32[16,112,112,224]{2,1,3,0} %maximum.750, f32[] %constant_3300), window={size=1x3x3x1 stride=1x2x2x1 pad=0_0x0_1x0_1x0_0}, to_apply=%region_184.7164.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/reduce_window_max[window_dimensions=(1, 3, 3, 1) window_strides=(1, 2, 2, 1) padding=((0, 0), (0, 1), (0, 1), (0, 0)) base_dilation=(1, 1, 1, 1) window_dilation=(1, 1, 1, 1)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
}

%horizontally_fused_computation (param_0_0: f32[3584], param_0_1: f32[3584], param_1_0: f32[3584], param_3.1589: f32[1792], param_4.1393: f32[1792], param_5.1366: f32[896], param_6.1219: f32[896]) -> (f32[3584], f32[3584], f32[1792], f32[896]) {
  %param_0_0 = f32[3584]{0} parameter(0)
  %param_0_1 = f32[3584]{0} parameter(1)
  %add.1364 = f32[3584]{0} add(f32[3584]{0} %param_0_0, f32[3584]{0} %param_0_1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %param_1_0 = f32[3584]{0} parameter(2)
  %add.1365 = f32[3584]{0} add(f32[3584]{0} %param_1_0, f32[3584]{0} %param_0_1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %param_3.1589 = f32[1792]{0} parameter(3)
  %param_4.1393 = f32[1792]{0} parameter(4)
  %add.1366 = f32[1792]{0} add(f32[1792]{0} %param_3.1589, f32[1792]{0} %param_4.1393), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %param_5.1366 = f32[896]{0} parameter(5)
  %param_6.1219 = f32[896]{0} parameter(6)
  %add.1367 = f32[896]{0} add(f32[896]{0} %param_5.1366, f32[896]{0} %param_6.1219), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %concatenate = f32[9856]{0} concatenate(f32[3584]{0} %add.1364, f32[3584]{0} %add.1365, f32[1792]{0} %add.1366, f32[896]{0} %add.1367), dimensions={0}
  %slice.36 = f32[3584]{0} slice(f32[9856]{0} %concatenate), slice={[0:3584]}
  %slice.37 = f32[3584]{0} slice(f32[9856]{0} %concatenate), slice={[3584:7168]}
  %slice.38 = f32[1792]{0} slice(f32[9856]{0} %concatenate), slice={[7168:8960]}
  %slice.39 = f32[896]{0} slice(f32[9856]{0} %concatenate), slice={[8960:9856]}
  ROOT %tuple.112 = (f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}) tuple(f32[3584]{0} %slice.36, f32[3584]{0} %slice.37, f32[1792]{0} %slice.38, f32[896]{0} %slice.39), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
}

%horizontally_fused_computation.1 (param_0_0.1: f32[448], param_0_1.1: f32[16,448], param_1_0.1: f32[448], param_1_1.1: f32[16,448], param_2_0.1: f32[896], param_2_1.1: f32[16,896], param_3_0.1: f32[1792], param_3_1.1: f32[16,1792], param_4_0: f32[896], param_4_1: f32[16,896], param_5_0: f32[224], param_5_1: f32[16,224], param_6_0: f32[448], param_6_1: f32[16,448], param_7_0: f32[896], param_7_1: f32[16,896], param_8_0: f32[224], param_8_1: f32[16,224], param_9_0: f32[448], param_9_1: f32[16,448], param_10_0: f32[896], param_10_1: f32[16,896], param_11_0: f32[224], param_11_1: f32[16,224], param_12_0: f32[224], param_12_1: f32[16,224], param_13_0: f32[448], param_13_1: f32[16,448], param_14_0: f32[1792], param_14_1: f32[16,1792], param_15_0: f32[896], param_15_1: f32[16,896], param_16_0: f32[1792], param_16_1: f32[16,1792], param_17_0: f32[448], param_17_1: f32[16,448], param_18_0: f32[896], param_18_1: f32[16,896], param_19_0: f32[1792], param_19_1: f32[16,1792], param_20_0: f32[448], param_20_1: f32[16,448], param_21_0: f32[896], param_21_1: f32[16,896]) -> (f32[448], f32[448], f32[896], f32[1792], f32[896], /*index=5*/f32[224], f32[448], f32[896], f32[224], f32[448], /*index=10*/f32[896], f32[224], f32[224], f32[448], f32[1792], /*index=15*/f32[896], f32[1792], f32[448], f32[896], f32[1792], /*index=20*/f32[448], f32[896]) {
  %param_0_0.1 = f32[448]{0} parameter(0)
  %param_0_1.1 = f32[16,448]{1,0} parameter(1)
  %constant_3318 = f32[] constant(0)
  %reduce.902 = f32[448]{0} reduce(f32[16,448]{1,0} %param_0_1.1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1368 = f32[448]{0} add(f32[448]{0} %param_0_0.1, f32[448]{0} %reduce.902), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %param_1_0.1 = f32[448]{0} parameter(2)
  %param_1_1.1 = f32[16,448]{1,0} parameter(3)
  %reduce.903 = f32[448]{0} reduce(f32[16,448]{1,0} %param_1_1.1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1369 = f32[448]{0} add(f32[448]{0} %param_1_0.1, f32[448]{0} %reduce.903), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %param_2_0.1 = f32[896]{0} parameter(4)
  %param_2_1.1 = f32[16,896]{1,0} parameter(5)
  %reduce.904 = f32[896]{0} reduce(f32[16,896]{1,0} %param_2_1.1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1370 = f32[896]{0} add(f32[896]{0} %param_2_0.1, f32[896]{0} %reduce.904), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %param_3_0.1 = f32[1792]{0} parameter(6)
  %param_3_1.1 = f32[16,1792]{1,0} parameter(7)
  %reduce.905 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_3_1.1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1371 = f32[1792]{0} add(f32[1792]{0} %param_3_0.1, f32[1792]{0} %reduce.905), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %param_4_0 = f32[896]{0} parameter(8)
  %param_4_1 = f32[16,896]{1,0} parameter(9)
  %reduce.906 = f32[896]{0} reduce(f32[16,896]{1,0} %param_4_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1372 = f32[896]{0} add(f32[896]{0} %param_4_0, f32[896]{0} %reduce.906), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %param_5_0 = f32[224]{0} parameter(10)
  %param_5_1 = f32[16,224]{1,0} parameter(11)
  %reduce.907 = f32[224]{0} reduce(f32[16,224]{1,0} %param_5_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1373 = f32[224]{0} add(f32[224]{0} %param_5_0, f32[224]{0} %reduce.907), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %param_6_0 = f32[448]{0} parameter(12)
  %param_6_1 = f32[16,448]{1,0} parameter(13)
  %reduce.908 = f32[448]{0} reduce(f32[16,448]{1,0} %param_6_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1374 = f32[448]{0} add(f32[448]{0} %param_6_0, f32[448]{0} %reduce.908), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %param_7_0 = f32[896]{0} parameter(14)
  %param_7_1 = f32[16,896]{1,0} parameter(15)
  %reduce.909 = f32[896]{0} reduce(f32[16,896]{1,0} %param_7_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1375 = f32[896]{0} add(f32[896]{0} %param_7_0, f32[896]{0} %reduce.909), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %param_8_0 = f32[224]{0} parameter(16)
  %param_8_1 = f32[16,224]{1,0} parameter(17)
  %reduce.910 = f32[224]{0} reduce(f32[16,224]{1,0} %param_8_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1376 = f32[224]{0} add(f32[224]{0} %param_8_0, f32[224]{0} %reduce.910), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %param_9_0 = f32[448]{0} parameter(18)
  %param_9_1 = f32[16,448]{1,0} parameter(19)
  %reduce.911 = f32[448]{0} reduce(f32[16,448]{1,0} %param_9_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1377 = f32[448]{0} add(f32[448]{0} %param_9_0, f32[448]{0} %reduce.911), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %param_10_0 = f32[896]{0} parameter(20)
  %param_10_1 = f32[16,896]{1,0} parameter(21)
  %reduce.912 = f32[896]{0} reduce(f32[16,896]{1,0} %param_10_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1378 = f32[896]{0} add(f32[896]{0} %param_10_0, f32[896]{0} %reduce.912), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %param_11_0 = f32[224]{0} parameter(22)
  %param_11_1 = f32[16,224]{1,0} parameter(23)
  %reduce.913 = f32[224]{0} reduce(f32[16,224]{1,0} %param_11_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1379 = f32[224]{0} add(f32[224]{0} %param_11_0, f32[224]{0} %reduce.913), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %param_12_0 = f32[224]{0} parameter(24)
  %param_12_1 = f32[16,224]{1,0} parameter(25)
  %reduce.914 = f32[224]{0} reduce(f32[16,224]{1,0} %param_12_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1380 = f32[224]{0} add(f32[224]{0} %param_12_0, f32[224]{0} %reduce.914), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %param_13_0 = f32[448]{0} parameter(26)
  %param_13_1 = f32[16,448]{1,0} parameter(27)
  %reduce.915 = f32[448]{0} reduce(f32[16,448]{1,0} %param_13_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1381 = f32[448]{0} add(f32[448]{0} %param_13_0, f32[448]{0} %reduce.915), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %param_14_0 = f32[1792]{0} parameter(28)
  %param_14_1 = f32[16,1792]{1,0} parameter(29)
  %reduce.916 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_14_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1382 = f32[1792]{0} add(f32[1792]{0} %param_14_0, f32[1792]{0} %reduce.916), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %param_15_0 = f32[896]{0} parameter(30)
  %param_15_1 = f32[16,896]{1,0} parameter(31)
  %reduce.917 = f32[896]{0} reduce(f32[16,896]{1,0} %param_15_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1383 = f32[896]{0} add(f32[896]{0} %param_15_0, f32[896]{0} %reduce.917), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %param_16_0 = f32[1792]{0} parameter(32)
  %param_16_1 = f32[16,1792]{1,0} parameter(33)
  %reduce.918 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_16_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1384 = f32[1792]{0} add(f32[1792]{0} %param_16_0, f32[1792]{0} %reduce.918), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %param_17_0 = f32[448]{0} parameter(34)
  %param_17_1 = f32[16,448]{1,0} parameter(35)
  %reduce.919 = f32[448]{0} reduce(f32[16,448]{1,0} %param_17_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1385 = f32[448]{0} add(f32[448]{0} %param_17_0, f32[448]{0} %reduce.919), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %param_18_0 = f32[896]{0} parameter(36)
  %param_18_1 = f32[16,896]{1,0} parameter(37)
  %reduce.920 = f32[896]{0} reduce(f32[16,896]{1,0} %param_18_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1386 = f32[896]{0} add(f32[896]{0} %param_18_0, f32[896]{0} %reduce.920), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %param_19_0 = f32[1792]{0} parameter(38)
  %param_19_1 = f32[16,1792]{1,0} parameter(39)
  %reduce.921 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_19_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1387 = f32[1792]{0} add(f32[1792]{0} %param_19_0, f32[1792]{0} %reduce.921), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %param_20_0 = f32[448]{0} parameter(40)
  %param_20_1 = f32[16,448]{1,0} parameter(41)
  %reduce.922 = f32[448]{0} reduce(f32[16,448]{1,0} %param_20_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1388 = f32[448]{0} add(f32[448]{0} %param_20_0, f32[448]{0} %reduce.922), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %param_21_0 = f32[896]{0} parameter(42)
  %param_21_1 = f32[16,896]{1,0} parameter(43)
  %reduce.923 = f32[896]{0} reduce(f32[16,896]{1,0} %param_21_1, f32[] %constant_3318), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1389 = f32[896]{0} add(f32[896]{0} %param_21_0, f32[896]{0} %reduce.923), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %concatenate.1 = f32[17472]{0} concatenate(f32[448]{0} %add.1368, f32[448]{0} %add.1369, f32[896]{0} %add.1370, f32[1792]{0} %add.1371, f32[896]{0} %add.1372, /*index=5*/f32[224]{0} %add.1373, f32[448]{0} %add.1374, f32[896]{0} %add.1375, f32[224]{0} %add.1376, f32[448]{0} %add.1377, /*index=10*/f32[896]{0} %add.1378, f32[224]{0} %add.1379, f32[224]{0} %add.1380, f32[448]{0} %add.1381, f32[1792]{0} %add.1382, /*index=15*/f32[896]{0} %add.1383, f32[1792]{0} %add.1384, f32[448]{0} %add.1385, f32[896]{0} %add.1386, f32[1792]{0} %add.1387, /*index=20*/f32[448]{0} %add.1388, f32[896]{0} %add.1389), dimensions={0}
  %slice.40 = f32[448]{0} slice(f32[17472]{0} %concatenate.1), slice={[0:448]}
  %slice.41 = f32[448]{0} slice(f32[17472]{0} %concatenate.1), slice={[448:896]}
  %slice.42 = f32[896]{0} slice(f32[17472]{0} %concatenate.1), slice={[896:1792]}
  %slice.43 = f32[1792]{0} slice(f32[17472]{0} %concatenate.1), slice={[1792:3584]}
  %slice.44 = f32[896]{0} slice(f32[17472]{0} %concatenate.1), slice={[3584:4480]}
  %slice.45 = f32[224]{0} slice(f32[17472]{0} %concatenate.1), slice={[4480:4704]}
  %slice.46 = f32[448]{0} slice(f32[17472]{0} %concatenate.1), slice={[4704:5152]}
  %slice.47 = f32[896]{0} slice(f32[17472]{0} %concatenate.1), slice={[5152:6048]}
  %slice.48 = f32[224]{0} slice(f32[17472]{0} %concatenate.1), slice={[6048:6272]}
  %slice.49 = f32[448]{0} slice(f32[17472]{0} %concatenate.1), slice={[6272:6720]}
  %slice.50 = f32[896]{0} slice(f32[17472]{0} %concatenate.1), slice={[6720:7616]}
  %slice.51 = f32[224]{0} slice(f32[17472]{0} %concatenate.1), slice={[7616:7840]}
  %slice.52 = f32[224]{0} slice(f32[17472]{0} %concatenate.1), slice={[7840:8064]}
  %slice.53 = f32[448]{0} slice(f32[17472]{0} %concatenate.1), slice={[8064:8512]}
  %slice.54 = f32[1792]{0} slice(f32[17472]{0} %concatenate.1), slice={[8512:10304]}
  %slice.55 = f32[896]{0} slice(f32[17472]{0} %concatenate.1), slice={[10304:11200]}
  %slice.56 = f32[1792]{0} slice(f32[17472]{0} %concatenate.1), slice={[11200:12992]}
  %slice.57 = f32[448]{0} slice(f32[17472]{0} %concatenate.1), slice={[12992:13440]}
  %slice.58 = f32[896]{0} slice(f32[17472]{0} %concatenate.1), slice={[13440:14336]}
  %slice.59 = f32[1792]{0} slice(f32[17472]{0} %concatenate.1), slice={[14336:16128]}
  %slice.60 = f32[448]{0} slice(f32[17472]{0} %concatenate.1), slice={[16128:16576]}
  %slice.61 = f32[896]{0} slice(f32[17472]{0} %concatenate.1), slice={[16576:17472]}
  ROOT %tuple.113 = (f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) tuple(f32[448]{0} %slice.40, f32[448]{0} %slice.41, f32[896]{0} %slice.42, f32[1792]{0} %slice.43, f32[896]{0} %slice.44, /*index=5*/f32[224]{0} %slice.45, f32[448]{0} %slice.46, f32[896]{0} %slice.47, f32[224]{0} %slice.48, f32[448]{0} %slice.49, /*index=10*/f32[896]{0} %slice.50, f32[224]{0} %slice.51, f32[224]{0} %slice.52, f32[448]{0} %slice.53, f32[1792]{0} %slice.54, /*index=15*/f32[896]{0} %slice.55, f32[1792]{0} %slice.56, f32[448]{0} %slice.57, f32[896]{0} %slice.58, f32[1792]{0} %slice.59, /*index=20*/f32[448]{0} %slice.60, f32[896]{0} %slice.61), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
}

%horizontally_fused_computation.2 (param_0_0.2: f32[448], param_0_1.2: f32[1,1,1,448], param_0_2: f32[448], param_1_0.2: f32[896], param_1_1.2: f32[1,1,1,896], param_1_2: f32[896], param_2_0.2: f32[448], param_2_1.2: f32[1,1,1,448], param_2_2: f32[448], param_3_0.2: f32[1792], param_3_1.2: f32[1,1,1,1792], param_3_2: f32[1792], param_4_0.1: f32[224], param_4_1.1: f32[1,1,1,224], param_4_2: f32[224], param_5_0.1: f32[896], param_5_1.1: f32[1,1,1,896], param_5_2: f32[896], param_6_0.1: f32[224], param_6_1.1: f32[1,1,1,224], param_6_2: f32[224], param_7_0.1: f32[448], param_7_1.1: f32[1,1,1,448], param_7_2: f32[448], param_8_0.1: f32[1792], param_8_1.1: f32[1,1,1,1792], param_8_2: f32[1792], param_9_0.1: f32[448], param_9_1.1: f32[1,1,1,448], param_9_2: f32[448], param_10_0.1: f32[896], param_10_1.1: f32[1,1,1,896], param_10_2: f32[896], param_11_0.1: f32[224], param_11_1.1: f32[1,1,1,224], param_11_2: f32[224], param_12_0.1: f32[896], param_12_1.1: f32[1,1,1,896], param_12_2: f32[896], param_13_0.1: f32[896], param_13_1.1: f32[1,1,1,896], param_13_2: f32[896], param_14_0.1: f32[1792], param_14_1.1: f32[1,1,1,1792], param_14_2: f32[1792], param_15_0.1: f32[896], param_15_1.1: f32[1,1,1,896], param_15_2: f32[896], param_16_0.1: f32[448], param_16_1.1: f32[1,1,1,448], param_16_2: f32[448], param_17_0.1: f32[448], param_17_1.1: f32[1,1,1,448], param_17_2: f32[448], param_18_0.1: f32[448], param_18_1.1: f32[1,1,1,448], param_18_2: f32[448], param_19_0.1: f32[224], param_19_1.1: f32[1,1,1,224], param_19_2: f32[224], param_20_0.1: f32[896], param_20_1.1: f32[1,1,1,896], param_20_2: f32[896], param_21_0.1: f32[896], param_21_1.1: f32[1,1,1,896], param_21_2: f32[896]) -> (f32[448], f32[896], f32[448], f32[1792], f32[224], /*index=5*/f32[896], f32[224], f32[448], f32[1792], f32[448], /*index=10*/f32[896], f32[224], f32[896], f32[896], f32[1792], /*index=15*/f32[896], f32[448], f32[448], f32[448], f32[224], /*index=20*/f32[896], f32[896]) {
  %param_0_0.2 = f32[448]{0} parameter(0)
  %param_0_2 = f32[448]{0} parameter(2)
  %constant_3340 = f32[] constant(0)
  %broadcast.4169 = f32[448]{0} broadcast(f32[] %constant_3340), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.834 = f32[448]{0} maximum(f32[448]{0} %param_0_2, f32[448]{0} %broadcast.4169), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3341 = f32[] constant(1e-05)
  %broadcast.4170 = f32[448]{0} broadcast(f32[] %constant_3341), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1390 = f32[448]{0} add(f32[448]{0} %maximum.834, f32[448]{0} %broadcast.4170), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2457 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1390), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.566 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2457), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_0_1.2 = f32[1,1,1,448]{3,2,1,0} parameter(1)
  %multiply.2466 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.566, f32[1,1,1,448]{3,2,1,0} %param_0_1.2), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2458 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2466), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1391 = f32[448]{0} add(f32[448]{0} %param_0_0.2, f32[448]{0} %bitcast.2458), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %param_1_0.2 = f32[896]{0} parameter(3)
  %param_1_2 = f32[896]{0} parameter(5)
  %broadcast.4171 = f32[896]{0} broadcast(f32[] %constant_3340), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.835 = f32[896]{0} maximum(f32[896]{0} %param_1_2, f32[896]{0} %broadcast.4171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.4172 = f32[896]{0} broadcast(f32[] %constant_3341), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1392 = f32[896]{0} add(f32[896]{0} %maximum.835, f32[896]{0} %broadcast.4172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2459 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.567 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2459), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1_1.2 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.2467 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.567, f32[1,1,1,896]{3,2,1,0} %param_1_1.2), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2460 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2467), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1393 = f32[896]{0} add(f32[896]{0} %param_1_0.2, f32[896]{0} %bitcast.2460), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %param_2_0.2 = f32[448]{0} parameter(6)
  %param_2_2 = f32[448]{0} parameter(8)
  %maximum.836 = f32[448]{0} maximum(f32[448]{0} %param_2_2, f32[448]{0} %broadcast.4169), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1394 = f32[448]{0} add(f32[448]{0} %maximum.836, f32[448]{0} %broadcast.4170), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2461 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1394), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.568 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2_1.2 = f32[1,1,1,448]{3,2,1,0} parameter(7)
  %multiply.2468 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.568, f32[1,1,1,448]{3,2,1,0} %param_2_1.2), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2462 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2468), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1395 = f32[448]{0} add(f32[448]{0} %param_2_0.2, f32[448]{0} %bitcast.2462), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %param_3_0.2 = f32[1792]{0} parameter(9)
  %param_3_2 = f32[1792]{0} parameter(11)
  %broadcast.4175 = f32[1792]{0} broadcast(f32[] %constant_3340), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.837 = f32[1792]{0} maximum(f32[1792]{0} %param_3_2, f32[1792]{0} %broadcast.4175), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.4176 = f32[1792]{0} broadcast(f32[] %constant_3341), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1396 = f32[1792]{0} add(f32[1792]{0} %maximum.837, f32[1792]{0} %broadcast.4176), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2463 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1396), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.569 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2463), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_3_1.2 = f32[1,1,1,1792]{3,2,1,0} parameter(10)
  %multiply.2469 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.569, f32[1,1,1,1792]{3,2,1,0} %param_3_1.2), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2464 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2469), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1397 = f32[1792]{0} add(f32[1792]{0} %param_3_0.2, f32[1792]{0} %bitcast.2464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %param_4_0.1 = f32[224]{0} parameter(12)
  %param_4_2 = f32[224]{0} parameter(14)
  %broadcast.4177 = f32[224]{0} broadcast(f32[] %constant_3340), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.838 = f32[224]{0} maximum(f32[224]{0} %param_4_2, f32[224]{0} %broadcast.4177), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.4178 = f32[224]{0} broadcast(f32[] %constant_3341), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1398 = f32[224]{0} add(f32[224]{0} %maximum.838, f32[224]{0} %broadcast.4178), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2465 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1398), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.570 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2465), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_4_1.1 = f32[1,1,1,224]{3,2,1,0} parameter(13)
  %multiply.2470 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.570, f32[1,1,1,224]{3,2,1,0} %param_4_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2466 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2470), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reshape[new_sizes=(224,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1399 = f32[224]{0} add(f32[224]{0} %param_4_0.1, f32[224]{0} %bitcast.2466), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %param_5_0.1 = f32[896]{0} parameter(15)
  %param_5_2 = f32[896]{0} parameter(17)
  %maximum.839 = f32[896]{0} maximum(f32[896]{0} %param_5_2, f32[896]{0} %broadcast.4171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1400 = f32[896]{0} add(f32[896]{0} %maximum.839, f32[896]{0} %broadcast.4172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2467 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1400), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.571 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2467), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(16)
  %multiply.2471 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.571, f32[1,1,1,896]{3,2,1,0} %param_5_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2468 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2471), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1401 = f32[896]{0} add(f32[896]{0} %param_5_0.1, f32[896]{0} %bitcast.2468), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %param_6_0.1 = f32[224]{0} parameter(18)
  %param_6_2 = f32[224]{0} parameter(20)
  %maximum.840 = f32[224]{0} maximum(f32[224]{0} %param_6_2, f32[224]{0} %broadcast.4177), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1402 = f32[224]{0} add(f32[224]{0} %maximum.840, f32[224]{0} %broadcast.4178), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2469 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1402), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.572 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2469), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_6_1.1 = f32[1,1,1,224]{3,2,1,0} parameter(19)
  %multiply.2472 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.572, f32[1,1,1,224]{3,2,1,0} %param_6_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2470 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2472), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reshape[new_sizes=(224,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1403 = f32[224]{0} add(f32[224]{0} %param_6_0.1, f32[224]{0} %bitcast.2470), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %param_7_0.1 = f32[448]{0} parameter(21)
  %param_7_2 = f32[448]{0} parameter(23)
  %maximum.841 = f32[448]{0} maximum(f32[448]{0} %param_7_2, f32[448]{0} %broadcast.4169), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1404 = f32[448]{0} add(f32[448]{0} %maximum.841, f32[448]{0} %broadcast.4170), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2471 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1404), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.573 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2471), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_7_1.1 = f32[1,1,1,448]{3,2,1,0} parameter(22)
  %multiply.2473 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.573, f32[1,1,1,448]{3,2,1,0} %param_7_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2472 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2473), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1405 = f32[448]{0} add(f32[448]{0} %param_7_0.1, f32[448]{0} %bitcast.2472), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %param_8_0.1 = f32[1792]{0} parameter(24)
  %param_8_2 = f32[1792]{0} parameter(26)
  %maximum.842 = f32[1792]{0} maximum(f32[1792]{0} %param_8_2, f32[1792]{0} %broadcast.4175), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1406 = f32[1792]{0} add(f32[1792]{0} %maximum.842, f32[1792]{0} %broadcast.4176), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2473 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1406), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.574 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2473), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_8_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(25)
  %multiply.2474 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.574, f32[1,1,1,1792]{3,2,1,0} %param_8_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2474 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2474), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1407 = f32[1792]{0} add(f32[1792]{0} %param_8_0.1, f32[1792]{0} %bitcast.2474), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %param_9_0.1 = f32[448]{0} parameter(27)
  %param_9_2 = f32[448]{0} parameter(29)
  %maximum.843 = f32[448]{0} maximum(f32[448]{0} %param_9_2, f32[448]{0} %broadcast.4169), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1408 = f32[448]{0} add(f32[448]{0} %maximum.843, f32[448]{0} %broadcast.4170), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2475 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1408), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.575 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2475), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_9_1.1 = f32[1,1,1,448]{3,2,1,0} parameter(28)
  %multiply.2475 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.575, f32[1,1,1,448]{3,2,1,0} %param_9_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2476 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2475), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1409 = f32[448]{0} add(f32[448]{0} %param_9_0.1, f32[448]{0} %bitcast.2476), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %param_10_0.1 = f32[896]{0} parameter(30)
  %param_10_2 = f32[896]{0} parameter(32)
  %maximum.844 = f32[896]{0} maximum(f32[896]{0} %param_10_2, f32[896]{0} %broadcast.4171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1410 = f32[896]{0} add(f32[896]{0} %maximum.844, f32[896]{0} %broadcast.4172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2477 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1410), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.576 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_10_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(31)
  %multiply.2476 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.576, f32[1,1,1,896]{3,2,1,0} %param_10_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2478 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2476), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1411 = f32[896]{0} add(f32[896]{0} %param_10_0.1, f32[896]{0} %bitcast.2478), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %param_11_0.1 = f32[224]{0} parameter(33)
  %param_11_2 = f32[224]{0} parameter(35)
  %maximum.845 = f32[224]{0} maximum(f32[224]{0} %param_11_2, f32[224]{0} %broadcast.4177), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1412 = f32[224]{0} add(f32[224]{0} %maximum.845, f32[224]{0} %broadcast.4178), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2479 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1412), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.577 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2479), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_11_1.1 = f32[1,1,1,224]{3,2,1,0} parameter(34)
  %multiply.2477 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.577, f32[1,1,1,224]{3,2,1,0} %param_11_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2480 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reshape[new_sizes=(224,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1413 = f32[224]{0} add(f32[224]{0} %param_11_0.1, f32[224]{0} %bitcast.2480), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %param_12_0.1 = f32[896]{0} parameter(36)
  %param_12_2 = f32[896]{0} parameter(38)
  %maximum.846 = f32[896]{0} maximum(f32[896]{0} %param_12_2, f32[896]{0} %broadcast.4171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1414 = f32[896]{0} add(f32[896]{0} %maximum.846, f32[896]{0} %broadcast.4172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2481 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1414), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.578 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2481), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_12_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(37)
  %multiply.2478 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.578, f32[1,1,1,896]{3,2,1,0} %param_12_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2482 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2478), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1415 = f32[896]{0} add(f32[896]{0} %param_12_0.1, f32[896]{0} %bitcast.2482), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %param_13_0.1 = f32[896]{0} parameter(39)
  %param_13_2 = f32[896]{0} parameter(41)
  %maximum.847 = f32[896]{0} maximum(f32[896]{0} %param_13_2, f32[896]{0} %broadcast.4171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1416 = f32[896]{0} add(f32[896]{0} %maximum.847, f32[896]{0} %broadcast.4172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2483 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1416), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.579 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2483), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_13_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(40)
  %multiply.2479 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.579, f32[1,1,1,896]{3,2,1,0} %param_13_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2484 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2479), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1417 = f32[896]{0} add(f32[896]{0} %param_13_0.1, f32[896]{0} %bitcast.2484), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %param_14_0.1 = f32[1792]{0} parameter(42)
  %param_14_2 = f32[1792]{0} parameter(44)
  %maximum.848 = f32[1792]{0} maximum(f32[1792]{0} %param_14_2, f32[1792]{0} %broadcast.4175), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1418 = f32[1792]{0} add(f32[1792]{0} %maximum.848, f32[1792]{0} %broadcast.4176), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2485 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1418), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.580 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2485), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_14_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(43)
  %multiply.2480 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.580, f32[1,1,1,1792]{3,2,1,0} %param_14_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2486 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2480), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1419 = f32[1792]{0} add(f32[1792]{0} %param_14_0.1, f32[1792]{0} %bitcast.2486), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %param_15_0.1 = f32[896]{0} parameter(45)
  %param_15_2 = f32[896]{0} parameter(47)
  %maximum.849 = f32[896]{0} maximum(f32[896]{0} %param_15_2, f32[896]{0} %broadcast.4171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1420 = f32[896]{0} add(f32[896]{0} %maximum.849, f32[896]{0} %broadcast.4172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2487 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1420), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.581 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2487), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_15_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(46)
  %multiply.2481 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.581, f32[1,1,1,896]{3,2,1,0} %param_15_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2488 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2481), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1421 = f32[896]{0} add(f32[896]{0} %param_15_0.1, f32[896]{0} %bitcast.2488), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %param_16_0.1 = f32[448]{0} parameter(48)
  %param_16_2 = f32[448]{0} parameter(50)
  %maximum.850 = f32[448]{0} maximum(f32[448]{0} %param_16_2, f32[448]{0} %broadcast.4169), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1422 = f32[448]{0} add(f32[448]{0} %maximum.850, f32[448]{0} %broadcast.4170), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2489 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1422), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.582 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2489), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_16_1.1 = f32[1,1,1,448]{3,2,1,0} parameter(49)
  %multiply.2482 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.582, f32[1,1,1,448]{3,2,1,0} %param_16_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2490 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2482), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1423 = f32[448]{0} add(f32[448]{0} %param_16_0.1, f32[448]{0} %bitcast.2490), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %param_17_0.1 = f32[448]{0} parameter(51)
  %param_17_2 = f32[448]{0} parameter(53)
  %maximum.851 = f32[448]{0} maximum(f32[448]{0} %param_17_2, f32[448]{0} %broadcast.4169), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1424 = f32[448]{0} add(f32[448]{0} %maximum.851, f32[448]{0} %broadcast.4170), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2491 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1424), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.583 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2491), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_17_1.1 = f32[1,1,1,448]{3,2,1,0} parameter(52)
  %multiply.2483 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.583, f32[1,1,1,448]{3,2,1,0} %param_17_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2492 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2483), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1425 = f32[448]{0} add(f32[448]{0} %param_17_0.1, f32[448]{0} %bitcast.2492), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %param_18_0.1 = f32[448]{0} parameter(54)
  %param_18_2 = f32[448]{0} parameter(56)
  %maximum.852 = f32[448]{0} maximum(f32[448]{0} %param_18_2, f32[448]{0} %broadcast.4169), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1426 = f32[448]{0} add(f32[448]{0} %maximum.852, f32[448]{0} %broadcast.4170), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2493 = f32[1,1,1,448]{3,2,1,0} bitcast(f32[448]{0} %add.1426), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.584 = f32[1,1,1,448]{3,2,1,0} rsqrt(f32[1,1,1,448]{3,2,1,0} %bitcast.2493), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_18_1.1 = f32[1,1,1,448]{3,2,1,0} parameter(55)
  %multiply.2484 = f32[1,1,1,448]{3,2,1,0} multiply(f32[1,1,1,448]{3,2,1,0} %rsqrt.584, f32[1,1,1,448]{3,2,1,0} %param_18_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2494 = f32[448]{0} bitcast(f32[1,1,1,448]{3,2,1,0} %multiply.2484), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reshape[new_sizes=(448,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1427 = f32[448]{0} add(f32[448]{0} %param_18_0.1, f32[448]{0} %bitcast.2494), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %param_19_0.1 = f32[224]{0} parameter(57)
  %param_19_2 = f32[224]{0} parameter(59)
  %maximum.853 = f32[224]{0} maximum(f32[224]{0} %param_19_2, f32[224]{0} %broadcast.4177), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1428 = f32[224]{0} add(f32[224]{0} %maximum.853, f32[224]{0} %broadcast.4178), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2495 = f32[1,1,1,224]{3,2,1,0} bitcast(f32[224]{0} %add.1428), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.585 = f32[1,1,1,224]{3,2,1,0} rsqrt(f32[1,1,1,224]{3,2,1,0} %bitcast.2495), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_19_1.1 = f32[1,1,1,224]{3,2,1,0} parameter(58)
  %multiply.2485 = f32[1,1,1,224]{3,2,1,0} multiply(f32[1,1,1,224]{3,2,1,0} %rsqrt.585, f32[1,1,1,224]{3,2,1,0} %param_19_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2496 = f32[224]{0} bitcast(f32[1,1,1,224]{3,2,1,0} %multiply.2485), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reshape[new_sizes=(224,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1429 = f32[224]{0} add(f32[224]{0} %param_19_0.1, f32[224]{0} %bitcast.2496), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %param_20_0.1 = f32[896]{0} parameter(60)
  %param_20_2 = f32[896]{0} parameter(62)
  %maximum.854 = f32[896]{0} maximum(f32[896]{0} %param_20_2, f32[896]{0} %broadcast.4171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1430 = f32[896]{0} add(f32[896]{0} %maximum.854, f32[896]{0} %broadcast.4172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2497 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.586 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2497), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_20_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(61)
  %multiply.2486 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.586, f32[1,1,1,896]{3,2,1,0} %param_20_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2498 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2486), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1431 = f32[896]{0} add(f32[896]{0} %param_20_0.1, f32[896]{0} %bitcast.2498), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %param_21_0.1 = f32[896]{0} parameter(63)
  %param_21_2 = f32[896]{0} parameter(65)
  %maximum.855 = f32[896]{0} maximum(f32[896]{0} %param_21_2, f32[896]{0} %broadcast.4171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1432 = f32[896]{0} add(f32[896]{0} %maximum.855, f32[896]{0} %broadcast.4172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2499 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1432), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.587 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_21_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(64)
  %multiply.2487 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.587, f32[1,1,1,896]{3,2,1,0} %param_21_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2500 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2487), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1433 = f32[896]{0} add(f32[896]{0} %param_21_0.1, f32[896]{0} %bitcast.2500), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %concatenate.2 = f32[16576]{0} concatenate(f32[448]{0} %add.1391, f32[896]{0} %add.1393, f32[448]{0} %add.1395, f32[1792]{0} %add.1397, f32[224]{0} %add.1399, /*index=5*/f32[896]{0} %add.1401, f32[224]{0} %add.1403, f32[448]{0} %add.1405, f32[1792]{0} %add.1407, f32[448]{0} %add.1409, /*index=10*/f32[896]{0} %add.1411, f32[224]{0} %add.1413, f32[896]{0} %add.1415, f32[896]{0} %add.1417, f32[1792]{0} %add.1419, /*index=15*/f32[896]{0} %add.1421, f32[448]{0} %add.1423, f32[448]{0} %add.1425, f32[448]{0} %add.1427, f32[224]{0} %add.1429, /*index=20*/f32[896]{0} %add.1431, f32[896]{0} %add.1433), dimensions={0}
  %slice.62 = f32[448]{0} slice(f32[16576]{0} %concatenate.2), slice={[0:448]}
  %slice.63 = f32[896]{0} slice(f32[16576]{0} %concatenate.2), slice={[448:1344]}
  %slice.64 = f32[448]{0} slice(f32[16576]{0} %concatenate.2), slice={[1344:1792]}
  %slice.65 = f32[1792]{0} slice(f32[16576]{0} %concatenate.2), slice={[1792:3584]}
  %slice.66 = f32[224]{0} slice(f32[16576]{0} %concatenate.2), slice={[3584:3808]}
  %slice.67 = f32[896]{0} slice(f32[16576]{0} %concatenate.2), slice={[3808:4704]}
  %slice.68 = f32[224]{0} slice(f32[16576]{0} %concatenate.2), slice={[4704:4928]}
  %slice.69 = f32[448]{0} slice(f32[16576]{0} %concatenate.2), slice={[4928:5376]}
  %slice.70 = f32[1792]{0} slice(f32[16576]{0} %concatenate.2), slice={[5376:7168]}
  %slice.71 = f32[448]{0} slice(f32[16576]{0} %concatenate.2), slice={[7168:7616]}
  %slice.72 = f32[896]{0} slice(f32[16576]{0} %concatenate.2), slice={[7616:8512]}
  %slice.73 = f32[224]{0} slice(f32[16576]{0} %concatenate.2), slice={[8512:8736]}
  %slice.74 = f32[896]{0} slice(f32[16576]{0} %concatenate.2), slice={[8736:9632]}
  %slice.75 = f32[896]{0} slice(f32[16576]{0} %concatenate.2), slice={[9632:10528]}
  %slice.76 = f32[1792]{0} slice(f32[16576]{0} %concatenate.2), slice={[10528:12320]}
  %slice.77 = f32[896]{0} slice(f32[16576]{0} %concatenate.2), slice={[12320:13216]}
  %slice.78 = f32[448]{0} slice(f32[16576]{0} %concatenate.2), slice={[13216:13664]}
  %slice.79 = f32[448]{0} slice(f32[16576]{0} %concatenate.2), slice={[13664:14112]}
  %slice.80 = f32[448]{0} slice(f32[16576]{0} %concatenate.2), slice={[14112:14560]}
  %slice.81 = f32[224]{0} slice(f32[16576]{0} %concatenate.2), slice={[14560:14784]}
  %slice.82 = f32[896]{0} slice(f32[16576]{0} %concatenate.2), slice={[14784:15680]}
  %slice.83 = f32[896]{0} slice(f32[16576]{0} %concatenate.2), slice={[15680:16576]}
  ROOT %tuple.114 = (f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) tuple(f32[448]{0} %slice.62, f32[896]{0} %slice.63, f32[448]{0} %slice.64, f32[1792]{0} %slice.65, f32[224]{0} %slice.66, /*index=5*/f32[896]{0} %slice.67, f32[224]{0} %slice.68, f32[448]{0} %slice.69, f32[1792]{0} %slice.70, f32[448]{0} %slice.71, /*index=10*/f32[896]{0} %slice.72, f32[224]{0} %slice.73, f32[896]{0} %slice.74, f32[896]{0} %slice.75, f32[1792]{0} %slice.76, /*index=15*/f32[896]{0} %slice.77, f32[448]{0} %slice.78, f32[448]{0} %slice.79, f32[448]{0} %slice.80, f32[224]{0} %slice.81, /*index=20*/f32[896]{0} %slice.82, f32[896]{0} %slice.83), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
}

%fused_computation.37.clone (param_0.1752: f32[16,448,3136]) -> (f32[16,448], f32[16,448]) {
  %param_0.1752 = f32[16,448,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3384 = f32[] constant(0)
  %reduce.924 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %param_0.1752, f32[] %constant_3384), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.320.clone.3 = f32[16,448,3136]{2,1,0} multiply(f32[16,448,3136]{2,1,0} %param_0.1752, f32[16,448,3136]{2,1,0} %param_0.1752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.701.clone.2 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %multiply.320.clone.3, f32[] %constant_3384), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.115 = (f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.924, f32[16,448]{1,0} %reduce.701.clone.2)
}

%fused_computation.47.clone (param_0.1754: f32[16,224,3136]) -> (f32[16,224], f32[16,224]) {
  %param_0.1754 = f32[16,224,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 224, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3385 = f32[] constant(0)
  %reduce.925 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %param_0.1754, f32[] %constant_3385), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.326.clone.3 = f32[16,224,3136]{2,1,0} multiply(f32[16,224,3136]{2,1,0} %param_0.1754, f32[16,224,3136]{2,1,0} %param_0.1754), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.704.clone.2 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %multiply.326.clone.3, f32[] %constant_3385), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.116 = (f32[16,224]{1,0}, f32[16,224]{1,0}) tuple(f32[16,224]{1,0} %reduce.925, f32[16,224]{1,0} %reduce.704.clone.2)
}

%fused_computation.57.clone (param_0.1756: f32[16,224,12544]) -> (f32[16,224], f32[16,224]) {
  %param_0.1756 = f32[16,224,12544]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/conv_init/conv_general_dilated[window_strides=(2, 2) padding=((3, 3), (3, 3)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 224, 224, 3) rhs_shape=(7, 7, 3, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3386 = f32[] constant(0)
  %reduce.926 = f32[16,224]{1,0} reduce(f32[16,224,12544]{2,1,0} %param_0.1756, f32[] %constant_3386), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.332.clone.3 = f32[16,224,12544]{2,1,0} multiply(f32[16,224,12544]{2,1,0} %param_0.1756, f32[16,224,12544]{2,1,0} %param_0.1756), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.707.clone.2 = f32[16,224]{1,0} reduce(f32[16,224,12544]{2,1,0} %multiply.332.clone.3, f32[] %constant_3386), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.117 = (f32[16,224]{1,0}, f32[16,224]{1,0}) tuple(f32[16,224]{1,0} %reduce.926, f32[16,224]{1,0} %reduce.707.clone.2)
}

%fused_computation.102.clone (param_0.1758: f32[16,896,3136], param_1.2440: f32[16,896,3136], param_2.1785: f32[896]) -> f32[16,896] {
  %param_1.2440 = f32[16,896,3136]{2,1,0} parameter(1)
  %param_2.1785 = f32[896]{0} parameter(2)
  %constant_3388 = f32[] constant(1.99298465e-05)
  %broadcast.4214 = f32[896]{0} broadcast(f32[] %constant_3388), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2489 = f32[896]{0} multiply(f32[896]{0} %param_2.1785, f32[896]{0} %broadcast.4214), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4213 = f32[16,56,56,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2489), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.74 = f32[16,896,56,56]{3,2,1,0} transpose(f32[16,56,56,896]{2,1,3,0} %broadcast.4213), dimensions={0,3,1,2}
  %bitcast.2518 = f32[16,896,3136]{2,1,0} bitcast(f32[16,896,56,56]{3,2,1,0} %transpose.74)
  %subtract.455 = f32[16,896,3136]{2,1,0} subtract(f32[16,896,3136]{2,1,0} %param_1.2440, f32[16,896,3136]{2,1,0} %bitcast.2518), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_0.1758 = f32[16,896,3136]{2,1,0} parameter(0)
  %multiply.2490 = f32[16,896,3136]{2,1,0} multiply(f32[16,896,3136]{2,1,0} %subtract.455, f32[16,896,3136]{2,1,0} %param_0.1758), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %constant_3387 = f32[] constant(0)
  ROOT %reduce.927 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %multiply.2490, f32[] %constant_3387), dimensions={2}, to_apply=%region_63.4346.3
}

%fused_computation.109.clone (param_0.1760: f32[16,896,3136]) -> (f32[16,896], f32[16,896]) {
  %param_0.1760 = f32[16,896,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2492 = f32[16,896,3136]{2,1,0} multiply(f32[16,896,3136]{2,1,0} %param_0.1760, f32[16,896,3136]{2,1,0} %param_0.1760), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3389 = f32[] constant(0)
  %reduce.928 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %multiply.2492, f32[] %constant_3389), dimensions={2}, to_apply=%region_63.4346.3
  %reduce.732.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %param_0.1760, f32[] %constant_3389), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.118 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.928, f32[16,896]{1,0} %reduce.732.clone.2)
}

%fused_computation.119.clone (param_0.1762: f32[16,448,3136]) -> (f32[16,448], f32[16,448]) {
  %param_0.1762 = f32[16,448,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3390 = f32[] constant(0)
  %reduce.929 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %param_0.1762, f32[] %constant_3390), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.403.clone.3 = f32[16,448,3136]{2,1,0} multiply(f32[16,448,3136]{2,1,0} %param_0.1762, f32[16,448,3136]{2,1,0} %param_0.1762), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.735.clone.2 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %multiply.403.clone.3, f32[] %constant_3390), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.119 = (f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.929, f32[16,448]{1,0} %reduce.735.clone.2)
}

%fused_computation.129.clone (param_0.1764: f32[16,224,3136]) -> (f32[16,224], f32[16,224]) {
  %param_0.1764 = f32[16,224,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3391 = f32[] constant(0)
  %reduce.930 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %param_0.1764, f32[] %constant_3391), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.409.clone.3 = f32[16,224,3136]{2,1,0} multiply(f32[16,224,3136]{2,1,0} %param_0.1764, f32[16,224,3136]{2,1,0} %param_0.1764), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.738.clone.2 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %multiply.409.clone.3, f32[] %constant_3391), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.120 = (f32[16,224]{1,0}, f32[16,224]{1,0}) tuple(f32[16,224]{1,0} %reduce.930, f32[16,224]{1,0} %reduce.738.clone.2)
}

%fused_computation.139.clone (param_0.1766: f32[16,896,3136]) -> (f32[16,896], f32[16,896]) {
  %param_0.1766 = f32[16,896,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3392 = f32[] constant(0)
  %reduce.931 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %param_0.1766, f32[] %constant_3392), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.416.clone.3 = f32[16,896,3136]{2,1,0} multiply(f32[16,896,3136]{2,1,0} %param_0.1766, f32[16,896,3136]{2,1,0} %param_0.1766), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.741.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %multiply.416.clone.3, f32[] %constant_3392), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.121 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.931, f32[16,896]{1,0} %reduce.741.clone.2)
}

%fused_computation.147.clone (param_0.1768: f32[16,896,3136]) -> (f32[16,896], f32[16,896]) {
  %param_0.1768 = f32[16,896,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 224, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3393 = f32[] constant(0)
  %reduce.932 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %param_0.1768, f32[] %constant_3393), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.421.clone.3 = f32[16,896,3136]{2,1,0} multiply(f32[16,896,3136]{2,1,0} %param_0.1768, f32[16,896,3136]{2,1,0} %param_0.1768), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.744.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %multiply.421.clone.3, f32[] %constant_3393), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.122 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.932, f32[16,896]{1,0} %reduce.744.clone.2)
}

%fused_computation.186.clone (param_0.1770: f32[16,896,3136]) -> (f32[16,896], f32[16,896]) {
  %param_0.1770 = f32[16,896,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3394 = f32[] constant(0)
  %reduce.933 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %param_0.1770, f32[] %constant_3394), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.463.clone.3 = f32[16,896,3136]{2,1,0} multiply(f32[16,896,3136]{2,1,0} %param_0.1770, f32[16,896,3136]{2,1,0} %param_0.1770), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.762.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,3136]{2,1,0} %multiply.463.clone.3, f32[] %constant_3394), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.123 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.933, f32[16,896]{1,0} %reduce.762.clone.2)
}

%fused_computation.196.clone (param_0.1772: f32[16,448,3136]) -> (f32[16,448], f32[16,448]) {
  %param_0.1772 = f32[16,448,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3395 = f32[] constant(0)
  %reduce.934 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %param_0.1772, f32[] %constant_3395), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.469.clone.3 = f32[16,448,3136]{2,1,0} multiply(f32[16,448,3136]{2,1,0} %param_0.1772, f32[16,448,3136]{2,1,0} %param_0.1772), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.765.clone.2 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %multiply.469.clone.3, f32[] %constant_3395), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.124 = (f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.934, f32[16,448]{1,0} %reduce.765.clone.2)
}

%fused_computation.206.clone (param_0.1774: f32[16,224,3136]) -> (f32[16,224], f32[16,224]) {
  %param_0.1774 = f32[16,224,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3396 = f32[] constant(0)
  %reduce.935 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %param_0.1774, f32[] %constant_3396), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.475.clone.3 = f32[16,224,3136]{2,1,0} multiply(f32[16,224,3136]{2,1,0} %param_0.1774, f32[16,224,3136]{2,1,0} %param_0.1774), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.768.clone.2 = f32[16,224]{1,0} reduce(f32[16,224,3136]{2,1,0} %multiply.475.clone.3, f32[] %constant_3396), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.125 = (f32[16,224]{1,0}, f32[16,224]{1,0}) tuple(f32[16,224]{1,0} %reduce.935, f32[16,224]{1,0} %reduce.768.clone.2)
}

%fused_computation.213.clone (param_0.1776: f32[16,1792,784], param_1.2442: f32[16,1792,784], param_2.1786: f32[1792], param_3.1591: f32[16,1792,784], param_4.1394: f32[1792]) -> (f32[16,1792], f32[16,1792]) {
  %param_1.2442 = f32[16,1792,784]{2,1,0} parameter(1)
  %param_2.1786 = f32[1792]{0} parameter(2)
  %constant_3398 = f32[] constant(7.97193861e-05)
  %broadcast.4216 = f32[1792]{0} broadcast(f32[] %constant_3398), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2494 = f32[1792]{0} multiply(f32[1792]{0} %param_2.1786, f32[1792]{0} %broadcast.4216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4215 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.2494), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.75 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %broadcast.4215), dimensions={0,3,1,2}
  %bitcast.2562 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.75)
  %subtract.457 = f32[16,1792,784]{2,1,0} subtract(f32[16,1792,784]{2,1,0} %param_1.2442, f32[16,1792,784]{2,1,0} %bitcast.2562), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_0.1776 = f32[16,1792,784]{2,1,0} parameter(0)
  %multiply.2495 = f32[16,1792,784]{2,1,0} multiply(f32[16,1792,784]{2,1,0} %subtract.457, f32[16,1792,784]{2,1,0} %param_0.1776), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %constant_3397 = f32[] constant(0)
  %reduce.936 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %multiply.2495, f32[] %constant_3397), dimensions={2}, to_apply=%region_63.4346.3
  %param_3.1591 = f32[16,1792,784]{2,1,0} parameter(3)
  %param_4.1394 = f32[1792]{0} parameter(4)
  %multiply.1815.clone.2 = f32[1792]{0} multiply(f32[1792]{0} %param_4.1394, f32[1792]{0} %broadcast.4216), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.544.clone.2 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1815.clone.2), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.76 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %broadcast.544.clone.2), dimensions={0,3,1,2}
  %bitcast.2556 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.76)
  %subtract.24.clone.3 = f32[16,1792,784]{2,1,0} subtract(f32[16,1792,784]{2,1,0} %param_3.1591, f32[16,1792,784]{2,1,0} %bitcast.2556), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.528.clone.3 = f32[16,1792,784]{2,1,0} multiply(f32[16,1792,784]{2,1,0} %subtract.24.clone.3, f32[16,1792,784]{2,1,0} %param_0.1776), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.789.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %multiply.528.clone.3, f32[] %constant_3397), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.126 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.936, f32[16,1792]{1,0} %reduce.789.clone.2)
}

%fused_computation.220.clone (param_0.1778: f32[16,1792,784]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1778 = f32[16,1792,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2497 = f32[16,1792,784]{2,1,0} multiply(f32[16,1792,784]{2,1,0} %param_0.1778, f32[16,1792,784]{2,1,0} %param_0.1778), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3399 = f32[] constant(0)
  %reduce.937 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %multiply.2497, f32[] %constant_3399), dimensions={2}, to_apply=%region_63.4346.3
  %reduce.774.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %param_0.1778, f32[] %constant_3399), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.127 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.937, f32[16,1792]{1,0} %reduce.774.clone.2)
}

%fused_computation.254.clone (param_0.1780: f32[16,1792,784]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1780 = f32[16,1792,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2499 = f32[16,1792,784]{2,1,0} multiply(f32[16,1792,784]{2,1,0} %param_0.1780, f32[16,1792,784]{2,1,0} %param_0.1780), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3400 = f32[] constant(0)
  %reduce.938 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %multiply.2499, f32[] %constant_3400), dimensions={2}, to_apply=%region_63.4346.3
  %reduce.791.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %param_0.1780, f32[] %constant_3400), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.128 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.938, f32[16,1792]{1,0} %reduce.791.clone.2)
}

%fused_computation.264.clone (param_0.1782: f32[16,896,784]) -> (f32[16,896], f32[16,896]) {
  %param_0.1782 = f32[16,896,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3401 = f32[] constant(0)
  %reduce.939 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %param_0.1782, f32[] %constant_3401), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.539.clone.3 = f32[16,896,784]{2,1,0} multiply(f32[16,896,784]{2,1,0} %param_0.1782, f32[16,896,784]{2,1,0} %param_0.1782), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.794.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %multiply.539.clone.3, f32[] %constant_3401), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.129 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.939, f32[16,896]{1,0} %reduce.794.clone.2)
}

%fused_computation.274.clone (param_0.1784: f32[16,448,3136]) -> (f32[16,448], f32[16,448]) {
  %param_0.1784 = f32[16,448,3136]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3402 = f32[] constant(0)
  %reduce.940 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %param_0.1784, f32[] %constant_3402), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.545.clone.3 = f32[16,448,3136]{2,1,0} multiply(f32[16,448,3136]{2,1,0} %param_0.1784, f32[16,448,3136]{2,1,0} %param_0.1784), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.797.clone.2 = f32[16,448]{1,0} reduce(f32[16,448,3136]{2,1,0} %multiply.545.clone.3, f32[] %constant_3402), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.130 = (f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.940, f32[16,448]{1,0} %reduce.797.clone.2)
}

%fused_computation.303.clone (param_0.1786: f32[16,1792,784], param_1.2444: f32[16,1792,784], param_2.1787: f32[1792]) -> f32[16,1792] {
  %param_1.2444 = f32[16,1792,784]{2,1,0} parameter(1)
  %param_2.1787 = f32[1792]{0} parameter(2)
  %constant_3404 = f32[] constant(7.97193861e-05)
  %broadcast.4218 = f32[1792]{0} broadcast(f32[] %constant_3404), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2501 = f32[1792]{0} multiply(f32[1792]{0} %param_2.1787, f32[1792]{0} %broadcast.4218), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4217 = f32[16,28,28,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.2501), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.77 = f32[16,1792,28,28]{3,2,1,0} transpose(f32[16,28,28,1792]{2,1,3,0} %broadcast.4217), dimensions={0,3,1,2}
  %bitcast.2585 = f32[16,1792,784]{2,1,0} bitcast(f32[16,1792,28,28]{3,2,1,0} %transpose.77)
  %subtract.459 = f32[16,1792,784]{2,1,0} subtract(f32[16,1792,784]{2,1,0} %param_1.2444, f32[16,1792,784]{2,1,0} %bitcast.2585), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_0.1786 = f32[16,1792,784]{2,1,0} parameter(0)
  %multiply.2502 = f32[16,1792,784]{2,1,0} multiply(f32[16,1792,784]{2,1,0} %subtract.459, f32[16,1792,784]{2,1,0} %param_0.1786), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %constant_3403 = f32[] constant(0)
  ROOT %reduce.941 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %multiply.2502, f32[] %constant_3403), dimensions={2}, to_apply=%region_63.4346.3
}

%fused_computation.310.clone (param_0.1788: f32[16,1792,784]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1788 = f32[16,1792,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2504 = f32[16,1792,784]{2,1,0} multiply(f32[16,1792,784]{2,1,0} %param_0.1788, f32[16,1792,784]{2,1,0} %param_0.1788), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3405 = f32[] constant(0)
  %reduce.942 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %multiply.2504, f32[] %constant_3405), dimensions={2}, to_apply=%region_63.4346.3
  %reduce.815.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %param_0.1788, f32[] %constant_3405), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.131 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.942, f32[16,1792]{1,0} %reduce.815.clone.2)
}

%fused_computation.320.clone (param_0.1790: f32[16,896,784]) -> (f32[16,896], f32[16,896]) {
  %param_0.1790 = f32[16,896,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3406 = f32[] constant(0)
  %reduce.943 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %param_0.1790, f32[] %constant_3406), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.592.clone.3 = f32[16,896,784]{2,1,0} multiply(f32[16,896,784]{2,1,0} %param_0.1790, f32[16,896,784]{2,1,0} %param_0.1790), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.818.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %multiply.592.clone.3, f32[] %constant_3406), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.132 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.943, f32[16,896]{1,0} %reduce.818.clone.2)
}

%fused_computation.330.clone (param_0.1792: f32[16,448,784]) -> (f32[16,448], f32[16,448]) {
  %param_0.1792 = f32[16,448,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3407 = f32[] constant(0)
  %reduce.944 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %param_0.1792, f32[] %constant_3407), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.598.clone.3 = f32[16,448,784]{2,1,0} multiply(f32[16,448,784]{2,1,0} %param_0.1792, f32[16,448,784]{2,1,0} %param_0.1792), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.821.clone.2 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %multiply.598.clone.3, f32[] %constant_3407), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.133 = (f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.944, f32[16,448]{1,0} %reduce.821.clone.2)
}

%fused_computation.370.clone (param_0.1794: f32[16,1792,784]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1794 = f32[16,1792,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3408 = f32[] constant(0)
  %reduce.945 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %param_0.1794, f32[] %constant_3408), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.640.clone.3 = f32[16,1792,784]{2,1,0} multiply(f32[16,1792,784]{2,1,0} %param_0.1794, f32[16,1792,784]{2,1,0} %param_0.1794), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.839.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %multiply.640.clone.3, f32[] %constant_3408), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.134 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.945, f32[16,1792]{1,0} %reduce.839.clone.2)
}

%fused_computation.380.clone (param_0.1796: f32[16,896,784]) -> (f32[16,896], f32[16,896]) {
  %param_0.1796 = f32[16,896,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3409 = f32[] constant(0)
  %reduce.946 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %param_0.1796, f32[] %constant_3409), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.646.clone.3 = f32[16,896,784]{2,1,0} multiply(f32[16,896,784]{2,1,0} %param_0.1796, f32[16,896,784]{2,1,0} %param_0.1796), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.842.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %multiply.646.clone.3, f32[] %constant_3409), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.135 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.946, f32[16,896]{1,0} %reduce.842.clone.2)
}

%fused_computation.390.clone (param_0.1798: f32[16,448,784]) -> (f32[16,448], f32[16,448]) {
  %param_0.1798 = f32[16,448,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3410 = f32[] constant(0)
  %reduce.947 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %param_0.1798, f32[] %constant_3410), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.652.clone.3 = f32[16,448,784]{2,1,0} multiply(f32[16,448,784]{2,1,0} %param_0.1798, f32[16,448,784]{2,1,0} %param_0.1798), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.845.clone.2 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %multiply.652.clone.3, f32[] %constant_3410), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.136 = (f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.947, f32[16,448]{1,0} %reduce.845.clone.2)
}

%fused_computation.429.clone (param_0.1800: f32[16,1792,784]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1800 = f32[16,1792,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3411 = f32[] constant(0)
  %reduce.948 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %param_0.1800, f32[] %constant_3411), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.694.clone.3 = f32[16,1792,784]{2,1,0} multiply(f32[16,1792,784]{2,1,0} %param_0.1800, f32[16,1792,784]{2,1,0} %param_0.1800), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.863.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,784]{2,1,0} %multiply.694.clone.3, f32[] %constant_3411), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.137 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.948, f32[16,1792]{1,0} %reduce.863.clone.2)
}

%fused_computation.439.clone (param_0.1802: f32[16,896,784]) -> (f32[16,896], f32[16,896]) {
  %param_0.1802 = f32[16,896,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3412 = f32[] constant(0)
  %reduce.949 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %param_0.1802, f32[] %constant_3412), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.700.clone.3 = f32[16,896,784]{2,1,0} multiply(f32[16,896,784]{2,1,0} %param_0.1802, f32[16,896,784]{2,1,0} %param_0.1802), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.866.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %multiply.700.clone.3, f32[] %constant_3412), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.138 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.949, f32[16,896]{1,0} %reduce.866.clone.2)
}

%fused_computation.449.clone (param_0.1804: f32[16,448,784]) -> (f32[16,448], f32[16,448]) {
  %param_0.1804 = f32[16,448,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3413 = f32[] constant(0)
  %reduce.950 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %param_0.1804, f32[] %constant_3413), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.706.clone.3 = f32[16,448,784]{2,1,0} multiply(f32[16,448,784]{2,1,0} %param_0.1804, f32[16,448,784]{2,1,0} %param_0.1804), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.869.clone.2 = f32[16,448]{1,0} reduce(f32[16,448,784]{2,1,0} %multiply.706.clone.3, f32[] %constant_3413), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.139 = (f32[16,448]{1,0}, f32[16,448]{1,0}) tuple(f32[16,448]{1,0} %reduce.950, f32[16,448]{1,0} %reduce.869.clone.2)
}

%fused_computation.462.clone (param_0.1806: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1806 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2506 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.1806, f32[16,3584,196]{2,1,0} %param_0.1806), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3414 = f32[] constant(0)
  %reduce.951 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.2506, f32[] %constant_3414), dimensions={2}, to_apply=%region_63.4346.3
  %reduce.875.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.1806, f32[] %constant_3414), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.140 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.951, f32[16,3584]{1,0} %reduce.875.clone.2)
}

%fused_computation.463.clone (param_0.1808: f32[3136,3584]) -> f32[3584] {
  %param_0.1808 = f32[3136,3584]{1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %constant_3415 = f32[] constant(0)
  ROOT %reduce.952 = f32[3584]{0} reduce(f32[3136,3584]{1,0} %param_0.1808, f32[] %constant_3415), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
}

%fused_computation.489.clone (param_0.1810: f32[16,3584,196], param_1.2446: f32[16,3584,196], param_2.1788: f32[3584], param_3.1593: f32[16,3584,196], param_4.1395: f32[3584]) -> (f32[16,3584], f32[16,3584]) {
  %param_1.2446 = f32[16,3584,196]{2,1,0} parameter(1)
  %param_2.1788 = f32[3584]{0} parameter(2)
  %constant_3417 = f32[] constant(0.000318877544)
  %broadcast.4220 = f32[3584]{0} broadcast(f32[] %constant_3417), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2508 = f32[3584]{0} multiply(f32[3584]{0} %param_2.1788, f32[3584]{0} %broadcast.4220), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.4219 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.2508), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.78 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %broadcast.4219), dimensions={0,3,1,2}
  %bitcast.2639 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.78)
  %subtract.461 = f32[16,3584,196]{2,1,0} subtract(f32[16,3584,196]{2,1,0} %param_1.2446, f32[16,3584,196]{2,1,0} %bitcast.2639), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_0.1810 = f32[16,3584,196]{2,1,0} parameter(0)
  %multiply.2509 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %subtract.461, f32[16,3584,196]{2,1,0} %param_0.1810), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %constant_3416 = f32[] constant(0)
  %reduce.953 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.2509, f32[] %constant_3416), dimensions={2}, to_apply=%region_63.4346.3
  %param_3.1593 = f32[16,3584,196]{2,1,0} parameter(3)
  %param_4.1395 = f32[3584]{0} parameter(4)
  %multiply.1331.clone.2 = f32[3584]{0} multiply(f32[3584]{0} %param_4.1395, f32[3584]{0} %broadcast.4220), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.734.clone.2 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1331.clone.2), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.79 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %broadcast.734.clone.2), dimensions={0,3,1,2}
  %bitcast.2633 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.79)
  %subtract.48.clone.3 = f32[16,3584,196]{2,1,0} subtract(f32[16,3584,196]{2,1,0} %param_3.1593, f32[16,3584,196]{2,1,0} %bitcast.2633), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.718.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %subtract.48.clone.3, f32[16,3584,196]{2,1,0} %param_0.1810), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.873.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.718.clone.3, f32[] %constant_3416), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.141 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.953, f32[16,3584]{1,0} %reduce.873.clone.2)
}

%fused_computation.496.clone (param_0.1812: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1812 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2511 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.1812, f32[16,3584,196]{2,1,0} %param_0.1812), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3418 = f32[] constant(0)
  %reduce.954 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.2511, f32[] %constant_3418), dimensions={2}, to_apply=%region_63.4346.3
  %reduce.892.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.1812, f32[] %constant_3418), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.142 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.954, f32[16,3584]{1,0} %reduce.892.clone.2)
}

%fused_computation.506.clone (param_0.1814: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1814 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3419 = f32[] constant(0)
  %reduce.955 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.1814, f32[] %constant_3419), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.770.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.1814, f32[16,1792,196]{2,1,0} %param_0.1814), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.895.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.770.clone.3, f32[] %constant_3419), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.143 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.955, f32[16,1792]{1,0} %reduce.895.clone.2)
}

%fused_computation.516.clone (param_0.1816: f32[16,896,784]) -> (f32[16,896], f32[16,896]) {
  %param_0.1816 = f32[16,896,784]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3420 = f32[] constant(0)
  %reduce.956 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %param_0.1816, f32[] %constant_3420), dimensions={2}, to_apply=%region_63.4346.3
  %multiply.776.clone.3 = f32[16,896,784]{2,1,0} multiply(f32[16,896,784]{2,1,0} %param_0.1816, f32[16,896,784]{2,1,0} %param_0.1816), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.898.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,784]{2,1,0} %multiply.776.clone.3, f32[] %constant_3420), dimensions={2}, to_apply=%region_63.4346.3
  ROOT %tuple.144 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.956, f32[16,896]{1,0} %reduce.898.clone.2)
}

%horizontally_fused_computation.3 (param_0_0.3: f32[1792], param_0_1.3: f32[16,1792], param_1_0.3: f32[896], param_1_1.3: f32[16,896]) -> (f32[1792], f32[1792], f32[896], f32[896]) {
  %param_0_0.3 = f32[1792]{0} parameter(0)
  %param_0_1.3 = f32[16,1792]{1,0} parameter(1)
  %constant_3421 = f32[] constant(0)
  %reduce.957 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0_1.3, f32[] %constant_3421), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1434 = f32[1792]{0} add(f32[1792]{0} %param_0_0.3, f32[1792]{0} %reduce.957), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %param_1_0.3 = f32[896]{0} parameter(2)
  %param_1_1.3 = f32[16,896]{1,0} parameter(3)
  %reduce.958 = f32[896]{0} reduce(f32[16,896]{1,0} %param_1_1.3, f32[] %constant_3421), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1435 = f32[896]{0} add(f32[896]{0} %param_1_0.3, f32[896]{0} %reduce.958), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %concatenate.3 = f32[2688]{0} concatenate(f32[1792]{0} %add.1434, f32[896]{0} %add.1435), dimensions={0}
  %slice.84 = f32[1792]{0} slice(f32[2688]{0} %concatenate.3), slice={[0:1792]}
  %concatenate.4 = f32[2688]{0} concatenate(f32[1792]{0} %reduce.957, f32[896]{0} %reduce.958), dimensions={0}
  %slice.86 = f32[1792]{0} slice(f32[2688]{0} %concatenate.4), slice={[0:1792]}
  %slice.85 = f32[896]{0} slice(f32[2688]{0} %concatenate.3), slice={[1792:2688]}
  %slice.87 = f32[896]{0} slice(f32[2688]{0} %concatenate.4), slice={[1792:2688]}
  ROOT %tuple.145 = (f32[1792]{0}, f32[1792]{0}, f32[896]{0}, f32[896]{0}) tuple(f32[1792]{0} %slice.84, f32[1792]{0} %slice.86, f32[896]{0} %slice.85, f32[896]{0} %slice.87), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
}

ENTRY %main.11352-3 (param_0: f32[1,1,1792,896], param_1: f32[896], param_2: f32[896], param_3: f32[3,3,896,1792], param_4: f32[1792], param_5: f32[1792], param_6: f32[1,1,1792,3584], param_7: f32[3584], param_8: f32[3584], param_9: f32[1,1,1792,3584], param_10: f32[3584], param_11: f32[3584], param_12: f32[1,1,1792,448], param_13: f32[448], param_14: f32[448], param_15: f32[3,3,448,896], param_16: f32[896], param_17: f32[896], param_18: f32[1,1,896,1792], param_19: f32[1792], param_20: f32[1792], param_21: f32[1,1,1792,448], param_22: f32[448], param_23: f32[448], param_24: f32[3,3,448,896], param_25: f32[896], param_26: f32[896], param_27: f32[1,1,896,1792], param_28: f32[1792], param_29: f32[1792], param_30: f32[1,1,1792,448], param_31: f32[448], param_32: f32[448], param_33: f32[3,3,448,896], param_34: f32[896], param_35: f32[896], param_36: f32[1,1,896,1792], param_37: f32[1792], param_38: f32[1792], param_39: f32[1,1,896,448], param_40: f32[448], param_41: f32[448], param_42: f32[3,3,448,896], param_43: f32[896], param_44: f32[896], param_45: f32[1,1,896,1792], param_46: f32[1792], param_47: f32[1792], param_48: f32[1,1,896,1792], param_49: f32[1792], param_50: f32[1792], param_51: f32[1,1,896,224], param_52: f32[224], param_53: f32[224], param_54: f32[3,3,224,448], param_55: f32[448], param_56: f32[448], param_57: f32[1,1,448,896], param_58: f32[896], param_59: f32[896], param_60: f32[1,1,448,896], param_61: f32[896], param_62: f32[896], param_63: f32[1,1,224,896], param_64: f32[896], param_65: f32[896], param_66: f32[1,1,896,224], param_67: f32[224], param_68: f32[224], param_69: f32[3,3,224,448], param_70: f32[448], param_71: f32[448], param_72: f32[1,1,448,896], param_73: f32[896], param_74: f32[896], param_75: f32[7,7,3,224], param_76: f32[224], param_77: f32[224], param_78: f32[1,1,224,224], param_79: f32[224], param_80: f32[224], param_81: f32[3,3,224,448], param_82: f32[448], param_83: f32[448], param_84: f32[16,14,14,3584], param_85: f32[16,28,28,1792], param_86: f32[1,1,1792,896], param_87: f32[896], param_88: f32[896], param_89: f32[3,3,896,1792], param_90: f32[1792], param_91: f32[1792], param_92: f32[1,1,1792,3584], param_93: f32[3584], param_94: f32[1,1,1792,3584], param_95: f32[3584], param_96: f32[16,28,28,1792], param_97: f32[1,1,1792,448], param_98: f32[448], param_99: f32[448], param_100: f32[3,3,448,896], param_101: f32[896], param_102: f32[896], param_103: f32[1,1,896,1792], param_104: f32[1792], param_105: f32[1792], param_106: f32[16,28,28,1792], param_107: f32[1,1,1792,448], param_108: f32[448], param_109: f32[448], param_110: f32[3,3,448,896], param_111: f32[896], param_112: f32[896], param_113: f32[1,1,896,1792], param_114: f32[1792], param_115: f32[1792], param_116: f32[16,28,28,1792], param_117: f32[1,1,1792,448], param_118: f32[448], param_119: f32[448], param_120: f32[3,3,448,896], param_121: f32[896], param_122: f32[896], param_123: f32[1,1,896,1792], param_124: f32[1792], param_125: f32[16,56,56,896], param_126: f32[1,1,896,448], param_127: f32[448], param_128: f32[448], param_129: f32[3,3,448,896], param_130: f32[896], param_131: f32[896], param_132: f32[1,1,896,1792], param_133: f32[1792], param_134: f32[1,1,896,1792], param_135: f32[1792], param_136: f32[16,56,56,896], param_137: f32[1,1,896,224], param_138: f32[224], param_139: f32[224], param_140: f32[3,3,224,448], param_141: f32[448], param_142: f32[448], param_143: f32[1,1,448,896], param_144: f32[896], param_145: f32[896], param_146: f32[16,56,56,448], param_147: f32[1,1,448,896], param_148: f32[896], param_149: f32[896], param_150: f32[16,56,56,224], param_151: f32[1,1,224,896], param_152: f32[896], param_153: f32[896], param_154: f32[1,1,896,224], param_155: f32[224], param_156: f32[224], param_157: f32[3,3,224,448], param_158: f32[448], param_159: f32[448], param_160: f32[1,1,448,896], param_161: f32[896], param_162: s32[16,224,224,3], param_163: f32[7,7,3,224], param_164: f32[224], param_165: f32[224], param_166: f32[1,1,224,224], param_167: f32[224], param_168: f32[224], param_169: f32[3,3,224,448], param_170: f32[448], param_171: f32[448]) -> (f32[1,1,1792,896], f32[896], f32[896], f32[3,3,896,1792], f32[1792], /*index=5*/f32[1792], f32[1,1,1792,3584], f32[3584], f32[3584], f32[1,1,1792,3584], /*index=10*/f32[3584], f32[3584], f32[1,1,1792,448], f32[448], f32[448], /*index=15*/f32[3,3,448,896], f32[896], f32[896], f32[1,1,896,1792], f32[1792], /*index=20*/f32[1792], f32[1,1,1792,448], f32[448], f32[448], f32[3,3,448,896], /*index=25*/f32[896], f32[896], f32[1,1,896,1792], f32[1792], f32[1792], /*index=30*/f32[1,1,1792,448], f32[448], f32[448], f32[3,3,448,896], f32[896], /*index=35*/f32[896], f32[1,1,896,1792], f32[1792], f32[1792], f32[1,1,896,448], /*index=40*/f32[448], f32[448], f32[3,3,448,896], f32[896], f32[896], /*index=45*/f32[1,1,896,1792], f32[1792], f32[1792], f32[1,1,896,1792], f32[1792], /*index=50*/f32[1792], f32[1,1,896,224], f32[224], f32[224], f32[3,3,224,448], /*index=55*/f32[448], f32[448], f32[1,1,448,896], f32[896], f32[896], /*index=60*/f32[1,1,448,896], f32[896], f32[896], f32[1,1,224,896], f32[896], /*index=65*/f32[896], f32[1,1,896,224], f32[224], f32[224], f32[3,3,224,448], /*index=70*/f32[448], f32[448], f32[1,1,448,896], f32[896], f32[896], /*index=75*/f32[7,7,3,224], f32[224], f32[224], f32[1,1,224,224], f32[224], /*index=80*/f32[224], f32[3,3,224,448], f32[448], f32[448]) {
  %param_85 = f32[16,28,28,1792]{3,2,1,0} parameter(85), metadata={op_name="3$start"}
  %param_86 = f32[1,1,1792,896]{3,2,1,0} parameter(86), metadata={op_name="3$start"}
  %param_87 = f32[896]{0} parameter(87), metadata={op_name="3$start"}
  %param_88 = f32[896]{0} parameter(88), metadata={op_name="3$start"}
  %param_89 = f32[3,3,896,1792]{3,2,1,0} parameter(89), metadata={op_name="3$start"}
  %param_90 = f32[1792]{0} parameter(90), metadata={op_name="3$start"}
  %param_91 = f32[1792]{0} parameter(91), metadata={op_name="3$start"}
  %param_92 = f32[1,1,1792,3584]{3,2,1,0} parameter(92), metadata={op_name="3$start"}
  %param_93 = f32[3584]{0} parameter(93), metadata={op_name="3$start"}
  %param_94 = f32[1,1,1792,3584]{3,2,1,0} parameter(94), metadata={op_name="3$start"}
  %param_95 = f32[3584]{0} parameter(95), metadata={op_name="3$start"}
  %param_84 = f32[16,14,14,3584]{3,2,1,0} parameter(84), metadata={op_name="3$start"}
  %tuple.45 = (f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) tuple(f32[16,28,28,1792]{3,2,1,0} %param_85, f32[1,1,1792,896]{3,2,1,0} %param_86, f32[896]{0} %param_87, f32[896]{0} %param_88, f32[3,3,896,1792]{3,2,1,0} %param_89, /*index=5*/f32[1792]{0} %param_90, f32[1792]{0} %param_91, f32[1,1,1792,3584]{3,2,1,0} %param_92, f32[3584]{0} %param_93, f32[1,1,1792,3584]{3,2,1,0} %param_94, /*index=10*/f32[3584]{0} %param_95, f32[16,14,14,3584]{3,2,1,0} %param_84), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2653 = (f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) bitcast((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %tuple.45)
  %get-tuple-element.596 = f32[16,28,28,1792]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.8 = f32[16,28,28,1792]{2,1,3,0} copy(f32[16,28,28,1792]{3,2,1,0} %get-tuple-element.596), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.595 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.4 = f32[16,14,14,3584]{2,1,3,0} copy(f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.595), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.606 = f32[3584]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_7 = f32[3584]{0} parameter(7), metadata={op_name="3$start"}
  %bitcast.2637 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %copy.4)
  %get-tuple-element.604 = f32[1792]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.603 = f32[1792]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.601 = f32[896]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.600 = f32[896]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.599 = f32[1,1,1792,896]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.1 = f32[1,1,1792,896]{1,0,2,3} copy(f32[1,1,1792,896]{3,2,1,0} %get-tuple-element.599), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.1 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %copy.8, f32[1,1,1792,896]{1,0,2,3} %copy.1), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.2 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.1), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2652 = f32[16,896,784]{2,1,0} bitcast(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.2)
  %fusion.516 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,784]{2,1,0} %bitcast.2652), kind=kInput, calls=%fused_computation.516.clone
  %get-tuple-element.334 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.516), index=1
  %get-tuple-element.333 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.516), index=0
  %constant_708 = f32[] constant(0)
  %reduce.256 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.333, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.512 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.334, f32[896]{0} %reduce.256), kind=kLoop, calls=%fused_computation.512, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.507 = f32[16,29,29,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.601, f32[896]{0} %get-tuple-element.600, f32[896]{0} %fusion.512, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.2, f32[896]{0} %reduce.256), kind=kLoop, calls=%fused_computation.507, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.602 = f32[3,3,896,1792]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.2 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %get-tuple-element.602), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.2 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,29,29,896]{2,1,3,0} %fusion.507, f32[3,3,896,1792]{1,0,2,3} %copy.2), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.3 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.2), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2648 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.3)
  %fusion.506 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.2648), kind=kInput, calls=%fused_computation.506.clone
  %get-tuple-element.332 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.506), index=1
  %get-tuple-element.331 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.506), index=0
  %reduce.258 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.331, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.502 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.332, f32[1792]{0} %reduce.258), kind=kLoop, calls=%fused_computation.502, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.497 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.604, f32[1792]{0} %get-tuple-element.603, f32[1792]{0} %fusion.502, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.3, f32[1792]{0} %reduce.258), kind=kLoop, calls=%fused_computation.497, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.605 = f32[1,1,1792,3584]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.3 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.605), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.3 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.497, f32[1,1,1792,3584]{1,0,2,3} %copy.3), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.4 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.3), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2640 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.4)
  %bitcast.2644 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.4)
  %fusion.496 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.2644), kind=kInput, calls=%fused_computation.496.clone
  %get-tuple-element.324 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.496), index=1
  %reduce.261 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.324, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.597 = f32[1,1,1792,3584]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.13 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.597), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %copy.8, f32[1,1,1792,3584]{1,0,2,3} %copy.13), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2634 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element)
  %bitcast.2626 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element)
  %fusion.462 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.2626), kind=kInput, calls=%fused_computation.462.clone
  %get-tuple-element.314 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.462), index=1
  %reduce.253 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.314, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.489 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.2637, f32[16,3584,196]{2,1,0} %bitcast.2640, f32[3584]{0} %reduce.261, f32[16,3584,196]{2,1,0} %bitcast.2634, f32[3584]{0} %reduce.253), kind=kInput, calls=%fused_computation.489.clone
  %get-tuple-element.327 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.489), index=0
  %fusion.488 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.327), kind=kLoop, calls=%fused_computation.488, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.323 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.496), index=0
  %fusion.464 = (f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_7, f32[1,1,1,3584]{3,2,1,0} %fusion.488, f32[3584]{0} %reduce.261, f32[16,3584]{1,0} %get-tuple-element.323), kind=kLoop, calls=%fused_computation.464, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %get-tuple-element.322 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}) %fusion.464), index=1
  %get-tuple-element.598 = f32[3584]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) %bitcast.2653), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_10 = f32[3584]{0} parameter(10), metadata={op_name="3$start"}
  %get-tuple-element.328 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.489), index=1
  %fusion.454 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.328), kind=kLoop, calls=%fused_computation.454, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.313 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.462), index=0
  %fusion.450 = (f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_10, f32[1,1,1,3584]{3,2,1,0} %fusion.454, f32[3584]{0} %reduce.253, f32[16,3584]{1,0} %get-tuple-element.313), kind=kLoop, calls=%fused_computation.450, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %get-tuple-element.312 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}) %fusion.450), index=1
  %fusion.487 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %copy.4, f32[3584]{0} %get-tuple-element.606, f32[3584]{0} %get-tuple-element.322, f32[3584]{0} %get-tuple-element.598, f32[3584]{0} %get-tuple-element.312), kind=kInput, calls=%fused_computation.487
  %get-tuple-element.325 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.487), index=0
  %reduce.263 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.325, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.326 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.487), index=1
  %reduce.255 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.326, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.486 = (f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{2,1,3,0}) fusion(f32[3584]{0} %reduce.263, f32[3584]{0} %reduce.261, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.4, f32[3584]{0} %get-tuple-element.322, f32[1,1,1,3584]{3,2,1,0} %fusion.488, /*index=5*/f32[3584]{0} %get-tuple-element.606, f32[16,14,14,3584]{2,1,3,0} %copy.4, f32[3584]{0} %reduce.255, f32[3584]{0} %reduce.253, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element, /*index=10*/f32[3584]{0} %get-tuple-element.312, f32[1,1,1,3584]{3,2,1,0} %fusion.454, f32[3584]{0} %get-tuple-element.598), kind=kLoop, calls=%fused_computation.486, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.329 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{2,1,3,0}) %fusion.486), index=0
  %bitcast.292 = f32[1,1,1792,3584]{1,0,3,2} bitcast(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.605), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.4 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.329, f32[1,1,1792,3584]{1,0,3,2} %bitcast.292), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.6 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.4), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.467 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.6, f32[1792]{0} %get-tuple-element.604, f32[1792]{0} %get-tuple-element.603, f32[1792]{0} %fusion.502, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.3, /*index=5*/f32[1792]{0} %reduce.258), kind=kInput, calls=%fused_computation.467
  %get-tuple-element.319 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.467), index=1
  %reduce.265 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.319, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.320 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.467), index=2
  %fusion.482 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.320), kind=kLoop, calls=%fused_computation.482, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.480 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.265, f32[1792]{0} %reduce.258, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.3, f32[1792]{0} %fusion.502, f32[1,1,1,1792]{3,2,1,0} %fusion.482, /*index=5*/f32[1792]{0} %get-tuple-element.603, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.6, f32[1792]{0} %get-tuple-element.604), kind=kLoop, calls=%fused_computation.480, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.10 = (f32[16,29,29,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.480, f32[3,3,896,1792]{1,0,2,3} %copy.2), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.91 = f32[16,29,29,896]{2,1,3,0} get-tuple-element((f32[16,29,29,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.10), index=0
  %fusion.471 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,29,29,896]{2,1,3,0} %get-tuple-element.91, f32[896]{0} %get-tuple-element.601, f32[896]{0} %get-tuple-element.600, f32[896]{0} %fusion.512, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.2, /*index=5*/f32[896]{0} %reduce.256), kind=kInput, calls=%fused_computation.471
  %get-tuple-element.316 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.471), index=1
  %reduce.267 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.316, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.317 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.471), index=2
  %fusion.476 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.317), kind=kLoop, calls=%fused_computation.476, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.474 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %reduce.267, f32[896]{0} %reduce.256, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.2, f32[896]{0} %fusion.512, f32[1,1,1,896]{3,2,1,0} %fusion.476, /*index=5*/f32[896]{0} %get-tuple-element.600, f32[16,29,29,896]{2,1,3,0} %get-tuple-element.91, f32[896]{0} %get-tuple-element.601), kind=kLoop, calls=%fused_computation.474, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-filter.3 = (f32[1,1,1792,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %copy.8, f32[16,28,28,896]{2,1,3,0} %fusion.474), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.9 = f32[1,1,1792,896]{1,0,2,3} get-tuple-element((f32[1,1,1792,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.3), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_0 = f32[1,1,1792,896]{3,2,1,0} parameter(0), metadata={op_name="3$start"}
  %fusion.473 = f32[1,1,1792,896]{3,2,1,0} fusion(f32[1,1,1792,896]{1,0,2,3} %get-tuple-element.9, f32[1,1,1792,896]{3,2,1,0} %param_0), kind=kLoop, calls=%fused_computation.473, metadata={op_name="tuple.85"}
  %param_31 = f32[448]{0} parameter(31), metadata={op_name="3$start"}
  %param_116 = f32[16,28,28,1792]{3,2,1,0} parameter(116), metadata={op_name="3$start"}
  %param_117 = f32[1,1,1792,448]{3,2,1,0} parameter(117), metadata={op_name="3$start"}
  %param_118 = f32[448]{0} parameter(118), metadata={op_name="3$start"}
  %param_119 = f32[448]{0} parameter(119), metadata={op_name="3$start"}
  %param_120 = f32[3,3,448,896]{3,2,1,0} parameter(120), metadata={op_name="3$start"}
  %param_121 = f32[896]{0} parameter(121), metadata={op_name="3$start"}
  %param_122 = f32[896]{0} parameter(122), metadata={op_name="3$start"}
  %param_123 = f32[1,1,896,1792]{3,2,1,0} parameter(123), metadata={op_name="3$start"}
  %param_124 = f32[1792]{0} parameter(124), metadata={op_name="3$start"}
  %param_106 = f32[16,28,28,1792]{3,2,1,0} parameter(106), metadata={op_name="3$start"}
  %param_107 = f32[1,1,1792,448]{3,2,1,0} parameter(107), metadata={op_name="3$start"}
  %param_108 = f32[448]{0} parameter(108), metadata={op_name="3$start"}
  %param_109 = f32[448]{0} parameter(109), metadata={op_name="3$start"}
  %param_110 = f32[3,3,448,896]{3,2,1,0} parameter(110), metadata={op_name="3$start"}
  %param_111 = f32[896]{0} parameter(111), metadata={op_name="3$start"}
  %param_112 = f32[896]{0} parameter(112), metadata={op_name="3$start"}
  %param_113 = f32[1,1,896,1792]{3,2,1,0} parameter(113), metadata={op_name="3$start"}
  %param_114 = f32[1792]{0} parameter(114), metadata={op_name="3$start"}
  %param_115 = f32[1792]{0} parameter(115), metadata={op_name="3$start"}
  %param_96 = f32[16,28,28,1792]{3,2,1,0} parameter(96), metadata={op_name="3$start"}
  %param_97 = f32[1,1,1792,448]{3,2,1,0} parameter(97), metadata={op_name="3$start"}
  %param_98 = f32[448]{0} parameter(98), metadata={op_name="3$start"}
  %param_99 = f32[448]{0} parameter(99), metadata={op_name="3$start"}
  %param_100 = f32[3,3,448,896]{3,2,1,0} parameter(100), metadata={op_name="3$start"}
  %param_101 = f32[896]{0} parameter(101), metadata={op_name="3$start"}
  %param_102 = f32[896]{0} parameter(102), metadata={op_name="3$start"}
  %param_103 = f32[1,1,896,1792]{3,2,1,0} parameter(103), metadata={op_name="3$start"}
  %param_104 = f32[1792]{0} parameter(104), metadata={op_name="3$start"}
  %param_105 = f32[1792]{0} parameter(105), metadata={op_name="3$start"}
  %bitcast.316 = f32[1,1,1792,896]{1,0,3,2} bitcast(f32[1,1,1792,896]{3,2,1,0} %get-tuple-element.599), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %broadcast.1115 = f32[1792]{0} broadcast(f32[] %constant_708), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %get-tuple-element.330 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, f32[16,14,14,3584]{2,1,3,0}) %fusion.486), index=1
  %cudnn-conv-bw-input.1 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.330, f32[1,1,1792,3584]{1,0,2,3} %copy.13), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.11 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.1), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %cudnn-conv-bias-activation.2 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.474, f32[1,1,1792,896]{1,0,3,2} %bitcast.316, f32[1792]{0} %broadcast.1115, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.11), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 1792, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.83 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.2), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.47 = (f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) tuple(f32[16,28,28,1792]{3,2,1,0} %param_96, f32[1,1,1792,448]{3,2,1,0} %param_97, f32[448]{0} %param_98, f32[448]{0} %param_99, f32[3,3,448,896]{3,2,1,0} %param_100, /*index=5*/f32[896]{0} %param_101, f32[896]{0} %param_102, f32[1,1,896,1792]{3,2,1,0} %param_103, f32[1792]{0} %param_104, f32[1792]{0} %param_105, /*index=10*/f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.83), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2654 = (f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) bitcast((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %tuple.47)
  %get-tuple-element.630 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.620 = f32[16,28,28,1792]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.27 = f32[16,28,28,1792]{2,1,3,0} copy(f32[16,28,28,1792]{3,2,1,0} %get-tuple-element.620), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.629 = f32[1792]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.626 = f32[896]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.625 = f32[896]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.623 = f32[448]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.622 = f32[448]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.621 = f32[1,1,1792,448]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.21 = f32[1,1,1792,448]{1,0,2,3} copy(f32[1,1,1792,448]{3,2,1,0} %get-tuple-element.621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.6 = (f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %copy.27, f32[1,1,1792,448]{1,0,2,3} %copy.21), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.12 = f32[16,28,28,448]{2,1,3,0} get-tuple-element((f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.6), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2622 = f32[16,448,784]{2,1,0} bitcast(f32[16,28,28,448]{2,1,3,0} %get-tuple-element.12)
  %fusion.449 = (f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,448,784]{2,1,0} %bitcast.2622), kind=kInput, calls=%fused_computation.449.clone
  %get-tuple-element.310 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.449), index=1
  %get-tuple-element.309 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.449), index=0
  %reduce.272 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.309, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.445 = f32[448]{0} fusion(f32[16,448]{1,0} %get-tuple-element.310, f32[448]{0} %reduce.272), kind=kLoop, calls=%fused_computation.445, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.440 = f32[16,28,28,448]{2,1,3,0} fusion(f32[448]{0} %get-tuple-element.623, f32[448]{0} %get-tuple-element.622, f32[448]{0} %fusion.445, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.12, f32[448]{0} %reduce.272), kind=kLoop, calls=%fused_computation.440, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.624 = f32[3,3,448,896]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.22 = f32[3,3,448,896]{1,0,2,3} copy(f32[3,3,448,896]{3,2,1,0} %get-tuple-element.624), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.7 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.440, f32[3,3,448,896]{1,0,2,3} %copy.22), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.13 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.7), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2618 = f32[16,896,784]{2,1,0} bitcast(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.13)
  %fusion.439 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,784]{2,1,0} %bitcast.2618), kind=kInput, calls=%fused_computation.439.clone
  %get-tuple-element.308 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.439), index=1
  %get-tuple-element.307 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.439), index=0
  %reduce.274 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.307, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.435 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.308, f32[896]{0} %reduce.274), kind=kLoop, calls=%fused_computation.435, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.430 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.626, f32[896]{0} %get-tuple-element.625, f32[896]{0} %fusion.435, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.13, f32[896]{0} %reduce.274), kind=kLoop, calls=%fused_computation.430, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.627 = f32[1,1,896,1792]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.23 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.627), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.8 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.430, f32[1,1,896,1792]{1,0,2,3} %copy.23), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.14 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2614 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.14)
  %fusion.429 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,784]{2,1,0} %bitcast.2614), kind=kInput, calls=%fused_computation.429.clone
  %get-tuple-element.305 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.429), index=0
  %reduce.276 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.305, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.628 = f32[1792]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2654), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.306 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.429), index=1
  %fusion.425 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.306, f32[1792]{0} %reduce.276), kind=kLoop, calls=%fused_computation.425, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.421 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.630, f32[16,28,28,1792]{2,1,3,0} %copy.27, f32[1792]{0} %get-tuple-element.629, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.14, f32[1792]{0} %reduce.276, /*index=5*/f32[1792]{0} %get-tuple-element.628, f32[1792]{0} %fusion.425), kind=kLoop, calls=%fused_computation.421, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.417 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,28,28,1792]{2,1,3,0} %fusion.421, f32[1792]{0} %get-tuple-element.628, f32[1792]{0} %fusion.425, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.14, f32[1792]{0} %reduce.276), kind=kInput, calls=%fused_computation.417
  %get-tuple-element.302 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.417), index=0
  %reduce.279 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.302, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.303 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.417), index=1
  %fusion.418 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.303), kind=kLoop, calls=%fused_computation.418, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.416 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.279, f32[1792]{0} %reduce.276, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.14, f32[1792]{0} %fusion.425, f32[1,1,1,1792]{3,2,1,0} %fusion.418, /*index=5*/f32[1792]{0} %get-tuple-element.628, f32[16,28,28,1792]{2,1,3,0} %fusion.421), kind=kLoop, calls=%fused_computation.416, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.336 = f32[1,1,896,1792]{1,0,3,2} bitcast(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.627), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.9 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %fusion.416, f32[1,1,896,1792]{1,0,3,2} %bitcast.336), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.16 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.9), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.397 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.16, f32[896]{0} %get-tuple-element.626, f32[896]{0} %get-tuple-element.625, f32[896]{0} %fusion.435, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.13, /*index=5*/f32[896]{0} %reduce.274), kind=kInput, calls=%fused_computation.397
  %get-tuple-element.300 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.397), index=1
  %reduce.281 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.300, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.301 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.397), index=2
  %fusion.412 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.301), kind=kLoop, calls=%fused_computation.412, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.410 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %reduce.281, f32[896]{0} %reduce.274, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.13, f32[896]{0} %fusion.435, f32[1,1,1,896]{3,2,1,0} %fusion.412, /*index=5*/f32[896]{0} %get-tuple-element.625, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.16, f32[896]{0} %get-tuple-element.626), kind=kLoop, calls=%fused_computation.410, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.2 = (f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.410, f32[3,3,448,896]{1,0,2,3} %copy.22), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.18 = f32[16,28,28,448]{2,1,3,0} get-tuple-element((f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.2), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.401 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,28,28,448]{2,1,3,0} %get-tuple-element.18, f32[448]{0} %get-tuple-element.623, f32[448]{0} %get-tuple-element.622, f32[448]{0} %fusion.445, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.12, /*index=5*/f32[448]{0} %reduce.272), kind=kInput, calls=%fused_computation.401
  %get-tuple-element.297 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.401), index=1
  %reduce.283 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.297, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.298 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.401), index=2
  %fusion.406 = f32[1,1,1,448]{3,2,1,0} fusion(f32[16,448]{1,0} %get-tuple-element.298), kind=kLoop, calls=%fused_computation.406, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.404 = f32[16,28,28,448]{2,1,3,0} fusion(f32[448]{0} %reduce.283, f32[448]{0} %reduce.272, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.12, f32[448]{0} %fusion.445, f32[1,1,1,448]{3,2,1,0} %fusion.406, /*index=5*/f32[448]{0} %get-tuple-element.622, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.18, f32[448]{0} %get-tuple-element.623), kind=kLoop, calls=%fused_computation.404, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.351 = f32[1,1,1792,448]{1,0,3,2} bitcast(f32[1,1,1792,448]{3,2,1,0} %get-tuple-element.621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.5 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.404, f32[1,1,1792,448]{1,0,3,2} %bitcast.351, f32[1792]{0} %broadcast.1115, f32[16,28,28,1792]{2,1,3,0} %fusion.421), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.84 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.5), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.49 = (f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) tuple(f32[16,28,28,1792]{3,2,1,0} %param_106, f32[1,1,1792,448]{3,2,1,0} %param_107, f32[448]{0} %param_108, f32[448]{0} %param_109, f32[3,3,448,896]{3,2,1,0} %param_110, /*index=5*/f32[896]{0} %param_111, f32[896]{0} %param_112, f32[1,1,896,1792]{3,2,1,0} %param_113, f32[1792]{0} %param_114, f32[1792]{0} %param_115, /*index=10*/f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.84), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2655 = (f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) bitcast((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %tuple.49)
  %get-tuple-element.651 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.641 = f32[16,28,28,1792]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.32 = f32[16,28,28,1792]{2,1,3,0} copy(f32[16,28,28,1792]{3,2,1,0} %get-tuple-element.641), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.391 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[16,28,28,1792]{2,1,3,0} %copy.32), kind=kLoop, calls=%fused_computation.391, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.650 = f32[1792]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.647 = f32[896]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.646 = f32[896]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.644 = f32[448]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.643 = f32[448]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.642 = f32[1,1,1792,448]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.33 = f32[1,1,1792,448]{1,0,2,3} copy(f32[1,1,1792,448]{3,2,1,0} %get-tuple-element.642), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.11 = (f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %fusion.391, f32[1,1,1792,448]{1,0,2,3} %copy.33), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.21 = f32[16,28,28,448]{2,1,3,0} get-tuple-element((f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.11), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2610 = f32[16,448,784]{2,1,0} bitcast(f32[16,28,28,448]{2,1,3,0} %get-tuple-element.21)
  %fusion.390 = (f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,448,784]{2,1,0} %bitcast.2610), kind=kInput, calls=%fused_computation.390.clone
  %get-tuple-element.295 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.390), index=1
  %get-tuple-element.294 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.390), index=0
  %reduce.287 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.294, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.386 = f32[448]{0} fusion(f32[16,448]{1,0} %get-tuple-element.295, f32[448]{0} %reduce.287), kind=kLoop, calls=%fused_computation.386, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.381 = f32[16,28,28,448]{2,1,3,0} fusion(f32[448]{0} %get-tuple-element.644, f32[448]{0} %get-tuple-element.643, f32[448]{0} %fusion.386, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.21, f32[448]{0} %reduce.287), kind=kLoop, calls=%fused_computation.381, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.645 = f32[3,3,448,896]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.34 = f32[3,3,448,896]{1,0,2,3} copy(f32[3,3,448,896]{3,2,1,0} %get-tuple-element.645), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.12 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.381, f32[3,3,448,896]{1,0,2,3} %copy.34), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.22 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.12), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2606 = f32[16,896,784]{2,1,0} bitcast(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.22)
  %fusion.380 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,784]{2,1,0} %bitcast.2606), kind=kInput, calls=%fused_computation.380.clone
  %get-tuple-element.293 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.380), index=1
  %get-tuple-element.292 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.380), index=0
  %reduce.289 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.292, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.376 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.293, f32[896]{0} %reduce.289), kind=kLoop, calls=%fused_computation.376, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.371 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.647, f32[896]{0} %get-tuple-element.646, f32[896]{0} %fusion.376, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.22, f32[896]{0} %reduce.289), kind=kLoop, calls=%fused_computation.371, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.648 = f32[1,1,896,1792]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.35 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.648), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.13 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.371, f32[1,1,896,1792]{1,0,2,3} %copy.35), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.23 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.13), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2602 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.23)
  %fusion.370 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,784]{2,1,0} %bitcast.2602), kind=kInput, calls=%fused_computation.370.clone
  %get-tuple-element.290 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.370), index=0
  %reduce.291 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.290, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.649 = f32[1792]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=10*/f32[16,28,28,1792]{2,1,3,0}) %bitcast.2655), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.291 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.370), index=1
  %fusion.366 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.291, f32[1792]{0} %reduce.291), kind=kLoop, calls=%fused_computation.366, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.362 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.651, f32[16,28,28,1792]{2,1,3,0} %fusion.391, f32[1792]{0} %get-tuple-element.650, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.23, f32[1792]{0} %reduce.291, /*index=5*/f32[1792]{0} %get-tuple-element.649, f32[1792]{0} %fusion.366), kind=kLoop, calls=%fused_computation.362, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.358 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,28,28,1792]{2,1,3,0} %fusion.362, f32[1792]{0} %get-tuple-element.649, f32[1792]{0} %fusion.366, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.23, f32[1792]{0} %reduce.291), kind=kInput, calls=%fused_computation.358
  %get-tuple-element.287 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.358), index=0
  %reduce.294 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.287, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.288 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.358), index=1
  %fusion.359 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.288), kind=kLoop, calls=%fused_computation.359, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.357 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.294, f32[1792]{0} %reduce.291, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.23, f32[1792]{0} %fusion.366, f32[1,1,1,1792]{3,2,1,0} %fusion.359, /*index=5*/f32[1792]{0} %get-tuple-element.649, f32[16,28,28,1792]{2,1,3,0} %fusion.362), kind=kLoop, calls=%fused_computation.357, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.371 = f32[1,1,896,1792]{1,0,3,2} bitcast(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.648), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.14 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %fusion.357, f32[1,1,896,1792]{1,0,3,2} %bitcast.371), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.25 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.14), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.338 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.25, f32[896]{0} %get-tuple-element.647, f32[896]{0} %get-tuple-element.646, f32[896]{0} %fusion.376, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.22, /*index=5*/f32[896]{0} %reduce.289), kind=kInput, calls=%fused_computation.338
  %get-tuple-element.285 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.338), index=1
  %reduce.296 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.285, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.286 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.338), index=2
  %fusion.353 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.286), kind=kLoop, calls=%fused_computation.353, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.351 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %reduce.296, f32[896]{0} %reduce.289, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.22, f32[896]{0} %fusion.376, f32[1,1,1,896]{3,2,1,0} %fusion.353, /*index=5*/f32[896]{0} %get-tuple-element.646, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.25, f32[896]{0} %get-tuple-element.647), kind=kLoop, calls=%fused_computation.351, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.3 = (f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.351, f32[3,3,448,896]{1,0,2,3} %copy.34), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.27 = f32[16,28,28,448]{2,1,3,0} get-tuple-element((f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.3), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.342 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,28,28,448]{2,1,3,0} %get-tuple-element.27, f32[448]{0} %get-tuple-element.644, f32[448]{0} %get-tuple-element.643, f32[448]{0} %fusion.386, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.21, /*index=5*/f32[448]{0} %reduce.287), kind=kInput, calls=%fused_computation.342
  %get-tuple-element.282 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.342), index=1
  %reduce.298 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.282, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.283 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.342), index=2
  %fusion.347 = f32[1,1,1,448]{3,2,1,0} fusion(f32[16,448]{1,0} %get-tuple-element.283), kind=kLoop, calls=%fused_computation.347, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.345 = f32[16,28,28,448]{2,1,3,0} fusion(f32[448]{0} %reduce.298, f32[448]{0} %reduce.287, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.21, f32[448]{0} %fusion.386, f32[1,1,1,448]{3,2,1,0} %fusion.347, /*index=5*/f32[448]{0} %get-tuple-element.643, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.27, f32[448]{0} %get-tuple-element.644), kind=kLoop, calls=%fused_computation.345, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.386 = f32[1,1,1792,448]{1,0,3,2} bitcast(f32[1,1,1792,448]{3,2,1,0} %get-tuple-element.642), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.8 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.345, f32[1,1,1792,448]{1,0,3,2} %bitcast.386, f32[1792]{0} %broadcast.1115, f32[16,28,28,1792]{2,1,3,0} %fusion.362), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.85 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.332 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.85, f32[16,28,28,1792]{2,1,3,0} %copy.32), kind=kLoop, calls=%fused_computation.332, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %tuple.51 = (f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) tuple(f32[16,28,28,1792]{3,2,1,0} %param_116, f32[1,1,1792,448]{3,2,1,0} %param_117, f32[448]{0} %param_118, f32[448]{0} %param_119, f32[3,3,448,896]{3,2,1,0} %param_120, /*index=5*/f32[896]{0} %param_121, f32[896]{0} %param_122, f32[1,1,896,1792]{3,2,1,0} %param_123, f32[1792]{0} %param_124, f32[16,28,28,1792]{2,1,3,0} %fusion.332), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2656 = (f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) bitcast((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %tuple.51)
  %get-tuple-element.663 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.671 = f32[1792]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_37 = f32[1792]{0} parameter(37), metadata={op_name="3$start"}
  %bitcast.2583 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.663)
  %get-tuple-element.669 = f32[896]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.668 = f32[896]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.666 = f32[448]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.665 = f32[448]{0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.662 = f32[16,28,28,1792]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.43 = f32[16,28,28,1792]{2,1,3,0} copy(f32[16,28,28,1792]{3,2,1,0} %get-tuple-element.662), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.331 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[16,28,28,1792]{2,1,3,0} %copy.43), kind=kLoop, calls=%fused_computation.331, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.664 = f32[1,1,1792,448]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.44 = f32[1,1,1792,448]{1,0,2,3} copy(f32[1,1,1792,448]{3,2,1,0} %get-tuple-element.664), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.16 = (f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %fusion.331, f32[1,1,1792,448]{1,0,2,3} %copy.44), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.30 = f32[16,28,28,448]{2,1,3,0} get-tuple-element((f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.16), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2598 = f32[16,448,784]{2,1,0} bitcast(f32[16,28,28,448]{2,1,3,0} %get-tuple-element.30)
  %fusion.330 = (f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,448,784]{2,1,0} %bitcast.2598), kind=kInput, calls=%fused_computation.330.clone
  %get-tuple-element.280 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.330), index=1
  %get-tuple-element.279 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.330), index=0
  %reduce.302 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.279, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.326 = f32[448]{0} fusion(f32[16,448]{1,0} %get-tuple-element.280, f32[448]{0} %reduce.302), kind=kLoop, calls=%fused_computation.326, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.321 = f32[16,28,28,448]{2,1,3,0} fusion(f32[448]{0} %get-tuple-element.666, f32[448]{0} %get-tuple-element.665, f32[448]{0} %fusion.326, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.30, f32[448]{0} %reduce.302), kind=kLoop, calls=%fused_computation.321, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.667 = f32[3,3,448,896]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.45 = f32[3,3,448,896]{1,0,2,3} copy(f32[3,3,448,896]{3,2,1,0} %get-tuple-element.667), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.17 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.321, f32[3,3,448,896]{1,0,2,3} %copy.45), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.31 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.17), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2594 = f32[16,896,784]{2,1,0} bitcast(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.31)
  %fusion.320 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,784]{2,1,0} %bitcast.2594), kind=kInput, calls=%fused_computation.320.clone
  %get-tuple-element.278 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.320), index=1
  %get-tuple-element.277 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.320), index=0
  %reduce.304 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.277, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.316 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.278, f32[896]{0} %reduce.304), kind=kLoop, calls=%fused_computation.316, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.311 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.669, f32[896]{0} %get-tuple-element.668, f32[896]{0} %fusion.316, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.31, f32[896]{0} %reduce.304), kind=kLoop, calls=%fused_computation.311, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.670 = f32[1,1,896,1792]{3,2,1,0} get-tuple-element((f32[16,28,28,1792]{3,2,1,0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2656), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.46 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.670), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.18 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.311, f32[1,1,896,1792]{1,0,2,3} %copy.46), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.32 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.18), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2586 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.32)
  %bitcast.2590 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.32)
  %fusion.310 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,784]{2,1,0} %bitcast.2590), kind=kInput, calls=%fused_computation.310.clone
  %get-tuple-element.274 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.310), index=1
  %reduce.307 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.274, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.303 = f32[16,1792]{1,0} fusion(f32[16,1792,784]{2,1,0} %bitcast.2583, f32[16,1792,784]{2,1,0} %bitcast.2586, f32[1792]{0} %reduce.307), kind=kInput, calls=%fused_computation.303.clone
  %fusion.302 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %fusion.303), kind=kLoop, calls=%fused_computation.302, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.273 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.310), index=0
  %fusion.278 = (f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_37, f32[1,1,1,1792]{3,2,1,0} %fusion.302, f32[1792]{0} %reduce.307, f32[16,1792]{1,0} %get-tuple-element.273), kind=kLoop, calls=%fused_computation.278, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %get-tuple-element.272 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}) %fusion.278), index=1
  %fusion.301 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.663, f32[1792]{0} %get-tuple-element.671, f32[1792]{0} %get-tuple-element.272), kind=kInput, calls=%fused_computation.301
  %get-tuple-element.275 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.301), index=0
  %reduce.309 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.275, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.300 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.309, f32[1792]{0} %reduce.307, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.32, f32[1792]{0} %get-tuple-element.272, f32[1,1,1,1792]{3,2,1,0} %fusion.302, /*index=5*/f32[1792]{0} %get-tuple-element.671, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.663), kind=kLoop, calls=%fused_computation.300, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.406 = f32[1,1,896,1792]{1,0,3,2} bitcast(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.670), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.19 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %fusion.300, f32[1,1,896,1792]{1,0,3,2} %bitcast.406), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.34 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.19), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.281 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.34, f32[896]{0} %get-tuple-element.669, f32[896]{0} %get-tuple-element.668, f32[896]{0} %fusion.316, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.31, /*index=5*/f32[896]{0} %reduce.304), kind=kInput, calls=%fused_computation.281
  %get-tuple-element.269 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.281), index=1
  %reduce.311 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.269, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.270 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.281), index=2
  %fusion.296 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.270), kind=kLoop, calls=%fused_computation.296, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.294 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %reduce.311, f32[896]{0} %reduce.304, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.31, f32[896]{0} %fusion.316, f32[1,1,1,896]{3,2,1,0} %fusion.296, /*index=5*/f32[896]{0} %get-tuple-element.668, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.34, f32[896]{0} %get-tuple-element.669), kind=kLoop, calls=%fused_computation.294, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.4 = (f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.294, f32[3,3,448,896]{1,0,2,3} %copy.45), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.36 = f32[16,28,28,448]{2,1,3,0} get-tuple-element((f32[16,28,28,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.4), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.285 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,28,28,448]{2,1,3,0} %get-tuple-element.36, f32[448]{0} %get-tuple-element.666, f32[448]{0} %get-tuple-element.665, f32[448]{0} %fusion.326, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.30, /*index=5*/f32[448]{0} %reduce.302), kind=kInput, calls=%fused_computation.285
  %get-tuple-element.267 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.285), index=2
  %fusion.290 = f32[1,1,1,448]{3,2,1,0} fusion(f32[16,448]{1,0} %get-tuple-element.267), kind=kLoop, calls=%fused_computation.290, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_43 = f32[896]{0} parameter(43), metadata={op_name="3$start"}
  %param_125 = f32[16,56,56,896]{3,2,1,0} parameter(125), metadata={op_name="3$start"}
  %param_126 = f32[1,1,896,448]{3,2,1,0} parameter(126), metadata={op_name="3$start"}
  %param_127 = f32[448]{0} parameter(127), metadata={op_name="3$start"}
  %param_128 = f32[448]{0} parameter(128), metadata={op_name="3$start"}
  %param_129 = f32[3,3,448,896]{3,2,1,0} parameter(129), metadata={op_name="3$start"}
  %param_130 = f32[896]{0} parameter(130), metadata={op_name="3$start"}
  %param_131 = f32[896]{0} parameter(131), metadata={op_name="3$start"}
  %param_132 = f32[1,1,896,1792]{3,2,1,0} parameter(132), metadata={op_name="3$start"}
  %param_133 = f32[1792]{0} parameter(133), metadata={op_name="3$start"}
  %param_134 = f32[1,1,896,1792]{3,2,1,0} parameter(134), metadata={op_name="3$start"}
  %param_135 = f32[1792]{0} parameter(135), metadata={op_name="3$start"}
  %get-tuple-element.266 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.285), index=1
  %reduce.313 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.266, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.288 = f32[16,28,28,448]{2,1,3,0} fusion(f32[448]{0} %reduce.313, f32[448]{0} %reduce.302, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.30, f32[448]{0} %fusion.326, f32[1,1,1,448]{3,2,1,0} %fusion.290, /*index=5*/f32[448]{0} %get-tuple-element.665, f32[16,28,28,448]{2,1,3,0} %get-tuple-element.36, f32[448]{0} %get-tuple-element.666), kind=kLoop, calls=%fused_computation.288, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.421 = f32[1,1,1792,448]{1,0,3,2} bitcast(f32[1,1,1792,448]{3,2,1,0} %get-tuple-element.664), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.11 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.288, f32[1,1,1792,448]{1,0,3,2} %bitcast.421, f32[1792]{0} %broadcast.1115, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.663), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(1, 1, 1792, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.86 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.11), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.275 = f32[16,28,28,1792]{2,1,3,0} fusion(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.86, f32[16,28,28,1792]{2,1,3,0} %copy.43), kind=kLoop, calls=%fused_computation.275, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %tuple.53 = (f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) tuple(f32[16,56,56,896]{3,2,1,0} %param_125, f32[1,1,896,448]{3,2,1,0} %param_126, f32[448]{0} %param_127, f32[448]{0} %param_128, f32[3,3,448,896]{3,2,1,0} %param_129, /*index=5*/f32[896]{0} %param_130, f32[896]{0} %param_131, f32[1,1,896,1792]{3,2,1,0} %param_132, f32[1792]{0} %param_133, f32[1,1,896,1792]{3,2,1,0} %param_134, /*index=10*/f32[1792]{0} %param_135, f32[16,28,28,1792]{2,1,3,0} %fusion.275), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2657 = (f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) bitcast((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %tuple.53)
  %get-tuple-element.682 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.685 = f32[1792]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_49 = f32[1792]{0} parameter(49), metadata={op_name="3$start"}
  %bitcast.2560 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.682)
  %get-tuple-element.683 = f32[16,56,56,896]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.60 = f32[16,56,56,896]{2,1,3,0} copy(f32[16,56,56,896]{3,2,1,0} %get-tuple-element.683), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.684 = f32[1,1,896,1792]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.65 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.684), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.21 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %copy.60, f32[1,1,896,1792]{1,0,2,3} %copy.65), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.39 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.21), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2563 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.39)
  %bitcast.2567 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.39)
  %fusion.220 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,784]{2,1,0} %bitcast.2567), kind=kInput, calls=%fused_computation.220.clone
  %get-tuple-element.241 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.220), index=1
  %reduce.318 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.241, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.691 = f32[896]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.690 = f32[896]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.688 = f32[448]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.687 = f32[448]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.686 = f32[1,1,896,448]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.55 = f32[1,1,896,448]{1,0,2,3} copy(f32[1,1,896,448]{3,2,1,0} %get-tuple-element.686), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.22 = (f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %copy.60, f32[1,1,896,448]{1,0,2,3} %copy.55), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.41 = f32[16,56,56,448]{2,1,3,0} get-tuple-element((f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.22), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2579 = f32[16,448,3136]{2,1,0} bitcast(f32[16,56,56,448]{2,1,3,0} %get-tuple-element.41)
  %fusion.274 = (f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,448,3136]{2,1,0} %bitcast.2579), kind=kInput, calls=%fused_computation.274.clone
  %get-tuple-element.264 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.274), index=1
  %get-tuple-element.263 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.274), index=0
  %reduce.321 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.263, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.270 = f32[448]{0} fusion(f32[16,448]{1,0} %get-tuple-element.264, f32[448]{0} %reduce.321), kind=kLoop, calls=%fused_computation.270, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.265 = f32[16,57,57,448]{2,1,3,0} fusion(f32[448]{0} %get-tuple-element.688, f32[448]{0} %get-tuple-element.687, f32[448]{0} %fusion.270, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.41, f32[448]{0} %reduce.321), kind=kLoop, calls=%fused_computation.265, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.689 = f32[3,3,448,896]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.56 = f32[3,3,448,896]{1,0,2,3} copy(f32[3,3,448,896]{3,2,1,0} %get-tuple-element.689), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.23 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,57,57,448]{2,1,3,0} %fusion.265, f32[3,3,448,896]{1,0,2,3} %copy.56), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.42 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.23), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2575 = f32[16,896,784]{2,1,0} bitcast(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.42)
  %fusion.264 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,784]{2,1,0} %bitcast.2575), kind=kInput, calls=%fused_computation.264.clone
  %get-tuple-element.262 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.264), index=1
  %get-tuple-element.261 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.264), index=0
  %reduce.323 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.261, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.260 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.262, f32[896]{0} %reduce.323), kind=kLoop, calls=%fused_computation.260, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.255 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.691, f32[896]{0} %get-tuple-element.690, f32[896]{0} %fusion.260, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.42, f32[896]{0} %reduce.323), kind=kLoop, calls=%fused_computation.255, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.692 = f32[1,1,896,1792]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.57 = f32[1,1,896,1792]{1,0,2,3} copy(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.692), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.24 = (f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.255, f32[1,1,896,1792]{1,0,2,3} %copy.57), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.43 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.24), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2557 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.43)
  %bitcast.2571 = f32[16,1792,784]{2,1,0} bitcast(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.43)
  %fusion.254 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,784]{2,1,0} %bitcast.2571), kind=kInput, calls=%fused_computation.254.clone
  %get-tuple-element.253 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.254), index=1
  %reduce.326 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.253, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.213 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,784]{2,1,0} %bitcast.2560, f32[16,1792,784]{2,1,0} %bitcast.2563, f32[1792]{0} %reduce.318, f32[16,1792,784]{2,1,0} %bitcast.2557, f32[1792]{0} %reduce.326), kind=kInput, calls=%fused_computation.213.clone
  %get-tuple-element.257 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.213), index=0
  %fusion.212 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.257), kind=kLoop, calls=%fused_computation.212, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.240 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.220), index=0
  %fusion.208 = (f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_49, f32[1,1,1,1792]{3,2,1,0} %fusion.212, f32[1792]{0} %reduce.318, f32[16,1792]{1,0} %get-tuple-element.240), kind=kLoop, calls=%fused_computation.208, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %get-tuple-element.239 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}) %fusion.208), index=1
  %get-tuple-element.693 = f32[1792]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=5*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, /*index=10*/f32[1792]{0}, f32[16,28,28,1792]{2,1,3,0}) %bitcast.2657), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_46 = f32[1792]{0} parameter(46), metadata={op_name="3$start"}
  %get-tuple-element.258 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.213), index=1
  %fusion.246 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.258), kind=kLoop, calls=%fused_computation.246, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.252 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.254), index=0
  %fusion.222 = (f32[1792]{0}, f32[1792]{0}) fusion(f32[1792]{0} %param_46, f32[1,1,1,1792]{3,2,1,0} %fusion.246, f32[1792]{0} %reduce.326, f32[16,1792]{1,0} %get-tuple-element.252), kind=kLoop, calls=%fused_computation.222, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %get-tuple-element.251 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}) %fusion.222), index=1
  %fusion.211 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.682, f32[1792]{0} %get-tuple-element.685, f32[1792]{0} %get-tuple-element.239, f32[1792]{0} %get-tuple-element.693, f32[1792]{0} %get-tuple-element.251), kind=kInput, calls=%fused_computation.211
  %get-tuple-element.255 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.211), index=1
  %reduce.328 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.255, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.254 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.211), index=0
  %reduce.320 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.254, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.244 = (f32[16,28,28,1792]{2,1,3,0}, f32[16,28,28,1792]{2,1,3,0}) fusion(f32[1792]{0} %reduce.328, f32[1792]{0} %reduce.326, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.43, f32[1792]{0} %get-tuple-element.251, f32[1,1,1,1792]{3,2,1,0} %fusion.246, /*index=5*/f32[1792]{0} %get-tuple-element.693, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.682, f32[1792]{0} %reduce.320, f32[1792]{0} %reduce.318, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.39, /*index=10*/f32[1792]{0} %get-tuple-element.239, f32[1,1,1,1792]{3,2,1,0} %fusion.212, f32[1792]{0} %get-tuple-element.685), kind=kLoop, calls=%fused_computation.244, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.259 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, f32[16,28,28,1792]{2,1,3,0}) %fusion.244), index=0
  %bitcast.441 = f32[1,1,896,1792]{1,0,3,2} bitcast(f32[1,1,896,1792]{3,2,1,0} %get-tuple-element.692), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.25 = (f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.259, f32[1,1,896,1792]{1,0,3,2} %bitcast.441), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.45 = f32[16,28,28,896]{2,1,3,0} get-tuple-element((f32[16,28,28,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.25), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.225 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,28,28,896]{2,1,3,0} %get-tuple-element.45, f32[896]{0} %get-tuple-element.691, f32[896]{0} %get-tuple-element.690, f32[896]{0} %fusion.260, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.42, /*index=5*/f32[896]{0} %reduce.323), kind=kInput, calls=%fused_computation.225
  %get-tuple-element.249 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.225), index=2
  %fusion.240 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.249), kind=kLoop, calls=%fused_computation.240, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_82 = f32[448]{0} parameter(82), metadata={op_name="3$start"}
  %param_163 = f32[7,7,3,224]{3,2,1,0} parameter(163), metadata={op_name="3$start"}
  %param_164 = f32[224]{0} parameter(164), metadata={op_name="3$start"}
  %param_165 = f32[224]{0} parameter(165), metadata={op_name="3$start"}
  %param_166 = f32[1,1,224,224]{3,2,1,0} parameter(166), metadata={op_name="3$start"}
  %param_167 = f32[224]{0} parameter(167), metadata={op_name="3$start"}
  %param_168 = f32[224]{0} parameter(168), metadata={op_name="3$start"}
  %param_169 = f32[3,3,224,448]{3,2,1,0} parameter(169), metadata={op_name="3$start"}
  %param_170 = f32[448]{0} parameter(170), metadata={op_name="3$start"}
  %param_171 = f32[448]{0} parameter(171), metadata={op_name="3$start"}
  %param_162 = s32[16,224,224,3]{3,2,1,0} parameter(162), metadata={op_name="3$start"}
  %param_146 = f32[16,56,56,448]{3,2,1,0} parameter(146), metadata={op_name="3$start"}
  %param_147 = f32[1,1,448,896]{3,2,1,0} parameter(147), metadata={op_name="3$start"}
  %param_148 = f32[896]{0} parameter(148), metadata={op_name="3$start"}
  %param_149 = f32[896]{0} parameter(149), metadata={op_name="3$start"}
  %param_150 = f32[16,56,56,224]{3,2,1,0} parameter(150), metadata={op_name="3$start"}
  %param_151 = f32[1,1,224,896]{3,2,1,0} parameter(151), metadata={op_name="3$start"}
  %param_152 = f32[896]{0} parameter(152), metadata={op_name="3$start"}
  %param_153 = f32[896]{0} parameter(153), metadata={op_name="3$start"}
  %param_154 = f32[1,1,896,224]{3,2,1,0} parameter(154), metadata={op_name="3$start"}
  %param_155 = f32[224]{0} parameter(155), metadata={op_name="3$start"}
  %param_156 = f32[224]{0} parameter(156), metadata={op_name="3$start"}
  %param_157 = f32[3,3,224,448]{3,2,1,0} parameter(157), metadata={op_name="3$start"}
  %param_158 = f32[448]{0} parameter(158), metadata={op_name="3$start"}
  %param_159 = f32[448]{0} parameter(159), metadata={op_name="3$start"}
  %param_160 = f32[1,1,448,896]{3,2,1,0} parameter(160), metadata={op_name="3$start"}
  %param_161 = f32[896]{0} parameter(161), metadata={op_name="3$start"}
  %param_136 = f32[16,56,56,896]{3,2,1,0} parameter(136), metadata={op_name="3$start"}
  %param_137 = f32[1,1,896,224]{3,2,1,0} parameter(137), metadata={op_name="3$start"}
  %param_138 = f32[224]{0} parameter(138), metadata={op_name="3$start"}
  %param_139 = f32[224]{0} parameter(139), metadata={op_name="3$start"}
  %param_140 = f32[3,3,224,448]{3,2,1,0} parameter(140), metadata={op_name="3$start"}
  %param_141 = f32[448]{0} parameter(141), metadata={op_name="3$start"}
  %param_142 = f32[448]{0} parameter(142), metadata={op_name="3$start"}
  %param_143 = f32[1,1,448,896]{3,2,1,0} parameter(143), metadata={op_name="3$start"}
  %param_144 = f32[896]{0} parameter(144), metadata={op_name="3$start"}
  %param_145 = f32[896]{0} parameter(145), metadata={op_name="3$start"}
  %get-tuple-element.248 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.225), index=1
  %reduce.330 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.248, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.238 = f32[16,28,28,896]{2,1,3,0} fusion(f32[896]{0} %reduce.330, f32[896]{0} %reduce.323, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.42, f32[896]{0} %fusion.260, f32[1,1,1,896]{3,2,1,0} %fusion.240, /*index=5*/f32[896]{0} %get-tuple-element.690, f32[16,28,28,896]{2,1,3,0} %get-tuple-element.45, f32[896]{0} %get-tuple-element.691), kind=kLoop, calls=%fused_computation.238, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.11 = (f32[16,57,57,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.238, f32[3,3,448,896]{1,0,2,3} %copy.56), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(3, 3, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.93 = f32[16,57,57,448]{2,1,3,0} get-tuple-element((f32[16,57,57,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.11), index=0
  %fusion.229 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,57,57,448]{2,1,3,0} %get-tuple-element.93, f32[448]{0} %get-tuple-element.688, f32[448]{0} %get-tuple-element.687, f32[448]{0} %fusion.270, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.41, /*index=5*/f32[448]{0} %reduce.321), kind=kInput, calls=%fused_computation.229
  %get-tuple-element.245 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.229), index=1
  %reduce.332 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.245, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.246 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.229), index=2
  %fusion.234 = f32[1,1,1,448]{3,2,1,0} fusion(f32[16,448]{1,0} %get-tuple-element.246), kind=kLoop, calls=%fused_computation.234, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.232 = f32[16,56,56,448]{2,1,3,0} fusion(f32[448]{0} %reduce.332, f32[448]{0} %reduce.321, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.41, f32[448]{0} %fusion.270, f32[1,1,1,448]{3,2,1,0} %fusion.234, /*index=5*/f32[448]{0} %get-tuple-element.687, f32[16,57,57,448]{2,1,3,0} %get-tuple-element.93, f32[448]{0} %get-tuple-element.688), kind=kLoop, calls=%fused_computation.232, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.466 = f32[1,1,896,448]{1,0,3,2} bitcast(f32[1,1,896,448]{3,2,1,0} %get-tuple-element.686), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %broadcast.1105 = f32[896]{0} broadcast(f32[] %constant_708), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %get-tuple-element.260 = f32[16,28,28,1792]{2,1,3,0} get-tuple-element((f32[16,28,28,1792]{2,1,3,0}, f32[16,28,28,1792]{2,1,3,0}) %fusion.244), index=1
  %cudnn-conv-bw-input.6 = (f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.260, f32[1,1,896,1792]{1,0,2,3} %copy.65), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.50 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.6), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(1, 1, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %cudnn-conv-bias-activation.14 = (f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %fusion.232, f32[1,1,896,448]{1,0,3,2} %bitcast.466, f32[896]{0} %broadcast.1105, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.50), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 896, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.87 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.14), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.55 = (f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) tuple(f32[16,56,56,896]{3,2,1,0} %param_136, f32[1,1,896,224]{3,2,1,0} %param_137, f32[224]{0} %param_138, f32[224]{0} %param_139, f32[3,3,224,448]{3,2,1,0} %param_140, /*index=5*/f32[448]{0} %param_141, f32[448]{0} %param_142, f32[1,1,448,896]{3,2,1,0} %param_143, f32[896]{0} %param_144, f32[896]{0} %param_145, /*index=10*/f32[16,56,56,896]{2,1,3,0} %get-tuple-element.87), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2658 = (f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) bitcast((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %tuple.55)
  %get-tuple-element.717 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.707 = f32[16,56,56,896]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.70 = f32[16,56,56,896]{2,1,3,0} copy(f32[16,56,56,896]{3,2,1,0} %get-tuple-element.707), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.207 = f32[16,56,56,896]{2,1,3,0} fusion(f32[16,56,56,896]{2,1,3,0} %copy.70), kind=kLoop, calls=%fused_computation.207, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.716 = f32[896]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.713 = f32[448]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.712 = f32[448]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.710 = f32[224]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.709 = f32[224]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.708 = f32[1,1,896,224]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.71 = f32[1,1,896,224]{1,0,2,3} copy(f32[1,1,896,224]{3,2,1,0} %get-tuple-element.708), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.27 = (f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %fusion.207, f32[1,1,896,224]{1,0,2,3} %copy.71), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.51 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv.27), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2551 = f32[16,224,3136]{2,1,0} bitcast(f32[16,56,56,224]{2,1,3,0} %get-tuple-element.51)
  %fusion.206 = (f32[16,224]{1,0}, f32[16,224]{1,0}) fusion(f32[16,224,3136]{2,1,0} %bitcast.2551), kind=kInput, calls=%fused_computation.206.clone
  %get-tuple-element.237 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.206), index=1
  %get-tuple-element.236 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.206), index=0
  %reduce.337 = f32[224]{0} reduce(f32[16,224]{1,0} %get-tuple-element.236, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.202 = f32[224]{0} fusion(f32[16,224]{1,0} %get-tuple-element.237, f32[224]{0} %reduce.337), kind=kLoop, calls=%fused_computation.202, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.197 = f32[16,56,56,224]{2,1,3,0} fusion(f32[224]{0} %get-tuple-element.710, f32[224]{0} %get-tuple-element.709, f32[224]{0} %fusion.202, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.51, f32[224]{0} %reduce.337), kind=kLoop, calls=%fused_computation.197, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.711 = f32[3,3,224,448]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.72 = f32[3,3,224,448]{1,0,2,3} copy(f32[3,3,224,448]{3,2,1,0} %get-tuple-element.711), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.28 = (f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.197, f32[3,3,224,448]{1,0,2,3} %copy.72), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.52 = f32[16,56,56,448]{2,1,3,0} get-tuple-element((f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.28), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2547 = f32[16,448,3136]{2,1,0} bitcast(f32[16,56,56,448]{2,1,3,0} %get-tuple-element.52)
  %fusion.196 = (f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,448,3136]{2,1,0} %bitcast.2547), kind=kInput, calls=%fused_computation.196.clone
  %get-tuple-element.235 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.196), index=1
  %get-tuple-element.234 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.196), index=0
  %reduce.339 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.234, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.192 = f32[448]{0} fusion(f32[16,448]{1,0} %get-tuple-element.235, f32[448]{0} %reduce.339), kind=kLoop, calls=%fused_computation.192, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.187 = f32[16,56,56,448]{2,1,3,0} fusion(f32[448]{0} %get-tuple-element.713, f32[448]{0} %get-tuple-element.712, f32[448]{0} %fusion.192, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.52, f32[448]{0} %reduce.339), kind=kLoop, calls=%fused_computation.187, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.714 = f32[1,1,448,896]{3,2,1,0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.73 = f32[1,1,448,896]{1,0,2,3} copy(f32[1,1,448,896]{3,2,1,0} %get-tuple-element.714), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.29 = (f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %fusion.187, f32[1,1,448,896]{1,0,2,3} %copy.73), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.53 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.29), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2543 = f32[16,896,3136]{2,1,0} bitcast(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.53)
  %fusion.186 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,3136]{2,1,0} %bitcast.2543), kind=kInput, calls=%fused_computation.186.clone
  %get-tuple-element.232 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.186), index=0
  %reduce.341 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.232, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.715 = f32[896]{0} get-tuple-element((f32[16,56,56,896]{3,2,1,0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=5*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=10*/f32[16,56,56,896]{2,1,3,0}) %bitcast.2658), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.233 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.186), index=1
  %fusion.182 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.233, f32[896]{0} %reduce.341), kind=kLoop, calls=%fused_computation.182, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.178 = f32[16,56,56,896]{2,1,3,0} fusion(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.717, f32[16,56,56,896]{2,1,3,0} %fusion.207, f32[896]{0} %get-tuple-element.716, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.53, f32[896]{0} %reduce.341, /*index=5*/f32[896]{0} %get-tuple-element.715, f32[896]{0} %fusion.182), kind=kLoop, calls=%fused_computation.178, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.174 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,56,56,896]{2,1,3,0} %fusion.178, f32[896]{0} %get-tuple-element.715, f32[896]{0} %fusion.182, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.53, f32[896]{0} %reduce.341), kind=kInput, calls=%fused_computation.174
  %get-tuple-element.229 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.174), index=0
  %reduce.344 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.229, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.230 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.174), index=1
  %fusion.175 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.230), kind=kLoop, calls=%fused_computation.175, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.173 = f32[16,56,56,896]{2,1,3,0} fusion(f32[896]{0} %reduce.344, f32[896]{0} %reduce.341, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.53, f32[896]{0} %fusion.182, f32[1,1,1,896]{3,2,1,0} %fusion.175, /*index=5*/f32[896]{0} %get-tuple-element.715, f32[16,56,56,896]{2,1,3,0} %fusion.178), kind=kLoop, calls=%fused_computation.173, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.486 = f32[1,1,448,896]{1,0,3,2} bitcast(f32[1,1,448,896]{3,2,1,0} %get-tuple-element.714), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.30 = (f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %fusion.173, f32[1,1,448,896]{1,0,3,2} %bitcast.486), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.55 = f32[16,56,56,448]{2,1,3,0} get-tuple-element((f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.30), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.154 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,56,56,448]{2,1,3,0} %get-tuple-element.55, f32[448]{0} %get-tuple-element.713, f32[448]{0} %get-tuple-element.712, f32[448]{0} %fusion.192, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.52, /*index=5*/f32[448]{0} %reduce.339), kind=kInput, calls=%fused_computation.154
  %get-tuple-element.227 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.154), index=1
  %reduce.346 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.227, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.228 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.154), index=2
  %fusion.169 = f32[1,1,1,448]{3,2,1,0} fusion(f32[16,448]{1,0} %get-tuple-element.228), kind=kLoop, calls=%fused_computation.169, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.167 = f32[16,56,56,448]{2,1,3,0} fusion(f32[448]{0} %reduce.346, f32[448]{0} %reduce.339, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.52, f32[448]{0} %fusion.192, f32[1,1,1,448]{3,2,1,0} %fusion.169, /*index=5*/f32[448]{0} %get-tuple-element.712, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.55, f32[448]{0} %get-tuple-element.713), kind=kLoop, calls=%fused_computation.167, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.7 = (f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %fusion.167, f32[3,3,224,448]{1,0,2,3} %copy.72), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.57 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.7), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.158 = (f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) fusion(f32[16,56,56,224]{2,1,3,0} %get-tuple-element.57, f32[224]{0} %get-tuple-element.710, f32[224]{0} %get-tuple-element.709, f32[224]{0} %fusion.202, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.51, /*index=5*/f32[224]{0} %reduce.337), kind=kInput, calls=%fused_computation.158
  %get-tuple-element.224 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.158), index=1
  %reduce.348 = f32[224]{0} reduce(f32[16,224]{1,0} %get-tuple-element.224, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.225 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.158), index=2
  %fusion.163 = f32[1,1,1,224]{3,2,1,0} fusion(f32[16,224]{1,0} %get-tuple-element.225), kind=kLoop, calls=%fused_computation.163, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.161 = f32[16,56,56,224]{2,1,3,0} fusion(f32[224]{0} %reduce.348, f32[224]{0} %reduce.337, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.51, f32[224]{0} %fusion.202, f32[1,1,1,224]{3,2,1,0} %fusion.163, /*index=5*/f32[224]{0} %get-tuple-element.709, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.57, f32[224]{0} %get-tuple-element.710), kind=kLoop, calls=%fused_computation.161, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.501 = f32[1,1,896,224]{1,0,3,2} bitcast(f32[1,1,896,224]{3,2,1,0} %get-tuple-element.708), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.17 = (f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.161, f32[1,1,896,224]{1,0,3,2} %bitcast.501, f32[896]{0} %broadcast.1105, f32[16,56,56,896]{2,1,3,0} %fusion.178), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 896, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.88 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.17), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.148 = f32[16,56,56,896]{2,1,3,0} fusion(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.88, f32[16,56,56,896]{2,1,3,0} %copy.70), kind=kLoop, calls=%fused_computation.148, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %tuple.57 = (f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) tuple(f32[16,56,56,448]{3,2,1,0} %param_146, f32[1,1,448,896]{3,2,1,0} %param_147, f32[896]{0} %param_148, f32[896]{0} %param_149, f32[16,56,56,224]{3,2,1,0} %param_150, /*index=5*/f32[1,1,224,896]{3,2,1,0} %param_151, f32[896]{0} %param_152, f32[896]{0} %param_153, f32[1,1,896,224]{3,2,1,0} %param_154, f32[224]{0} %param_155, /*index=10*/f32[224]{0} %param_156, f32[3,3,224,448]{3,2,1,0} %param_157, f32[448]{0} %param_158, f32[448]{0} %param_159, f32[1,1,448,896]{3,2,1,0} %param_160, /*index=15*/f32[896]{0} %param_161, f32[16,56,56,896]{2,1,3,0} %fusion.148), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2659 = (f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) bitcast((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %tuple.57)
  %get-tuple-element.734 = f32[896]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.732 = f32[16,56,56,448]{3,2,1,0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.91 = f32[16,56,56,448]{2,1,3,0} copy(f32[16,56,56,448]{3,2,1,0} %get-tuple-element.732), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.733 = f32[1,1,448,896]{3,2,1,0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.84 = f32[1,1,448,896]{1,0,2,3} copy(f32[1,1,448,896]{3,2,1,0} %get-tuple-element.733), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.32 = (f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %copy.91, f32[1,1,448,896]{1,0,2,3} %copy.84), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.60 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.32), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2535 = f32[16,896,3136]{2,1,0} bitcast(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.60)
  %fusion.139 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,3136]{2,1,0} %bitcast.2535), kind=kInput, calls=%fused_computation.139.clone
  %get-tuple-element.222 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.139), index=1
  %get-tuple-element.221 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.139), index=0
  %reduce.354 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.221, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.135 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.222, f32[896]{0} %reduce.354), kind=kLoop, calls=%fused_computation.135, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %get-tuple-element.730 = f32[896]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.728 = f32[16,56,56,224]{3,2,1,0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.81 = f32[16,56,56,224]{2,1,3,0} copy(f32[16,56,56,224]{3,2,1,0} %get-tuple-element.728), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.729 = f32[1,1,224,896]{3,2,1,0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.82 = f32[1,1,224,896]{1,0,2,3} copy(f32[1,1,224,896]{3,2,1,0} %get-tuple-element.729), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.33 = (f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %copy.81, f32[1,1,224,896]{1,0,2,3} %copy.82), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 224, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.61 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.33), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 224, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2539 = f32[16,896,3136]{2,1,0} bitcast(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.61)
  %fusion.147 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,3136]{2,1,0} %bitcast.2539), kind=kInput, calls=%fused_computation.147.clone
  %get-tuple-element.220 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.147), index=1
  %get-tuple-element.219 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.147), index=0
  %reduce.352 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.219, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.143 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.220, f32[896]{0} %reduce.352), kind=kLoop, calls=%fused_computation.143, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %get-tuple-element.736 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=16, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.744 = f32[896]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=15, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_73 = f32[896]{0} parameter(73), metadata={op_name="3$start"}
  %bitcast.2516 = f32[16,896,3136]{2,1,0} bitcast(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.736)
  %get-tuple-element.742 = f32[448]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=13, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.741 = f32[448]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=12, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.739 = f32[224]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.738 = f32[224]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.735 = f32[896]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.731 = f32[896]{0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.130 = f32[16,56,56,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.735, f32[896]{0} %get-tuple-element.734, f32[896]{0} %fusion.135, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.60, f32[896]{0} %reduce.354, /*index=5*/f32[896]{0} %get-tuple-element.731, f32[896]{0} %get-tuple-element.730, f32[896]{0} %fusion.143, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.61, f32[896]{0} %reduce.352), kind=kLoop, calls=%fused_computation.130, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.737 = f32[1,1,896,224]{3,2,1,0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.85 = f32[1,1,896,224]{1,0,2,3} copy(f32[1,1,896,224]{3,2,1,0} %get-tuple-element.737), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.34 = (f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %fusion.130, f32[1,1,896,224]{1,0,2,3} %copy.85), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.62 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv.34), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 896, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2531 = f32[16,224,3136]{2,1,0} bitcast(f32[16,56,56,224]{2,1,3,0} %get-tuple-element.62)
  %fusion.129 = (f32[16,224]{1,0}, f32[16,224]{1,0}) fusion(f32[16,224,3136]{2,1,0} %bitcast.2531), kind=kInput, calls=%fused_computation.129.clone
  %get-tuple-element.218 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.129), index=1
  %get-tuple-element.217 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.129), index=0
  %reduce.356 = f32[224]{0} reduce(f32[16,224]{1,0} %get-tuple-element.217, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.125 = f32[224]{0} fusion(f32[16,224]{1,0} %get-tuple-element.218, f32[224]{0} %reduce.356), kind=kLoop, calls=%fused_computation.125, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.120 = f32[16,56,56,224]{2,1,3,0} fusion(f32[224]{0} %get-tuple-element.739, f32[224]{0} %get-tuple-element.738, f32[224]{0} %fusion.125, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.62, f32[224]{0} %reduce.356), kind=kLoop, calls=%fused_computation.120, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.740 = f32[3,3,224,448]{3,2,1,0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.86 = f32[3,3,224,448]{1,0,2,3} copy(f32[3,3,224,448]{3,2,1,0} %get-tuple-element.740), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.35 = (f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.120, f32[3,3,224,448]{1,0,2,3} %copy.86), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.63 = f32[16,56,56,448]{2,1,3,0} get-tuple-element((f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.35), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2527 = f32[16,448,3136]{2,1,0} bitcast(f32[16,56,56,448]{2,1,3,0} %get-tuple-element.63)
  %fusion.119 = (f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,448,3136]{2,1,0} %bitcast.2527), kind=kInput, calls=%fused_computation.119.clone
  %get-tuple-element.216 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.119), index=1
  %get-tuple-element.215 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.119), index=0
  %reduce.358 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.215, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.115 = f32[448]{0} fusion(f32[16,448]{1,0} %get-tuple-element.216, f32[448]{0} %reduce.358), kind=kLoop, calls=%fused_computation.115, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.110 = f32[16,56,56,448]{2,1,3,0} fusion(f32[448]{0} %get-tuple-element.742, f32[448]{0} %get-tuple-element.741, f32[448]{0} %fusion.115, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.63, f32[448]{0} %reduce.358), kind=kLoop, calls=%fused_computation.110, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.743 = f32[1,1,448,896]{3,2,1,0} get-tuple-element((f32[16,56,56,448]{3,2,1,0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[16,56,56,224]{3,2,1,0}, /*index=5*/f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, /*index=10*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, /*index=15*/f32[896]{0}, f32[16,56,56,896]{2,1,3,0}) %bitcast.2659), index=14, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.87 = f32[1,1,448,896]{1,0,2,3} copy(f32[1,1,448,896]{3,2,1,0} %get-tuple-element.743), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.36 = (f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %fusion.110, f32[1,1,448,896]{1,0,2,3} %copy.87), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.64 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.36), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2519 = f32[16,896,3136]{2,1,0} bitcast(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.64)
  %bitcast.2523 = f32[16,896,3136]{2,1,0} bitcast(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.64)
  %fusion.109 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,3136]{2,1,0} %bitcast.2523), kind=kInput, calls=%fused_computation.109.clone
  %get-tuple-element.212 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.109), index=1
  %reduce.361 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.212, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.102 = f32[16,896]{1,0} fusion(f32[16,896,3136]{2,1,0} %bitcast.2516, f32[16,896,3136]{2,1,0} %bitcast.2519, f32[896]{0} %reduce.361), kind=kInput, calls=%fused_computation.102.clone
  %fusion.101 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %fusion.102), kind=kLoop, calls=%fused_computation.101, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.211 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.109), index=0
  %fusion.61 = (f32[896]{0}, f32[896]{0}) fusion(f32[896]{0} %param_73, f32[1,1,1,896]{3,2,1,0} %fusion.101, f32[896]{0} %reduce.361, f32[16,896]{1,0} %get-tuple-element.211), kind=kLoop, calls=%fused_computation.61, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %get-tuple-element.210 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}) %fusion.61), index=1
  %fusion.100 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.736, f32[896]{0} %get-tuple-element.744, f32[896]{0} %get-tuple-element.210), kind=kInput, calls=%fused_computation.100
  %get-tuple-element.213 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.100), index=0
  %reduce.363 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.213, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.99 = f32[16,56,56,896]{2,1,3,0} fusion(f32[896]{0} %reduce.363, f32[896]{0} %reduce.361, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.64, f32[896]{0} %get-tuple-element.210, f32[1,1,1,896]{3,2,1,0} %fusion.101, /*index=5*/f32[896]{0} %get-tuple-element.744, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.736), kind=kLoop, calls=%fused_computation.99, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.531 = f32[1,1,448,896]{1,0,3,2} bitcast(f32[1,1,448,896]{3,2,1,0} %get-tuple-element.743), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.37 = (f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %fusion.99, f32[1,1,448,896]{1,0,3,2} %bitcast.531), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.66 = f32[16,56,56,448]{2,1,3,0} get-tuple-element((f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.37), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.64 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,56,56,448]{2,1,3,0} %get-tuple-element.66, f32[448]{0} %get-tuple-element.742, f32[448]{0} %get-tuple-element.741, f32[448]{0} %fusion.115, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.63, /*index=5*/f32[448]{0} %reduce.358), kind=kInput, calls=%fused_computation.64
  %get-tuple-element.207 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.64), index=1
  %reduce.365 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.207, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.208 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.64), index=2
  %fusion.95 = f32[1,1,1,448]{3,2,1,0} fusion(f32[16,448]{1,0} %get-tuple-element.208), kind=kLoop, calls=%fused_computation.95, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.93 = f32[16,56,56,448]{2,1,3,0} fusion(f32[448]{0} %reduce.365, f32[448]{0} %reduce.358, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.63, f32[448]{0} %fusion.115, f32[1,1,1,448]{3,2,1,0} %fusion.95, /*index=5*/f32[448]{0} %get-tuple-element.741, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.66, f32[448]{0} %get-tuple-element.742), kind=kLoop, calls=%fused_computation.93, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.8 = (f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %fusion.93, f32[3,3,224,448]{1,0,2,3} %copy.86), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.68 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.68 = (f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) fusion(f32[16,56,56,224]{2,1,3,0} %get-tuple-element.68, f32[224]{0} %get-tuple-element.739, f32[224]{0} %get-tuple-element.738, f32[224]{0} %fusion.125, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.62, /*index=5*/f32[224]{0} %reduce.356), kind=kInput, calls=%fused_computation.68
  %get-tuple-element.204 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.68), index=1
  %reduce.367 = f32[224]{0} reduce(f32[16,224]{1,0} %get-tuple-element.204, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.205 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.68), index=2
  %fusion.89 = f32[1,1,1,224]{3,2,1,0} fusion(f32[16,224]{1,0} %get-tuple-element.205), kind=kLoop, calls=%fused_computation.89, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.87 = f32[16,56,56,224]{2,1,3,0} fusion(f32[224]{0} %reduce.367, f32[224]{0} %reduce.356, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.62, f32[224]{0} %fusion.125, f32[1,1,1,224]{3,2,1,0} %fusion.89, /*index=5*/f32[224]{0} %get-tuple-element.738, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.68, f32[224]{0} %get-tuple-element.739), kind=kLoop, calls=%fused_computation.87, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.540 = f32[1,1,896,224]{1,0,3,2} bitcast(f32[1,1,896,224]{3,2,1,0} %get-tuple-element.737), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.20 = (f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.87, f32[1,1,896,224]{1,0,3,2} %bitcast.540, f32[896]{0} %broadcast.1105, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.736), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 896, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.89 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.20), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.82 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[896]{0} %get-tuple-element.734, f32[896]{0} %fusion.135, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.60, f32[896]{0} %reduce.354, f32[896]{0} %get-tuple-element.730, /*index=5*/f32[896]{0} %fusion.143, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.61, f32[896]{0} %reduce.352, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.89, f32[896]{0} %get-tuple-element.735, /*index=10*/f32[896]{0} %get-tuple-element.731), kind=kInput, calls=%fused_computation.82
  %get-tuple-element.196 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.82), index=0
  %reduce.369 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.196, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.197 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.82), index=1
  %fusion.83 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.197), kind=kLoop, calls=%fused_computation.83, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.198 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.82), index=2
  %reduce.371 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.198, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.199 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.82), index=3
  %fusion.75 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.199), kind=kLoop, calls=%fused_computation.75, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/norm_proj/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.81 = (f32[16,56,56,896]{2,1,3,0}, f32[16,56,56,896]{2,1,3,0}) fusion(f32[896]{0} %reduce.369, f32[896]{0} %reduce.354, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.60, f32[896]{0} %fusion.135, f32[1,1,1,896]{3,2,1,0} %fusion.83, /*index=5*/f32[896]{0} %get-tuple-element.734, f32[896]{0} %reduce.371, f32[896]{0} %reduce.352, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.61, f32[896]{0} %fusion.143, /*index=10*/f32[1,1,1,896]{3,2,1,0} %fusion.75, f32[896]{0} %get-tuple-element.730, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.89, f32[896]{0} %get-tuple-element.735, f32[896]{0} %get-tuple-element.731), kind=kLoop, calls=%fused_computation.81, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.201 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, f32[16,56,56,896]{2,1,3,0}) %fusion.81), index=0
  %bitcast.558 = f32[1,1,448,896]{1,0,3,2} bitcast(f32[1,1,448,896]{3,2,1,0} %get-tuple-element.733), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.40 = (f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.201, f32[1,1,448,896]{1,0,3,2} %bitcast.558), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.74 = f32[16,56,56,448]{2,1,3,0} get-tuple-element((f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.40), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 448, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %get-tuple-element.202 = f32[16,56,56,896]{2,1,3,0} get-tuple-element((f32[16,56,56,896]{2,1,3,0}, f32[16,56,56,896]{2,1,3,0}) %fusion.81), index=1
  %bitcast.559 = f32[1,1,224,896]{1,0,3,2} bitcast(f32[1,1,224,896]{3,2,1,0} %get-tuple-element.729), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.39 = (f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %get-tuple-element.202, f32[1,1,224,896]{1,0,3,2} %bitcast.559), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 224, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.73 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv.39), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(1, 1, 224, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.59 = (f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) tuple(f32[7,7,3,224]{3,2,1,0} %param_163, f32[224]{0} %param_164, f32[224]{0} %param_165, f32[1,1,224,224]{3,2,1,0} %param_166, f32[224]{0} %param_167, /*index=5*/f32[224]{0} %param_168, f32[3,3,224,448]{3,2,1,0} %param_169, f32[448]{0} %param_170, f32[448]{0} %param_171, s32[16,224,224,3]{3,2,1,0} %param_162, /*index=10*/f32[16,56,56,448]{2,1,3,0} %get-tuple-element.74, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.73), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2660 = (f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) bitcast((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %tuple.59)
  %get-tuple-element.773 = f32[16,56,56,448]{2,1,3,0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.772 = f32[448]{0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.771 = f32[448]{0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.769 = f32[224]{0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.768 = f32[224]{0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.765 = f32[224]{0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.764 = f32[224]{0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.762 = s32[16,224,224,3]{3,2,1,0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.58 = f32[16,224,224,3]{2,1,3,0} fusion(s32[16,224,224,3]{3,2,1,0} %get-tuple-element.762), kind=kLoop, calls=%fused_computation.58, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/conv_init/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/dtypes.py" source_line=97}
  %get-tuple-element.763 = f32[7,7,3,224]{3,2,1,0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.101 = f32[7,7,3,224]{1,0,2,3} copy(f32[7,7,3,224]{3,2,1,0} %get-tuple-element.763), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.41 = (f32[16,112,112,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,224,224,3]{2,1,3,0} %fusion.58, f32[7,7,3,224]{1,0,2,3} %copy.101), window={size=7x7 stride=2x2 pad=3_3x3_3}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/conv_init/conv_general_dilated[window_strides=(2, 2) padding=((3, 3), (3, 3)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 224, 224, 3) rhs_shape=(7, 7, 3, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.75 = f32[16,112,112,224]{2,1,3,0} get-tuple-element((f32[16,112,112,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv.41), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/conv_init/conv_general_dilated[window_strides=(2, 2) padding=((3, 3), (3, 3)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 224, 224, 3) rhs_shape=(7, 7, 3, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2512 = f32[16,224,12544]{2,1,0} bitcast(f32[16,112,112,224]{2,1,3,0} %get-tuple-element.75)
  %fusion.57 = (f32[16,224]{1,0}, f32[16,224]{1,0}) fusion(f32[16,224,12544]{2,1,0} %bitcast.2512), kind=kInput, calls=%fused_computation.57.clone
  %get-tuple-element.193 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.57), index=1
  %get-tuple-element.192 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.57), index=0
  %reduce.377 = f32[224]{0} reduce(f32[16,224]{1,0} %get-tuple-element.192, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.53 = f32[224]{0} fusion(f32[16,224]{1,0} %get-tuple-element.193, f32[224]{0} %reduce.377), kind=kLoop, calls=%fused_computation.53, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.518 = f32[16,56,56,224]{2,1,3,0} fusion(f32[224]{0} %get-tuple-element.765, f32[224]{0} %get-tuple-element.764, f32[224]{0} %fusion.53, f32[16,112,112,224]{2,1,3,0} %get-tuple-element.75, f32[224]{0} %reduce.377), kind=kLoop, calls=%fused_computation.518, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/reduce_window_max[window_dimensions=(1, 3, 3, 1) window_strides=(1, 2, 2, 1) padding=((0, 0), (0, 1), (0, 1), (0, 0)) base_dilation=(1, 1, 1, 1) window_dilation=(1, 1, 1, 1)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
  %get-tuple-element.767 = f32[1,1,224,224]{3,2,1,0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.102 = f32[1,1,224,224]{1,0,2,3} copy(f32[1,1,224,224]{3,2,1,0} %get-tuple-element.767), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.42 = (f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.518, f32[1,1,224,224]{1,0,2,3} %copy.102), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 224, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.76 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv.42), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 224, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2508 = f32[16,224,3136]{2,1,0} bitcast(f32[16,56,56,224]{2,1,3,0} %get-tuple-element.76)
  %fusion.47 = (f32[16,224]{1,0}, f32[16,224]{1,0}) fusion(f32[16,224,3136]{2,1,0} %bitcast.2508), kind=kInput, calls=%fused_computation.47.clone
  %get-tuple-element.191 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.47), index=1
  %get-tuple-element.190 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.47), index=0
  %reduce.379 = f32[224]{0} reduce(f32[16,224]{1,0} %get-tuple-element.190, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.43 = f32[224]{0} fusion(f32[16,224]{1,0} %get-tuple-element.191, f32[224]{0} %reduce.379), kind=kLoop, calls=%fused_computation.43, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.38 = f32[16,56,56,224]{2,1,3,0} fusion(f32[224]{0} %get-tuple-element.769, f32[224]{0} %get-tuple-element.768, f32[224]{0} %fusion.43, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.76, f32[224]{0} %reduce.379), kind=kLoop, calls=%fused_computation.38, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.770 = f32[3,3,224,448]{3,2,1,0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.103 = f32[3,3,224,448]{1,0,2,3} copy(f32[3,3,224,448]{3,2,1,0} %get-tuple-element.770), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.43 = (f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.38, f32[3,3,224,448]{1,0,2,3} %copy.103), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.77 = f32[16,56,56,448]{2,1,3,0} get-tuple-element((f32[16,56,56,448]{2,1,3,0}, u8[0]{0}) %cudnn-conv.43), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2504 = f32[16,448,3136]{2,1,0} bitcast(f32[16,56,56,448]{2,1,3,0} %get-tuple-element.77)
  %fusion.37 = (f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,448,3136]{2,1,0} %bitcast.2504), kind=kInput, calls=%fused_computation.37.clone
  %get-tuple-element.189 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.37), index=1
  %get-tuple-element.188 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.37), index=0
  %reduce.381 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.188, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.33 = f32[448]{0} fusion(f32[16,448]{1,0} %get-tuple-element.189, f32[448]{0} %reduce.381), kind=kLoop, calls=%fused_computation.33, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.1 = (f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) fusion(f32[16,56,56,448]{2,1,3,0} %get-tuple-element.773, f32[448]{0} %get-tuple-element.772, f32[448]{0} %get-tuple-element.771, f32[448]{0} %fusion.33, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.77, /*index=5*/f32[448]{0} %reduce.381), kind=kInput, calls=%fused_computation.1
  %get-tuple-element.187 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.1), index=2
  %fusion.26 = f32[1,1,1,448]{3,2,1,0} fusion(f32[16,448]{1,0} %get-tuple-element.187), kind=kLoop, calls=%fused_computation.26, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 448) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4 = f32[1792]{0} parameter(4), metadata={op_name="3$start"}
  %param_79 = f32[224]{0} parameter(79), metadata={op_name="3$start"}
  %get-tuple-element.186 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.1), index=1
  %reduce.384 = f32[448]{0} reduce(f32[16,448]{1,0} %get-tuple-element.186, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.24 = f32[16,56,56,448]{2,1,3,0} fusion(f32[448]{0} %reduce.384, f32[448]{0} %reduce.381, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.77, f32[448]{0} %fusion.33, f32[1,1,1,448]{3,2,1,0} %fusion.26, /*index=5*/f32[448]{0} %get-tuple-element.771, f32[16,56,56,448]{2,1,3,0} %get-tuple-element.773, f32[448]{0} %get-tuple-element.772), kind=kLoop, calls=%fused_computation.24, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.9 = (f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %fusion.24, f32[3,3,224,448]{1,0,2,3} %copy.103), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.79 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.9), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(3, 3, 224, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.5 = (f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) fusion(f32[16,56,56,224]{2,1,3,0} %get-tuple-element.79, f32[224]{0} %get-tuple-element.769, f32[224]{0} %get-tuple-element.768, f32[224]{0} %fusion.43, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.76, /*index=5*/f32[224]{0} %reduce.379), kind=kInput, calls=%fused_computation.5
  %get-tuple-element.184 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.5), index=2
  %fusion.20 = f32[1,1,1,224]{3,2,1,0} fusion(f32[16,224]{1,0} %get-tuple-element.184), kind=kLoop, calls=%fused_computation.20, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_34 = f32[896]{0} parameter(34), metadata={op_name="3$start"}
  %param_76 = f32[224]{0} parameter(76), metadata={op_name="3$start"}
  %fusion.517 = f32[16,113,113,224]{2,1,3,0} fusion(f32[224]{0} %get-tuple-element.765, f32[224]{0} %get-tuple-element.764, f32[224]{0} %fusion.53, f32[16,112,112,224]{2,1,3,0} %get-tuple-element.75, f32[224]{0} %reduce.377), kind=kLoop, calls=%fused_computation.517, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/pad[padding_config=((0, 0, 0), (0, 1, 0), (0, 1, 0), (0, 0, 0))]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
  %get-tuple-element.183 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.5), index=1
  %reduce.386 = f32[224]{0} reduce(f32[16,224]{1,0} %get-tuple-element.183, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.18 = f32[16,56,56,224]{2,1,3,0} fusion(f32[224]{0} %reduce.386, f32[224]{0} %reduce.379, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.76, f32[224]{0} %fusion.43, f32[1,1,1,224]{3,2,1,0} %fusion.20, /*index=5*/f32[224]{0} %get-tuple-element.768, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.79, f32[224]{0} %get-tuple-element.769), kind=kLoop, calls=%fused_computation.18, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.583 = f32[1,1,224,224]{1,0,3,2} bitcast(f32[1,1,224,224]{3,2,1,0} %get-tuple-element.767), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %broadcast.1382 = f32[224]{0} broadcast(f32[] %constant_708), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %get-tuple-element.766 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=5*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, s32[16,224,224,3]{3,2,1,0}, /*index=10*/f32[16,56,56,448]{2,1,3,0}, f32[16,56,56,224]{2,1,3,0}) %bitcast.2660), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.23 = (f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.18, f32[1,1,224,224]{1,0,3,2} %bitcast.583, f32[224]{0} %broadcast.1382, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.766), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(1, 1, 224, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.90 = f32[16,56,56,224]{2,1,3,0} get-tuple-element((f32[16,56,56,224]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.23), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %select-and-scatter.1 = f32[16,113,113,224]{2,1,3,0} select-and-scatter(f32[16,113,113,224]{2,1,3,0} %fusion.517, f32[16,56,56,224]{2,1,3,0} %get-tuple-element.90, f32[] %constant_708), window={size=1x3x3x1 stride=1x2x2x1}, select=%region_195.7208.3, scatter=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/select_and_scatter[select_consts=() scatter_consts=() window_dimensions=(1, 3, 3, 1) window_strides=(1, 2, 2, 1) padding=((0, 0), (0, 0), (0, 0), (0, 0))]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/pooling.py" source_line=66}
  %fusion.9 = (f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) fusion(f32[16,113,113,224]{2,1,3,0} %select-and-scatter.1, f32[224]{0} %get-tuple-element.765, f32[224]{0} %get-tuple-element.764, f32[224]{0} %fusion.53, f32[16,112,112,224]{2,1,3,0} %get-tuple-element.75, /*index=5*/f32[224]{0} %reduce.377), kind=kInput, calls=%fused_computation.9
  %get-tuple-element.181 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.9), index=2
  %fusion.14 = f32[1,1,1,224]{3,2,1,0} fusion(f32[16,224]{1,0} %get-tuple-element.181), kind=kLoop, calls=%fused_computation.14, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reshape[new_sizes=(1, 1, 1, 224) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_13 = f32[448]{0} parameter(13), metadata={op_name="3$start"}
  %param_28 = f32[1792]{0} parameter(28), metadata={op_name="3$start"}
  %param_70 = f32[448]{0} parameter(70), metadata={op_name="3$start"}
  %param_16 = f32[896]{0} parameter(16), metadata={op_name="3$start"}
  %param_67 = f32[224]{0} parameter(67), metadata={op_name="3$start"}
  %param_64 = f32[896]{0} parameter(64), metadata={op_name="3$start"}
  %param_61 = f32[896]{0} parameter(61), metadata={op_name="3$start"}
  %param_19 = f32[1792]{0} parameter(19), metadata={op_name="3$start"}
  %param_58 = f32[896]{0} parameter(58), metadata={op_name="3$start"}
  %param_40 = f32[448]{0} parameter(40), metadata={op_name="3$start"}
  %param_55 = f32[448]{0} parameter(55), metadata={op_name="3$start"}
  %param_22 = f32[448]{0} parameter(22), metadata={op_name="3$start"}
  %param_52 = f32[224]{0} parameter(52), metadata={op_name="3$start"}
  %param_1 = f32[896]{0} parameter(1), metadata={op_name="3$start"}
  %param_25 = f32[896]{0} parameter(25), metadata={op_name="3$start"}
  %fusion.527 = (f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) fusion(f32[448]{0} %param_31, f32[1,1,1,448]{3,2,1,0} %fusion.290, f32[448]{0} %fusion.326, f32[896]{0} %param_43, f32[1,1,1,896]{3,2,1,0} %fusion.240, /*index=5*/f32[896]{0} %fusion.260, f32[448]{0} %param_82, f32[1,1,1,448]{3,2,1,0} %fusion.26, f32[448]{0} %fusion.33, f32[1792]{0} %param_4, /*index=10*/f32[1,1,1,1792]{3,2,1,0} %fusion.482, f32[1792]{0} %fusion.502, f32[224]{0} %param_79, f32[1,1,1,224]{3,2,1,0} %fusion.20, f32[224]{0} %fusion.43, /*index=15*/f32[896]{0} %param_34, f32[1,1,1,896]{3,2,1,0} %fusion.296, f32[896]{0} %fusion.316, f32[224]{0} %param_76, f32[1,1,1,224]{3,2,1,0} %fusion.14, /*index=20*/f32[224]{0} %fusion.53, f32[448]{0} %param_13, f32[1,1,1,448]{3,2,1,0} %fusion.406, f32[448]{0} %fusion.445, f32[1792]{0} %param_28, /*index=25*/f32[1,1,1,1792]{3,2,1,0} %fusion.359, f32[1792]{0} %fusion.366, f32[448]{0} %param_70, f32[1,1,1,448]{3,2,1,0} %fusion.95, f32[448]{0} %fusion.115, /*index=30*/f32[896]{0} %param_16, f32[1,1,1,896]{3,2,1,0} %fusion.412, f32[896]{0} %fusion.435, f32[224]{0} %param_67, f32[1,1,1,224]{3,2,1,0} %fusion.89, /*index=35*/f32[224]{0} %fusion.125, f32[896]{0} %param_64, f32[1,1,1,896]{3,2,1,0} %fusion.75, f32[896]{0} %fusion.143, f32[896]{0} %param_61, /*index=40*/f32[1,1,1,896]{3,2,1,0} %fusion.83, f32[896]{0} %fusion.135, f32[1792]{0} %param_19, f32[1,1,1,1792]{3,2,1,0} %fusion.418, f32[1792]{0} %fusion.425, /*index=45*/f32[896]{0} %param_58, f32[1,1,1,896]{3,2,1,0} %fusion.175, f32[896]{0} %fusion.182, f32[448]{0} %param_40, f32[1,1,1,448]{3,2,1,0} %fusion.234, /*index=50*/f32[448]{0} %fusion.270, f32[448]{0} %param_55, f32[1,1,1,448]{3,2,1,0} %fusion.169, f32[448]{0} %fusion.192, f32[448]{0} %param_22, /*index=55*/f32[1,1,1,448]{3,2,1,0} %fusion.347, f32[448]{0} %fusion.386, f32[224]{0} %param_52, f32[1,1,1,224]{3,2,1,0} %fusion.163, f32[224]{0} %fusion.202, /*index=60*/f32[896]{0} %param_1, f32[1,1,1,896]{3,2,1,0} %fusion.476, f32[896]{0} %fusion.512, f32[896]{0} %param_25, f32[1,1,1,896]{3,2,1,0} %fusion.353, /*index=65*/f32[896]{0} %fusion.376), kind=kInput, calls=%horizontally_fused_computation.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %get-tuple-element.388 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=20, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %param_32 = f32[448]{0} parameter(32), metadata={op_name="3$start"}
  %get-tuple-element.265 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.285), index=0
  %param_41 = f32[448]{0} parameter(41), metadata={op_name="3$start"}
  %get-tuple-element.244 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.229), index=0
  %param_35 = f32[896]{0} parameter(35), metadata={op_name="3$start"}
  %get-tuple-element.268 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.281), index=0
  %param_38 = f32[1792]{0} parameter(38), metadata={op_name="3$start"}
  %get-tuple-element.276 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.301), index=1
  %param_44 = f32[896]{0} parameter(44), metadata={op_name="3$start"}
  %get-tuple-element.247 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.225), index=0
  %param_53 = f32[224]{0} parameter(53), metadata={op_name="3$start"}
  %get-tuple-element.223 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.158), index=0
  %param_56 = f32[448]{0} parameter(56), metadata={op_name="3$start"}
  %get-tuple-element.226 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.154), index=0
  %param_59 = f32[896]{0} parameter(59), metadata={op_name="3$start"}
  %get-tuple-element.231 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.174), index=2
  %param_68 = f32[224]{0} parameter(68), metadata={op_name="3$start"}
  %get-tuple-element.203 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.68), index=0
  %param_71 = f32[448]{0} parameter(71), metadata={op_name="3$start"}
  %get-tuple-element.206 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.64), index=0
  %param_74 = f32[896]{0} parameter(74), metadata={op_name="3$start"}
  %get-tuple-element.214 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.100), index=1
  %param_77 = f32[224]{0} parameter(77), metadata={op_name="3$start"}
  %get-tuple-element.179 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.9), index=0
  %param_80 = f32[224]{0} parameter(80), metadata={op_name="3$start"}
  %get-tuple-element.182 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.5), index=0
  %param_83 = f32[448]{0} parameter(83), metadata={op_name="3$start"}
  %get-tuple-element.185 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.1), index=0
  %param_29 = f32[1792]{0} parameter(29), metadata={op_name="3$start"}
  %get-tuple-element.289 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.358), index=2
  %param_2 = f32[896]{0} parameter(2), metadata={op_name="3$start"}
  %get-tuple-element.315 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.471), index=0
  %param_5 = f32[1792]{0} parameter(5), metadata={op_name="3$start"}
  %get-tuple-element.318 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.467), index=0
  %param_14 = f32[448]{0} parameter(14), metadata={op_name="3$start"}
  %get-tuple-element.296 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.401), index=0
  %param_17 = f32[896]{0} parameter(17), metadata={op_name="3$start"}
  %get-tuple-element.299 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.397), index=0
  %param_20 = f32[1792]{0} parameter(20), metadata={op_name="3$start"}
  %get-tuple-element.304 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.417), index=2
  %param_23 = f32[448]{0} parameter(23), metadata={op_name="3$start"}
  %get-tuple-element.281 = f32[16,448]{1,0} get-tuple-element((f32[16,448]{1,0}, f32[16,448]{1,0}, f32[16,448]{1,0}) %fusion.342), index=0
  %param_26 = f32[896]{0} parameter(26), metadata={op_name="3$start"}
  %get-tuple-element.284 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.338), index=0
  %fusion.526 = (f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) fusion(f32[448]{0} %param_32, f32[16,448]{1,0} %get-tuple-element.265, f32[448]{0} %param_41, f32[16,448]{1,0} %get-tuple-element.244, f32[896]{0} %param_35, /*index=5*/f32[16,896]{1,0} %get-tuple-element.268, f32[1792]{0} %param_38, f32[16,1792]{1,0} %get-tuple-element.276, f32[896]{0} %param_44, f32[16,896]{1,0} %get-tuple-element.247, /*index=10*/f32[224]{0} %param_53, f32[16,224]{1,0} %get-tuple-element.223, f32[448]{0} %param_56, f32[16,448]{1,0} %get-tuple-element.226, f32[896]{0} %param_59, /*index=15*/f32[16,896]{1,0} %get-tuple-element.231, f32[224]{0} %param_68, f32[16,224]{1,0} %get-tuple-element.203, f32[448]{0} %param_71, f32[16,448]{1,0} %get-tuple-element.206, /*index=20*/f32[896]{0} %param_74, f32[16,896]{1,0} %get-tuple-element.214, f32[224]{0} %param_77, f32[16,224]{1,0} %get-tuple-element.179, f32[224]{0} %param_80, /*index=25*/f32[16,224]{1,0} %get-tuple-element.182, f32[448]{0} %param_83, f32[16,448]{1,0} %get-tuple-element.185, f32[1792]{0} %param_29, f32[16,1792]{1,0} %get-tuple-element.289, /*index=30*/f32[896]{0} %param_2, f32[16,896]{1,0} %get-tuple-element.315, f32[1792]{0} %param_5, f32[16,1792]{1,0} %get-tuple-element.318, f32[448]{0} %param_14, /*index=35*/f32[16,448]{1,0} %get-tuple-element.296, f32[896]{0} %param_17, f32[16,896]{1,0} %get-tuple-element.299, f32[1792]{0} %param_20, f32[16,1792]{1,0} %get-tuple-element.304, /*index=40*/f32[448]{0} %param_23, f32[16,448]{1,0} %get-tuple-element.281, f32[896]{0} %param_26, f32[16,896]{1,0} %get-tuple-element.284), kind=kInput, calls=%horizontally_fused_computation.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %get-tuple-element.389 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=15, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %cudnn-conv-bw-filter.2 = (f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,29,29,896]{2,1,3,0} %fusion.507, f32[16,14,14,1792]{2,1,3,0} %fusion.480), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.7 = f32[3,3,896,1792]{1,0,2,3} get-tuple-element((f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.2), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_3 = f32[3,3,896,1792]{3,2,1,0} parameter(3), metadata={op_name="3$start"}
  %fusion.469 = f32[3,3,896,1792]{3,2,1,0} fusion(f32[3,3,896,1792]{1,0,2,3} %get-tuple-element.7, f32[3,3,896,1792]{3,2,1,0} %param_3), kind=kLoop, calls=%fused_computation.469, metadata={op_name="tuple.85"}
  %get-tuple-element.391 = f32[1792]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %get-tuple-element.392 = f32[1792]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=16, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %cudnn-conv-bw-filter.1 = (f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.497, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.329), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.5 = f32[1,1,1792,3584]{1,0,2,3} get-tuple-element((f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.1), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_6 = f32[1,1,1792,3584]{3,2,1,0} parameter(6), metadata={op_name="3$start"}
  %fusion.465 = f32[1,1,1792,3584]{3,2,1,0} fusion(f32[1,1,1792,3584]{1,0,2,3} %get-tuple-element.5, f32[1,1,1792,3584]{3,2,1,0} %param_6), kind=kLoop, calls=%fused_computation.465, metadata={op_name="tuple.85"}
  %get-tuple-element.394 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}) %fusion.464), index=0
  %param_8 = f32[3584]{0} parameter(8), metadata={op_name="3$start"}
  %bitcast.2628 = f32[3136,3584]{1,0} bitcast(f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.595)
  %fusion.463 = f32[3584]{0} fusion(f32[3136,3584]{1,0} %bitcast.2628), kind=kInput, calls=%fused_computation.463.clone, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %param_11 = f32[3584]{0} parameter(11), metadata={op_name="3$start"}
  %param_50 = f32[1792]{0} parameter(50), metadata={op_name="3$start"}
  %param_47 = f32[1792]{0} parameter(47), metadata={op_name="3$start"}
  %get-tuple-element.256 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.211), index=2
  %param_62 = f32[896]{0} parameter(62), metadata={op_name="3$start"}
  %get-tuple-element.200 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.82), index=4
  %fusion.528 = (f32[1792]{0}, f32[1792]{0}, f32[896]{0}, f32[896]{0}) fusion(f32[1792]{0} %param_47, f32[16,1792]{1,0} %get-tuple-element.256, f32[896]{0} %param_62, f32[16,896]{1,0} %get-tuple-element.200), kind=kInput, calls=%horizontally_fused_computation.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %get-tuple-element.243 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[896]{0}, f32[896]{0}) %fusion.528), index=1
  %param_65 = f32[896]{0} parameter(65), metadata={op_name="3$start"}
  %get-tuple-element.195 = f32[896]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[896]{0}, f32[896]{0}) %fusion.528), index=3
  %fusion.525 = (f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}) fusion(f32[3584]{0} %param_8, f32[3584]{0} %fusion.463, f32[3584]{0} %param_11, f32[1792]{0} %param_50, f32[1792]{0} %get-tuple-element.243, /*index=5*/f32[896]{0} %param_65, f32[896]{0} %get-tuple-element.195), kind=kInput, calls=%horizontally_fused_computation, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %get-tuple-element.395 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}) %fusion.525), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %cudnn-conv-bw-filter = (f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %copy.8, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.330), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, -1), (0, -1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.1 = f32[1,1,1792,3584]{1,0,2,3} get-tuple-element((f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, -1), (0, -1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_9 = f32[1,1,1792,3584]{3,2,1,0} parameter(9), metadata={op_name="3$start"}
  %fusion.451 = f32[1,1,1792,3584]{3,2,1,0} fusion(f32[1,1,1792,3584]{1,0,2,3} %get-tuple-element.1, f32[1,1,1792,3584]{3,2,1,0} %param_9), kind=kLoop, calls=%fused_computation.451, metadata={op_name="tuple.85"}
  %get-tuple-element.397 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}) %fusion.450), index=0
  %get-tuple-element.398 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}) %fusion.525), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(30)/add"}
  %cudnn-conv-bw-filter.6 = (f32[1,1,1792,448]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %copy.27, f32[16,28,28,448]{2,1,3,0} %fusion.404), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 28, 28, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.19 = f32[1,1,1792,448]{1,0,2,3} get-tuple-element((f32[1,1,1792,448]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.6), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 28, 28, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_12 = f32[1,1,1792,448]{3,2,1,0} parameter(12), metadata={op_name="3$start"}
  %fusion.403 = f32[1,1,1792,448]{3,2,1,0} fusion(f32[1,1,1792,448]{1,0,2,3} %get-tuple-element.19, f32[1,1,1792,448]{3,2,1,0} %param_12), kind=kLoop, calls=%fused_computation.403, metadata={op_name="tuple.85"}
  %get-tuple-element.400 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %get-tuple-element.401 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=17, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %cudnn-conv-bw-filter.5 = (f32[3,3,448,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.440, f32[16,28,28,896]{2,1,3,0} %fusion.410), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.17 = f32[3,3,448,896]{1,0,2,3} get-tuple-element((f32[3,3,448,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.5), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_15 = f32[3,3,448,896]{3,2,1,0} parameter(15), metadata={op_name="3$start"}
  %fusion.399 = f32[3,3,448,896]{3,2,1,0} fusion(f32[3,3,448,896]{1,0,2,3} %get-tuple-element.17, f32[3,3,448,896]{3,2,1,0} %param_15), kind=kLoop, calls=%fused_computation.399, metadata={op_name="tuple.85"}
  %get-tuple-element.403 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %get-tuple-element.404 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=18, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %cudnn-conv-bw-filter.4 = (f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.430, f32[16,28,28,1792]{2,1,3,0} %fusion.416), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.15 = f32[1,1,896,1792]{1,0,2,3} get-tuple-element((f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.4), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_6/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_18 = f32[1,1,896,1792]{3,2,1,0} parameter(18), metadata={op_name="3$start"}
  %fusion.395 = f32[1,1,896,1792]{3,2,1,0} fusion(f32[1,1,896,1792]{1,0,2,3} %get-tuple-element.15, f32[1,1,896,1792]{3,2,1,0} %param_18), kind=kLoop, calls=%fused_computation.395, metadata={op_name="tuple.85"}
  %get-tuple-element.406 = f32[1792]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=14, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %get-tuple-element.407 = f32[1792]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=19, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(31)/add"}
  %cudnn-conv-bw-filter.9 = (f32[1,1,1792,448]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %fusion.391, f32[16,28,28,448]{2,1,3,0} %fusion.345), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 28, 28, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.28 = f32[1,1,1792,448]{1,0,2,3} get-tuple-element((f32[1,1,1792,448]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.9), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 28, 28, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_21 = f32[1,1,1792,448]{3,2,1,0} parameter(21), metadata={op_name="3$start"}
  %fusion.344 = f32[1,1,1792,448]{3,2,1,0} fusion(f32[1,1,1792,448]{1,0,2,3} %get-tuple-element.28, f32[1,1,1792,448]{3,2,1,0} %param_21), kind=kLoop, calls=%fused_computation.344, metadata={op_name="tuple.85"}
  %get-tuple-element.409 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=18, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %get-tuple-element.410 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=20, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %cudnn-conv-bw-filter.8 = (f32[3,3,448,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.381, f32[16,28,28,896]{2,1,3,0} %fusion.351), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.26 = f32[3,3,448,896]{1,0,2,3} get-tuple-element((f32[3,3,448,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_24 = f32[3,3,448,896]{3,2,1,0} parameter(24), metadata={op_name="3$start"}
  %fusion.340 = f32[3,3,448,896]{3,2,1,0} fusion(f32[3,3,448,896]{1,0,2,3} %get-tuple-element.26, f32[3,3,448,896]{3,2,1,0} %param_24), kind=kLoop, calls=%fused_computation.340, metadata={op_name="tuple.85"}
  %get-tuple-element.412 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=21, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %get-tuple-element.413 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=21, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %cudnn-conv-bw-filter.7 = (f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.371, f32[16,28,28,1792]{2,1,3,0} %fusion.357), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.24 = f32[1,1,896,1792]{1,0,2,3} get-tuple-element((f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.7), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_5/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_27 = f32[1,1,896,1792]{3,2,1,0} parameter(27), metadata={op_name="3$start"}
  %fusion.336 = f32[1,1,896,1792]{3,2,1,0} fusion(f32[1,1,896,1792]{1,0,2,3} %get-tuple-element.24, f32[1,1,896,1792]{3,2,1,0} %param_27), kind=kLoop, calls=%fused_computation.336, metadata={op_name="tuple.85"}
  %get-tuple-element.415 = f32[1792]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %get-tuple-element.416 = f32[1792]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=14, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(32)/add"}
  %cudnn-conv-bw-filter.12 = (f32[1,1,1792,448]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,1792]{2,1,3,0} %fusion.331, f32[16,28,28,448]{2,1,3,0} %fusion.288), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 28, 28, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.37 = f32[1,1,1792,448]{1,0,2,3} get-tuple-element((f32[1,1,1792,448]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.12), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 1792) rhs_shape=(16, 28, 28, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_30 = f32[1,1,1792,448]{3,2,1,0} parameter(30), metadata={op_name="3$start"}
  %fusion.287 = f32[1,1,1792,448]{3,2,1,0} fusion(f32[1,1,1792,448]{1,0,2,3} %get-tuple-element.37, f32[1,1,1792,448]{3,2,1,0} %param_30), kind=kLoop, calls=%fused_computation.287, metadata={op_name="tuple.85"}
  %get-tuple-element.418 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %get-tuple-element.419 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %cudnn-conv-bw-filter.11 = (f32[3,3,448,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,448]{2,1,3,0} %fusion.321, f32[16,28,28,896]{2,1,3,0} %fusion.294), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.35 = f32[3,3,448,896]{1,0,2,3} get-tuple-element((f32[3,3,448,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.11), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 448) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_33 = f32[3,3,448,896]{3,2,1,0} parameter(33), metadata={op_name="3$start"}
  %fusion.283 = f32[3,3,448,896]{3,2,1,0} fusion(f32[3,3,448,896]{1,0,2,3} %get-tuple-element.35, f32[3,3,448,896]{3,2,1,0} %param_33), kind=kLoop, calls=%fused_computation.283, metadata={op_name="tuple.85"}
  %get-tuple-element.421 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %get-tuple-element.422 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %cudnn-conv-bw-filter.10 = (f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.311, f32[16,28,28,1792]{2,1,3,0} %fusion.300), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.33 = f32[1,1,896,1792]{1,0,2,3} get-tuple-element((f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.10), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_4/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_36 = f32[1,1,896,1792]{3,2,1,0} parameter(36), metadata={op_name="3$start"}
  %fusion.279 = f32[1,1,896,1792]{3,2,1,0} fusion(f32[1,1,896,1792]{1,0,2,3} %get-tuple-element.33, f32[1,1,896,1792]{3,2,1,0} %param_36), kind=kLoop, calls=%fused_computation.279, metadata={op_name="tuple.85"}
  %get-tuple-element.424 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}) %fusion.278), index=0
  %get-tuple-element.425 = f32[1792]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(33)/add"}
  %cudnn-conv-bw-filter.16 = (f32[1,1,896,448]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %copy.60, f32[16,56,56,448]{2,1,3,0} %fusion.232), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(16, 56, 56, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.48 = f32[1,1,896,448]{1,0,2,3} get-tuple-element((f32[1,1,896,448]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.16), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(16, 56, 56, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_39 = f32[1,1,896,448]{3,2,1,0} parameter(39), metadata={op_name="3$start"}
  %fusion.231 = f32[1,1,896,448]{3,2,1,0} fusion(f32[1,1,896,448]{1,0,2,3} %get-tuple-element.48, f32[1,1,896,448]{3,2,1,0} %param_39), kind=kLoop, calls=%fused_computation.231, metadata={op_name="tuple.85"}
  %get-tuple-element.427 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=16, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %get-tuple-element.428 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %cudnn-conv-bw-filter.15 = (f32[3,3,448,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,57,57,448]{2,1,3,0} %fusion.265, f32[16,28,28,896]{2,1,3,0} %fusion.238), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.46 = f32[3,3,448,896]{1,0,2,3} get-tuple-element((f32[3,3,448,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.15), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(16, 28, 28, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_42 = f32[3,3,448,896]{3,2,1,0} parameter(42), metadata={op_name="3$start"}
  %fusion.227 = f32[3,3,448,896]{3,2,1,0} fusion(f32[3,3,448,896]{1,0,2,3} %get-tuple-element.46, f32[3,3,448,896]{3,2,1,0} %param_42), kind=kLoop, calls=%fused_computation.227, metadata={op_name="tuple.85"}
  %get-tuple-element.430 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %get-tuple-element.431 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %cudnn-conv-bw-filter.14 = (f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,28,28,896]{2,1,3,0} %fusion.255, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.259), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.44 = f32[1,1,896,1792]{1,0,2,3} get-tuple-element((f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.14), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 28, 28, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_45 = f32[1,1,896,1792]{3,2,1,0} parameter(45), metadata={op_name="3$start"}
  %fusion.223 = f32[1,1,896,1792]{3,2,1,0} fusion(f32[1,1,896,1792]{1,0,2,3} %get-tuple-element.44, f32[1,1,896,1792]{3,2,1,0} %param_45), kind=kLoop, calls=%fused_computation.223, metadata={op_name="tuple.85"}
  %get-tuple-element.433 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}) %fusion.222), index=0
  %get-tuple-element.434 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[896]{0}, f32[896]{0}) %fusion.528), index=0
  %cudnn-conv-bw-filter.13 = (f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %copy.60, f32[16,28,28,1792]{2,1,3,0} %get-tuple-element.260), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, -1), (0, -1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.40 = f32[1,1,896,1792]{1,0,2,3} get-tuple-element((f32[1,1,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.13), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_3/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, -1), (0, -1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(16, 28, 28, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_48 = f32[1,1,896,1792]{3,2,1,0} parameter(48), metadata={op_name="3$start"}
  %fusion.209 = f32[1,1,896,1792]{3,2,1,0} fusion(f32[1,1,896,1792]{1,0,2,3} %get-tuple-element.40, f32[1,1,896,1792]{3,2,1,0} %param_48), kind=kLoop, calls=%fused_computation.209, metadata={op_name="tuple.85"}
  %get-tuple-element.436 = f32[1792]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}) %fusion.208), index=0
  %get-tuple-element.437 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}) %fusion.525), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(34)/add"}
  %cudnn-conv-bw-filter.19 = (f32[1,1,896,224]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %fusion.207, f32[16,56,56,224]{2,1,3,0} %fusion.161), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(16, 56, 56, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.58 = f32[1,1,896,224]{1,0,2,3} get-tuple-element((f32[1,1,896,224]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.19), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(16, 56, 56, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_51 = f32[1,1,896,224]{3,2,1,0} parameter(51), metadata={op_name="3$start"}
  %fusion.160 = f32[1,1,896,224]{3,2,1,0} fusion(f32[1,1,896,224]{1,0,2,3} %get-tuple-element.58, f32[1,1,896,224]{3,2,1,0} %param_51), kind=kLoop, calls=%fused_computation.160, metadata={op_name="tuple.85"}
  %get-tuple-element.439 = f32[224]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=19, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %get-tuple-element.440 = f32[224]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %cudnn-conv-bw-filter.18 = (f32[3,3,224,448]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.197, f32[16,56,56,448]{2,1,3,0} %fusion.167), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.56 = f32[3,3,224,448]{1,0,2,3} get-tuple-element((f32[3,3,224,448]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.18), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_54 = f32[3,3,224,448]{3,2,1,0} parameter(54), metadata={op_name="3$start"}
  %fusion.156 = f32[3,3,224,448]{3,2,1,0} fusion(f32[3,3,224,448]{1,0,2,3} %get-tuple-element.56, f32[3,3,224,448]{3,2,1,0} %param_54), kind=kLoop, calls=%fused_computation.156, metadata={op_name="tuple.85"}
  %get-tuple-element.442 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=17, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %get-tuple-element.443 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %cudnn-conv-bw-filter.17 = (f32[1,1,448,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %fusion.187, f32[16,56,56,896]{2,1,3,0} %fusion.173), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(16, 56, 56, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.54 = f32[1,1,448,896]{1,0,2,3} get-tuple-element((f32[1,1,448,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.17), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_2/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(16, 56, 56, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_57 = f32[1,1,448,896]{3,2,1,0} parameter(57), metadata={op_name="3$start"}
  %fusion.152 = f32[1,1,448,896]{3,2,1,0} fusion(f32[1,1,448,896]{1,0,2,3} %get-tuple-element.54, f32[1,1,448,896]{3,2,1,0} %param_57), kind=kLoop, calls=%fused_computation.152, metadata={op_name="tuple.85"}
  %get-tuple-element.445 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=15, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %get-tuple-element.446 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(35)/add"}
  %cudnn-conv-bw-filter.24 = (f32[1,1,448,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %copy.91, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.201), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(16, 56, 56, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.72 = f32[1,1,448,896]{1,0,2,3} get-tuple-element((f32[1,1,448,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.24), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(16, 56, 56, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_60 = f32[1,1,448,896]{3,2,1,0} parameter(60), metadata={op_name="3$start"}
  %fusion.80 = f32[1,1,448,896]{3,2,1,0} fusion(f32[1,1,448,896]{1,0,2,3} %get-tuple-element.72, f32[1,1,448,896]{3,2,1,0} %param_60), kind=kLoop, calls=%fused_computation.80, metadata={op_name="tuple.85"}
  %get-tuple-element.448 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=13, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %get-tuple-element.449 = f32[896]{0} get-tuple-element((f32[1792]{0}, f32[1792]{0}, f32[896]{0}, f32[896]{0}) %fusion.528), index=2
  %cudnn-conv-bw-filter.23 = (f32[1,1,224,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %copy.81, f32[16,56,56,896]{2,1,3,0} %get-tuple-element.202), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.71 = f32[1,1,224,896]{1,0,2,3} get-tuple-element((f32[1,1,224,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.23), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_63 = f32[1,1,224,896]{3,2,1,0} parameter(63), metadata={op_name="3$start"}
  %fusion.72 = f32[1,1,224,896]{3,2,1,0} fusion(f32[1,1,224,896]{1,0,2,3} %get-tuple-element.71, f32[1,1,224,896]{3,2,1,0} %param_63), kind=kLoop, calls=%fused_computation.72, metadata={op_name="tuple.85"}
  %get-tuple-element.451 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=12, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %get-tuple-element.452 = f32[896]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}) %fusion.525), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %cudnn-conv-bw-filter.22 = (f32[1,1,896,224]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,896]{2,1,3,0} %fusion.130, f32[16,56,56,224]{2,1,3,0} %fusion.87), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(16, 56, 56, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.69 = f32[1,1,896,224]{1,0,2,3} get-tuple-element((f32[1,1,896,224]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.22), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 896) rhs_shape=(16, 56, 56, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_66 = f32[1,1,896,224]{3,2,1,0} parameter(66), metadata={op_name="3$start"}
  %fusion.70 = f32[1,1,896,224]{3,2,1,0} fusion(f32[1,1,896,224]{1,0,2,3} %get-tuple-element.69, f32[1,1,896,224]{3,2,1,0} %param_66), kind=kLoop, calls=%fused_computation.70, metadata={op_name="tuple.85"}
  %get-tuple-element.454 = f32[224]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %get-tuple-element.455 = f32[224]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %cudnn-conv-bw-filter.21 = (f32[3,3,224,448]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.120, f32[16,56,56,448]{2,1,3,0} %fusion.93), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.67 = f32[3,3,224,448]{1,0,2,3} get-tuple-element((f32[3,3,224,448]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.21), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_69 = f32[3,3,224,448]{3,2,1,0} parameter(69), metadata={op_name="3$start"}
  %fusion.66 = f32[3,3,224,448]{3,2,1,0} fusion(f32[3,3,224,448]{1,0,2,3} %get-tuple-element.67, f32[3,3,224,448]{3,2,1,0} %param_69), kind=kLoop, calls=%fused_computation.66, metadata={op_name="tuple.85"}
  %get-tuple-element.457 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %get-tuple-element.458 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %cudnn-conv-bw-filter.20 = (f32[1,1,448,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,448]{2,1,3,0} %fusion.110, f32[16,56,56,896]{2,1,3,0} %fusion.99), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(16, 56, 56, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.65 = f32[1,1,448,896]{1,0,2,3} get-tuple-element((f32[1,1,448,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.20), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_1/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 448) rhs_shape=(16, 56, 56, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_72 = f32[1,1,448,896]{3,2,1,0} parameter(72), metadata={op_name="3$start"}
  %fusion.62 = f32[1,1,448,896]{3,2,1,0} fusion(f32[1,1,448,896]{1,0,2,3} %get-tuple-element.65, f32[1,1,448,896]{3,2,1,0} %param_72), kind=kLoop, calls=%fused_computation.62, metadata={op_name="tuple.85"}
  %get-tuple-element.460 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[896]{0}) %fusion.61), index=0
  %get-tuple-element.461 = f32[896]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(36)/add"}
  %get-tuple-element.180 = f32[16,224]{1,0} get-tuple-element((f32[16,224]{1,0}, f32[16,224]{1,0}, f32[16,224]{1,0}) %fusion.9), index=1
  %reduce.388 = f32[224]{0} reduce(f32[16,224]{1,0} %get-tuple-element.180, f32[] %constant_708), dimensions={0}, to_apply=%region_63.4346.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.12 = f32[16,112,112,224]{2,1,3,0} fusion(f32[224]{0} %reduce.388, f32[224]{0} %reduce.377, f32[16,112,112,224]{2,1,3,0} %get-tuple-element.75, f32[224]{0} %fusion.53, f32[1,1,1,224]{3,2,1,0} %fusion.14, /*index=5*/f32[224]{0} %get-tuple-element.764, f32[16,113,113,224]{2,1,3,0} %select-and-scatter.1, f32[224]{0} %get-tuple-element.765), kind=kLoop, calls=%fused_computation.12, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/bn_init/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-filter.27 = (f32[7,7,3,224]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,224,224,3]{2,1,3,0} %fusion.58, f32[16,112,112,224]{2,1,3,0} %fusion.12), window={size=7x7 stride=2x2 pad=3_3x3_3}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/conv_init/conv_general_dilated[window_strides=(1, 1) padding=((3, 2), (3, 2)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 224, 224, 3) rhs_shape=(16, 112, 112, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.82 = f32[7,7,3,224]{1,0,2,3} get-tuple-element((f32[7,7,3,224]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.27), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/conv_init/conv_general_dilated[window_strides=(1, 1) padding=((3, 2), (3, 2)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 224, 224, 3) rhs_shape=(16, 112, 112, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_75 = f32[7,7,3,224]{3,2,1,0} parameter(75), metadata={op_name="3$start"}
  %fusion.11 = f32[7,7,3,224]{3,2,1,0} fusion(f32[7,7,3,224]{1,0,2,3} %get-tuple-element.82, f32[7,7,3,224]{3,2,1,0} %param_75), kind=kLoop, calls=%fused_computation.11, metadata={op_name="tuple.85"}
  %get-tuple-element.463 = f32[224]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %get-tuple-element.464 = f32[224]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %cudnn-conv-bw-filter.26 = (f32[1,1,224,224]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.518, f32[16,56,56,224]{2,1,3,0} %fusion.18), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.80 = f32[1,1,224,224]{1,0,2,3} get-tuple-element((f32[1,1,224,224]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.26), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 224) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_78 = f32[1,1,224,224]{3,2,1,0} parameter(78), metadata={op_name="3$start"}
  %fusion.7 = f32[1,1,224,224]{3,2,1,0} fusion(f32[1,1,224,224]{1,0,2,3} %get-tuple-element.80, f32[1,1,224,224]{3,2,1,0} %param_78), kind=kLoop, calls=%fused_computation.7, metadata={op_name="tuple.85"}
  %get-tuple-element.466 = f32[224]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %get-tuple-element.467 = f32[224]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=12, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %cudnn-conv-bw-filter.25 = (f32[3,3,224,448]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,56,56,224]{2,1,3,0} %fusion.38, f32[16,56,56,448]{2,1,3,0} %fusion.24), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.78 = f32[3,3,224,448]{1,0,2,3} get-tuple-element((f32[3,3,224,448]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.25), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_0/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 56, 56, 224) rhs_shape=(16, 56, 56, 448) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_81 = f32[3,3,224,448]{3,2,1,0} parameter(81), metadata={op_name="3$start"}
  %fusion.3 = f32[3,3,224,448]{3,2,1,0} fusion(f32[3,3,224,448]{1,0,2,3} %get-tuple-element.78, f32[3,3,224,448]{3,2,1,0} %param_81), kind=kLoop, calls=%fused_computation.3, metadata={op_name="tuple.85"}
  %get-tuple-element.469 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[896]{0}, f32[448]{0}, f32[1792]{0}, f32[224]{0}, /*index=5*/f32[896]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[896]{0}, f32[896]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[448]{0}, f32[448]{0}, f32[448]{0}, f32[224]{0}, /*index=20*/f32[896]{0}, f32[896]{0}) %fusion.527), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  %get-tuple-element.470 = f32[448]{0} get-tuple-element((f32[448]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=5*/f32[224]{0}, f32[448]{0}, f32[896]{0}, f32[224]{0}, f32[448]{0}, /*index=10*/f32[896]{0}, f32[224]{0}, f32[224]{0}, f32[448]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[448]{0}, f32[896]{0}, f32[1792]{0}, /*index=20*/f32[448]{0}, f32[896]{0}) %fusion.526), index=13, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_0)/jit(main)/jit(3)/jit(37)/add"}
  ROOT %tuple.148 = (f32[1,1,1792,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=10*/f32[3584]{0}, f32[3584]{0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, /*index=15*/f32[3,3,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, /*index=20*/f32[1792]{0}, f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, /*index=25*/f32[896]{0}, f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=30*/f32[1,1,1792,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, f32[896]{0}, /*index=35*/f32[896]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[1,1,896,448]{3,2,1,0}, /*index=40*/f32[448]{0}, f32[448]{0}, f32[3,3,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=45*/f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[1,1,896,1792]{3,2,1,0}, f32[1792]{0}, /*index=50*/f32[1792]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=55*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=60*/f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[1,1,224,896]{3,2,1,0}, f32[896]{0}, /*index=65*/f32[896]{0}, f32[1,1,896,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, /*index=70*/f32[448]{0}, f32[448]{0}, f32[1,1,448,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=75*/f32[7,7,3,224]{3,2,1,0}, f32[224]{0}, f32[224]{0}, f32[1,1,224,224]{3,2,1,0}, f32[224]{0}, /*index=80*/f32[224]{0}, f32[3,3,224,448]{3,2,1,0}, f32[448]{0}, f32[448]{0}) tuple(f32[1,1,1792,896]{3,2,1,0} %fusion.473, f32[896]{0} %get-tuple-element.388, f32[896]{0} %get-tuple-element.389, f32[3,3,896,1792]{3,2,1,0} %fusion.469, f32[1792]{0} %get-tuple-element.391, /*index=5*/f32[1792]{0} %get-tuple-element.392, f32[1,1,1792,3584]{3,2,1,0} %fusion.465, f32[3584]{0} %get-tuple-element.394, f32[3584]{0} %get-tuple-element.395, f32[1,1,1792,3584]{3,2,1,0} %fusion.451, /*index=10*/f32[3584]{0} %get-tuple-element.397, f32[3584]{0} %get-tuple-element.398, f32[1,1,1792,448]{3,2,1,0} %fusion.403, f32[448]{0} %get-tuple-element.400, f32[448]{0} %get-tuple-element.401, /*index=15*/f32[3,3,448,896]{3,2,1,0} %fusion.399, f32[896]{0} %get-tuple-element.403, f32[896]{0} %get-tuple-element.404, f32[1,1,896,1792]{3,2,1,0} %fusion.395, f32[1792]{0} %get-tuple-element.406, /*index=20*/f32[1792]{0} %get-tuple-element.407, f32[1,1,1792,448]{3,2,1,0} %fusion.344, f32[448]{0} %get-tuple-element.409, f32[448]{0} %get-tuple-element.410, f32[3,3,448,896]{3,2,1,0} %fusion.340, /*index=25*/f32[896]{0} %get-tuple-element.412, f32[896]{0} %get-tuple-element.413, f32[1,1,896,1792]{3,2,1,0} %fusion.336, f32[1792]{0} %get-tuple-element.415, f32[1792]{0} %get-tuple-element.416, /*index=30*/f32[1,1,1792,448]{3,2,1,0} %fusion.287, f32[448]{0} %get-tuple-element.418, f32[448]{0} %get-tuple-element.419, f32[3,3,448,896]{3,2,1,0} %fusion.283, f32[896]{0} %get-tuple-element.421, /*index=35*/f32[896]{0} %get-tuple-element.422, f32[1,1,896,1792]{3,2,1,0} %fusion.279, f32[1792]{0} %get-tuple-element.424, f32[1792]{0} %get-tuple-element.425, f32[1,1,896,448]{3,2,1,0} %fusion.231, /*index=40*/f32[448]{0} %get-tuple-element.427, f32[448]{0} %get-tuple-element.428, f32[3,3,448,896]{3,2,1,0} %fusion.227, f32[896]{0} %get-tuple-element.430, f32[896]{0} %get-tuple-element.431, /*index=45*/f32[1,1,896,1792]{3,2,1,0} %fusion.223, f32[1792]{0} %get-tuple-element.433, f32[1792]{0} %get-tuple-element.434, f32[1,1,896,1792]{3,2,1,0} %fusion.209, f32[1792]{0} %get-tuple-element.436, /*index=50*/f32[1792]{0} %get-tuple-element.437, f32[1,1,896,224]{3,2,1,0} %fusion.160, f32[224]{0} %get-tuple-element.439, f32[224]{0} %get-tuple-element.440, f32[3,3,224,448]{3,2,1,0} %fusion.156, /*index=55*/f32[448]{0} %get-tuple-element.442, f32[448]{0} %get-tuple-element.443, f32[1,1,448,896]{3,2,1,0} %fusion.152, f32[896]{0} %get-tuple-element.445, f32[896]{0} %get-tuple-element.446, /*index=60*/f32[1,1,448,896]{3,2,1,0} %fusion.80, f32[896]{0} %get-tuple-element.448, f32[896]{0} %get-tuple-element.449, f32[1,1,224,896]{3,2,1,0} %fusion.72, f32[896]{0} %get-tuple-element.451, /*index=65*/f32[896]{0} %get-tuple-element.452, f32[1,1,896,224]{3,2,1,0} %fusion.70, f32[224]{0} %get-tuple-element.454, f32[224]{0} %get-tuple-element.455, f32[3,3,224,448]{3,2,1,0} %fusion.66, /*index=70*/f32[448]{0} %get-tuple-element.457, f32[448]{0} %get-tuple-element.458, f32[1,1,448,896]{3,2,1,0} %fusion.62, f32[896]{0} %get-tuple-element.460, f32[896]{0} %get-tuple-element.461, /*index=75*/f32[7,7,3,224]{3,2,1,0} %fusion.11, f32[224]{0} %get-tuple-element.463, f32[224]{0} %get-tuple-element.464, f32[1,1,224,224]{3,2,1,0} %fusion.7, f32[224]{0} %get-tuple-element.466, /*index=80*/f32[224]{0} %get-tuple-element.467, f32[3,3,224,448]{3,2,1,0} %fusion.3, f32[448]{0} %get-tuple-element.469, f32[448]{0} %get-tuple-element.470)
}

