HloModule train_step_func_pipeshard_parallel_mesh_1-2, input_output_alias={ {0}: (0, {}, may-alias), {1}: (1, {}, may-alias), {2}: (2, {}, may-alias), {3}: (3, {}, may-alias), {4}: (4, {}, may-alias), {5}: (5, {}, may-alias), {6}: (6, {}, may-alias), {7}: (7, {}, may-alias), {8}: (8, {}, may-alias), {9}: (9, {}, may-alias), {10}: (10, {}, may-alias), {11}: (11, {}, may-alias), {12}: (12, {}, may-alias), {13}: (13, {}, may-alias), {14}: (14, {}, may-alias), {15}: (15, {}, may-alias), {16}: (16, {}, may-alias), {17}: (17, {}, may-alias), {18}: (18, {}, may-alias), {19}: (19, {}, may-alias), {20}: (20, {}, may-alias), {21}: (21, {}, may-alias), {22}: (22, {}, may-alias), {23}: (23, {}, may-alias), {24}: (24, {}, may-alias), {25}: (25, {}, may-alias), {26}: (26, {}, may-alias), {27}: (27, {}, may-alias), {28}: (28, {}, may-alias), {29}: (29, {}, may-alias), {30}: (30, {}, may-alias), {31}: (31, {}, may-alias), {32}: (32, {}, may-alias), {33}: (33, {}, may-alias), {34}: (34, {}, may-alias), {35}: (35, {}, may-alias), {36}: (36, {}, may-alias), {37}: (37, {}, may-alias), {38}: (38, {}, may-alias), {39}: (39, {}, may-alias), {40}: (40, {}, may-alias), {41}: (41, {}, may-alias), {42}: (42, {}, may-alias), {43}: (43, {}, may-alias), {44}: (44, {}, may-alias), {45}: (45, {}, may-alias), {46}: (46, {}, may-alias), {47}: (47, {}, may-alias), {48}: (48, {}, may-alias), {49}: (49, {}, may-alias), {50}: (50, {}, may-alias), {51}: (51, {}, may-alias), {52}: (52, {}, may-alias), {53}: (53, {}, may-alias), {54}: (54, {}, may-alias), {55}: (55, {}, may-alias), {56}: (56, {}, may-alias), {57}: (57, {}, may-alias), {58}: (58, {}, may-alias), {59}: (59, {}, may-alias), {60}: (60, {}, may-alias), {61}: (61, {}, may-alias), {62}: (62, {}, may-alias), {63}: (63, {}, may-alias), {64}: (64, {}, may-alias), {65}: (65, {}, may-alias), {66}: (66, {}, may-alias), {67}: (67, {}, may-alias), {68}: (68, {}, may-alias), {69}: (69, {}, may-alias), {70}: (70, {}, may-alias), {71}: (71, {}, may-alias), {72}: (72, {}, may-alias), {73}: (73, {}, may-alias), {74}: (74, {}, may-alias), {75}: (75, {}, may-alias), {76}: (76, {}, may-alias) }, entry_computation_layout={(f32[1,1,7168,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[7168,1024]{1,0},f32[1024]{0},f32[1,1,7168,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[1,1,3584,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},s32[16]{0},f32[16,7,7,7168]{3,2,1,0},f32[1,1,7168,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[7168,1024]{1,0},f32[1024]{0},f32[16,7,7,7168]{3,2,1,0},f32[1,1,7168,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[7168]{0},f32[16,14,14,3584]{3,2,1,0},f32[1,1,3584,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[3,3,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[1,1,3584,7168]{3,2,1,0},f32[7168]{0},f32[16,14,14,3584]{3,2,1,0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[16,14,14,3584]{3,2,1,0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[16,14,14,3584]{3,2,1,0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[16,14,14,3584]{3,2,1,0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0},f32[3584]{0},f32[16,14,14,3584]{3,2,1,0},f32[1,1,3584,896]{3,2,1,0},f32[896]{0},f32[896]{0},f32[3,3,896,1792]{3,2,1,0},f32[1792]{0},f32[1792]{0},f32[1,1,1792,3584]{3,2,1,0},f32[3584]{0})->(f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, f32[3584]{0}, /*index=5*/f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, f32[7168,1024]{1,0}, /*index=10*/f32[1024]{0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=15*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=20*/f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, f32[3584]{0}, /*index=25*/f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=30*/f32[7168]{0}, f32[7168]{0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=35*/f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, /*index=40*/f32[3584]{0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=45*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=50*/f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, /*index=55*/f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,896]{3,2,1,0}, /*index=60*/f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=65*/f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, /*index=70*/f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=75*/f32[3584]{0}, f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0})}

%region_64.4142.2 (Arg_0.4143: f32[], Arg_1.4144: f32[]) -> f32[] {
  %Arg_0.4143 = f32[] parameter(0)
  %Arg_1.4144 = f32[] parameter(1)
  ROOT %maximum.4145 = f32[] maximum(f32[] %Arg_0.4143, f32[] %Arg_1.4144), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/reduce_max[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
}

%region_57.4114.2 (Arg_0.4115: f32[], Arg_1.4116: f32[]) -> f32[] {
  %Arg_0.4115 = f32[] parameter(0)
  %Arg_1.4116 = f32[] parameter(1)
  ROOT %add.4117 = f32[] add(f32[] %Arg_0.4115, f32[] %Arg_1.4116), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation (param_0.3: f32[16,14,14,3584], param_1.3: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_1.3 = f32[16,14,14,3584]{2,1,3,0} parameter(1)
  %constant_165 = f32[] constant(0)
  %broadcast.289 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_165), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.0 = pred[16,14,14,3584]{2,1,3,0} compare(f32[16,14,14,3584]{2,1,3,0} %param_1.3, f32[16,14,14,3584]{2,1,3,0} %broadcast.289), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.3 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %select.0 = f32[16,14,14,3584]{2,1,3,0} select(pred[16,14,14,3584]{2,1,3,0} %compare.0, f32[16,14,14,3584]{2,1,3,0} %param_0.3, f32[16,14,14,3584]{2,1,3,0} %broadcast.289), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %copy.123 = f32[16,14,14,3584]{3,2,1,0} copy(f32[16,14,14,3584]{2,1,3,0} %select.0), metadata={op_name="tuple.79"}
}

%fused_computation.3 (param_0.7: f32[3584], param_1.1257: f32[1,1,1,3584], param_2.1614: f32[3584], param_3.1404: f32[16,3584]) -> (f32[3584], f32[3584]) {
  %param_0.7 = f32[3584]{0} parameter(0)
  %param_3.1404 = f32[16,3584]{1,0} parameter(3)
  %constant_2968 = f32[] constant(0)
  %reduce.644.clone.1 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_3.1404, f32[] %constant_2968), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_2944_clone_1 = f32[] constant(0.000318877544)
  %broadcast.322.clone.1 = f32[3584]{0} broadcast(f32[] %constant_2944_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.291.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %reduce.644.clone.1, f32[3584]{0} %broadcast.322.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1614 = f32[3584]{0} parameter(2)
  %multiply.2159.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_2.1614, f32[3584]{0} %broadcast.322.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.290.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %multiply.2159.clone.1, f32[3584]{0} %multiply.2159.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.1.clone.1 = f32[3584]{0} subtract(f32[3584]{0} %multiply.291.clone.1, f32[3584]{0} %multiply.290.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.3703 = f32[3584]{0} broadcast(f32[] %constant_2968), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.723 = f32[3584]{0} maximum(f32[3584]{0} %subtract.1.clone.1, f32[3584]{0} %broadcast.3703), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2967 = f32[] constant(1e-05)
  %broadcast.3702 = f32[3584]{0} broadcast(f32[] %constant_2967), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1188 = f32[3584]{0} add(f32[3584]{0} %maximum.723, f32[3584]{0} %broadcast.3702), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2142 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1188), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.0 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2142), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1257 = f32[1,1,1,3584]{3,2,1,0} parameter(1)
  %multiply.253 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.0, f32[1,1,1,3584]{3,2,1,0} %param_1.1257), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.542 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.253), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.26 = f32[3584]{0} add(f32[3584]{0} %param_0.7, f32[3584]{0} %bitcast.542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  ROOT %tuple.6 = (f32[3584]{0}, f32[3584]{0}) tuple(f32[3584]{0} %add.26, f32[3584]{0} %subtract.1.clone.1)
}

%fused_computation.4 (param_0.10: f32[1,1,1792,3584], param_1.12: f32[1,1,1792,3584]) -> f32[1,1,1792,3584] {
  %param_1.12 = f32[1,1,1792,3584]{3,2,1,0} parameter(1)
  %copy.125 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_1.12), metadata={op_name="2$start"}
  %param_0.10 = f32[1,1,1792,3584]{1,0,2,3} parameter(0)
  %add.27 = f32[1,1,1792,3584]{1,0,2,3} add(f32[1,1,1792,3584]{1,0,2,3} %copy.125, f32[1,1,1792,3584]{1,0,2,3} %param_0.10), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  ROOT %copy.124 = f32[1,1,1792,3584]{3,2,1,0} copy(f32[1,1,1792,3584]{1,0,2,3} %add.27), metadata={op_name="tuple.79"}
}

%fused_computation.6 (param_0.1604: f32[16,14,14,1792], param_1.2203: f32[1792], param_2.1576: f32[1792], param_3.1356: f32[1792], param_4.1191: f32[16,14,14,1792], param_5.1198: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.1191 = f32[16,14,14,1792]{2,1,3,0} parameter(4)
  %param_5.1198 = f32[1792]{0} parameter(5)
  %constant_3005 = f32[] constant(0.000318877544)
  %broadcast.3757 = f32[1792]{0} broadcast(f32[] %constant_3005), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2187 = f32[1792]{0} multiply(f32[1792]{0} %param_5.1198, f32[1792]{0} %broadcast.3757), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3756 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.2187), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.407 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_4.1191, f32[16,14,14,1792]{2,1,3,0} %broadcast.3756), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1356 = f32[1792]{0} parameter(3)
  %constant_169 = f32[] constant(0)
  %broadcast.3755 = f32[1792]{0} broadcast(f32[] %constant_169), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.733 = f32[1792]{0} maximum(f32[1792]{0} %param_3.1356, f32[1792]{0} %broadcast.3755), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3003 = f32[] constant(1e-05)
  %broadcast.3754 = f32[1792]{0} broadcast(f32[] %constant_3003), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1204 = f32[1792]{0} add(f32[1792]{0} %maximum.733, f32[1792]{0} %broadcast.3754), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2172 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1204), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.493 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2172), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1576 = f32[1792]{0} parameter(2)
  %bitcast.2171 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.1576), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2186 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.493, f32[1,1,1,1792]{3,2,1,0} %bitcast.2171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2170 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2186), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3753 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.2170), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2185 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.407, f32[16,14,14,1792]{2,1,3,0} %broadcast.3753), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2203 = f32[1792]{0} parameter(1)
  %broadcast.3752 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.2203), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1203 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.2185, f32[16,14,14,1792]{2,1,3,0} %broadcast.3752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3751 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_169), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.301 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.1203, f32[16,14,14,1792]{2,1,3,0} %broadcast.3751), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1604 = f32[16,14,14,1792]{2,1,3,0} parameter(0)
  %select.301 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.301, f32[16,14,14,1792]{2,1,3,0} %param_0.1604, f32[16,14,14,1792]{2,1,3,0} %broadcast.3751), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %select.301), dimensions={0,3,1,2}
  %bitcast.543 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.632 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.543, f32[] %constant_169), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.2203.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.301, f32[16,14,14,1792]{2,1,3,0} %broadcast.3753), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.4.clone.1 = f32[16,14,14,1792]{2,1,3,0} negate(f32[16,14,14,1792]{2,1,3,0} %multiply.2203.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.2 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %negate.4.clone.1), dimensions={0,3,1,2}
  %bitcast.552.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.2), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.638.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.552.clone.1, f32[] %constant_169), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.276.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.407, f32[16,14,14,1792]{2,1,3,0} %select.301), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.3 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %multiply.276.clone.1), dimensions={0,3,1,2}
  %bitcast.554.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.3), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.640.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.554.clone.1, f32[] %constant_169), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.5 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.632, f32[16,1792]{1,0} %reduce.638.clone.1, f32[16,1792]{1,0} %reduce.640.clone.1)
}

%fused_computation.8 (param_0.17: f32[3,3,896,1792], param_1.21: f32[3,3,896,1792]) -> f32[3,3,896,1792] {
  %param_1.21 = f32[3,3,896,1792]{3,2,1,0} parameter(1)
  %copy.127 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_1.21), metadata={op_name="2$start"}
  %param_0.17 = f32[3,3,896,1792]{1,0,2,3} parameter(0)
  %add.30 = f32[3,3,896,1792]{1,0,2,3} add(f32[3,3,896,1792]{1,0,2,3} %copy.127, f32[3,3,896,1792]{1,0,2,3} %param_0.17), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  ROOT %copy.126 = f32[3,3,896,1792]{3,2,1,0} copy(f32[3,3,896,1792]{1,0,2,3} %add.30), metadata={op_name="tuple.79"}
}

%fused_computation.10 (param_0.1615: f32[16,14,14,896], param_1.2221: f32[896], param_2.1601: f32[896], param_3.1387: f32[896], param_4.1225: f32[16,14,14,896], param_5.1241: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.1225 = f32[16,14,14,896]{2,1,3,0} parameter(4)
  %param_5.1241 = f32[896]{0} parameter(5)
  %constant_3058 = f32[] constant(0.000318877544)
  %broadcast.3839 = f32[896]{0} broadcast(f32[] %constant_3058), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2225 = f32[896]{0} multiply(f32[896]{0} %param_5.1241, f32[896]{0} %broadcast.3839), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3838 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2225), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.417 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_4.1225, f32[16,14,14,896]{2,1,3,0} %broadcast.3838), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1387 = f32[896]{0} parameter(3)
  %constant_171 = f32[] constant(0)
  %broadcast.3837 = f32[896]{0} broadcast(f32[] %constant_171), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.747 = f32[896]{0} maximum(f32[896]{0} %param_3.1387, f32[896]{0} %broadcast.3837), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3056 = f32[] constant(1e-05)
  %broadcast.3836 = f32[896]{0} broadcast(f32[] %constant_3056), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1228 = f32[896]{0} add(f32[896]{0} %maximum.747, f32[896]{0} %broadcast.3836), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2214 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1228), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.507 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2214), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1601 = f32[896]{0} parameter(2)
  %bitcast.2213 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.1601), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2224 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.507, f32[1,1,1,896]{3,2,1,0} %bitcast.2213), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2212 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2224), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3835 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2212), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2223 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.417, f32[16,14,14,896]{2,1,3,0} %broadcast.3835), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2221 = f32[896]{0} parameter(1)
  %broadcast.3834 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.2221), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1227 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.2223, f32[16,14,14,896]{2,1,3,0} %broadcast.3834), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3833 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_171), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.311 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.1227, f32[16,14,14,896]{2,1,3,0} %broadcast.3833), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1615 = f32[16,14,14,896]{2,1,3,0} parameter(0)
  %select.311 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.311, f32[16,14,14,896]{2,1,3,0} %param_0.1615, f32[16,14,14,896]{2,1,3,0} %broadcast.3833), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.4 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %select.311), dimensions={0,3,1,2}
  %bitcast.545 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.4), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.634 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.545, f32[] %constant_171), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.2241.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.311, f32[16,14,14,896]{2,1,3,0} %broadcast.3835), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.2.clone.1 = f32[16,14,14,896]{2,1,3,0} negate(f32[16,14,14,896]{2,1,3,0} %multiply.2241.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.5 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %negate.2.clone.1), dimensions={0,3,1,2}
  %bitcast.548.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.5), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.635.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.548.clone.1, f32[] %constant_171), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.265.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.417, f32[16,14,14,896]{2,1,3,0} %select.311), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.6 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %multiply.265.clone.1), dimensions={0,3,1,2}
  %bitcast.550.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.6), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.637.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.550.clone.1, f32[] %constant_171), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.3 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.634, f32[16,896]{1,0} %reduce.635.clone.1, f32[16,896]{1,0} %reduce.637.clone.1)
}

%fused_computation.12 (param_0.24: f32[1,1,3584,896], param_1.30: f32[1,1,3584,896]) -> f32[1,1,3584,896] {
  %param_1.30 = f32[1,1,3584,896]{3,2,1,0} parameter(1)
  %copy.129 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_1.30), metadata={op_name="2$start"}
  %param_0.24 = f32[1,1,3584,896]{1,0,2,3} parameter(0)
  %add.33 = f32[1,1,3584,896]{1,0,2,3} add(f32[1,1,3584,896]{1,0,2,3} %copy.129, f32[1,1,3584,896]{1,0,2,3} %param_0.24), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  ROOT %copy.128 = f32[1,1,3584,896]{3,2,1,0} copy(f32[1,1,3584,896]{1,0,2,3} %add.33), metadata={op_name="tuple.79"}
}

%fused_computation.13 (param_0.27: f32[896], param_1.36: f32[896], param_2.1603: f32[16,14,14,896], param_3.1389: f32[896], param_4.1227: f32[1,1,1,896], param_5.1243: f32[896], param_6.789: f32[16,14,14,896], param_7.829: f32[896]) -> f32[16,14,14,896] {
  %param_2.1603 = f32[16,14,14,896]{2,1,3,0} parameter(2)
  %param_1.36 = f32[896]{0} parameter(1)
  %constant_173 = f32[] constant(0.000318877544)
  %broadcast.3859 = f32[896]{0} broadcast(f32[] %constant_173), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2235 = f32[896]{0} multiply(f32[896]{0} %param_1.36, f32[896]{0} %broadcast.3859), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3858 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2235), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.419 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_2.1603, f32[16,14,14,896]{2,1,3,0} %broadcast.3858), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1389 = f32[896]{0} parameter(3)
  %constant_176 = f32[] constant(0)
  %broadcast.3857 = f32[896]{0} broadcast(f32[] %constant_176), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.751 = f32[896]{0} maximum(f32[896]{0} %param_3.1389, f32[896]{0} %broadcast.3857), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2854 = f32[] constant(1e-05)
  %broadcast.3856 = f32[896]{0} broadcast(f32[] %constant_2854), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1234 = f32[896]{0} add(f32[896]{0} %maximum.751, f32[896]{0} %broadcast.3856), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2226 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1234), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.511 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2226), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1243 = f32[896]{0} parameter(5)
  %bitcast.2225 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.1243), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2234 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.511, f32[1,1,1,896]{3,2,1,0} %bitcast.2225), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2224 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2234), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3855 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2224), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2233 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.419, f32[16,14,14,896]{2,1,3,0} %broadcast.3855), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.829 = f32[896]{0} parameter(7)
  %broadcast.3854 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.829), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1233 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.2233, f32[16,14,14,896]{2,1,3,0} %broadcast.3854), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3853 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_176), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.313 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.1233, f32[16,14,14,896]{2,1,3,0} %broadcast.3853), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.789 = f32[16,14,14,896]{2,1,3,0} parameter(6)
  %select.313 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.313, f32[16,14,14,896]{2,1,3,0} %param_6.789, f32[16,14,14,896]{2,1,3,0} %broadcast.3853), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.2231 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.313, f32[16,14,14,896]{2,1,3,0} %broadcast.3855), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1227 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.264 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.1227, f32[1,1,1,896]{3,2,1,0} %bitcast.2225), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.2 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.511, f32[1,1,1,896]{3,2,1,0} %bitcast.2226), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_174 = f32[] constant(-0.5)
  %broadcast.295 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_174), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.263 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.2, f32[1,1,1,896]{3,2,1,0} %broadcast.295), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.262 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.264, f32[1,1,1,896]{3,2,1,0} %multiply.263), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.547 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.262), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.2 = pred[896]{0} compare(f32[896]{0} %param_3.1389, f32[896]{0} %maximum.751), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_177 = f32[] constant(1)
  %broadcast.294 = f32[896]{0} broadcast(f32[] %constant_177), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.2 = f32[896]{0} select(pred[896]{0} %compare.2, f32[896]{0} %broadcast.294, f32[896]{0} %broadcast.3857), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.1 = pred[896]{0} compare(f32[896]{0} %broadcast.3857, f32[896]{0} %maximum.751), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_175 = f32[] constant(2)
  %broadcast.293 = f32[896]{0} broadcast(f32[] %constant_175), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.1 = f32[896]{0} select(pred[896]{0} %compare.1, f32[896]{0} %broadcast.293, f32[896]{0} %broadcast.294), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.1 = f32[896]{0} divide(f32[896]{0} %select.2, f32[896]{0} %select.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.261 = f32[896]{0} multiply(f32[896]{0} %bitcast.547, f32[896]{0} %divide.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_172 = f32[] constant(0.000637755089)
  %broadcast.292 = f32[896]{0} broadcast(f32[] %constant_172), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.260 = f32[896]{0} multiply(f32[896]{0} %multiply.261, f32[896]{0} %broadcast.292), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.291 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.260), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.259 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %param_2.1603, f32[16,14,14,896]{2,1,3,0} %broadcast.291), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.36 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.2231, f32[16,14,14,896]{2,1,3,0} %multiply.259), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.27 = f32[896]{0} parameter(0)
  %negate.1 = f32[896]{0} negate(f32[896]{0} %multiply.261), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.258 = f32[896]{0} multiply(f32[896]{0} %param_1.36, f32[896]{0} %broadcast.292), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.257 = f32[896]{0} multiply(f32[896]{0} %negate.1, f32[896]{0} %multiply.258), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.35 = f32[896]{0} add(f32[896]{0} %param_0.27, f32[896]{0} %multiply.257), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.256 = f32[896]{0} multiply(f32[896]{0} %add.35, f32[896]{0} %broadcast.3859), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.290 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.256), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/broadcast_in_dim[shape=(16, 14, 14, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.34 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %add.36, f32[16,14,14,896]{2,1,3,0} %broadcast.290), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.15 (param_0.31: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.31 = f32[16,896]{1,0} parameter(0)
  %constant_178 = f32[] constant(0)
  %reduce.636 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.31, f32[] %constant_178), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.549 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.636), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.19 (param_0.39: f32[1792], param_1.54: f32[1792], param_2.1578: f32[16,14,14,1792], param_3.1358: f32[1792], param_4.1193: f32[1,1,1,1792], param_5.1200: f32[1792], param_6.764: f32[16,14,14,1792], param_7.811: f32[1792]) -> f32[16,14,14,1792] {
  %param_2.1578 = f32[16,14,14,1792]{2,1,3,0} parameter(2)
  %param_1.54 = f32[1792]{0} parameter(1)
  %constant_183 = f32[] constant(0.000318877544)
  %broadcast.3777 = f32[1792]{0} broadcast(f32[] %constant_183), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2197 = f32[1792]{0} multiply(f32[1792]{0} %param_1.54, f32[1792]{0} %broadcast.3777), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3776 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.2197), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.409 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_2.1578, f32[16,14,14,1792]{2,1,3,0} %broadcast.3776), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1358 = f32[1792]{0} parameter(3)
  %constant_186 = f32[] constant(0)
  %broadcast.3775 = f32[1792]{0} broadcast(f32[] %constant_186), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.737 = f32[1792]{0} maximum(f32[1792]{0} %param_3.1358, f32[1792]{0} %broadcast.3775), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2911 = f32[] constant(1e-05)
  %broadcast.3774 = f32[1792]{0} broadcast(f32[] %constant_2911), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1210 = f32[1792]{0} add(f32[1792]{0} %maximum.737, f32[1792]{0} %broadcast.3774), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2184 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1210), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.497 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2184), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1200 = f32[1792]{0} parameter(5)
  %bitcast.2183 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.1200), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2196 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.497, f32[1,1,1,1792]{3,2,1,0} %bitcast.2183), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2182 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2196), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3773 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.2182), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2195 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.409, f32[16,14,14,1792]{2,1,3,0} %broadcast.3773), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.811 = f32[1792]{0} parameter(7)
  %broadcast.3772 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.811), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1209 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.2195, f32[16,14,14,1792]{2,1,3,0} %broadcast.3772), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3771 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_186), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.303 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.1209, f32[16,14,14,1792]{2,1,3,0} %broadcast.3771), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.764 = f32[16,14,14,1792]{2,1,3,0} parameter(6)
  %select.303 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.303, f32[16,14,14,1792]{2,1,3,0} %param_6.764, f32[16,14,14,1792]{2,1,3,0} %broadcast.3771), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.2193 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.303, f32[16,14,14,1792]{2,1,3,0} %broadcast.3773), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1193 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.275 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.1193, f32[1,1,1,1792]{3,2,1,0} %bitcast.2183), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.4 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.497, f32[1,1,1,1792]{3,2,1,0} %bitcast.2184), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_184 = f32[] constant(-0.5)
  %broadcast.306 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_184), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.274 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.4, f32[1,1,1,1792]{3,2,1,0} %broadcast.306), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.273 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.275, f32[1,1,1,1792]{3,2,1,0} %multiply.274), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.551 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.273), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.5 = pred[1792]{0} compare(f32[1792]{0} %param_3.1358, f32[1792]{0} %maximum.737), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_187 = f32[] constant(1)
  %broadcast.305 = f32[1792]{0} broadcast(f32[] %constant_187), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.5 = f32[1792]{0} select(pred[1792]{0} %compare.5, f32[1792]{0} %broadcast.305, f32[1792]{0} %broadcast.3775), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.4 = pred[1792]{0} compare(f32[1792]{0} %broadcast.3775, f32[1792]{0} %maximum.737), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_185 = f32[] constant(2)
  %broadcast.304 = f32[1792]{0} broadcast(f32[] %constant_185), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.4 = f32[1792]{0} select(pred[1792]{0} %compare.4, f32[1792]{0} %broadcast.304, f32[1792]{0} %broadcast.305), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.3 = f32[1792]{0} divide(f32[1792]{0} %select.5, f32[1792]{0} %select.4), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.272 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.551, f32[1792]{0} %divide.3), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_182 = f32[] constant(0.000637755089)
  %broadcast.302 = f32[1792]{0} broadcast(f32[] %constant_182), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.271 = f32[1792]{0} multiply(f32[1792]{0} %multiply.272, f32[1792]{0} %broadcast.302), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.301 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.271), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.270 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %param_2.1578, f32[16,14,14,1792]{2,1,3,0} %broadcast.301), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.39 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.2193, f32[16,14,14,1792]{2,1,3,0} %multiply.270), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.39 = f32[1792]{0} parameter(0)
  %negate.3 = f32[1792]{0} negate(f32[1792]{0} %multiply.272), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.269 = f32[1792]{0} multiply(f32[1792]{0} %param_1.54, f32[1792]{0} %broadcast.302), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.268 = f32[1792]{0} multiply(f32[1792]{0} %negate.3, f32[1792]{0} %multiply.269), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.38 = f32[1792]{0} add(f32[1792]{0} %param_0.39, f32[1792]{0} %multiply.268), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.267 = f32[1792]{0} multiply(f32[1792]{0} %add.38, f32[1792]{0} %broadcast.3777), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.300 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.267), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/broadcast_in_dim[shape=(16, 14, 14, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.37 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %add.39, f32[16,14,14,1792]{2,1,3,0} %broadcast.300), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.21 (param_0.43: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.43 = f32[16,1792]{1,0} parameter(0)
  %constant_188 = f32[] constant(0)
  %reduce.639 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.43, f32[] %constant_188), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.553 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.639), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.25 (param_0.51: f32[3584], param_1.72: f32[3584], param_2.1555: f32[16,14,14,3584], param_3.1333: f32[3584], param_4.1167: f32[1,1,1,3584], param_5.1170: f32[3584], param_6.744: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_6.744 = f32[16,14,14,3584]{2,1,3,0} parameter(6)
  %param_3.1333 = f32[3584]{0} parameter(3)
  %constant_196 = f32[] constant(0)
  %broadcast.3709 = f32[3584]{0} broadcast(f32[] %constant_196), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.725 = f32[3584]{0} maximum(f32[3584]{0} %param_3.1333, f32[3584]{0} %broadcast.3709), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2962 = f32[] constant(1e-05)
  %broadcast.3708 = f32[3584]{0} broadcast(f32[] %constant_2962), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1190 = f32[3584]{0} add(f32[3584]{0} %maximum.725, f32[3584]{0} %broadcast.3708), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2148 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1190), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.485 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2148), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1170 = f32[3584]{0} parameter(5)
  %bitcast.2147 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.1170), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2165 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.485, f32[1,1,1,3584]{3,2,1,0} %bitcast.2147), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2146 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2165), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3707 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.2146), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2164 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_6.744, f32[16,14,14,3584]{2,1,3,0} %broadcast.3707), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.1555 = f32[16,14,14,3584]{2,1,3,0} parameter(2)
  %param_4.1167 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.286 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.1167, f32[1,1,1,3584]{3,2,1,0} %bitcast.2147), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.6 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.485, f32[1,1,1,3584]{3,2,1,0} %bitcast.2148), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_194 = f32[] constant(-0.5)
  %broadcast.316 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_194), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.285 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.6, f32[1,1,1,3584]{3,2,1,0} %broadcast.316), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.284 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.286, f32[1,1,1,3584]{3,2,1,0} %multiply.285), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.555 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.284), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.8 = pred[3584]{0} compare(f32[3584]{0} %param_3.1333, f32[3584]{0} %maximum.725), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_197 = f32[] constant(1)
  %broadcast.315 = f32[3584]{0} broadcast(f32[] %constant_197), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.8 = f32[3584]{0} select(pred[3584]{0} %compare.8, f32[3584]{0} %broadcast.315, f32[3584]{0} %broadcast.3709), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.7 = pred[3584]{0} compare(f32[3584]{0} %broadcast.3709, f32[3584]{0} %maximum.725), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_195 = f32[] constant(2)
  %broadcast.314 = f32[3584]{0} broadcast(f32[] %constant_195), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.7 = f32[3584]{0} select(pred[3584]{0} %compare.7, f32[3584]{0} %broadcast.314, f32[3584]{0} %broadcast.315), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.5 = f32[3584]{0} divide(f32[3584]{0} %select.8, f32[3584]{0} %select.7), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.283 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.555, f32[3584]{0} %divide.5), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_192 = f32[] constant(0.000637755089)
  %broadcast.312 = f32[3584]{0} broadcast(f32[] %constant_192), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.282 = f32[3584]{0} multiply(f32[3584]{0} %multiply.283, f32[3584]{0} %broadcast.312), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.311 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.282), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.281 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_2.1555, f32[16,14,14,3584]{2,1,3,0} %broadcast.311), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.42 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.2164, f32[16,14,14,3584]{2,1,3,0} %multiply.281), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.51 = f32[3584]{0} parameter(0)
  %negate.5 = f32[3584]{0} negate(f32[3584]{0} %multiply.283), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.72 = f32[3584]{0} parameter(1)
  %multiply.280 = f32[3584]{0} multiply(f32[3584]{0} %param_1.72, f32[3584]{0} %broadcast.312), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.279 = f32[3584]{0} multiply(f32[3584]{0} %negate.5, f32[3584]{0} %multiply.280), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.41 = f32[3584]{0} add(f32[3584]{0} %param_0.51, f32[3584]{0} %multiply.279), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_193 = f32[] constant(0.000318877544)
  %broadcast.313 = f32[3584]{0} broadcast(f32[] %constant_193), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.278 = f32[3584]{0} multiply(f32[3584]{0} %add.41, f32[3584]{0} %broadcast.313), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.310 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.278), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/broadcast_in_dim[shape=(16, 14, 14, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.40 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %add.42, f32[16,14,14,3584]{2,1,3,0} %broadcast.310), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.26 (param_0.1597: f32[16,14,14,3584], param_1.2193: f32[3584], param_2.1562: f32[3584]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1597 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_2.1562 = f32[3584]{0} parameter(2)
  %constant_200 = f32[] constant(0)
  %broadcast.3715 = f32[3584]{0} broadcast(f32[] %constant_200), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.727 = f32[3584]{0} maximum(f32[3584]{0} %param_2.1562, f32[3584]{0} %broadcast.3715), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2977 = f32[] constant(1e-05)
  %broadcast.3714 = f32[3584]{0} broadcast(f32[] %constant_2977), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1192 = f32[3584]{0} add(f32[3584]{0} %maximum.727, f32[3584]{0} %broadcast.3714), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2154 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1192), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.487 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2154), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2193 = f32[3584]{0} parameter(1)
  %bitcast.2153 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.2193), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2169 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.487, f32[1,1,1,3584]{3,2,1,0} %bitcast.2153), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2152 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2169), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3713 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.2152), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2168 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_0.1597, f32[16,14,14,3584]{2,1,3,0} %broadcast.3713), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.6 = f32[16,14,14,3584]{2,1,3,0} negate(f32[16,14,14,3584]{2,1,3,0} %multiply.2168), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.7 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %negate.6), dimensions={0,3,1,2}
  %bitcast.556 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.7), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.641 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.556, f32[] %constant_200), dimensions={2}, to_apply=%region_57.4114.2
  %transpose.8 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %param_0.1597), dimensions={0,3,1,2}
  %bitcast.541.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.8), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %reduce.630.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.541.clone.1, f32[] %constant_200), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.8 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.641, f32[16,3584]{1,0} %reduce.630.clone.1)
}

%fused_computation.27 (param_0.55: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.55 = f32[16,3584]{1,0} parameter(0)
  %constant_198 = f32[] constant(0)
  %reduce.642 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.55, f32[] %constant_198), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.557 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.642), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.36 (param_0.1585: f32[1792], param_1.2183: f32[1792], param_2.1544: f32[1792], param_3.1322: f32[16,14,14,1792], param_4.1165: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.1322 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.1165 = f32[1792]{0} parameter(4)
  %constant_2941 = f32[] constant(0.000318877544)
  %broadcast.3683 = f32[1792]{0} broadcast(f32[] %constant_2941), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2157 = f32[1792]{0} multiply(f32[1792]{0} %param_4.1165, f32[1792]{0} %broadcast.3683), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3682 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.2157), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.401 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.1322, f32[16,14,14,1792]{2,1,3,0} %broadcast.3682), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1544 = f32[1792]{0} parameter(2)
  %constant_208 = f32[] constant(0)
  %broadcast.3681 = f32[1792]{0} broadcast(f32[] %constant_208), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.713 = f32[1792]{0} maximum(f32[1792]{0} %param_2.1544, f32[1792]{0} %broadcast.3681), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2939 = f32[] constant(1e-05)
  %broadcast.3680 = f32[1792]{0} broadcast(f32[] %constant_2939), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1182 = f32[1792]{0} add(f32[1792]{0} %maximum.713, f32[1792]{0} %broadcast.3680), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2136 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1182), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.483 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2136), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2183 = f32[1792]{0} parameter(1)
  %bitcast.2135 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.2183), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2156 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.483, f32[1,1,1,1792]{3,2,1,0} %bitcast.2135), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2134 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2156), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3679 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.2134), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2155 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.401, f32[16,14,14,1792]{2,1,3,0} %broadcast.3679), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1585 = f32[1792]{0} parameter(0)
  %broadcast.3678 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1585), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1181 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.2155, f32[16,14,14,1792]{2,1,3,0} %broadcast.3678), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.324 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_208), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.1 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.1181, f32[16,14,14,1792]{2,1,3,0} %broadcast.324), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.41 (param_0.1570: f32[16,1792], param_1.2160: f32[1792]) -> f32[1792] {
  %param_0.1570 = f32[16,1792]{1,0} parameter(0)
  %constant_212 = f32[] constant(0)
  %reduce.647 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1570, f32[] %constant_212), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_211 = f32[] constant(0.000318877544)
  %broadcast.329 = f32[1792]{0} broadcast(f32[] %constant_211), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.297 = f32[1792]{0} multiply(f32[1792]{0} %reduce.647, f32[1792]{0} %broadcast.329), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2160 = f32[1792]{0} parameter(1)
  %multiply.2137 = f32[1792]{0} multiply(f32[1792]{0} %param_1.2160, f32[1792]{0} %broadcast.329), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.296 = f32[1792]{0} multiply(f32[1792]{0} %multiply.2137, f32[1792]{0} %multiply.2137), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.2 = f32[1792]{0} subtract(f32[1792]{0} %multiply.297, f32[1792]{0} %multiply.296), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.46 (param_0.1567: f32[896], param_1.2158: f32[896], param_2.1510: f32[896], param_3.1291: f32[16,14,14,896], param_4.1140: f32[896]) -> f32[16,14,14,896] {
  %param_3.1291 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.1140 = f32[896]{0} parameter(4)
  %constant_2884 = f32[] constant(0.000318877544)
  %broadcast.3623 = f32[896]{0} broadcast(f32[] %constant_2884), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2133 = f32[896]{0} multiply(f32[896]{0} %param_4.1140, f32[896]{0} %broadcast.3623), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3622 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2133), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.393 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.1291, f32[16,14,14,896]{2,1,3,0} %broadcast.3622), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1510 = f32[896]{0} parameter(2)
  %constant_216 = f32[] constant(0)
  %broadcast.3621 = f32[896]{0} broadcast(f32[] %constant_216), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.695 = f32[896]{0} maximum(f32[896]{0} %param_2.1510, f32[896]{0} %broadcast.3621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2882 = f32[] constant(1e-05)
  %broadcast.3620 = f32[896]{0} broadcast(f32[] %constant_2882), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1164 = f32[896]{0} add(f32[896]{0} %maximum.695, f32[896]{0} %broadcast.3620), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2106 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1164), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.475 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2106), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2158 = f32[896]{0} parameter(1)
  %bitcast.2105 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.2158), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2132 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.475, f32[1,1,1,896]{3,2,1,0} %bitcast.2105), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2104 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2132), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3619 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2104), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2131 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.393, f32[16,14,14,896]{2,1,3,0} %broadcast.3619), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1567 = f32[896]{0} parameter(0)
  %broadcast.3618 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1567), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1163 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.2131, f32[16,14,14,896]{2,1,3,0} %broadcast.3618), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.332 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_216), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.3 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.1163, f32[16,14,14,896]{2,1,3,0} %broadcast.332), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.51 (param_0.1552: f32[16,896], param_1.2135: f32[896]) -> f32[896] {
  %param_0.1552 = f32[16,896]{1,0} parameter(0)
  %constant_220 = f32[] constant(0)
  %reduce.650 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1552, f32[] %constant_220), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_219 = f32[] constant(0.000318877544)
  %broadcast.337 = f32[896]{0} broadcast(f32[] %constant_219), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.303 = f32[896]{0} multiply(f32[896]{0} %reduce.650, f32[896]{0} %broadcast.337), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2135 = f32[896]{0} parameter(1)
  %multiply.2113 = f32[896]{0} multiply(f32[896]{0} %param_1.2135, f32[896]{0} %broadcast.337), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.302 = f32[896]{0} multiply(f32[896]{0} %multiply.2113, f32[896]{0} %multiply.2113), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.4 = f32[896]{0} subtract(f32[896]{0} %multiply.303, f32[896]{0} %multiply.302), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.56 (param_0.101: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_0.101 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %constant_224 = f32[] constant(0)
  %broadcast.340 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_224), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.5 = f32[16,14,14,3584]{2,1,3,0} maximum(f32[16,14,14,3584]{2,1,3,0} %param_0.101, f32[16,14,14,3584]{2,1,3,0} %broadcast.340), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.57 (param_0.103: f32[16,14,14,3584], param_1.153: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_1.153 = f32[16,14,14,3584]{2,1,3,0} parameter(1)
  %constant_225 = f32[] constant(0)
  %broadcast.341 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_225), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.9 = pred[16,14,14,3584]{2,1,3,0} compare(f32[16,14,14,3584]{2,1,3,0} %param_1.153, f32[16,14,14,3584]{2,1,3,0} %broadcast.341), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.103 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  ROOT %select.9 = f32[16,14,14,3584]{2,1,3,0} select(pred[16,14,14,3584]{2,1,3,0} %compare.9, f32[16,14,14,3584]{2,1,3,0} %param_0.103, f32[16,14,14,3584]{2,1,3,0} %broadcast.341), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.61 (param_0.110: f32[1,1,1792,3584], param_1.162: f32[1,1,1792,3584]) -> f32[1,1,1792,3584] {
  %param_1.162 = f32[1,1,1792,3584]{3,2,1,0} parameter(1)
  %copy.131 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_1.162), metadata={op_name="2$start"}
  %param_0.110 = f32[1,1,1792,3584]{1,0,2,3} parameter(0)
  %add.50 = f32[1,1,1792,3584]{1,0,2,3} add(f32[1,1,1792,3584]{1,0,2,3} %copy.131, f32[1,1,1792,3584]{1,0,2,3} %param_0.110), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  ROOT %copy.130 = f32[1,1,1792,3584]{3,2,1,0} copy(f32[1,1,1792,3584]{1,0,2,3} %add.50), metadata={op_name="tuple.79"}
}

%fused_computation.63 (param_0.1534: f32[16,14,14,1792], param_1.2107: f32[1792], param_2.1440: f32[1792], param_3.1217: f32[1792], param_4.1071: f32[16,14,14,1792], param_5.1079: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.1071 = f32[16,14,14,1792]{2,1,3,0} parameter(4)
  %param_5.1079 = f32[1792]{0} parameter(5)
  %constant_2748 = f32[] constant(0.000318877544)
  %broadcast.3441 = f32[1792]{0} broadcast(f32[] %constant_2748), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2051 = f32[1792]{0} multiply(f32[1792]{0} %param_5.1079, f32[1792]{0} %broadcast.3441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3440 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.2051), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.371 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_4.1071, f32[16,14,14,1792]{2,1,3,0} %broadcast.3440), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1217 = f32[1792]{0} parameter(3)
  %constant_229 = f32[] constant(0)
  %broadcast.3439 = f32[1792]{0} broadcast(f32[] %constant_229), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.655 = f32[1792]{0} maximum(f32[1792]{0} %param_3.1217, f32[1792]{0} %broadcast.3439), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2746 = f32[] constant(1e-05)
  %broadcast.3438 = f32[1792]{0} broadcast(f32[] %constant_2746), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1110 = f32[1792]{0} add(f32[1792]{0} %maximum.655, f32[1792]{0} %broadcast.3438), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2010 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1110), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.445 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2010), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1440 = f32[1792]{0} parameter(2)
  %bitcast.2009 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.1440), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2050 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.445, f32[1,1,1,1792]{3,2,1,0} %bitcast.2009), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2008 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2050), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3437 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.2008), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2049 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.371, f32[16,14,14,1792]{2,1,3,0} %broadcast.3437), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2107 = f32[1792]{0} parameter(1)
  %broadcast.3436 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.2107), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1109 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.2049, f32[16,14,14,1792]{2,1,3,0} %broadcast.3436), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3435 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_229), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.281 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.1109, f32[16,14,14,1792]{2,1,3,0} %broadcast.3435), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1534 = f32[16,14,14,1792]{2,1,3,0} parameter(0)
  %select.281 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.281, f32[16,14,14,1792]{2,1,3,0} %param_0.1534, f32[16,14,14,1792]{2,1,3,0} %broadcast.3435), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.9 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %select.281), dimensions={0,3,1,2}
  %bitcast.573 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.9), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.656 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.573, f32[] %constant_229), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.2067.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.281, f32[16,14,14,1792]{2,1,3,0} %broadcast.3437), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.10.clone.1 = f32[16,14,14,1792]{2,1,3,0} negate(f32[16,14,14,1792]{2,1,3,0} %multiply.2067.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.10 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %negate.10.clone.1), dimensions={0,3,1,2}
  %bitcast.582.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.10), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.662.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.582.clone.1, f32[] %constant_229), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.329.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.371, f32[16,14,14,1792]{2,1,3,0} %select.281), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.11 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %multiply.329.clone.1), dimensions={0,3,1,2}
  %bitcast.584.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.11), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.664.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.584.clone.1, f32[] %constant_229), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.14 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.656, f32[16,1792]{1,0} %reduce.662.clone.1, f32[16,1792]{1,0} %reduce.664.clone.1)
}

%fused_computation.65 (param_0.117: f32[3,3,896,1792], param_1.171: f32[3,3,896,1792]) -> f32[3,3,896,1792] {
  %param_1.171 = f32[3,3,896,1792]{3,2,1,0} parameter(1)
  %copy.133 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_1.171), metadata={op_name="2$start"}
  %param_0.117 = f32[3,3,896,1792]{1,0,2,3} parameter(0)
  %add.53 = f32[3,3,896,1792]{1,0,2,3} add(f32[3,3,896,1792]{1,0,2,3} %copy.133, f32[3,3,896,1792]{1,0,2,3} %param_0.117), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  ROOT %copy.132 = f32[3,3,896,1792]{3,2,1,0} copy(f32[3,3,896,1792]{1,0,2,3} %add.53), metadata={op_name="tuple.79"}
}

%fused_computation.67 (param_0.1545: f32[16,14,14,896], param_1.2125: f32[896], param_2.1465: f32[896], param_3.1248: f32[896], param_4.1105: f32[16,14,14,896], param_5.1122: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.1105 = f32[16,14,14,896]{2,1,3,0} parameter(4)
  %param_5.1122 = f32[896]{0} parameter(5)
  %constant_2801 = f32[] constant(0.000318877544)
  %broadcast.3523 = f32[896]{0} broadcast(f32[] %constant_2801), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2089 = f32[896]{0} multiply(f32[896]{0} %param_5.1122, f32[896]{0} %broadcast.3523), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3522 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2089), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.381 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_4.1105, f32[16,14,14,896]{2,1,3,0} %broadcast.3522), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1248 = f32[896]{0} parameter(3)
  %constant_231 = f32[] constant(0)
  %broadcast.3521 = f32[896]{0} broadcast(f32[] %constant_231), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.669 = f32[896]{0} maximum(f32[896]{0} %param_3.1248, f32[896]{0} %broadcast.3521), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2799 = f32[] constant(1e-05)
  %broadcast.3520 = f32[896]{0} broadcast(f32[] %constant_2799), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1134 = f32[896]{0} add(f32[896]{0} %maximum.669, f32[896]{0} %broadcast.3520), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2052 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1134), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.459 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2052), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1465 = f32[896]{0} parameter(2)
  %bitcast.2051 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.1465), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2088 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.459, f32[1,1,1,896]{3,2,1,0} %bitcast.2051), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2050 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2088), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3519 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2050), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2087 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.381, f32[16,14,14,896]{2,1,3,0} %broadcast.3519), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2125 = f32[896]{0} parameter(1)
  %broadcast.3518 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.2125), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1133 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.2087, f32[16,14,14,896]{2,1,3,0} %broadcast.3518), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3517 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_231), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.291 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.1133, f32[16,14,14,896]{2,1,3,0} %broadcast.3517), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1545 = f32[16,14,14,896]{2,1,3,0} parameter(0)
  %select.291 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.291, f32[16,14,14,896]{2,1,3,0} %param_0.1545, f32[16,14,14,896]{2,1,3,0} %broadcast.3517), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.12 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %select.291), dimensions={0,3,1,2}
  %bitcast.575 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.12), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.658 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.575, f32[] %constant_231), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.2105.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.291, f32[16,14,14,896]{2,1,3,0} %broadcast.3519), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.8.clone.1 = f32[16,14,14,896]{2,1,3,0} negate(f32[16,14,14,896]{2,1,3,0} %multiply.2105.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.13 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %negate.8.clone.1), dimensions={0,3,1,2}
  %bitcast.578.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.13), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.659.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.578.clone.1, f32[] %constant_231), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.318.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.381, f32[16,14,14,896]{2,1,3,0} %select.291), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.14 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %multiply.318.clone.1), dimensions={0,3,1,2}
  %bitcast.580.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.14), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.661.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.580.clone.1, f32[] %constant_231), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.12 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.658, f32[16,896]{1,0} %reduce.659.clone.1, f32[16,896]{1,0} %reduce.661.clone.1)
}

%fused_computation.69 (param_0.124: f32[1,1,3584,896], param_1.180: f32[1,1,3584,896]) -> f32[1,1,3584,896] {
  %param_1.180 = f32[1,1,3584,896]{3,2,1,0} parameter(1)
  %copy.135 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_1.180), metadata={op_name="2$start"}
  %param_0.124 = f32[1,1,3584,896]{1,0,2,3} parameter(0)
  %add.56 = f32[1,1,3584,896]{1,0,2,3} add(f32[1,1,3584,896]{1,0,2,3} %copy.135, f32[1,1,3584,896]{1,0,2,3} %param_0.124), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  ROOT %copy.134 = f32[1,1,3584,896]{3,2,1,0} copy(f32[1,1,3584,896]{1,0,2,3} %add.56), metadata={op_name="tuple.79"}
}

%fused_computation.70 (param_0.127: f32[896], param_1.186: f32[896], param_2.1467: f32[16,14,14,896], param_3.1250: f32[896], param_4.1107: f32[1,1,1,896], param_5.1124: f32[896], param_6.728: f32[16,14,14,896], param_7.769: f32[896]) -> f32[16,14,14,896] {
  %param_2.1467 = f32[16,14,14,896]{2,1,3,0} parameter(2)
  %param_1.186 = f32[896]{0} parameter(1)
  %constant_233 = f32[] constant(0.000318877544)
  %broadcast.3543 = f32[896]{0} broadcast(f32[] %constant_233), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2099 = f32[896]{0} multiply(f32[896]{0} %param_1.186, f32[896]{0} %broadcast.3543), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3542 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.2099), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.383 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_2.1467, f32[16,14,14,896]{2,1,3,0} %broadcast.3542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1250 = f32[896]{0} parameter(3)
  %constant_236 = f32[] constant(0)
  %broadcast.3541 = f32[896]{0} broadcast(f32[] %constant_236), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.673 = f32[896]{0} maximum(f32[896]{0} %param_3.1250, f32[896]{0} %broadcast.3541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2581 = f32[] constant(1e-05)
  %broadcast.3540 = f32[896]{0} broadcast(f32[] %constant_2581), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1140 = f32[896]{0} add(f32[896]{0} %maximum.673, f32[896]{0} %broadcast.3540), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2064 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1140), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.463 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2064), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1124 = f32[896]{0} parameter(5)
  %bitcast.2063 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.1124), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2098 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.463, f32[1,1,1,896]{3,2,1,0} %bitcast.2063), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2062 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2098), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3539 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.2062), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2097 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.383, f32[16,14,14,896]{2,1,3,0} %broadcast.3539), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.769 = f32[896]{0} parameter(7)
  %broadcast.3538 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.769), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1139 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.2097, f32[16,14,14,896]{2,1,3,0} %broadcast.3538), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3537 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_236), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.293 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.1139, f32[16,14,14,896]{2,1,3,0} %broadcast.3537), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.728 = f32[16,14,14,896]{2,1,3,0} parameter(6)
  %select.293 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.293, f32[16,14,14,896]{2,1,3,0} %param_6.728, f32[16,14,14,896]{2,1,3,0} %broadcast.3537), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.2095 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.293, f32[16,14,14,896]{2,1,3,0} %broadcast.3539), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1107 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.317 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.1107, f32[1,1,1,896]{3,2,1,0} %bitcast.2063), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.8 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.463, f32[1,1,1,896]{3,2,1,0} %bitcast.2064), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_234 = f32[] constant(-0.5)
  %broadcast.347 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_234), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.316 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.8, f32[1,1,1,896]{3,2,1,0} %broadcast.347), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.315 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.317, f32[1,1,1,896]{3,2,1,0} %multiply.316), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.577 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.315), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.11 = pred[896]{0} compare(f32[896]{0} %param_3.1250, f32[896]{0} %maximum.673), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_237 = f32[] constant(1)
  %broadcast.346 = f32[896]{0} broadcast(f32[] %constant_237), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.11 = f32[896]{0} select(pred[896]{0} %compare.11, f32[896]{0} %broadcast.346, f32[896]{0} %broadcast.3541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.10 = pred[896]{0} compare(f32[896]{0} %broadcast.3541, f32[896]{0} %maximum.673), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_235 = f32[] constant(2)
  %broadcast.345 = f32[896]{0} broadcast(f32[] %constant_235), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.10 = f32[896]{0} select(pred[896]{0} %compare.10, f32[896]{0} %broadcast.345, f32[896]{0} %broadcast.346), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.7 = f32[896]{0} divide(f32[896]{0} %select.11, f32[896]{0} %select.10), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.314 = f32[896]{0} multiply(f32[896]{0} %bitcast.577, f32[896]{0} %divide.7), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_232 = f32[] constant(0.000637755089)
  %broadcast.344 = f32[896]{0} broadcast(f32[] %constant_232), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.313 = f32[896]{0} multiply(f32[896]{0} %multiply.314, f32[896]{0} %broadcast.344), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.343 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.313), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.312 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %param_2.1467, f32[16,14,14,896]{2,1,3,0} %broadcast.343), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.59 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.2095, f32[16,14,14,896]{2,1,3,0} %multiply.312), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.127 = f32[896]{0} parameter(0)
  %negate.7 = f32[896]{0} negate(f32[896]{0} %multiply.314), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.311 = f32[896]{0} multiply(f32[896]{0} %param_1.186, f32[896]{0} %broadcast.344), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.310 = f32[896]{0} multiply(f32[896]{0} %negate.7, f32[896]{0} %multiply.311), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.58 = f32[896]{0} add(f32[896]{0} %param_0.127, f32[896]{0} %multiply.310), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.309 = f32[896]{0} multiply(f32[896]{0} %add.58, f32[896]{0} %broadcast.3543), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.342 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.309), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/broadcast_in_dim[shape=(16, 14, 14, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.57 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %add.59, f32[16,14,14,896]{2,1,3,0} %broadcast.342), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.72 (param_0.131: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.131 = f32[16,896]{1,0} parameter(0)
  %constant_238 = f32[] constant(0)
  %reduce.660 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.131, f32[] %constant_238), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.579 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.660), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.76 (param_0.139: f32[1792], param_1.204: f32[1792], param_2.1442: f32[16,14,14,1792], param_3.1219: f32[1792], param_4.1073: f32[1,1,1,1792], param_5.1081: f32[1792], param_6.703: f32[16,14,14,1792], param_7.751: f32[1792]) -> f32[16,14,14,1792] {
  %param_2.1442 = f32[16,14,14,1792]{2,1,3,0} parameter(2)
  %param_1.204 = f32[1792]{0} parameter(1)
  %constant_243 = f32[] constant(0.000318877544)
  %broadcast.3461 = f32[1792]{0} broadcast(f32[] %constant_243), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2061 = f32[1792]{0} multiply(f32[1792]{0} %param_1.204, f32[1792]{0} %broadcast.3461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3460 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.2061), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.373 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_2.1442, f32[16,14,14,1792]{2,1,3,0} %broadcast.3460), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1219 = f32[1792]{0} parameter(3)
  %constant_246 = f32[] constant(0)
  %broadcast.3459 = f32[1792]{0} broadcast(f32[] %constant_246), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.659 = f32[1792]{0} maximum(f32[1792]{0} %param_3.1219, f32[1792]{0} %broadcast.3459), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2638 = f32[] constant(1e-05)
  %broadcast.3458 = f32[1792]{0} broadcast(f32[] %constant_2638), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1116 = f32[1792]{0} add(f32[1792]{0} %maximum.659, f32[1792]{0} %broadcast.3458), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2022 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1116), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.449 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2022), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1081 = f32[1792]{0} parameter(5)
  %bitcast.2021 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.1081), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2060 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.449, f32[1,1,1,1792]{3,2,1,0} %bitcast.2021), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2020 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2060), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3457 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.2020), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2059 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.373, f32[16,14,14,1792]{2,1,3,0} %broadcast.3457), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.751 = f32[1792]{0} parameter(7)
  %broadcast.3456 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.751), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1115 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.2059, f32[16,14,14,1792]{2,1,3,0} %broadcast.3456), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3455 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_246), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.283 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.1115, f32[16,14,14,1792]{2,1,3,0} %broadcast.3455), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.703 = f32[16,14,14,1792]{2,1,3,0} parameter(6)
  %select.283 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.283, f32[16,14,14,1792]{2,1,3,0} %param_6.703, f32[16,14,14,1792]{2,1,3,0} %broadcast.3455), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.2057 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.283, f32[16,14,14,1792]{2,1,3,0} %broadcast.3457), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.1073 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.328 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.1073, f32[1,1,1,1792]{3,2,1,0} %bitcast.2021), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.10 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.449, f32[1,1,1,1792]{3,2,1,0} %bitcast.2022), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_244 = f32[] constant(-0.5)
  %broadcast.358 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_244), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.327 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.10, f32[1,1,1,1792]{3,2,1,0} %broadcast.358), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.326 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.328, f32[1,1,1,1792]{3,2,1,0} %multiply.327), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.581 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.326), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.14 = pred[1792]{0} compare(f32[1792]{0} %param_3.1219, f32[1792]{0} %maximum.659), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_247 = f32[] constant(1)
  %broadcast.357 = f32[1792]{0} broadcast(f32[] %constant_247), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.14 = f32[1792]{0} select(pred[1792]{0} %compare.14, f32[1792]{0} %broadcast.357, f32[1792]{0} %broadcast.3459), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.13 = pred[1792]{0} compare(f32[1792]{0} %broadcast.3459, f32[1792]{0} %maximum.659), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_245 = f32[] constant(2)
  %broadcast.356 = f32[1792]{0} broadcast(f32[] %constant_245), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.13 = f32[1792]{0} select(pred[1792]{0} %compare.13, f32[1792]{0} %broadcast.356, f32[1792]{0} %broadcast.357), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.9 = f32[1792]{0} divide(f32[1792]{0} %select.14, f32[1792]{0} %select.13), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.325 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.581, f32[1792]{0} %divide.9), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_242 = f32[] constant(0.000637755089)
  %broadcast.354 = f32[1792]{0} broadcast(f32[] %constant_242), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.324 = f32[1792]{0} multiply(f32[1792]{0} %multiply.325, f32[1792]{0} %broadcast.354), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.353 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.324), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.323 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %param_2.1442, f32[16,14,14,1792]{2,1,3,0} %broadcast.353), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.62 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.2057, f32[16,14,14,1792]{2,1,3,0} %multiply.323), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.139 = f32[1792]{0} parameter(0)
  %negate.9 = f32[1792]{0} negate(f32[1792]{0} %multiply.325), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.322 = f32[1792]{0} multiply(f32[1792]{0} %param_1.204, f32[1792]{0} %broadcast.354), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.321 = f32[1792]{0} multiply(f32[1792]{0} %negate.9, f32[1792]{0} %multiply.322), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.61 = f32[1792]{0} add(f32[1792]{0} %param_0.139, f32[1792]{0} %multiply.321), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.320 = f32[1792]{0} multiply(f32[1792]{0} %add.61, f32[1792]{0} %broadcast.3461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.352 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.320), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/broadcast_in_dim[shape=(16, 14, 14, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.60 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %add.62, f32[16,14,14,1792]{2,1,3,0} %broadcast.352), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.78 (param_0.143: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.143 = f32[16,1792]{1,0} parameter(0)
  %constant_248 = f32[] constant(0)
  %reduce.663 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.143, f32[] %constant_248), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.583 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.663), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.82 (param_0.151: f32[3584], param_1.222: f32[3584], param_2.1419: f32[16,14,14,3584], param_3.1194: f32[3584], param_4.1047: f32[1,1,1,3584], param_5.1051: f32[3584], param_6.683: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_6.683 = f32[16,14,14,3584]{2,1,3,0} parameter(6)
  %param_3.1194 = f32[3584]{0} parameter(3)
  %constant_256 = f32[] constant(0)
  %broadcast.3393 = f32[3584]{0} broadcast(f32[] %constant_256), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.647 = f32[3584]{0} maximum(f32[3584]{0} %param_3.1194, f32[3584]{0} %broadcast.3393), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2695 = f32[] constant(1e-05)
  %broadcast.3392 = f32[3584]{0} broadcast(f32[] %constant_2695), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1096 = f32[3584]{0} add(f32[3584]{0} %maximum.647, f32[3584]{0} %broadcast.3392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1986 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1096), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.437 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1986), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1051 = f32[3584]{0} parameter(5)
  %bitcast.1985 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.1051), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2029 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.437, f32[1,1,1,3584]{3,2,1,0} %bitcast.1985), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1984 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2029), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3391 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1984), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2028 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_6.683, f32[16,14,14,3584]{2,1,3,0} %broadcast.3391), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.1419 = f32[16,14,14,3584]{2,1,3,0} parameter(2)
  %param_4.1047 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.339 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.1047, f32[1,1,1,3584]{3,2,1,0} %bitcast.1985), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.12 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.437, f32[1,1,1,3584]{3,2,1,0} %bitcast.1986), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_254 = f32[] constant(-0.5)
  %broadcast.368 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_254), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.338 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.12, f32[1,1,1,3584]{3,2,1,0} %broadcast.368), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.337 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.339, f32[1,1,1,3584]{3,2,1,0} %multiply.338), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.585 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.337), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.17 = pred[3584]{0} compare(f32[3584]{0} %param_3.1194, f32[3584]{0} %maximum.647), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_257 = f32[] constant(1)
  %broadcast.367 = f32[3584]{0} broadcast(f32[] %constant_257), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.17 = f32[3584]{0} select(pred[3584]{0} %compare.17, f32[3584]{0} %broadcast.367, f32[3584]{0} %broadcast.3393), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.16 = pred[3584]{0} compare(f32[3584]{0} %broadcast.3393, f32[3584]{0} %maximum.647), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_255 = f32[] constant(2)
  %broadcast.366 = f32[3584]{0} broadcast(f32[] %constant_255), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.16 = f32[3584]{0} select(pred[3584]{0} %compare.16, f32[3584]{0} %broadcast.366, f32[3584]{0} %broadcast.367), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.11 = f32[3584]{0} divide(f32[3584]{0} %select.17, f32[3584]{0} %select.16), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.336 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.585, f32[3584]{0} %divide.11), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_252 = f32[] constant(0.000637755089)
  %broadcast.364 = f32[3584]{0} broadcast(f32[] %constant_252), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.335 = f32[3584]{0} multiply(f32[3584]{0} %multiply.336, f32[3584]{0} %broadcast.364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.363 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.335), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.334 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_2.1419, f32[16,14,14,3584]{2,1,3,0} %broadcast.363), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.65 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.2028, f32[16,14,14,3584]{2,1,3,0} %multiply.334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.151 = f32[3584]{0} parameter(0)
  %negate.11 = f32[3584]{0} negate(f32[3584]{0} %multiply.336), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.222 = f32[3584]{0} parameter(1)
  %multiply.333 = f32[3584]{0} multiply(f32[3584]{0} %param_1.222, f32[3584]{0} %broadcast.364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.332 = f32[3584]{0} multiply(f32[3584]{0} %negate.11, f32[3584]{0} %multiply.333), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.64 = f32[3584]{0} add(f32[3584]{0} %param_0.151, f32[3584]{0} %multiply.332), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_253 = f32[] constant(0.000318877544)
  %broadcast.365 = f32[3584]{0} broadcast(f32[] %constant_253), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.331 = f32[3584]{0} multiply(f32[3584]{0} %add.64, f32[3584]{0} %broadcast.365), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.362 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.331), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/broadcast_in_dim[shape=(16, 14, 14, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.63 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %add.65, f32[16,14,14,3584]{2,1,3,0} %broadcast.362), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.83 (param_0.1527: f32[16,14,14,3584], param_1.2097: f32[3584], param_2.1426: f32[3584], param_3.1409: f32[16,14,14,3584], param_4.1245: f32[3584]) -> (f32[16,3584], f32[16,3584], f32[16,3584]) {
  %param_0.1527 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_2.1426 = f32[3584]{0} parameter(2)
  %constant_260 = f32[] constant(0)
  %broadcast.3399 = f32[3584]{0} broadcast(f32[] %constant_260), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.649 = f32[3584]{0} maximum(f32[3584]{0} %param_2.1426, f32[3584]{0} %broadcast.3399), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2720 = f32[] constant(1e-05)
  %broadcast.3398 = f32[3584]{0} broadcast(f32[] %constant_2720), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1098 = f32[3584]{0} add(f32[3584]{0} %maximum.649, f32[3584]{0} %broadcast.3398), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1992 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1098), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.439 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1992), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2097 = f32[3584]{0} parameter(1)
  %bitcast.1991 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.2097), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2033 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.439, f32[1,1,1,3584]{3,2,1,0} %bitcast.1991), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1990 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3397 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1990), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2032 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_0.1527, f32[16,14,14,3584]{2,1,3,0} %broadcast.3397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.12 = f32[16,14,14,3584]{2,1,3,0} negate(f32[16,14,14,3584]{2,1,3,0} %multiply.2032), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.15 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %negate.12), dimensions={0,3,1,2}
  %bitcast.586 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.15), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.665 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.586, f32[] %constant_260), dimensions={2}, to_apply=%region_57.4114.2
  %param_3.1409 = f32[16,14,14,3584]{2,1,3,0} parameter(3)
  %param_4.1245 = f32[3584]{0} parameter(4)
  %constant_2680_clone_1 = f32[] constant(0.000318877544)
  %broadcast.3363.clone.1 = f32[3584]{0} broadcast(f32[] %constant_2680_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2021.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_4.1245, f32[3584]{0} %broadcast.3363.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3362.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.2021.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.365.clone.1 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_3.1409, f32[16,14,14,3584]{2,1,3,0} %broadcast.3362.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.340.clone.1 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.365.clone.1, f32[16,14,14,3584]{2,1,3,0} %param_0.1527), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.16 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %multiply.340.clone.1), dimensions={0,3,1,2}
  %bitcast.588.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.16), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.667.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.588.clone.1, f32[] %constant_260), dimensions={2}, to_apply=%region_57.4114.2
  %transpose.17 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %param_0.1527), dimensions={0,3,1,2}
  %bitcast.571.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.17), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.654.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.571.clone.1, f32[] %constant_260), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.16 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.665, f32[16,3584]{1,0} %reduce.667.clone.1, f32[16,3584]{1,0} %reduce.654.clone.1)
}

%fused_computation.84 (param_0.155: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.155 = f32[16,3584]{1,0} parameter(0)
  %constant_258 = f32[] constant(0)
  %reduce.666 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.155, f32[] %constant_258), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.587 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.666), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.87 (param_0.160: f32[16,14,14,3584], param_1.234: f32[16,14,14,3584], param_2.79: f32[3584], param_3.1189: f32[16,14,14,3584], param_4.1046: f32[3584], param_5.1050: f32[3584], param_6.682: f32[3584]) -> f32[16,14,14,3584] {
  %param_1.234 = f32[16,14,14,3584]{2,1,3,0} parameter(1)
  %param_3.1189 = f32[16,14,14,3584]{2,1,3,0} parameter(3)
  %param_4.1046 = f32[3584]{0} parameter(4)
  %constant_2677 = f32[] constant(0.000318877544)
  %broadcast.3359 = f32[3584]{0} broadcast(f32[] %constant_2677), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2019 = f32[3584]{0} multiply(f32[3584]{0} %param_4.1046, f32[3584]{0} %broadcast.3359), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3358 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.2019), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.363 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_3.1189, f32[16,14,14,3584]{2,1,3,0} %broadcast.3358), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_6.682 = f32[3584]{0} parameter(6)
  %constant_261 = f32[] constant(0)
  %broadcast.3383 = f32[3584]{0} broadcast(f32[] %constant_261), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.643 = f32[3584]{0} maximum(f32[3584]{0} %param_6.682, f32[3584]{0} %broadcast.3383), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2705 = f32[] constant(1e-05)
  %broadcast.3382 = f32[3584]{0} broadcast(f32[] %constant_2705), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1092 = f32[3584]{0} add(f32[3584]{0} %maximum.643, f32[3584]{0} %broadcast.3382), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1974 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1092), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.433 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1974), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.1050 = f32[3584]{0} parameter(5)
  %bitcast.1973 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.1050), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2023 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.433, f32[1,1,1,3584]{3,2,1,0} %bitcast.1973), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1972 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2023), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.372 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1972), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.342 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.363, f32[16,14,14,3584]{2,1,3,0} %broadcast.372), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.79 = f32[3584]{0} parameter(2)
  %broadcast.371 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_2.79), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.67 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.342, f32[16,14,14,3584]{2,1,3,0} %broadcast.371), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.66 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_1.234, f32[16,14,14,3584]{2,1,3,0} %add.67), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.373 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_261), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.18 = pred[16,14,14,3584]{2,1,3,0} compare(f32[16,14,14,3584]{2,1,3,0} %add.66, f32[16,14,14,3584]{2,1,3,0} %broadcast.373), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.160 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  ROOT %select.18 = f32[16,14,14,3584]{2,1,3,0} select(pred[16,14,14,3584]{2,1,3,0} %compare.18, f32[16,14,14,3584]{2,1,3,0} %param_0.160, f32[16,14,14,3584]{2,1,3,0} %broadcast.373), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.91 (param_0.1513: f32[16,3584], param_1.2077: f32[3584]) -> f32[3584] {
  %param_0.1513 = f32[16,3584]{1,0} parameter(0)
  %constant_265 = f32[] constant(0)
  %reduce.668 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.1513, f32[] %constant_265), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_264 = f32[] constant(0.000318877544)
  %broadcast.376 = f32[3584]{0} broadcast(f32[] %constant_264), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.345 = f32[3584]{0} multiply(f32[3584]{0} %reduce.668, f32[3584]{0} %broadcast.376), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2077 = f32[3584]{0} parameter(1)
  %multiply.2017 = f32[3584]{0} multiply(f32[3584]{0} %param_1.2077, f32[3584]{0} %broadcast.376), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.344 = f32[3584]{0} multiply(f32[3584]{0} %multiply.2017, f32[3584]{0} %multiply.2017), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.6 = f32[3584]{0} subtract(f32[3584]{0} %multiply.345, f32[3584]{0} %multiply.344), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.96 (param_0.1509: f32[1792], param_1.2072: f32[1792], param_2.1392: f32[1792], param_3.1174: f32[16,14,14,1792], param_4.1035: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.1174 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.1035 = f32[1792]{0} parameter(4)
  %constant_2661 = f32[] constant(0.000318877544)
  %broadcast.3339 = f32[1792]{0} broadcast(f32[] %constant_2661), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2007 = f32[1792]{0} multiply(f32[1792]{0} %param_4.1035, f32[1792]{0} %broadcast.3339), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3338 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.2007), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.359 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.1174, f32[16,14,14,1792]{2,1,3,0} %broadcast.3338), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1392 = f32[1792]{0} parameter(2)
  %constant_269 = f32[] constant(0)
  %broadcast.3337 = f32[1792]{0} broadcast(f32[] %constant_269), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.629 = f32[1792]{0} maximum(f32[1792]{0} %param_2.1392, f32[1792]{0} %broadcast.3337), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2659 = f32[] constant(1e-05)
  %broadcast.3336 = f32[1792]{0} broadcast(f32[] %constant_2659), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1080 = f32[1792]{0} add(f32[1792]{0} %maximum.629, f32[1792]{0} %broadcast.3336), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1956 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1080), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.429 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1956), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2072 = f32[1792]{0} parameter(1)
  %bitcast.1955 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.2072), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.2006 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.429, f32[1,1,1,1792]{3,2,1,0} %bitcast.1955), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1954 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2006), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3335 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1954), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.2005 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.359, f32[16,14,14,1792]{2,1,3,0} %broadcast.3335), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1509 = f32[1792]{0} parameter(0)
  %broadcast.3334 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1509), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1079 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.2005, f32[16,14,14,1792]{2,1,3,0} %broadcast.3334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.379 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_269), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.7 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.1079, f32[16,14,14,1792]{2,1,3,0} %broadcast.379), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.101 (param_0.1495: f32[16,1792], param_1.2052: f32[1792]) -> f32[1792] {
  %param_0.1495 = f32[16,1792]{1,0} parameter(0)
  %constant_273 = f32[] constant(0)
  %reduce.671 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1495, f32[] %constant_273), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_272 = f32[] constant(0.000318877544)
  %broadcast.384 = f32[1792]{0} broadcast(f32[] %constant_272), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.351 = f32[1792]{0} multiply(f32[1792]{0} %reduce.671, f32[1792]{0} %broadcast.384), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2052 = f32[1792]{0} parameter(1)
  %multiply.1993 = f32[1792]{0} multiply(f32[1792]{0} %param_1.2052, f32[1792]{0} %broadcast.384), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.350 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1993, f32[1792]{0} %multiply.1993), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.8 = f32[1792]{0} subtract(f32[1792]{0} %multiply.351, f32[1792]{0} %multiply.350), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.106 (param_0.1491: f32[896], param_1.2047: f32[896], param_2.1358: f32[896], param_3.1143: f32[16,14,14,896], param_4.1010: f32[896]) -> f32[16,14,14,896] {
  %param_3.1143 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.1010 = f32[896]{0} parameter(4)
  %constant_2604 = f32[] constant(0.000318877544)
  %broadcast.3279 = f32[896]{0} broadcast(f32[] %constant_2604), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1983 = f32[896]{0} multiply(f32[896]{0} %param_4.1010, f32[896]{0} %broadcast.3279), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3278 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1983), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.351 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.1143, f32[16,14,14,896]{2,1,3,0} %broadcast.3278), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1358 = f32[896]{0} parameter(2)
  %constant_277 = f32[] constant(0)
  %broadcast.3277 = f32[896]{0} broadcast(f32[] %constant_277), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.611 = f32[896]{0} maximum(f32[896]{0} %param_2.1358, f32[896]{0} %broadcast.3277), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2602 = f32[] constant(1e-05)
  %broadcast.3276 = f32[896]{0} broadcast(f32[] %constant_2602), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1062 = f32[896]{0} add(f32[896]{0} %maximum.611, f32[896]{0} %broadcast.3276), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1926 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1062), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.421 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1926), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.2047 = f32[896]{0} parameter(1)
  %bitcast.1925 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.2047), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1982 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.421, f32[1,1,1,896]{3,2,1,0} %bitcast.1925), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1924 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1982), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3275 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1924), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1981 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.351, f32[16,14,14,896]{2,1,3,0} %broadcast.3275), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1491 = f32[896]{0} parameter(0)
  %broadcast.3274 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1491), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1061 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1981, f32[16,14,14,896]{2,1,3,0} %broadcast.3274), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.387 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_277), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.9 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.1061, f32[16,14,14,896]{2,1,3,0} %broadcast.387), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.111 (param_0.1477: f32[16,896], param_1.2027: f32[896]) -> f32[896] {
  %param_0.1477 = f32[16,896]{1,0} parameter(0)
  %constant_281 = f32[] constant(0)
  %reduce.674 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1477, f32[] %constant_281), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_280 = f32[] constant(0.000318877544)
  %broadcast.392 = f32[896]{0} broadcast(f32[] %constant_280), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.357 = f32[896]{0} multiply(f32[896]{0} %reduce.674, f32[896]{0} %broadcast.392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.2027 = f32[896]{0} parameter(1)
  %multiply.1969 = f32[896]{0} multiply(f32[896]{0} %param_1.2027, f32[896]{0} %broadcast.392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.356 = f32[896]{0} multiply(f32[896]{0} %multiply.1969, f32[896]{0} %multiply.1969), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.10 = f32[896]{0} subtract(f32[896]{0} %multiply.357, f32[896]{0} %multiply.356), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.116 (param_0.206: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_0.206 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %constant_285 = f32[] constant(0)
  %broadcast.395 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_285), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.11 = f32[16,14,14,3584]{2,1,3,0} maximum(f32[16,14,14,3584]{2,1,3,0} %param_0.206, f32[16,14,14,3584]{2,1,3,0} %broadcast.395), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.120 (param_0.213: f32[1,1,1792,3584], param_1.312: f32[1,1,1792,3584]) -> f32[1,1,1792,3584] {
  %param_1.312 = f32[1,1,1792,3584]{3,2,1,0} parameter(1)
  %copy.137 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_1.312), metadata={op_name="2$start"}
  %param_0.213 = f32[1,1,1792,3584]{1,0,2,3} parameter(0)
  %add.75 = f32[1,1,1792,3584]{1,0,2,3} add(f32[1,1,1792,3584]{1,0,2,3} %copy.137, f32[1,1,1792,3584]{1,0,2,3} %param_0.213), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  ROOT %copy.136 = f32[1,1,1792,3584]{3,2,1,0} copy(f32[1,1,1792,3584]{1,0,2,3} %add.75), metadata={op_name="tuple.79"}
}

%fused_computation.122 (param_0.1459: f32[16,14,14,1792], param_1.1999: f32[1792], param_2.1293: f32[1792], param_3.1076: f32[1792], param_4.949: f32[16,14,14,1792], param_5.954: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.949 = f32[16,14,14,1792]{2,1,3,0} parameter(4)
  %param_5.954 = f32[1792]{0} parameter(5)
  %constant_2475 = f32[] constant(0.000318877544)
  %broadcast.3109 = f32[1792]{0} broadcast(f32[] %constant_2475), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1907 = f32[1792]{0} multiply(f32[1792]{0} %param_5.954, f32[1792]{0} %broadcast.3109), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3108 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1907), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.331 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_4.949, f32[16,14,14,1792]{2,1,3,0} %broadcast.3108), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1076 = f32[1792]{0} parameter(3)
  %constant_289 = f32[] constant(0)
  %broadcast.3107 = f32[1792]{0} broadcast(f32[] %constant_289), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.573 = f32[1792]{0} maximum(f32[1792]{0} %param_3.1076, f32[1792]{0} %broadcast.3107), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2473 = f32[] constant(1e-05)
  %broadcast.3106 = f32[1792]{0} broadcast(f32[] %constant_2473), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1012 = f32[1792]{0} add(f32[1792]{0} %maximum.573, f32[1792]{0} %broadcast.3106), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1836 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1012), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.393 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1836), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1293 = f32[1792]{0} parameter(2)
  %bitcast.1835 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.1293), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1906 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.393, f32[1,1,1,1792]{3,2,1,0} %bitcast.1835), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1834 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1906), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3105 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1834), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1905 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.331, f32[16,14,14,1792]{2,1,3,0} %broadcast.3105), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1999 = f32[1792]{0} parameter(1)
  %broadcast.3104 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.1999), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1011 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1905, f32[16,14,14,1792]{2,1,3,0} %broadcast.3104), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3103 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_289), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.261 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.1011, f32[16,14,14,1792]{2,1,3,0} %broadcast.3103), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1459 = f32[16,14,14,1792]{2,1,3,0} parameter(0)
  %select.261 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.261, f32[16,14,14,1792]{2,1,3,0} %param_0.1459, f32[16,14,14,1792]{2,1,3,0} %broadcast.3103), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.18 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %select.261), dimensions={0,3,1,2}
  %bitcast.603 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.18), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.680 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.603, f32[] %constant_289), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1923.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.261, f32[16,14,14,1792]{2,1,3,0} %broadcast.3105), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.16.clone.1 = f32[16,14,14,1792]{2,1,3,0} negate(f32[16,14,14,1792]{2,1,3,0} %multiply.1923.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.19 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %negate.16.clone.1), dimensions={0,3,1,2}
  %bitcast.612.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.19), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.686.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.612.clone.1, f32[] %constant_289), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.383.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.331, f32[16,14,14,1792]{2,1,3,0} %select.261), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.20 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %multiply.383.clone.1), dimensions={0,3,1,2}
  %bitcast.614.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.20), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.688.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.614.clone.1, f32[] %constant_289), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.23 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.680, f32[16,1792]{1,0} %reduce.686.clone.1, f32[16,1792]{1,0} %reduce.688.clone.1)
}

%fused_computation.124 (param_0.220: f32[3,3,896,1792], param_1.321: f32[3,3,896,1792]) -> f32[3,3,896,1792] {
  %param_1.321 = f32[3,3,896,1792]{3,2,1,0} parameter(1)
  %copy.139 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_1.321), metadata={op_name="2$start"}
  %param_0.220 = f32[3,3,896,1792]{1,0,2,3} parameter(0)
  %add.78 = f32[3,3,896,1792]{1,0,2,3} add(f32[3,3,896,1792]{1,0,2,3} %copy.139, f32[3,3,896,1792]{1,0,2,3} %param_0.220), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  ROOT %copy.138 = f32[3,3,896,1792]{3,2,1,0} copy(f32[3,3,896,1792]{1,0,2,3} %add.78), metadata={op_name="tuple.79"}
}

%fused_computation.126 (param_0.1470: f32[16,14,14,896], param_1.2017: f32[896], param_2.1318: f32[896], param_3.1107: f32[896], param_4.983: f32[16,14,14,896], param_5.997: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.983 = f32[16,14,14,896]{2,1,3,0} parameter(4)
  %param_5.997 = f32[896]{0} parameter(5)
  %constant_2528 = f32[] constant(0.000318877544)
  %broadcast.3191 = f32[896]{0} broadcast(f32[] %constant_2528), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1945 = f32[896]{0} multiply(f32[896]{0} %param_5.997, f32[896]{0} %broadcast.3191), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3190 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1945), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.341 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_4.983, f32[16,14,14,896]{2,1,3,0} %broadcast.3190), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1107 = f32[896]{0} parameter(3)
  %constant_291 = f32[] constant(0)
  %broadcast.3189 = f32[896]{0} broadcast(f32[] %constant_291), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.587 = f32[896]{0} maximum(f32[896]{0} %param_3.1107, f32[896]{0} %broadcast.3189), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2526 = f32[] constant(1e-05)
  %broadcast.3188 = f32[896]{0} broadcast(f32[] %constant_2526), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1036 = f32[896]{0} add(f32[896]{0} %maximum.587, f32[896]{0} %broadcast.3188), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1878 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1036), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.407 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1878), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1318 = f32[896]{0} parameter(2)
  %bitcast.1877 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.1318), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1944 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.407, f32[1,1,1,896]{3,2,1,0} %bitcast.1877), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1876 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1944), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3187 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1876), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1943 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.341, f32[16,14,14,896]{2,1,3,0} %broadcast.3187), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.2017 = f32[896]{0} parameter(1)
  %broadcast.3186 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.2017), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1035 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1943, f32[16,14,14,896]{2,1,3,0} %broadcast.3186), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3185 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_291), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.271 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.1035, f32[16,14,14,896]{2,1,3,0} %broadcast.3185), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1470 = f32[16,14,14,896]{2,1,3,0} parameter(0)
  %select.271 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.271, f32[16,14,14,896]{2,1,3,0} %param_0.1470, f32[16,14,14,896]{2,1,3,0} %broadcast.3185), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.21 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %select.271), dimensions={0,3,1,2}
  %bitcast.605 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.21), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.682 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.605, f32[] %constant_291), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1961.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.271, f32[16,14,14,896]{2,1,3,0} %broadcast.3187), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.14.clone.1 = f32[16,14,14,896]{2,1,3,0} negate(f32[16,14,14,896]{2,1,3,0} %multiply.1961.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.22 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %negate.14.clone.1), dimensions={0,3,1,2}
  %bitcast.608.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.22), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.683.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.608.clone.1, f32[] %constant_291), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.372.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.341, f32[16,14,14,896]{2,1,3,0} %select.271), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.23 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %multiply.372.clone.1), dimensions={0,3,1,2}
  %bitcast.610.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.23), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.685.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.610.clone.1, f32[] %constant_291), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.21 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.682, f32[16,896]{1,0} %reduce.683.clone.1, f32[16,896]{1,0} %reduce.685.clone.1)
}

%fused_computation.128 (param_0.227: f32[1,1,3584,896], param_1.330: f32[1,1,3584,896]) -> f32[1,1,3584,896] {
  %param_1.330 = f32[1,1,3584,896]{3,2,1,0} parameter(1)
  %copy.141 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_1.330), metadata={op_name="2$start"}
  %param_0.227 = f32[1,1,3584,896]{1,0,2,3} parameter(0)
  %add.81 = f32[1,1,3584,896]{1,0,2,3} add(f32[1,1,3584,896]{1,0,2,3} %copy.141, f32[1,1,3584,896]{1,0,2,3} %param_0.227), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  ROOT %copy.140 = f32[1,1,3584,896]{3,2,1,0} copy(f32[1,1,3584,896]{1,0,2,3} %add.81), metadata={op_name="tuple.79"}
}

%fused_computation.129 (param_0.230: f32[896], param_1.336: f32[896], param_2.1320: f32[16,14,14,896], param_3.1109: f32[896], param_4.985: f32[1,1,1,896], param_5.999: f32[896], param_6.659: f32[16,14,14,896], param_7.705: f32[896]) -> f32[16,14,14,896] {
  %param_2.1320 = f32[16,14,14,896]{2,1,3,0} parameter(2)
  %param_1.336 = f32[896]{0} parameter(1)
  %constant_293 = f32[] constant(0.000318877544)
  %broadcast.3211 = f32[896]{0} broadcast(f32[] %constant_293), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1955 = f32[896]{0} multiply(f32[896]{0} %param_1.336, f32[896]{0} %broadcast.3211), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3210 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1955), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.343 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_2.1320, f32[16,14,14,896]{2,1,3,0} %broadcast.3210), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1109 = f32[896]{0} parameter(3)
  %constant_296 = f32[] constant(0)
  %broadcast.3209 = f32[896]{0} broadcast(f32[] %constant_296), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.591 = f32[896]{0} maximum(f32[896]{0} %param_3.1109, f32[896]{0} %broadcast.3209), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2308 = f32[] constant(1e-05)
  %broadcast.3208 = f32[896]{0} broadcast(f32[] %constant_2308), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1042 = f32[896]{0} add(f32[896]{0} %maximum.591, f32[896]{0} %broadcast.3208), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1890 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1042), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.411 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1890), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.999 = f32[896]{0} parameter(5)
  %bitcast.1889 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.999), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1954 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.411, f32[1,1,1,896]{3,2,1,0} %bitcast.1889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1888 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1954), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3207 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1888), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1953 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.343, f32[16,14,14,896]{2,1,3,0} %broadcast.3207), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.705 = f32[896]{0} parameter(7)
  %broadcast.3206 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.705), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1041 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1953, f32[16,14,14,896]{2,1,3,0} %broadcast.3206), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3205 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_296), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.273 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.1041, f32[16,14,14,896]{2,1,3,0} %broadcast.3205), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.659 = f32[16,14,14,896]{2,1,3,0} parameter(6)
  %select.273 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.273, f32[16,14,14,896]{2,1,3,0} %param_6.659, f32[16,14,14,896]{2,1,3,0} %broadcast.3205), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1951 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.273, f32[16,14,14,896]{2,1,3,0} %broadcast.3207), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.985 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.371 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.985, f32[1,1,1,896]{3,2,1,0} %bitcast.1889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.14 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.411, f32[1,1,1,896]{3,2,1,0} %bitcast.1890), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_294 = f32[] constant(-0.5)
  %broadcast.401 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_294), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.370 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.14, f32[1,1,1,896]{3,2,1,0} %broadcast.401), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.369 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.371, f32[1,1,1,896]{3,2,1,0} %multiply.370), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.607 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.369), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.20 = pred[896]{0} compare(f32[896]{0} %param_3.1109, f32[896]{0} %maximum.591), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_297 = f32[] constant(1)
  %broadcast.400 = f32[896]{0} broadcast(f32[] %constant_297), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.20 = f32[896]{0} select(pred[896]{0} %compare.20, f32[896]{0} %broadcast.400, f32[896]{0} %broadcast.3209), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.19 = pred[896]{0} compare(f32[896]{0} %broadcast.3209, f32[896]{0} %maximum.591), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_295 = f32[] constant(2)
  %broadcast.399 = f32[896]{0} broadcast(f32[] %constant_295), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.19 = f32[896]{0} select(pred[896]{0} %compare.19, f32[896]{0} %broadcast.399, f32[896]{0} %broadcast.400), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.13 = f32[896]{0} divide(f32[896]{0} %select.20, f32[896]{0} %select.19), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.368 = f32[896]{0} multiply(f32[896]{0} %bitcast.607, f32[896]{0} %divide.13), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_292 = f32[] constant(0.000637755089)
  %broadcast.398 = f32[896]{0} broadcast(f32[] %constant_292), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.367 = f32[896]{0} multiply(f32[896]{0} %multiply.368, f32[896]{0} %broadcast.398), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.397 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.367), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.366 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %param_2.1320, f32[16,14,14,896]{2,1,3,0} %broadcast.397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.84 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1951, f32[16,14,14,896]{2,1,3,0} %multiply.366), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.230 = f32[896]{0} parameter(0)
  %negate.13 = f32[896]{0} negate(f32[896]{0} %multiply.368), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.365 = f32[896]{0} multiply(f32[896]{0} %param_1.336, f32[896]{0} %broadcast.398), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.364 = f32[896]{0} multiply(f32[896]{0} %negate.13, f32[896]{0} %multiply.365), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.83 = f32[896]{0} add(f32[896]{0} %param_0.230, f32[896]{0} %multiply.364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.363 = f32[896]{0} multiply(f32[896]{0} %add.83, f32[896]{0} %broadcast.3211), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.396 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.363), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/broadcast_in_dim[shape=(16, 14, 14, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.82 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %add.84, f32[16,14,14,896]{2,1,3,0} %broadcast.396), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.131 (param_0.234: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.234 = f32[16,896]{1,0} parameter(0)
  %constant_298 = f32[] constant(0)
  %reduce.684 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.234, f32[] %constant_298), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.609 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.684), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.135 (param_0.242: f32[1792], param_1.354: f32[1792], param_2.1295: f32[16,14,14,1792], param_3.1078: f32[1792], param_4.951: f32[1,1,1,1792], param_5.956: f32[1792], param_6.634: f32[16,14,14,1792], param_7.687: f32[1792]) -> f32[16,14,14,1792] {
  %param_2.1295 = f32[16,14,14,1792]{2,1,3,0} parameter(2)
  %param_1.354 = f32[1792]{0} parameter(1)
  %constant_303 = f32[] constant(0.000318877544)
  %broadcast.3129 = f32[1792]{0} broadcast(f32[] %constant_303), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1917 = f32[1792]{0} multiply(f32[1792]{0} %param_1.354, f32[1792]{0} %broadcast.3129), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3128 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1917), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.333 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_2.1295, f32[16,14,14,1792]{2,1,3,0} %broadcast.3128), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.1078 = f32[1792]{0} parameter(3)
  %constant_306 = f32[] constant(0)
  %broadcast.3127 = f32[1792]{0} broadcast(f32[] %constant_306), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.577 = f32[1792]{0} maximum(f32[1792]{0} %param_3.1078, f32[1792]{0} %broadcast.3127), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2365 = f32[] constant(1e-05)
  %broadcast.3126 = f32[1792]{0} broadcast(f32[] %constant_2365), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1018 = f32[1792]{0} add(f32[1792]{0} %maximum.577, f32[1792]{0} %broadcast.3126), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1848 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1018), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.397 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1848), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.956 = f32[1792]{0} parameter(5)
  %bitcast.1847 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.956), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1916 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.397, f32[1,1,1,1792]{3,2,1,0} %bitcast.1847), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1846 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1916), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3125 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1846), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1915 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.333, f32[16,14,14,1792]{2,1,3,0} %broadcast.3125), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.687 = f32[1792]{0} parameter(7)
  %broadcast.3124 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.687), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1017 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1915, f32[16,14,14,1792]{2,1,3,0} %broadcast.3124), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.3123 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_306), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.263 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.1017, f32[16,14,14,1792]{2,1,3,0} %broadcast.3123), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.634 = f32[16,14,14,1792]{2,1,3,0} parameter(6)
  %select.263 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.263, f32[16,14,14,1792]{2,1,3,0} %param_6.634, f32[16,14,14,1792]{2,1,3,0} %broadcast.3123), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1913 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.263, f32[16,14,14,1792]{2,1,3,0} %broadcast.3125), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.951 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.382 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.951, f32[1,1,1,1792]{3,2,1,0} %bitcast.1847), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.16 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.397, f32[1,1,1,1792]{3,2,1,0} %bitcast.1848), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_304 = f32[] constant(-0.5)
  %broadcast.412 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_304), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.381 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.16, f32[1,1,1,1792]{3,2,1,0} %broadcast.412), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.380 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.382, f32[1,1,1,1792]{3,2,1,0} %multiply.381), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.611 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.380), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.23 = pred[1792]{0} compare(f32[1792]{0} %param_3.1078, f32[1792]{0} %maximum.577), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_307 = f32[] constant(1)
  %broadcast.411 = f32[1792]{0} broadcast(f32[] %constant_307), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.23 = f32[1792]{0} select(pred[1792]{0} %compare.23, f32[1792]{0} %broadcast.411, f32[1792]{0} %broadcast.3127), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.22 = pred[1792]{0} compare(f32[1792]{0} %broadcast.3127, f32[1792]{0} %maximum.577), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_305 = f32[] constant(2)
  %broadcast.410 = f32[1792]{0} broadcast(f32[] %constant_305), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.22 = f32[1792]{0} select(pred[1792]{0} %compare.22, f32[1792]{0} %broadcast.410, f32[1792]{0} %broadcast.411), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.15 = f32[1792]{0} divide(f32[1792]{0} %select.23, f32[1792]{0} %select.22), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.379 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.611, f32[1792]{0} %divide.15), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_302 = f32[] constant(0.000637755089)
  %broadcast.408 = f32[1792]{0} broadcast(f32[] %constant_302), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.378 = f32[1792]{0} multiply(f32[1792]{0} %multiply.379, f32[1792]{0} %broadcast.408), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.407 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.378), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.377 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %param_2.1295, f32[16,14,14,1792]{2,1,3,0} %broadcast.407), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.87 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1913, f32[16,14,14,1792]{2,1,3,0} %multiply.377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.242 = f32[1792]{0} parameter(0)
  %negate.15 = f32[1792]{0} negate(f32[1792]{0} %multiply.379), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.376 = f32[1792]{0} multiply(f32[1792]{0} %param_1.354, f32[1792]{0} %broadcast.408), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.375 = f32[1792]{0} multiply(f32[1792]{0} %negate.15, f32[1792]{0} %multiply.376), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.86 = f32[1792]{0} add(f32[1792]{0} %param_0.242, f32[1792]{0} %multiply.375), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.374 = f32[1792]{0} multiply(f32[1792]{0} %add.86, f32[1792]{0} %broadcast.3129), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.406 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.374), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/broadcast_in_dim[shape=(16, 14, 14, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.85 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %add.87, f32[16,14,14,1792]{2,1,3,0} %broadcast.406), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.137 (param_0.246: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.246 = f32[16,1792]{1,0} parameter(0)
  %constant_308 = f32[] constant(0)
  %reduce.687 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.246, f32[] %constant_308), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.613 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.687), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.141 (param_0.254: f32[3584], param_1.372: f32[3584], param_2.1272: f32[16,14,14,3584], param_3.1053: f32[3584], param_4.925: f32[1,1,1,3584], param_5.926: f32[3584], param_6.614: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_6.614 = f32[16,14,14,3584]{2,1,3,0} parameter(6)
  %param_3.1053 = f32[3584]{0} parameter(3)
  %constant_316 = f32[] constant(0)
  %broadcast.3061 = f32[3584]{0} broadcast(f32[] %constant_316), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.565 = f32[3584]{0} maximum(f32[3584]{0} %param_3.1053, f32[3584]{0} %broadcast.3061), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2422 = f32[] constant(1e-05)
  %broadcast.3060 = f32[3584]{0} broadcast(f32[] %constant_2422), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.998 = f32[3584]{0} add(f32[3584]{0} %maximum.565, f32[3584]{0} %broadcast.3060), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1812 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.998), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.385 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1812), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.926 = f32[3584]{0} parameter(5)
  %bitcast.1811 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.926), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1885 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.385, f32[1,1,1,3584]{3,2,1,0} %bitcast.1811), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1810 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3059 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1810), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1884 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_6.614, f32[16,14,14,3584]{2,1,3,0} %broadcast.3059), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.1272 = f32[16,14,14,3584]{2,1,3,0} parameter(2)
  %param_4.925 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.393 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.925, f32[1,1,1,3584]{3,2,1,0} %bitcast.1811), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.18 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.385, f32[1,1,1,3584]{3,2,1,0} %bitcast.1812), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_314 = f32[] constant(-0.5)
  %broadcast.422 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_314), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.392 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.18, f32[1,1,1,3584]{3,2,1,0} %broadcast.422), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.391 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.393, f32[1,1,1,3584]{3,2,1,0} %multiply.392), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.615 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.391), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.26 = pred[3584]{0} compare(f32[3584]{0} %param_3.1053, f32[3584]{0} %maximum.565), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_317 = f32[] constant(1)
  %broadcast.421 = f32[3584]{0} broadcast(f32[] %constant_317), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.26 = f32[3584]{0} select(pred[3584]{0} %compare.26, f32[3584]{0} %broadcast.421, f32[3584]{0} %broadcast.3061), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.25 = pred[3584]{0} compare(f32[3584]{0} %broadcast.3061, f32[3584]{0} %maximum.565), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_315 = f32[] constant(2)
  %broadcast.420 = f32[3584]{0} broadcast(f32[] %constant_315), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.25 = f32[3584]{0} select(pred[3584]{0} %compare.25, f32[3584]{0} %broadcast.420, f32[3584]{0} %broadcast.421), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.17 = f32[3584]{0} divide(f32[3584]{0} %select.26, f32[3584]{0} %select.25), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.390 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.615, f32[3584]{0} %divide.17), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_312 = f32[] constant(0.000637755089)
  %broadcast.418 = f32[3584]{0} broadcast(f32[] %constant_312), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.389 = f32[3584]{0} multiply(f32[3584]{0} %multiply.390, f32[3584]{0} %broadcast.418), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.417 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.389), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.388 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_2.1272, f32[16,14,14,3584]{2,1,3,0} %broadcast.417), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.90 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.1884, f32[16,14,14,3584]{2,1,3,0} %multiply.388), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.254 = f32[3584]{0} parameter(0)
  %negate.17 = f32[3584]{0} negate(f32[3584]{0} %multiply.390), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.372 = f32[3584]{0} parameter(1)
  %multiply.387 = f32[3584]{0} multiply(f32[3584]{0} %param_1.372, f32[3584]{0} %broadcast.418), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.386 = f32[3584]{0} multiply(f32[3584]{0} %negate.17, f32[3584]{0} %multiply.387), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.89 = f32[3584]{0} add(f32[3584]{0} %param_0.254, f32[3584]{0} %multiply.386), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_313 = f32[] constant(0.000318877544)
  %broadcast.419 = f32[3584]{0} broadcast(f32[] %constant_313), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.385 = f32[3584]{0} multiply(f32[3584]{0} %add.89, f32[3584]{0} %broadcast.419), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.416 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.385), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/broadcast_in_dim[shape=(16, 14, 14, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.88 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %add.90, f32[16,14,14,3584]{2,1,3,0} %broadcast.416), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.142 (param_0.1452: f32[16,14,14,3584], param_1.1989: f32[3584], param_2.1279: f32[3584], param_3.1413: f32[16,14,14,3584], param_4.1249: f32[3584]) -> (f32[16,3584], f32[16,3584], f32[16,3584]) {
  %param_0.1452 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_2.1279 = f32[3584]{0} parameter(2)
  %constant_320 = f32[] constant(0)
  %broadcast.3067 = f32[3584]{0} broadcast(f32[] %constant_320), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.567 = f32[3584]{0} maximum(f32[3584]{0} %param_2.1279, f32[3584]{0} %broadcast.3067), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2447 = f32[] constant(1e-05)
  %broadcast.3066 = f32[3584]{0} broadcast(f32[] %constant_2447), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1000 = f32[3584]{0} add(f32[3584]{0} %maximum.567, f32[3584]{0} %broadcast.3066), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1818 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1000), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.387 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1818), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1989 = f32[3584]{0} parameter(1)
  %bitcast.1817 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.1989), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1889 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.387, f32[1,1,1,3584]{3,2,1,0} %bitcast.1817), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1816 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3065 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1816), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1888 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_0.1452, f32[16,14,14,3584]{2,1,3,0} %broadcast.3065), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.18 = f32[16,14,14,3584]{2,1,3,0} negate(f32[16,14,14,3584]{2,1,3,0} %multiply.1888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.24 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %negate.18), dimensions={0,3,1,2}
  %bitcast.616 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.24), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.689 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.616, f32[] %constant_320), dimensions={2}, to_apply=%region_57.4114.2
  %param_3.1413 = f32[16,14,14,3584]{2,1,3,0} parameter(3)
  %param_4.1249 = f32[3584]{0} parameter(4)
  %constant_2407_clone_1 = f32[] constant(0.000318877544)
  %broadcast.3031.clone.1 = f32[3584]{0} broadcast(f32[] %constant_2407_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1877.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_4.1249, f32[3584]{0} %broadcast.3031.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3030.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1877.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.325.clone.1 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_3.1413, f32[16,14,14,3584]{2,1,3,0} %broadcast.3030.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.394.clone.1 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.325.clone.1, f32[16,14,14,3584]{2,1,3,0} %param_0.1452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.25 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %multiply.394.clone.1), dimensions={0,3,1,2}
  %bitcast.618.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.25), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.691.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.618.clone.1, f32[] %constant_320), dimensions={2}, to_apply=%region_57.4114.2
  %transpose.26 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %param_0.1452), dimensions={0,3,1,2}
  %bitcast.601.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.26), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.678.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.601.clone.1, f32[] %constant_320), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.25 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.689, f32[16,3584]{1,0} %reduce.691.clone.1, f32[16,3584]{1,0} %reduce.678.clone.1)
}

%fused_computation.143 (param_0.258: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.258 = f32[16,3584]{1,0} parameter(0)
  %constant_318 = f32[] constant(0)
  %reduce.690 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.258, f32[] %constant_318), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.617 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.690), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.146 (param_0.263: f32[16,14,14,3584], param_1.384: f32[16,14,14,3584], param_2.123: f32[3584], param_3.1048: f32[16,14,14,3584], param_4.924: f32[3584], param_5.925: f32[3584], param_6.613: f32[3584]) -> f32[16,14,14,3584] {
  %param_1.384 = f32[16,14,14,3584]{2,1,3,0} parameter(1)
  %param_3.1048 = f32[16,14,14,3584]{2,1,3,0} parameter(3)
  %param_4.924 = f32[3584]{0} parameter(4)
  %constant_2404 = f32[] constant(0.000318877544)
  %broadcast.3027 = f32[3584]{0} broadcast(f32[] %constant_2404), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1875 = f32[3584]{0} multiply(f32[3584]{0} %param_4.924, f32[3584]{0} %broadcast.3027), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3026 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1875), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.323 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_3.1048, f32[16,14,14,3584]{2,1,3,0} %broadcast.3026), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_6.613 = f32[3584]{0} parameter(6)
  %constant_321 = f32[] constant(0)
  %broadcast.3051 = f32[3584]{0} broadcast(f32[] %constant_321), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.561 = f32[3584]{0} maximum(f32[3584]{0} %param_6.613, f32[3584]{0} %broadcast.3051), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2432 = f32[] constant(1e-05)
  %broadcast.3050 = f32[3584]{0} broadcast(f32[] %constant_2432), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.994 = f32[3584]{0} add(f32[3584]{0} %maximum.561, f32[3584]{0} %broadcast.3050), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1800 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.994), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.381 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1800), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.925 = f32[3584]{0} parameter(5)
  %bitcast.1799 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.925), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1879 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.381, f32[1,1,1,3584]{3,2,1,0} %bitcast.1799), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1798 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1879), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.426 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1798), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.396 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.323, f32[16,14,14,3584]{2,1,3,0} %broadcast.426), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.123 = f32[3584]{0} parameter(2)
  %broadcast.425 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_2.123), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.92 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.396, f32[16,14,14,3584]{2,1,3,0} %broadcast.425), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.91 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_1.384, f32[16,14,14,3584]{2,1,3,0} %add.92), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.427 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_321), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.27 = pred[16,14,14,3584]{2,1,3,0} compare(f32[16,14,14,3584]{2,1,3,0} %add.91, f32[16,14,14,3584]{2,1,3,0} %broadcast.427), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.263 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  ROOT %select.27 = f32[16,14,14,3584]{2,1,3,0} select(pred[16,14,14,3584]{2,1,3,0} %compare.27, f32[16,14,14,3584]{2,1,3,0} %param_0.263, f32[16,14,14,3584]{2,1,3,0} %broadcast.427), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.150 (param_0.1438: f32[16,3584], param_1.1969: f32[3584]) -> f32[3584] {
  %param_0.1438 = f32[16,3584]{1,0} parameter(0)
  %constant_325 = f32[] constant(0)
  %reduce.692 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.1438, f32[] %constant_325), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_324 = f32[] constant(0.000318877544)
  %broadcast.430 = f32[3584]{0} broadcast(f32[] %constant_324), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.399 = f32[3584]{0} multiply(f32[3584]{0} %reduce.692, f32[3584]{0} %broadcast.430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1969 = f32[3584]{0} parameter(1)
  %multiply.1873 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1969, f32[3584]{0} %broadcast.430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.398 = f32[3584]{0} multiply(f32[3584]{0} %multiply.1873, f32[3584]{0} %multiply.1873), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.12 = f32[3584]{0} subtract(f32[3584]{0} %multiply.399, f32[3584]{0} %multiply.398), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.155 (param_0.1434: f32[1792], param_1.1964: f32[1792], param_2.1245: f32[1792], param_3.1033: f32[16,14,14,1792], param_4.913: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.1033 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.913 = f32[1792]{0} parameter(4)
  %constant_2388 = f32[] constant(0.000318877544)
  %broadcast.3007 = f32[1792]{0} broadcast(f32[] %constant_2388), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1863 = f32[1792]{0} multiply(f32[1792]{0} %param_4.913, f32[1792]{0} %broadcast.3007), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3006 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1863), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.319 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.1033, f32[16,14,14,1792]{2,1,3,0} %broadcast.3006), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1245 = f32[1792]{0} parameter(2)
  %constant_329 = f32[] constant(0)
  %broadcast.3005 = f32[1792]{0} broadcast(f32[] %constant_329), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.547 = f32[1792]{0} maximum(f32[1792]{0} %param_2.1245, f32[1792]{0} %broadcast.3005), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2386 = f32[] constant(1e-05)
  %broadcast.3004 = f32[1792]{0} broadcast(f32[] %constant_2386), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.982 = f32[1792]{0} add(f32[1792]{0} %maximum.547, f32[1792]{0} %broadcast.3004), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1782 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.982), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.377 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1782), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1964 = f32[1792]{0} parameter(1)
  %bitcast.1781 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1964), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1862 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.377, f32[1,1,1,1792]{3,2,1,0} %bitcast.1781), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1780 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1862), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.3003 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1780), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1861 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.319, f32[16,14,14,1792]{2,1,3,0} %broadcast.3003), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1434 = f32[1792]{0} parameter(0)
  %broadcast.3002 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1434), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.981 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1861, f32[16,14,14,1792]{2,1,3,0} %broadcast.3002), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.433 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_329), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.13 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.981, f32[16,14,14,1792]{2,1,3,0} %broadcast.433), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.160 (param_0.1420: f32[16,1792], param_1.1944: f32[1792]) -> f32[1792] {
  %param_0.1420 = f32[16,1792]{1,0} parameter(0)
  %constant_333 = f32[] constant(0)
  %reduce.695 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1420, f32[] %constant_333), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_332 = f32[] constant(0.000318877544)
  %broadcast.438 = f32[1792]{0} broadcast(f32[] %constant_332), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.405 = f32[1792]{0} multiply(f32[1792]{0} %reduce.695, f32[1792]{0} %broadcast.438), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1944 = f32[1792]{0} parameter(1)
  %multiply.1849 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1944, f32[1792]{0} %broadcast.438), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.404 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1849, f32[1792]{0} %multiply.1849), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.14 = f32[1792]{0} subtract(f32[1792]{0} %multiply.405, f32[1792]{0} %multiply.404), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.165 (param_0.1416: f32[896], param_1.1939: f32[896], param_2.1211: f32[896], param_3.1002: f32[16,14,14,896], param_4.888: f32[896]) -> f32[16,14,14,896] {
  %param_3.1002 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.888 = f32[896]{0} parameter(4)
  %constant_2331 = f32[] constant(0.000318877544)
  %broadcast.2947 = f32[896]{0} broadcast(f32[] %constant_2331), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1839 = f32[896]{0} multiply(f32[896]{0} %param_4.888, f32[896]{0} %broadcast.2947), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2946 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1839), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.311 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.1002, f32[16,14,14,896]{2,1,3,0} %broadcast.2946), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1211 = f32[896]{0} parameter(2)
  %constant_337 = f32[] constant(0)
  %broadcast.2945 = f32[896]{0} broadcast(f32[] %constant_337), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.529 = f32[896]{0} maximum(f32[896]{0} %param_2.1211, f32[896]{0} %broadcast.2945), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2329 = f32[] constant(1e-05)
  %broadcast.2944 = f32[896]{0} broadcast(f32[] %constant_2329), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.964 = f32[896]{0} add(f32[896]{0} %maximum.529, f32[896]{0} %broadcast.2944), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1752 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.964), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.369 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1939 = f32[896]{0} parameter(1)
  %bitcast.1751 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.1939), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1838 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.369, f32[1,1,1,896]{3,2,1,0} %bitcast.1751), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1750 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1838), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2943 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1750), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1837 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.311, f32[16,14,14,896]{2,1,3,0} %broadcast.2943), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1416 = f32[896]{0} parameter(0)
  %broadcast.2942 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1416), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.963 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1837, f32[16,14,14,896]{2,1,3,0} %broadcast.2942), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.441 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_337), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.15 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.963, f32[16,14,14,896]{2,1,3,0} %broadcast.441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.170 (param_0.1402: f32[16,896], param_1.1919: f32[896]) -> f32[896] {
  %param_0.1402 = f32[16,896]{1,0} parameter(0)
  %constant_341 = f32[] constant(0)
  %reduce.698 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1402, f32[] %constant_341), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_340 = f32[] constant(0.000318877544)
  %broadcast.446 = f32[896]{0} broadcast(f32[] %constant_340), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.411 = f32[896]{0} multiply(f32[896]{0} %reduce.698, f32[896]{0} %broadcast.446), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1919 = f32[896]{0} parameter(1)
  %multiply.1825 = f32[896]{0} multiply(f32[896]{0} %param_1.1919, f32[896]{0} %broadcast.446), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.410 = f32[896]{0} multiply(f32[896]{0} %multiply.1825, f32[896]{0} %multiply.1825), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.16 = f32[896]{0} subtract(f32[896]{0} %multiply.411, f32[896]{0} %multiply.410), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.178 (param_0.315: f32[1,1,1792,3584], param_1.460: f32[1,1,1792,3584]) -> f32[1,1,1792,3584] {
  %param_1.460 = f32[1,1,1792,3584]{3,2,1,0} parameter(1)
  %copy.143 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_1.460), metadata={op_name="2$start"}
  %param_0.315 = f32[1,1,1792,3584]{1,0,2,3} parameter(0)
  %add.100 = f32[1,1,1792,3584]{1,0,2,3} add(f32[1,1,1792,3584]{1,0,2,3} %copy.143, f32[1,1,1792,3584]{1,0,2,3} %param_0.315), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  ROOT %copy.142 = f32[1,1,1792,3584]{3,2,1,0} copy(f32[1,1,1792,3584]{1,0,2,3} %add.100), metadata={op_name="tuple.79"}
}

%fused_computation.180 (param_0.1384: f32[16,14,14,1792], param_1.1891: f32[1792], param_2.1146: f32[1792], param_3.935: f32[1792], param_4.827: f32[16,14,14,1792], param_5.829: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.827 = f32[16,14,14,1792]{2,1,3,0} parameter(4)
  %param_5.829 = f32[1792]{0} parameter(5)
  %constant_2202 = f32[] constant(0.000318877544)
  %broadcast.2777 = f32[1792]{0} broadcast(f32[] %constant_2202), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1763 = f32[1792]{0} multiply(f32[1792]{0} %param_5.829, f32[1792]{0} %broadcast.2777), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2776 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1763), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.291 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_4.827, f32[16,14,14,1792]{2,1,3,0} %broadcast.2776), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.935 = f32[1792]{0} parameter(3)
  %constant_348 = f32[] constant(0)
  %broadcast.2775 = f32[1792]{0} broadcast(f32[] %constant_348), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.491 = f32[1792]{0} maximum(f32[1792]{0} %param_3.935, f32[1792]{0} %broadcast.2775), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2200 = f32[] constant(1e-05)
  %broadcast.2774 = f32[1792]{0} broadcast(f32[] %constant_2200), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.914 = f32[1792]{0} add(f32[1792]{0} %maximum.491, f32[1792]{0} %broadcast.2774), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1662 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.914), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.341 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1662), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1146 = f32[1792]{0} parameter(2)
  %bitcast.1661 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.1146), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1762 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.341, f32[1,1,1,1792]{3,2,1,0} %bitcast.1661), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1660 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1762), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2773 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1660), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1761 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.291, f32[16,14,14,1792]{2,1,3,0} %broadcast.2773), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1891 = f32[1792]{0} parameter(1)
  %broadcast.2772 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.1891), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.913 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1761, f32[16,14,14,1792]{2,1,3,0} %broadcast.2772), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2771 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_348), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.241 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.913, f32[16,14,14,1792]{2,1,3,0} %broadcast.2771), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1384 = f32[16,14,14,1792]{2,1,3,0} parameter(0)
  %select.241 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.241, f32[16,14,14,1792]{2,1,3,0} %param_0.1384, f32[16,14,14,1792]{2,1,3,0} %broadcast.2771), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.27 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %select.241), dimensions={0,3,1,2}
  %bitcast.633 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.27), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.704 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.633, f32[] %constant_348), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1779.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.241, f32[16,14,14,1792]{2,1,3,0} %broadcast.2773), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.22.clone.1 = f32[16,14,14,1792]{2,1,3,0} negate(f32[16,14,14,1792]{2,1,3,0} %multiply.1779.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.28 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %negate.22.clone.1), dimensions={0,3,1,2}
  %bitcast.642.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.28), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.710.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.642.clone.1, f32[] %constant_348), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.437.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.291, f32[16,14,14,1792]{2,1,3,0} %select.241), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.29 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %multiply.437.clone.1), dimensions={0,3,1,2}
  %bitcast.644.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.29), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.712.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.644.clone.1, f32[] %constant_348), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.32 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.704, f32[16,1792]{1,0} %reduce.710.clone.1, f32[16,1792]{1,0} %reduce.712.clone.1)
}

%fused_computation.182 (param_0.322: f32[3,3,896,1792], param_1.469: f32[3,3,896,1792]) -> f32[3,3,896,1792] {
  %param_1.469 = f32[3,3,896,1792]{3,2,1,0} parameter(1)
  %copy.145 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_1.469), metadata={op_name="2$start"}
  %param_0.322 = f32[3,3,896,1792]{1,0,2,3} parameter(0)
  %add.103 = f32[3,3,896,1792]{1,0,2,3} add(f32[3,3,896,1792]{1,0,2,3} %copy.145, f32[3,3,896,1792]{1,0,2,3} %param_0.322), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  ROOT %copy.144 = f32[3,3,896,1792]{3,2,1,0} copy(f32[3,3,896,1792]{1,0,2,3} %add.103), metadata={op_name="tuple.79"}
}

%fused_computation.184 (param_0.1395: f32[16,14,14,896], param_1.1909: f32[896], param_2.1171: f32[896], param_3.966: f32[896], param_4.861: f32[16,14,14,896], param_5.872: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.861 = f32[16,14,14,896]{2,1,3,0} parameter(4)
  %param_5.872 = f32[896]{0} parameter(5)
  %constant_2255 = f32[] constant(0.000318877544)
  %broadcast.2859 = f32[896]{0} broadcast(f32[] %constant_2255), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1801 = f32[896]{0} multiply(f32[896]{0} %param_5.872, f32[896]{0} %broadcast.2859), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2858 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1801), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.301 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_4.861, f32[16,14,14,896]{2,1,3,0} %broadcast.2858), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.966 = f32[896]{0} parameter(3)
  %constant_350 = f32[] constant(0)
  %broadcast.2857 = f32[896]{0} broadcast(f32[] %constant_350), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.505 = f32[896]{0} maximum(f32[896]{0} %param_3.966, f32[896]{0} %broadcast.2857), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2253 = f32[] constant(1e-05)
  %broadcast.2856 = f32[896]{0} broadcast(f32[] %constant_2253), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.938 = f32[896]{0} add(f32[896]{0} %maximum.505, f32[896]{0} %broadcast.2856), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1704 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.938), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.355 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1171 = f32[896]{0} parameter(2)
  %bitcast.1703 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.1171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1800 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.355, f32[1,1,1,896]{3,2,1,0} %bitcast.1703), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1702 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1800), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2855 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1702), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1799 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.301, f32[16,14,14,896]{2,1,3,0} %broadcast.2855), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1909 = f32[896]{0} parameter(1)
  %broadcast.2854 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.1909), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.937 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1799, f32[16,14,14,896]{2,1,3,0} %broadcast.2854), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2853 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_350), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.251 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.937, f32[16,14,14,896]{2,1,3,0} %broadcast.2853), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1395 = f32[16,14,14,896]{2,1,3,0} parameter(0)
  %select.251 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.251, f32[16,14,14,896]{2,1,3,0} %param_0.1395, f32[16,14,14,896]{2,1,3,0} %broadcast.2853), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.30 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %select.251), dimensions={0,3,1,2}
  %bitcast.635 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.30), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.706 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.635, f32[] %constant_350), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1817.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.251, f32[16,14,14,896]{2,1,3,0} %broadcast.2855), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.20.clone.1 = f32[16,14,14,896]{2,1,3,0} negate(f32[16,14,14,896]{2,1,3,0} %multiply.1817.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.31 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %negate.20.clone.1), dimensions={0,3,1,2}
  %bitcast.638.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.31), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.707.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.638.clone.1, f32[] %constant_350), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.426.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.301, f32[16,14,14,896]{2,1,3,0} %select.251), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.32 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %multiply.426.clone.1), dimensions={0,3,1,2}
  %bitcast.640.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.32), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.709.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.640.clone.1, f32[] %constant_350), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.30 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.706, f32[16,896]{1,0} %reduce.707.clone.1, f32[16,896]{1,0} %reduce.709.clone.1)
}

%fused_computation.186 (param_0.329: f32[1,1,3584,896], param_1.478: f32[1,1,3584,896]) -> f32[1,1,3584,896] {
  %param_1.478 = f32[1,1,3584,896]{3,2,1,0} parameter(1)
  %copy.147 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_1.478), metadata={op_name="2$start"}
  %param_0.329 = f32[1,1,3584,896]{1,0,2,3} parameter(0)
  %add.106 = f32[1,1,3584,896]{1,0,2,3} add(f32[1,1,3584,896]{1,0,2,3} %copy.147, f32[1,1,3584,896]{1,0,2,3} %param_0.329), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  ROOT %copy.146 = f32[1,1,3584,896]{3,2,1,0} copy(f32[1,1,3584,896]{1,0,2,3} %add.106), metadata={op_name="tuple.79"}
}

%fused_computation.187 (param_0.332: f32[896], param_1.484: f32[896], param_2.1173: f32[16,14,14,896], param_3.968: f32[896], param_4.863: f32[1,1,1,896], param_5.874: f32[896], param_6.590: f32[16,14,14,896], param_7.641: f32[896]) -> f32[16,14,14,896] {
  %param_2.1173 = f32[16,14,14,896]{2,1,3,0} parameter(2)
  %param_1.484 = f32[896]{0} parameter(1)
  %constant_352 = f32[] constant(0.000318877544)
  %broadcast.2879 = f32[896]{0} broadcast(f32[] %constant_352), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1811 = f32[896]{0} multiply(f32[896]{0} %param_1.484, f32[896]{0} %broadcast.2879), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2878 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1811), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.303 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_2.1173, f32[16,14,14,896]{2,1,3,0} %broadcast.2878), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.968 = f32[896]{0} parameter(3)
  %constant_355 = f32[] constant(0)
  %broadcast.2877 = f32[896]{0} broadcast(f32[] %constant_355), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.509 = f32[896]{0} maximum(f32[896]{0} %param_3.968, f32[896]{0} %broadcast.2877), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2035 = f32[] constant(1e-05)
  %broadcast.2876 = f32[896]{0} broadcast(f32[] %constant_2035), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.944 = f32[896]{0} add(f32[896]{0} %maximum.509, f32[896]{0} %broadcast.2876), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1716 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.944), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.359 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1716), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.874 = f32[896]{0} parameter(5)
  %bitcast.1715 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.874), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1810 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.359, f32[1,1,1,896]{3,2,1,0} %bitcast.1715), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1714 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1810), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2875 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1714), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1809 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.303, f32[16,14,14,896]{2,1,3,0} %broadcast.2875), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.641 = f32[896]{0} parameter(7)
  %broadcast.2874 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.641), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.943 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1809, f32[16,14,14,896]{2,1,3,0} %broadcast.2874), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2873 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_355), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.253 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.943, f32[16,14,14,896]{2,1,3,0} %broadcast.2873), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.590 = f32[16,14,14,896]{2,1,3,0} parameter(6)
  %select.253 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.253, f32[16,14,14,896]{2,1,3,0} %param_6.590, f32[16,14,14,896]{2,1,3,0} %broadcast.2873), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1807 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.253, f32[16,14,14,896]{2,1,3,0} %broadcast.2875), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.863 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.425 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.863, f32[1,1,1,896]{3,2,1,0} %bitcast.1715), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.20 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.359, f32[1,1,1,896]{3,2,1,0} %bitcast.1716), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_353 = f32[] constant(-0.5)
  %broadcast.454 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_353), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.424 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.20, f32[1,1,1,896]{3,2,1,0} %broadcast.454), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.423 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.425, f32[1,1,1,896]{3,2,1,0} %multiply.424), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.637 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.423), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.29 = pred[896]{0} compare(f32[896]{0} %param_3.968, f32[896]{0} %maximum.509), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_356 = f32[] constant(1)
  %broadcast.453 = f32[896]{0} broadcast(f32[] %constant_356), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.29 = f32[896]{0} select(pred[896]{0} %compare.29, f32[896]{0} %broadcast.453, f32[896]{0} %broadcast.2877), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.28 = pred[896]{0} compare(f32[896]{0} %broadcast.2877, f32[896]{0} %maximum.509), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_354 = f32[] constant(2)
  %broadcast.452 = f32[896]{0} broadcast(f32[] %constant_354), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.28 = f32[896]{0} select(pred[896]{0} %compare.28, f32[896]{0} %broadcast.452, f32[896]{0} %broadcast.453), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.19 = f32[896]{0} divide(f32[896]{0} %select.29, f32[896]{0} %select.28), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.422 = f32[896]{0} multiply(f32[896]{0} %bitcast.637, f32[896]{0} %divide.19), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_351 = f32[] constant(0.000637755089)
  %broadcast.451 = f32[896]{0} broadcast(f32[] %constant_351), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.421 = f32[896]{0} multiply(f32[896]{0} %multiply.422, f32[896]{0} %broadcast.451), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.450 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.421), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.420 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %param_2.1173, f32[16,14,14,896]{2,1,3,0} %broadcast.450), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.109 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1807, f32[16,14,14,896]{2,1,3,0} %multiply.420), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.332 = f32[896]{0} parameter(0)
  %negate.19 = f32[896]{0} negate(f32[896]{0} %multiply.422), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.419 = f32[896]{0} multiply(f32[896]{0} %param_1.484, f32[896]{0} %broadcast.451), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.418 = f32[896]{0} multiply(f32[896]{0} %negate.19, f32[896]{0} %multiply.419), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.108 = f32[896]{0} add(f32[896]{0} %param_0.332, f32[896]{0} %multiply.418), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.417 = f32[896]{0} multiply(f32[896]{0} %add.108, f32[896]{0} %broadcast.2879), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.449 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.417), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/broadcast_in_dim[shape=(16, 14, 14, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.107 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %add.109, f32[16,14,14,896]{2,1,3,0} %broadcast.449), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.189 (param_0.336: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.336 = f32[16,896]{1,0} parameter(0)
  %constant_357 = f32[] constant(0)
  %reduce.708 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.336, f32[] %constant_357), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.639 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.708), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.193 (param_0.344: f32[1792], param_1.502: f32[1792], param_2.1148: f32[16,14,14,1792], param_3.937: f32[1792], param_4.829: f32[1,1,1,1792], param_5.831: f32[1792], param_6.565: f32[16,14,14,1792], param_7.623: f32[1792]) -> f32[16,14,14,1792] {
  %param_2.1148 = f32[16,14,14,1792]{2,1,3,0} parameter(2)
  %param_1.502 = f32[1792]{0} parameter(1)
  %constant_362 = f32[] constant(0.000318877544)
  %broadcast.2797 = f32[1792]{0} broadcast(f32[] %constant_362), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1773 = f32[1792]{0} multiply(f32[1792]{0} %param_1.502, f32[1792]{0} %broadcast.2797), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2796 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1773), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.293 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_2.1148, f32[16,14,14,1792]{2,1,3,0} %broadcast.2796), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.937 = f32[1792]{0} parameter(3)
  %constant_365 = f32[] constant(0)
  %broadcast.2795 = f32[1792]{0} broadcast(f32[] %constant_365), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.495 = f32[1792]{0} maximum(f32[1792]{0} %param_3.937, f32[1792]{0} %broadcast.2795), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2092 = f32[] constant(1e-05)
  %broadcast.2794 = f32[1792]{0} broadcast(f32[] %constant_2092), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.920 = f32[1792]{0} add(f32[1792]{0} %maximum.495, f32[1792]{0} %broadcast.2794), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1674 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.920), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.345 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.831 = f32[1792]{0} parameter(5)
  %bitcast.1673 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.831), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1772 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.345, f32[1,1,1,1792]{3,2,1,0} %bitcast.1673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1672 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1772), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2793 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1672), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1771 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.293, f32[16,14,14,1792]{2,1,3,0} %broadcast.2793), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.623 = f32[1792]{0} parameter(7)
  %broadcast.2792 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.623), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.919 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1771, f32[16,14,14,1792]{2,1,3,0} %broadcast.2792), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2791 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_365), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.243 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.919, f32[16,14,14,1792]{2,1,3,0} %broadcast.2791), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.565 = f32[16,14,14,1792]{2,1,3,0} parameter(6)
  %select.243 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.243, f32[16,14,14,1792]{2,1,3,0} %param_6.565, f32[16,14,14,1792]{2,1,3,0} %broadcast.2791), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1769 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.243, f32[16,14,14,1792]{2,1,3,0} %broadcast.2793), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.829 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.436 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.829, f32[1,1,1,1792]{3,2,1,0} %bitcast.1673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.22 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.345, f32[1,1,1,1792]{3,2,1,0} %bitcast.1674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_363 = f32[] constant(-0.5)
  %broadcast.465 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_363), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.435 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.22, f32[1,1,1,1792]{3,2,1,0} %broadcast.465), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.434 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.436, f32[1,1,1,1792]{3,2,1,0} %multiply.435), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.641 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.434), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.32 = pred[1792]{0} compare(f32[1792]{0} %param_3.937, f32[1792]{0} %maximum.495), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_366 = f32[] constant(1)
  %broadcast.464 = f32[1792]{0} broadcast(f32[] %constant_366), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.32 = f32[1792]{0} select(pred[1792]{0} %compare.32, f32[1792]{0} %broadcast.464, f32[1792]{0} %broadcast.2795), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.31 = pred[1792]{0} compare(f32[1792]{0} %broadcast.2795, f32[1792]{0} %maximum.495), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_364 = f32[] constant(2)
  %broadcast.463 = f32[1792]{0} broadcast(f32[] %constant_364), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.31 = f32[1792]{0} select(pred[1792]{0} %compare.31, f32[1792]{0} %broadcast.463, f32[1792]{0} %broadcast.464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.21 = f32[1792]{0} divide(f32[1792]{0} %select.32, f32[1792]{0} %select.31), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.433 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.641, f32[1792]{0} %divide.21), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_361 = f32[] constant(0.000637755089)
  %broadcast.461 = f32[1792]{0} broadcast(f32[] %constant_361), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.432 = f32[1792]{0} multiply(f32[1792]{0} %multiply.433, f32[1792]{0} %broadcast.461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.460 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.432), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.431 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %param_2.1148, f32[16,14,14,1792]{2,1,3,0} %broadcast.460), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.112 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1769, f32[16,14,14,1792]{2,1,3,0} %multiply.431), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.344 = f32[1792]{0} parameter(0)
  %negate.21 = f32[1792]{0} negate(f32[1792]{0} %multiply.433), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.430 = f32[1792]{0} multiply(f32[1792]{0} %param_1.502, f32[1792]{0} %broadcast.461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.429 = f32[1792]{0} multiply(f32[1792]{0} %negate.21, f32[1792]{0} %multiply.430), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.111 = f32[1792]{0} add(f32[1792]{0} %param_0.344, f32[1792]{0} %multiply.429), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.428 = f32[1792]{0} multiply(f32[1792]{0} %add.111, f32[1792]{0} %broadcast.2797), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.459 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.428), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/broadcast_in_dim[shape=(16, 14, 14, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.110 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %add.112, f32[16,14,14,1792]{2,1,3,0} %broadcast.459), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.195 (param_0.348: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.348 = f32[16,1792]{1,0} parameter(0)
  %constant_367 = f32[] constant(0)
  %reduce.711 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.348, f32[] %constant_367), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.643 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.711), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.199 (param_0.356: f32[3584], param_1.520: f32[3584], param_2.1125: f32[16,14,14,3584], param_3.912: f32[3584], param_4.803: f32[1,1,1,3584], param_5.801: f32[3584], param_6.545: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_6.545 = f32[16,14,14,3584]{2,1,3,0} parameter(6)
  %param_3.912 = f32[3584]{0} parameter(3)
  %constant_375 = f32[] constant(0)
  %broadcast.2729 = f32[3584]{0} broadcast(f32[] %constant_375), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.483 = f32[3584]{0} maximum(f32[3584]{0} %param_3.912, f32[3584]{0} %broadcast.2729), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2149 = f32[] constant(1e-05)
  %broadcast.2728 = f32[3584]{0} broadcast(f32[] %constant_2149), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.900 = f32[3584]{0} add(f32[3584]{0} %maximum.483, f32[3584]{0} %broadcast.2728), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1638 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.900), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.333 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1638), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.801 = f32[3584]{0} parameter(5)
  %bitcast.1637 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.801), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1741 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.333, f32[1,1,1,3584]{3,2,1,0} %bitcast.1637), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1636 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1741), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2727 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1636), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1740 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_6.545, f32[16,14,14,3584]{2,1,3,0} %broadcast.2727), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.1125 = f32[16,14,14,3584]{2,1,3,0} parameter(2)
  %param_4.803 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.447 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.803, f32[1,1,1,3584]{3,2,1,0} %bitcast.1637), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.24 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.333, f32[1,1,1,3584]{3,2,1,0} %bitcast.1638), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_373 = f32[] constant(-0.5)
  %broadcast.475 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_373), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.446 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.24, f32[1,1,1,3584]{3,2,1,0} %broadcast.475), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.445 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.447, f32[1,1,1,3584]{3,2,1,0} %multiply.446), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.645 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.445), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.35 = pred[3584]{0} compare(f32[3584]{0} %param_3.912, f32[3584]{0} %maximum.483), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_376 = f32[] constant(1)
  %broadcast.474 = f32[3584]{0} broadcast(f32[] %constant_376), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.35 = f32[3584]{0} select(pred[3584]{0} %compare.35, f32[3584]{0} %broadcast.474, f32[3584]{0} %broadcast.2729), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.34 = pred[3584]{0} compare(f32[3584]{0} %broadcast.2729, f32[3584]{0} %maximum.483), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_374 = f32[] constant(2)
  %broadcast.473 = f32[3584]{0} broadcast(f32[] %constant_374), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.34 = f32[3584]{0} select(pred[3584]{0} %compare.34, f32[3584]{0} %broadcast.473, f32[3584]{0} %broadcast.474), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.23 = f32[3584]{0} divide(f32[3584]{0} %select.35, f32[3584]{0} %select.34), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.444 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.645, f32[3584]{0} %divide.23), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_371 = f32[] constant(0.000637755089)
  %broadcast.471 = f32[3584]{0} broadcast(f32[] %constant_371), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.443 = f32[3584]{0} multiply(f32[3584]{0} %multiply.444, f32[3584]{0} %broadcast.471), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.470 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.443), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.442 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_2.1125, f32[16,14,14,3584]{2,1,3,0} %broadcast.470), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.115 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.1740, f32[16,14,14,3584]{2,1,3,0} %multiply.442), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.356 = f32[3584]{0} parameter(0)
  %negate.23 = f32[3584]{0} negate(f32[3584]{0} %multiply.444), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.520 = f32[3584]{0} parameter(1)
  %multiply.441 = f32[3584]{0} multiply(f32[3584]{0} %param_1.520, f32[3584]{0} %broadcast.471), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.440 = f32[3584]{0} multiply(f32[3584]{0} %negate.23, f32[3584]{0} %multiply.441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.114 = f32[3584]{0} add(f32[3584]{0} %param_0.356, f32[3584]{0} %multiply.440), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_372 = f32[] constant(0.000318877544)
  %broadcast.472 = f32[3584]{0} broadcast(f32[] %constant_372), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.439 = f32[3584]{0} multiply(f32[3584]{0} %add.114, f32[3584]{0} %broadcast.472), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.469 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.439), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/broadcast_in_dim[shape=(16, 14, 14, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.113 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %add.115, f32[16,14,14,3584]{2,1,3,0} %broadcast.469), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.200 (param_0.1377: f32[16,14,14,3584], param_1.1881: f32[3584], param_2.1132: f32[3584], param_3.1417: f32[16,14,14,3584], param_4.1253: f32[3584]) -> (f32[16,3584], f32[16,3584], f32[16,3584]) {
  %param_0.1377 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_2.1132 = f32[3584]{0} parameter(2)
  %constant_379 = f32[] constant(0)
  %broadcast.2735 = f32[3584]{0} broadcast(f32[] %constant_379), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.485 = f32[3584]{0} maximum(f32[3584]{0} %param_2.1132, f32[3584]{0} %broadcast.2735), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2174 = f32[] constant(1e-05)
  %broadcast.2734 = f32[3584]{0} broadcast(f32[] %constant_2174), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.902 = f32[3584]{0} add(f32[3584]{0} %maximum.485, f32[3584]{0} %broadcast.2734), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1644 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.902), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.335 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1644), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1881 = f32[3584]{0} parameter(1)
  %bitcast.1643 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.1881), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1745 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.335, f32[1,1,1,3584]{3,2,1,0} %bitcast.1643), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1642 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1745), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2733 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1642), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1744 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_0.1377, f32[16,14,14,3584]{2,1,3,0} %broadcast.2733), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.24 = f32[16,14,14,3584]{2,1,3,0} negate(f32[16,14,14,3584]{2,1,3,0} %multiply.1744), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.33 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %negate.24), dimensions={0,3,1,2}
  %bitcast.646 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.33), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.713 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.646, f32[] %constant_379), dimensions={2}, to_apply=%region_57.4114.2
  %param_3.1417 = f32[16,14,14,3584]{2,1,3,0} parameter(3)
  %param_4.1253 = f32[3584]{0} parameter(4)
  %constant_2134_clone_1 = f32[] constant(0.000318877544)
  %broadcast.2699.clone.1 = f32[3584]{0} broadcast(f32[] %constant_2134_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1733.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_4.1253, f32[3584]{0} %broadcast.2699.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2698.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1733.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.285.clone.1 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_3.1417, f32[16,14,14,3584]{2,1,3,0} %broadcast.2698.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.448.clone.1 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.285.clone.1, f32[16,14,14,3584]{2,1,3,0} %param_0.1377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.34 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %multiply.448.clone.1), dimensions={0,3,1,2}
  %bitcast.648.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.34), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.715.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.648.clone.1, f32[] %constant_379), dimensions={2}, to_apply=%region_57.4114.2
  %transpose.35 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %param_0.1377), dimensions={0,3,1,2}
  %bitcast.631.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.35), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.702.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.631.clone.1, f32[] %constant_379), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.34 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.713, f32[16,3584]{1,0} %reduce.715.clone.1, f32[16,3584]{1,0} %reduce.702.clone.1)
}

%fused_computation.201 (param_0.360: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.360 = f32[16,3584]{1,0} parameter(0)
  %constant_377 = f32[] constant(0)
  %reduce.714 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.360, f32[] %constant_377), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.647 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.714), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.204 (param_0.365: f32[16,14,14,3584], param_1.532: f32[16,14,14,3584], param_2.167: f32[3584], param_3.907: f32[16,14,14,3584], param_4.802: f32[3584], param_5.800: f32[3584], param_6.544: f32[3584]) -> f32[16,14,14,3584] {
  %param_1.532 = f32[16,14,14,3584]{2,1,3,0} parameter(1)
  %param_3.907 = f32[16,14,14,3584]{2,1,3,0} parameter(3)
  %param_4.802 = f32[3584]{0} parameter(4)
  %constant_2131 = f32[] constant(0.000318877544)
  %broadcast.2695 = f32[3584]{0} broadcast(f32[] %constant_2131), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1731 = f32[3584]{0} multiply(f32[3584]{0} %param_4.802, f32[3584]{0} %broadcast.2695), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2694 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1731), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.283 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_3.907, f32[16,14,14,3584]{2,1,3,0} %broadcast.2694), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_6.544 = f32[3584]{0} parameter(6)
  %constant_380 = f32[] constant(0)
  %broadcast.2719 = f32[3584]{0} broadcast(f32[] %constant_380), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.479 = f32[3584]{0} maximum(f32[3584]{0} %param_6.544, f32[3584]{0} %broadcast.2719), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2159 = f32[] constant(1e-05)
  %broadcast.2718 = f32[3584]{0} broadcast(f32[] %constant_2159), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.896 = f32[3584]{0} add(f32[3584]{0} %maximum.479, f32[3584]{0} %broadcast.2718), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1626 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.896), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.329 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1626), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.800 = f32[3584]{0} parameter(5)
  %bitcast.1625 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.800), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1735 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.329, f32[1,1,1,3584]{3,2,1,0} %bitcast.1625), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1624 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1735), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.479 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1624), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.450 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.283, f32[16,14,14,3584]{2,1,3,0} %broadcast.479), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.167 = f32[3584]{0} parameter(2)
  %broadcast.478 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_2.167), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.117 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.450, f32[16,14,14,3584]{2,1,3,0} %broadcast.478), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.116 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_1.532, f32[16,14,14,3584]{2,1,3,0} %add.117), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.480 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_380), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.36 = pred[16,14,14,3584]{2,1,3,0} compare(f32[16,14,14,3584]{2,1,3,0} %add.116, f32[16,14,14,3584]{2,1,3,0} %broadcast.480), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.365 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  ROOT %select.36 = f32[16,14,14,3584]{2,1,3,0} select(pred[16,14,14,3584]{2,1,3,0} %compare.36, f32[16,14,14,3584]{2,1,3,0} %param_0.365, f32[16,14,14,3584]{2,1,3,0} %broadcast.480), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.208 (param_0.1363: f32[16,3584], param_1.1861: f32[3584]) -> f32[3584] {
  %param_0.1363 = f32[16,3584]{1,0} parameter(0)
  %constant_384 = f32[] constant(0)
  %reduce.716 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.1363, f32[] %constant_384), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_383 = f32[] constant(0.000318877544)
  %broadcast.483 = f32[3584]{0} broadcast(f32[] %constant_383), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.453 = f32[3584]{0} multiply(f32[3584]{0} %reduce.716, f32[3584]{0} %broadcast.483), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1861 = f32[3584]{0} parameter(1)
  %multiply.1729 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1861, f32[3584]{0} %broadcast.483), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.452 = f32[3584]{0} multiply(f32[3584]{0} %multiply.1729, f32[3584]{0} %multiply.1729), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.18 = f32[3584]{0} subtract(f32[3584]{0} %multiply.453, f32[3584]{0} %multiply.452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.213 (param_0.1359: f32[1792], param_1.1856: f32[1792], param_2.1098: f32[1792], param_3.892: f32[16,14,14,1792], param_4.791: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.892 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.791 = f32[1792]{0} parameter(4)
  %constant_2115 = f32[] constant(0.000318877544)
  %broadcast.2675 = f32[1792]{0} broadcast(f32[] %constant_2115), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1719 = f32[1792]{0} multiply(f32[1792]{0} %param_4.791, f32[1792]{0} %broadcast.2675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2674 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1719), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.279 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.892, f32[16,14,14,1792]{2,1,3,0} %broadcast.2674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1098 = f32[1792]{0} parameter(2)
  %constant_388 = f32[] constant(0)
  %broadcast.2673 = f32[1792]{0} broadcast(f32[] %constant_388), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.465 = f32[1792]{0} maximum(f32[1792]{0} %param_2.1098, f32[1792]{0} %broadcast.2673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2113 = f32[] constant(1e-05)
  %broadcast.2672 = f32[1792]{0} broadcast(f32[] %constant_2113), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.884 = f32[1792]{0} add(f32[1792]{0} %maximum.465, f32[1792]{0} %broadcast.2672), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1608 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.325 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1608), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1856 = f32[1792]{0} parameter(1)
  %bitcast.1607 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1856), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1718 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.325, f32[1,1,1,1792]{3,2,1,0} %bitcast.1607), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1606 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1718), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2671 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1606), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1717 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.279, f32[16,14,14,1792]{2,1,3,0} %broadcast.2671), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1359 = f32[1792]{0} parameter(0)
  %broadcast.2670 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1359), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.883 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1717, f32[16,14,14,1792]{2,1,3,0} %broadcast.2670), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.486 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_388), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.18 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.883, f32[16,14,14,1792]{2,1,3,0} %broadcast.486), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.218 (param_0.1345: f32[16,1792], param_1.1836: f32[1792]) -> f32[1792] {
  %param_0.1345 = f32[16,1792]{1,0} parameter(0)
  %constant_392 = f32[] constant(0)
  %reduce.719 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1345, f32[] %constant_392), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_391 = f32[] constant(0.000318877544)
  %broadcast.491 = f32[1792]{0} broadcast(f32[] %constant_391), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.459 = f32[1792]{0} multiply(f32[1792]{0} %reduce.719, f32[1792]{0} %broadcast.491), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1836 = f32[1792]{0} parameter(1)
  %multiply.1705 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1836, f32[1792]{0} %broadcast.491), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.458 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1705, f32[1792]{0} %multiply.1705), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.20 = f32[1792]{0} subtract(f32[1792]{0} %multiply.459, f32[1792]{0} %multiply.458), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.223 (param_0.1341: f32[896], param_1.1831: f32[896], param_2.1064: f32[896], param_3.861: f32[16,14,14,896], param_4.766: f32[896]) -> f32[16,14,14,896] {
  %param_3.861 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.766 = f32[896]{0} parameter(4)
  %constant_2058 = f32[] constant(0.000318877544)
  %broadcast.2615 = f32[896]{0} broadcast(f32[] %constant_2058), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1695 = f32[896]{0} multiply(f32[896]{0} %param_4.766, f32[896]{0} %broadcast.2615), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2614 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1695), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.271 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.861, f32[16,14,14,896]{2,1,3,0} %broadcast.2614), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.1064 = f32[896]{0} parameter(2)
  %constant_396 = f32[] constant(0)
  %broadcast.2613 = f32[896]{0} broadcast(f32[] %constant_396), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.447 = f32[896]{0} maximum(f32[896]{0} %param_2.1064, f32[896]{0} %broadcast.2613), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_2056 = f32[] constant(1e-05)
  %broadcast.2612 = f32[896]{0} broadcast(f32[] %constant_2056), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.866 = f32[896]{0} add(f32[896]{0} %maximum.447, f32[896]{0} %broadcast.2612), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1578 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.866), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.317 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1578), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1831 = f32[896]{0} parameter(1)
  %bitcast.1577 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.1831), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1694 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.317, f32[1,1,1,896]{3,2,1,0} %bitcast.1577), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1576 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1694), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2611 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1576), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1693 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.271, f32[16,14,14,896]{2,1,3,0} %broadcast.2611), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1341 = f32[896]{0} parameter(0)
  %broadcast.2610 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1341), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.865 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1693, f32[16,14,14,896]{2,1,3,0} %broadcast.2610), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.494 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_396), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.20 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.865, f32[16,14,14,896]{2,1,3,0} %broadcast.494), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.228 (param_0.1327: f32[16,896], param_1.1811: f32[896]) -> f32[896] {
  %param_0.1327 = f32[16,896]{1,0} parameter(0)
  %constant_400 = f32[] constant(0)
  %reduce.722 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1327, f32[] %constant_400), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_399 = f32[] constant(0.000318877544)
  %broadcast.499 = f32[896]{0} broadcast(f32[] %constant_399), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.465 = f32[896]{0} multiply(f32[896]{0} %reduce.722, f32[896]{0} %broadcast.499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1811 = f32[896]{0} parameter(1)
  %multiply.1681 = f32[896]{0} multiply(f32[896]{0} %param_1.1811, f32[896]{0} %broadcast.499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.464 = f32[896]{0} multiply(f32[896]{0} %multiply.1681, f32[896]{0} %multiply.1681), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.22 = f32[896]{0} subtract(f32[896]{0} %multiply.465, f32[896]{0} %multiply.464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.236 (param_0.417: f32[1,1,1792,3584], param_1.608: f32[1,1,1792,3584]) -> f32[1,1,1792,3584] {
  %param_1.608 = f32[1,1,1792,3584]{3,2,1,0} parameter(1)
  %copy.149 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %param_1.608), metadata={op_name="2$start"}
  %param_0.417 = f32[1,1,1792,3584]{1,0,2,3} parameter(0)
  %add.125 = f32[1,1,1792,3584]{1,0,2,3} add(f32[1,1,1792,3584]{1,0,2,3} %copy.149, f32[1,1,1792,3584]{1,0,2,3} %param_0.417), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  ROOT %copy.148 = f32[1,1,1792,3584]{3,2,1,0} copy(f32[1,1,1792,3584]{1,0,2,3} %add.125), metadata={op_name="tuple.79"}
}

%fused_computation.238 (param_0.1309: f32[16,14,14,1792], param_1.1783: f32[1792], param_2.999: f32[1792], param_3.794: f32[1792], param_4.705: f32[16,14,14,1792], param_5.704: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.705 = f32[16,14,14,1792]{2,1,3,0} parameter(4)
  %param_5.704 = f32[1792]{0} parameter(5)
  %constant_1929 = f32[] constant(0.000318877544)
  %broadcast.2445 = f32[1792]{0} broadcast(f32[] %constant_1929), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1619 = f32[1792]{0} multiply(f32[1792]{0} %param_5.704, f32[1792]{0} %broadcast.2445), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2444 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1619), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.251 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_4.705, f32[16,14,14,1792]{2,1,3,0} %broadcast.2444), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.794 = f32[1792]{0} parameter(3)
  %constant_407 = f32[] constant(0)
  %broadcast.2443 = f32[1792]{0} broadcast(f32[] %constant_407), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.409 = f32[1792]{0} maximum(f32[1792]{0} %param_3.794, f32[1792]{0} %broadcast.2443), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1927 = f32[] constant(1e-05)
  %broadcast.2442 = f32[1792]{0} broadcast(f32[] %constant_1927), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.816 = f32[1792]{0} add(f32[1792]{0} %maximum.409, f32[1792]{0} %broadcast.2442), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1488 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.816), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.289 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1488), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.999 = f32[1792]{0} parameter(2)
  %bitcast.1487 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.999), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1618 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.289, f32[1,1,1,1792]{3,2,1,0} %bitcast.1487), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1486 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1618), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2441 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1486), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1617 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.251, f32[16,14,14,1792]{2,1,3,0} %broadcast.2441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1783 = f32[1792]{0} parameter(1)
  %broadcast.2440 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.1783), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.815 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1617, f32[16,14,14,1792]{2,1,3,0} %broadcast.2440), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2439 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_407), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.221 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.815, f32[16,14,14,1792]{2,1,3,0} %broadcast.2439), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1309 = f32[16,14,14,1792]{2,1,3,0} parameter(0)
  %select.221 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.221, f32[16,14,14,1792]{2,1,3,0} %param_0.1309, f32[16,14,14,1792]{2,1,3,0} %broadcast.2439), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.36 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %select.221), dimensions={0,3,1,2}
  %bitcast.663 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.36), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.728 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.663, f32[] %constant_407), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1635.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.221, f32[16,14,14,1792]{2,1,3,0} %broadcast.2441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.28.clone.1 = f32[16,14,14,1792]{2,1,3,0} negate(f32[16,14,14,1792]{2,1,3,0} %multiply.1635.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.37 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %negate.28.clone.1), dimensions={0,3,1,2}
  %bitcast.672.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.37), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.734.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.672.clone.1, f32[] %constant_407), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.491.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.251, f32[16,14,14,1792]{2,1,3,0} %select.221), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.38 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %multiply.491.clone.1), dimensions={0,3,1,2}
  %bitcast.674.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.38), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.736.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.674.clone.1, f32[] %constant_407), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.41 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.728, f32[16,1792]{1,0} %reduce.734.clone.1, f32[16,1792]{1,0} %reduce.736.clone.1)
}

%fused_computation.240 (param_0.424: f32[3,3,896,1792], param_1.617: f32[3,3,896,1792]) -> f32[3,3,896,1792] {
  %param_1.617 = f32[3,3,896,1792]{3,2,1,0} parameter(1)
  %copy.151 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %param_1.617), metadata={op_name="2$start"}
  %param_0.424 = f32[3,3,896,1792]{1,0,2,3} parameter(0)
  %add.128 = f32[3,3,896,1792]{1,0,2,3} add(f32[3,3,896,1792]{1,0,2,3} %copy.151, f32[3,3,896,1792]{1,0,2,3} %param_0.424), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  ROOT %copy.150 = f32[3,3,896,1792]{3,2,1,0} copy(f32[3,3,896,1792]{1,0,2,3} %add.128), metadata={op_name="tuple.79"}
}

%fused_computation.242 (param_0.1320: f32[16,14,14,896], param_1.1801: f32[896], param_2.1024: f32[896], param_3.825: f32[896], param_4.739: f32[16,14,14,896], param_5.747: f32[896]) -> (f32[16,896], f32[16,896], f32[16,896]) {
  %param_4.739 = f32[16,14,14,896]{2,1,3,0} parameter(4)
  %param_5.747 = f32[896]{0} parameter(5)
  %constant_1982 = f32[] constant(0.000318877544)
  %broadcast.2527 = f32[896]{0} broadcast(f32[] %constant_1982), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1657 = f32[896]{0} multiply(f32[896]{0} %param_5.747, f32[896]{0} %broadcast.2527), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2526 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1657), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.261 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_4.739, f32[16,14,14,896]{2,1,3,0} %broadcast.2526), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.825 = f32[896]{0} parameter(3)
  %constant_409 = f32[] constant(0)
  %broadcast.2525 = f32[896]{0} broadcast(f32[] %constant_409), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.423 = f32[896]{0} maximum(f32[896]{0} %param_3.825, f32[896]{0} %broadcast.2525), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1980 = f32[] constant(1e-05)
  %broadcast.2524 = f32[896]{0} broadcast(f32[] %constant_1980), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.840 = f32[896]{0} add(f32[896]{0} %maximum.423, f32[896]{0} %broadcast.2524), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1530 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.840), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.303 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1530), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.1024 = f32[896]{0} parameter(2)
  %bitcast.1529 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_2.1024), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1656 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.303, f32[1,1,1,896]{3,2,1,0} %bitcast.1529), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1528 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1656), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2523 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1528), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1655 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.261, f32[16,14,14,896]{2,1,3,0} %broadcast.2523), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1801 = f32[896]{0} parameter(1)
  %broadcast.2522 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_1.1801), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.839 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1655, f32[16,14,14,896]{2,1,3,0} %broadcast.2522), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2521 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_409), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.231 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.839, f32[16,14,14,896]{2,1,3,0} %broadcast.2521), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1320 = f32[16,14,14,896]{2,1,3,0} parameter(0)
  %select.231 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.231, f32[16,14,14,896]{2,1,3,0} %param_0.1320, f32[16,14,14,896]{2,1,3,0} %broadcast.2521), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.39 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %select.231), dimensions={0,3,1,2}
  %bitcast.665 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.39), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.730 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.665, f32[] %constant_409), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1673.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.231, f32[16,14,14,896]{2,1,3,0} %broadcast.2523), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.26.clone.1 = f32[16,14,14,896]{2,1,3,0} negate(f32[16,14,14,896]{2,1,3,0} %multiply.1673.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.40 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %negate.26.clone.1), dimensions={0,3,1,2}
  %bitcast.668.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.40), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.731.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.668.clone.1, f32[] %constant_409), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.480.clone.1 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.261, f32[16,14,14,896]{2,1,3,0} %select.231), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.41 = f32[16,896,14,14]{3,2,1,0} transpose(f32[16,14,14,896]{2,1,3,0} %multiply.480.clone.1), dimensions={0,3,1,2}
  %bitcast.670.clone.1 = f32[16,896,196]{2,1,0} bitcast(f32[16,896,14,14]{3,2,1,0} %transpose.41), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.733.clone.1 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %bitcast.670.clone.1, f32[] %constant_409), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.39 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.730, f32[16,896]{1,0} %reduce.731.clone.1, f32[16,896]{1,0} %reduce.733.clone.1)
}

%fused_computation.244 (param_0.431: f32[1,1,3584,896], param_1.626: f32[1,1,3584,896]) -> f32[1,1,3584,896] {
  %param_1.626 = f32[1,1,3584,896]{3,2,1,0} parameter(1)
  %copy.153 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %param_1.626), metadata={op_name="2$start"}
  %param_0.431 = f32[1,1,3584,896]{1,0,2,3} parameter(0)
  %add.131 = f32[1,1,3584,896]{1,0,2,3} add(f32[1,1,3584,896]{1,0,2,3} %copy.153, f32[1,1,3584,896]{1,0,2,3} %param_0.431), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  ROOT %copy.152 = f32[1,1,3584,896]{3,2,1,0} copy(f32[1,1,3584,896]{1,0,2,3} %add.131), metadata={op_name="tuple.79"}
}

%fused_computation.245 (param_0.434: f32[896], param_1.632: f32[896], param_2.1026: f32[16,14,14,896], param_3.827: f32[896], param_4.741: f32[1,1,1,896], param_5.749: f32[896], param_6.521: f32[16,14,14,896], param_7.577: f32[896]) -> f32[16,14,14,896] {
  %param_2.1026 = f32[16,14,14,896]{2,1,3,0} parameter(2)
  %param_1.632 = f32[896]{0} parameter(1)
  %constant_411 = f32[] constant(0.000318877544)
  %broadcast.2547 = f32[896]{0} broadcast(f32[] %constant_411), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1667 = f32[896]{0} multiply(f32[896]{0} %param_1.632, f32[896]{0} %broadcast.2547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2546 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1667), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.263 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_2.1026, f32[16,14,14,896]{2,1,3,0} %broadcast.2546), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.827 = f32[896]{0} parameter(3)
  %constant_414 = f32[] constant(0)
  %broadcast.2545 = f32[896]{0} broadcast(f32[] %constant_414), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.427 = f32[896]{0} maximum(f32[896]{0} %param_3.827, f32[896]{0} %broadcast.2545), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1762 = f32[] constant(1e-05)
  %broadcast.2544 = f32[896]{0} broadcast(f32[] %constant_1762), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.846 = f32[896]{0} add(f32[896]{0} %maximum.427, f32[896]{0} %broadcast.2544), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1542 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.846), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.307 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.749 = f32[896]{0} parameter(5)
  %bitcast.1541 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_5.749), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1666 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.307, f32[1,1,1,896]{3,2,1,0} %bitcast.1541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1540 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1666), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2543 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1540), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1665 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.263, f32[16,14,14,896]{2,1,3,0} %broadcast.2543), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.577 = f32[896]{0} parameter(7)
  %broadcast.2542 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_7.577), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.845 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1665, f32[16,14,14,896]{2,1,3,0} %broadcast.2542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2541 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_414), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.233 = pred[16,14,14,896]{2,1,3,0} compare(f32[16,14,14,896]{2,1,3,0} %add.845, f32[16,14,14,896]{2,1,3,0} %broadcast.2541), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.521 = f32[16,14,14,896]{2,1,3,0} parameter(6)
  %select.233 = f32[16,14,14,896]{2,1,3,0} select(pred[16,14,14,896]{2,1,3,0} %compare.233, f32[16,14,14,896]{2,1,3,0} %param_6.521, f32[16,14,14,896]{2,1,3,0} %broadcast.2541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1663 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %select.233, f32[16,14,14,896]{2,1,3,0} %broadcast.2543), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.741 = f32[1,1,1,896]{3,2,1,0} parameter(4)
  %multiply.479 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %param_4.741, f32[1,1,1,896]{3,2,1,0} %bitcast.1541), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.26 = f32[1,1,1,896]{3,2,1,0} divide(f32[1,1,1,896]{3,2,1,0} %rsqrt.307, f32[1,1,1,896]{3,2,1,0} %bitcast.1542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_412 = f32[] constant(-0.5)
  %broadcast.507 = f32[1,1,1,896]{3,2,1,0} broadcast(f32[] %constant_412), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.478 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %divide.26, f32[1,1,1,896]{3,2,1,0} %broadcast.507), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.477 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %multiply.479, f32[1,1,1,896]{3,2,1,0} %multiply.478), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.667 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.38 = pred[896]{0} compare(f32[896]{0} %param_3.827, f32[896]{0} %maximum.427), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_415 = f32[] constant(1)
  %broadcast.506 = f32[896]{0} broadcast(f32[] %constant_415), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/broadcast_in_dim[shape=(896,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.38 = f32[896]{0} select(pred[896]{0} %compare.38, f32[896]{0} %broadcast.506, f32[896]{0} %broadcast.2545), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.37 = pred[896]{0} compare(f32[896]{0} %broadcast.2545, f32[896]{0} %maximum.427), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_413 = f32[] constant(2)
  %broadcast.505 = f32[896]{0} broadcast(f32[] %constant_413), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.37 = f32[896]{0} select(pred[896]{0} %compare.37, f32[896]{0} %broadcast.505, f32[896]{0} %broadcast.506), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.25 = f32[896]{0} divide(f32[896]{0} %select.38, f32[896]{0} %select.37), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.476 = f32[896]{0} multiply(f32[896]{0} %bitcast.667, f32[896]{0} %divide.25), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_410 = f32[] constant(0.000637755089)
  %broadcast.504 = f32[896]{0} broadcast(f32[] %constant_410), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.475 = f32[896]{0} multiply(f32[896]{0} %multiply.476, f32[896]{0} %broadcast.504), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.503 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.475), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.474 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %param_2.1026, f32[16,14,14,896]{2,1,3,0} %broadcast.503), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.134 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1663, f32[16,14,14,896]{2,1,3,0} %multiply.474), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.434 = f32[896]{0} parameter(0)
  %negate.25 = f32[896]{0} negate(f32[896]{0} %multiply.476), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.473 = f32[896]{0} multiply(f32[896]{0} %param_1.632, f32[896]{0} %broadcast.504), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.472 = f32[896]{0} multiply(f32[896]{0} %negate.25, f32[896]{0} %multiply.473), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.133 = f32[896]{0} add(f32[896]{0} %param_0.434, f32[896]{0} %multiply.472), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.471 = f32[896]{0} multiply(f32[896]{0} %add.133, f32[896]{0} %broadcast.2547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.502 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.471), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/broadcast_in_dim[shape=(16, 14, 14, 896) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.132 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %add.134, f32[16,14,14,896]{2,1,3,0} %broadcast.502), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.247 (param_0.438: f32[16,896]) -> f32[1,1,1,896] {
  %param_0.438 = f32[16,896]{1,0} parameter(0)
  %constant_416 = f32[] constant(0)
  %reduce.732 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.438, f32[] %constant_416), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.669 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %reduce.732), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.251 (param_0.446: f32[1792], param_1.650: f32[1792], param_2.1001: f32[16,14,14,1792], param_3.796: f32[1792], param_4.707: f32[1,1,1,1792], param_5.706: f32[1792], param_6.496: f32[16,14,14,1792], param_7.559: f32[1792]) -> f32[16,14,14,1792] {
  %param_2.1001 = f32[16,14,14,1792]{2,1,3,0} parameter(2)
  %param_1.650 = f32[1792]{0} parameter(1)
  %constant_421 = f32[] constant(0.000318877544)
  %broadcast.2465 = f32[1792]{0} broadcast(f32[] %constant_421), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1629 = f32[1792]{0} multiply(f32[1792]{0} %param_1.650, f32[1792]{0} %broadcast.2465), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2464 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1629), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.253 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_2.1001, f32[16,14,14,1792]{2,1,3,0} %broadcast.2464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.796 = f32[1792]{0} parameter(3)
  %constant_424 = f32[] constant(0)
  %broadcast.2463 = f32[1792]{0} broadcast(f32[] %constant_424), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.413 = f32[1792]{0} maximum(f32[1792]{0} %param_3.796, f32[1792]{0} %broadcast.2463), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1819 = f32[] constant(1e-05)
  %broadcast.2462 = f32[1792]{0} broadcast(f32[] %constant_1819), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.822 = f32[1792]{0} add(f32[1792]{0} %maximum.413, f32[1792]{0} %broadcast.2462), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1500 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.822), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.293 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1500), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.706 = f32[1792]{0} parameter(5)
  %bitcast.1499 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.706), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1628 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.293, f32[1,1,1,1792]{3,2,1,0} %bitcast.1499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1498 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1628), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2461 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1498), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1627 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.253, f32[16,14,14,1792]{2,1,3,0} %broadcast.2461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.559 = f32[1792]{0} parameter(7)
  %broadcast.2460 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.559), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.821 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1627, f32[16,14,14,1792]{2,1,3,0} %broadcast.2460), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2459 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_424), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.223 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.821, f32[16,14,14,1792]{2,1,3,0} %broadcast.2459), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.496 = f32[16,14,14,1792]{2,1,3,0} parameter(6)
  %select.223 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.223, f32[16,14,14,1792]{2,1,3,0} %param_6.496, f32[16,14,14,1792]{2,1,3,0} %broadcast.2459), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1625 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.223, f32[16,14,14,1792]{2,1,3,0} %broadcast.2461), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.707 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.490 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.707, f32[1,1,1,1792]{3,2,1,0} %bitcast.1499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.28 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.293, f32[1,1,1,1792]{3,2,1,0} %bitcast.1500), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_422 = f32[] constant(-0.5)
  %broadcast.518 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_422), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.489 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.28, f32[1,1,1,1792]{3,2,1,0} %broadcast.518), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.488 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.490, f32[1,1,1,1792]{3,2,1,0} %multiply.489), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.671 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.488), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.41 = pred[1792]{0} compare(f32[1792]{0} %param_3.796, f32[1792]{0} %maximum.413), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_425 = f32[] constant(1)
  %broadcast.517 = f32[1792]{0} broadcast(f32[] %constant_425), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.41 = f32[1792]{0} select(pred[1792]{0} %compare.41, f32[1792]{0} %broadcast.517, f32[1792]{0} %broadcast.2463), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.40 = pred[1792]{0} compare(f32[1792]{0} %broadcast.2463, f32[1792]{0} %maximum.413), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_423 = f32[] constant(2)
  %broadcast.516 = f32[1792]{0} broadcast(f32[] %constant_423), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.40 = f32[1792]{0} select(pred[1792]{0} %compare.40, f32[1792]{0} %broadcast.516, f32[1792]{0} %broadcast.517), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.27 = f32[1792]{0} divide(f32[1792]{0} %select.41, f32[1792]{0} %select.40), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.487 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.671, f32[1792]{0} %divide.27), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_420 = f32[] constant(0.000637755089)
  %broadcast.514 = f32[1792]{0} broadcast(f32[] %constant_420), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.486 = f32[1792]{0} multiply(f32[1792]{0} %multiply.487, f32[1792]{0} %broadcast.514), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.513 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.486), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.485 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %param_2.1001, f32[16,14,14,1792]{2,1,3,0} %broadcast.513), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.137 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1625, f32[16,14,14,1792]{2,1,3,0} %multiply.485), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.446 = f32[1792]{0} parameter(0)
  %negate.27 = f32[1792]{0} negate(f32[1792]{0} %multiply.487), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.484 = f32[1792]{0} multiply(f32[1792]{0} %param_1.650, f32[1792]{0} %broadcast.514), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.483 = f32[1792]{0} multiply(f32[1792]{0} %negate.27, f32[1792]{0} %multiply.484), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.136 = f32[1792]{0} add(f32[1792]{0} %param_0.446, f32[1792]{0} %multiply.483), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.482 = f32[1792]{0} multiply(f32[1792]{0} %add.136, f32[1792]{0} %broadcast.2465), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.512 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.482), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/broadcast_in_dim[shape=(16, 14, 14, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.135 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %add.137, f32[16,14,14,1792]{2,1,3,0} %broadcast.512), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.253 (param_0.450: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.450 = f32[16,1792]{1,0} parameter(0)
  %constant_426 = f32[] constant(0)
  %reduce.735 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.450, f32[] %constant_426), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.673 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.735), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.257 (param_0.458: f32[3584], param_1.668: f32[3584], param_2.978: f32[16,14,14,3584], param_3.771: f32[3584], param_4.681: f32[1,1,1,3584], param_5.676: f32[3584], param_6.476: f32[16,14,14,3584]) -> f32[16,14,14,3584] {
  %param_6.476 = f32[16,14,14,3584]{2,1,3,0} parameter(6)
  %param_3.771 = f32[3584]{0} parameter(3)
  %constant_434 = f32[] constant(0)
  %broadcast.2397 = f32[3584]{0} broadcast(f32[] %constant_434), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.401 = f32[3584]{0} maximum(f32[3584]{0} %param_3.771, f32[3584]{0} %broadcast.2397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1876 = f32[] constant(1e-05)
  %broadcast.2396 = f32[3584]{0} broadcast(f32[] %constant_1876), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.802 = f32[3584]{0} add(f32[3584]{0} %maximum.401, f32[3584]{0} %broadcast.2396), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1464 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.802), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.281 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.676 = f32[3584]{0} parameter(5)
  %bitcast.1463 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.676), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1597 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.281, f32[1,1,1,3584]{3,2,1,0} %bitcast.1463), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1462 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1597), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2395 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1462), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1596 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_6.476, f32[16,14,14,3584]{2,1,3,0} %broadcast.2395), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.978 = f32[16,14,14,3584]{2,1,3,0} parameter(2)
  %param_4.681 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.501 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.681, f32[1,1,1,3584]{3,2,1,0} %bitcast.1463), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.30 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.281, f32[1,1,1,3584]{3,2,1,0} %bitcast.1464), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_432 = f32[] constant(-0.5)
  %broadcast.528 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_432), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.500 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.30, f32[1,1,1,3584]{3,2,1,0} %broadcast.528), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.499 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.501, f32[1,1,1,3584]{3,2,1,0} %multiply.500), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.675 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.44 = pred[3584]{0} compare(f32[3584]{0} %param_3.771, f32[3584]{0} %maximum.401), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_435 = f32[] constant(1)
  %broadcast.527 = f32[3584]{0} broadcast(f32[] %constant_435), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.44 = f32[3584]{0} select(pred[3584]{0} %compare.44, f32[3584]{0} %broadcast.527, f32[3584]{0} %broadcast.2397), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.43 = pred[3584]{0} compare(f32[3584]{0} %broadcast.2397, f32[3584]{0} %maximum.401), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_433 = f32[] constant(2)
  %broadcast.526 = f32[3584]{0} broadcast(f32[] %constant_433), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.43 = f32[3584]{0} select(pred[3584]{0} %compare.43, f32[3584]{0} %broadcast.526, f32[3584]{0} %broadcast.527), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.29 = f32[3584]{0} divide(f32[3584]{0} %select.44, f32[3584]{0} %select.43), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.498 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.675, f32[3584]{0} %divide.29), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_430 = f32[] constant(0.000637755089)
  %broadcast.524 = f32[3584]{0} broadcast(f32[] %constant_430), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.497 = f32[3584]{0} multiply(f32[3584]{0} %multiply.498, f32[3584]{0} %broadcast.524), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.523 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.497), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.496 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_2.978, f32[16,14,14,3584]{2,1,3,0} %broadcast.523), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.140 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.1596, f32[16,14,14,3584]{2,1,3,0} %multiply.496), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.458 = f32[3584]{0} parameter(0)
  %negate.29 = f32[3584]{0} negate(f32[3584]{0} %multiply.498), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.668 = f32[3584]{0} parameter(1)
  %multiply.495 = f32[3584]{0} multiply(f32[3584]{0} %param_1.668, f32[3584]{0} %broadcast.524), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.494 = f32[3584]{0} multiply(f32[3584]{0} %negate.29, f32[3584]{0} %multiply.495), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.139 = f32[3584]{0} add(f32[3584]{0} %param_0.458, f32[3584]{0} %multiply.494), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_431 = f32[] constant(0.000318877544)
  %broadcast.525 = f32[3584]{0} broadcast(f32[] %constant_431), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.493 = f32[3584]{0} multiply(f32[3584]{0} %add.139, f32[3584]{0} %broadcast.525), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.522 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.493), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/broadcast_in_dim[shape=(16, 14, 14, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.138 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %add.140, f32[16,14,14,3584]{2,1,3,0} %broadcast.522), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.258 (param_0.1302: f32[16,14,14,3584], param_1.1773: f32[3584], param_2.985: f32[3584], param_3.1421: f32[16,14,14,3584], param_4.1257: f32[3584]) -> (f32[16,3584], f32[16,3584], f32[16,3584]) {
  %param_0.1302 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  %param_2.985 = f32[3584]{0} parameter(2)
  %constant_438 = f32[] constant(0)
  %broadcast.2403 = f32[3584]{0} broadcast(f32[] %constant_438), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.403 = f32[3584]{0} maximum(f32[3584]{0} %param_2.985, f32[3584]{0} %broadcast.2403), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1901 = f32[] constant(1e-05)
  %broadcast.2402 = f32[3584]{0} broadcast(f32[] %constant_1901), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.804 = f32[3584]{0} add(f32[3584]{0} %maximum.403, f32[3584]{0} %broadcast.2402), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1470 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.804), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.283 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1470), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1773 = f32[3584]{0} parameter(1)
  %bitcast.1469 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.1773), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1601 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.283, f32[1,1,1,3584]{3,2,1,0} %bitcast.1469), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1468 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1601), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2401 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1468), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1600 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %param_0.1302, f32[16,14,14,3584]{2,1,3,0} %broadcast.2401), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.30 = f32[16,14,14,3584]{2,1,3,0} negate(f32[16,14,14,3584]{2,1,3,0} %multiply.1600), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.42 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %negate.30), dimensions={0,3,1,2}
  %bitcast.676 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.42), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.737 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.676, f32[] %constant_438), dimensions={2}, to_apply=%region_57.4114.2
  %param_3.1421 = f32[16,14,14,3584]{2,1,3,0} parameter(3)
  %param_4.1257 = f32[3584]{0} parameter(4)
  %constant_1861_clone_1 = f32[] constant(0.000318877544)
  %broadcast.2367.clone.1 = f32[3584]{0} broadcast(f32[] %constant_1861_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1589.clone.1 = f32[3584]{0} multiply(f32[3584]{0} %param_4.1257, f32[3584]{0} %broadcast.2367.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2366.clone.1 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1589.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.245.clone.1 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_3.1421, f32[16,14,14,3584]{2,1,3,0} %broadcast.2366.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.502.clone.1 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.245.clone.1, f32[16,14,14,3584]{2,1,3,0} %param_0.1302), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.43 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %multiply.502.clone.1), dimensions={0,3,1,2}
  %bitcast.678.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.43), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.739.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.678.clone.1, f32[] %constant_438), dimensions={2}, to_apply=%region_57.4114.2
  %transpose.44 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %param_0.1302), dimensions={0,3,1,2}
  %bitcast.661.clone.1 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.44), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.726.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %bitcast.661.clone.1, f32[] %constant_438), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.43 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.737, f32[16,3584]{1,0} %reduce.739.clone.1, f32[16,3584]{1,0} %reduce.726.clone.1)
}

%fused_computation.259 (param_0.462: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.462 = f32[16,3584]{1,0} parameter(0)
  %constant_436 = f32[] constant(0)
  %reduce.738 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.462, f32[] %constant_436), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.677 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.738), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.262 (param_0.467: f32[16,14,14,3584], param_1.1310: f32[16,14,14,3584], param_2.400: f32[3584], param_3.766: f32[16,14,14,3584], param_4.680: f32[3584], param_5.675: f32[3584], param_6.475: f32[3584]) -> f32[16,14,14,3584] {
  %param_1.1310 = f32[16,14,14,3584]{2,1,3,0} parameter(1)
  %param_3.766 = f32[16,14,14,3584]{2,1,3,0} parameter(3)
  %param_4.680 = f32[3584]{0} parameter(4)
  %constant_1858 = f32[] constant(0.000318877544)
  %broadcast.2363 = f32[3584]{0} broadcast(f32[] %constant_1858), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1587 = f32[3584]{0} multiply(f32[3584]{0} %param_4.680, f32[3584]{0} %broadcast.2363), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2362 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1587), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.243 = f32[16,14,14,3584]{2,1,3,0} subtract(f32[16,14,14,3584]{2,1,3,0} %param_3.766, f32[16,14,14,3584]{2,1,3,0} %broadcast.2362), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_6.475 = f32[3584]{0} parameter(6)
  %constant_439 = f32[] constant(0)
  %broadcast.2387 = f32[3584]{0} broadcast(f32[] %constant_439), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.397 = f32[3584]{0} maximum(f32[3584]{0} %param_6.475, f32[3584]{0} %broadcast.2387), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1886 = f32[] constant(1e-05)
  %broadcast.2386 = f32[3584]{0} broadcast(f32[] %constant_1886), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.798 = f32[3584]{0} add(f32[3584]{0} %maximum.397, f32[3584]{0} %broadcast.2386), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1452 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.798), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.277 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1452), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.675 = f32[3584]{0} parameter(5)
  %bitcast.1451 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1591 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.277, f32[1,1,1,3584]{3,2,1,0} %bitcast.1451), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1450 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1591), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.533 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1450), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.504 = f32[16,14,14,3584]{2,1,3,0} multiply(f32[16,14,14,3584]{2,1,3,0} %subtract.243, f32[16,14,14,3584]{2,1,3,0} %broadcast.533), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.400 = f32[3584]{0} parameter(2)
  %broadcast.532 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_2.400), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.142 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %multiply.504, f32[16,14,14,3584]{2,1,3,0} %broadcast.532), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.141 = f32[16,14,14,3584]{2,1,3,0} add(f32[16,14,14,3584]{2,1,3,0} %param_1.1310, f32[16,14,14,3584]{2,1,3,0} %add.142), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.531 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[] %constant_439), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.45 = pred[16,14,14,3584]{2,1,3,0} compare(f32[16,14,14,3584]{2,1,3,0} %add.141, f32[16,14,14,3584]{2,1,3,0} %broadcast.531), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.467 = f32[16,14,14,3584]{2,1,3,0} parameter(0)
  ROOT %select.45 = f32[16,14,14,3584]{2,1,3,0} select(pred[16,14,14,3584]{2,1,3,0} %compare.45, f32[16,14,14,3584]{2,1,3,0} %param_0.467, f32[16,14,14,3584]{2,1,3,0} %broadcast.531), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.266 (param_0.1288: f32[16,3584], param_1.1753: f32[3584]) -> f32[3584] {
  %param_0.1288 = f32[16,3584]{1,0} parameter(0)
  %constant_443 = f32[] constant(0)
  %reduce.740 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.1288, f32[] %constant_443), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_442 = f32[] constant(0.000318877544)
  %broadcast.536 = f32[3584]{0} broadcast(f32[] %constant_442), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.507 = f32[3584]{0} multiply(f32[3584]{0} %reduce.740, f32[3584]{0} %broadcast.536), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1753 = f32[3584]{0} parameter(1)
  %multiply.1585 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1753, f32[3584]{0} %broadcast.536), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.506 = f32[3584]{0} multiply(f32[3584]{0} %multiply.1585, f32[3584]{0} %multiply.1585), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.24 = f32[3584]{0} subtract(f32[3584]{0} %multiply.507, f32[3584]{0} %multiply.506), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.271 (param_0.1284: f32[1792], param_1.1748: f32[1792], param_2.951: f32[1792], param_3.751: f32[16,14,14,1792], param_4.669: f32[1792]) -> f32[16,14,14,1792] {
  %param_3.751 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.669 = f32[1792]{0} parameter(4)
  %constant_1842 = f32[] constant(0.000318877544)
  %broadcast.2343 = f32[1792]{0} broadcast(f32[] %constant_1842), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1575 = f32[1792]{0} multiply(f32[1792]{0} %param_4.669, f32[1792]{0} %broadcast.2343), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2342 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1575), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.239 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.751, f32[16,14,14,1792]{2,1,3,0} %broadcast.2342), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.951 = f32[1792]{0} parameter(2)
  %constant_447 = f32[] constant(0)
  %broadcast.2341 = f32[1792]{0} broadcast(f32[] %constant_447), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.383 = f32[1792]{0} maximum(f32[1792]{0} %param_2.951, f32[1792]{0} %broadcast.2341), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1840 = f32[] constant(1e-05)
  %broadcast.2340 = f32[1792]{0} broadcast(f32[] %constant_1840), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.786 = f32[1792]{0} add(f32[1792]{0} %maximum.383, f32[1792]{0} %broadcast.2340), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1434 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.786), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.273 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1434), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1748 = f32[1792]{0} parameter(1)
  %bitcast.1433 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1748), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1574 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.273, f32[1,1,1,1792]{3,2,1,0} %bitcast.1433), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1432 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1574), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2339 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1432), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1573 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.239, f32[16,14,14,1792]{2,1,3,0} %broadcast.2339), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1284 = f32[1792]{0} parameter(0)
  %broadcast.2338 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1284), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.785 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1573, f32[16,14,14,1792]{2,1,3,0} %broadcast.2338), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.539 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_447), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.23 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.785, f32[16,14,14,1792]{2,1,3,0} %broadcast.539), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.276 (param_0.1270: f32[16,1792], param_1.1728: f32[1792]) -> f32[1792] {
  %param_0.1270 = f32[16,1792]{1,0} parameter(0)
  %constant_451 = f32[] constant(0)
  %reduce.743 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1270, f32[] %constant_451), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_450 = f32[] constant(0.000318877544)
  %broadcast.544 = f32[1792]{0} broadcast(f32[] %constant_450), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.513 = f32[1792]{0} multiply(f32[1792]{0} %reduce.743, f32[1792]{0} %broadcast.544), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1728 = f32[1792]{0} parameter(1)
  %multiply.1561 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1728, f32[1792]{0} %broadcast.544), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.512 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1561, f32[1792]{0} %multiply.1561), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.26 = f32[1792]{0} subtract(f32[1792]{0} %multiply.513, f32[1792]{0} %multiply.512), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.281 (param_0.1266: f32[896], param_1.1723: f32[896], param_2.917: f32[896], param_3.720: f32[16,14,14,896], param_4.644: f32[896]) -> f32[16,14,14,896] {
  %param_3.720 = f32[16,14,14,896]{2,1,3,0} parameter(3)
  %param_4.644 = f32[896]{0} parameter(4)
  %constant_1785 = f32[] constant(0.000318877544)
  %broadcast.2283 = f32[896]{0} broadcast(f32[] %constant_1785), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1551 = f32[896]{0} multiply(f32[896]{0} %param_4.644, f32[896]{0} %broadcast.2283), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2282 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %multiply.1551), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.231 = f32[16,14,14,896]{2,1,3,0} subtract(f32[16,14,14,896]{2,1,3,0} %param_3.720, f32[16,14,14,896]{2,1,3,0} %broadcast.2282), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.917 = f32[896]{0} parameter(2)
  %constant_455 = f32[] constant(0)
  %broadcast.2281 = f32[896]{0} broadcast(f32[] %constant_455), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.365 = f32[896]{0} maximum(f32[896]{0} %param_2.917, f32[896]{0} %broadcast.2281), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1783 = f32[] constant(1e-05)
  %broadcast.2280 = f32[896]{0} broadcast(f32[] %constant_1783), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.768 = f32[896]{0} add(f32[896]{0} %maximum.365, f32[896]{0} %broadcast.2280), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1404 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.768), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.265 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.1404), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1723 = f32[896]{0} parameter(1)
  %bitcast.1403 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %param_1.1723), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1550 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.265, f32[1,1,1,896]{3,2,1,0} %bitcast.1403), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1402 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.1550), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2279 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %bitcast.1402), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1549 = f32[16,14,14,896]{2,1,3,0} multiply(f32[16,14,14,896]{2,1,3,0} %subtract.231, f32[16,14,14,896]{2,1,3,0} %broadcast.2279), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1266 = f32[896]{0} parameter(0)
  %broadcast.2278 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[896]{0} %param_0.1266), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.767 = f32[16,14,14,896]{2,1,3,0} add(f32[16,14,14,896]{2,1,3,0} %multiply.1549, f32[16,14,14,896]{2,1,3,0} %broadcast.2278), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.547 = f32[16,14,14,896]{2,1,3,0} broadcast(f32[] %constant_455), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.25 = f32[16,14,14,896]{2,1,3,0} maximum(f32[16,14,14,896]{2,1,3,0} %add.767, f32[16,14,14,896]{2,1,3,0} %broadcast.547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.286 (param_0.1252: f32[16,896], param_1.1703: f32[896]) -> f32[896] {
  %param_0.1252 = f32[16,896]{1,0} parameter(0)
  %constant_459 = f32[] constant(0)
  %reduce.746 = f32[896]{0} reduce(f32[16,896]{1,0} %param_0.1252, f32[] %constant_459), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_458 = f32[] constant(0.000318877544)
  %broadcast.552 = f32[896]{0} broadcast(f32[] %constant_458), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.519 = f32[896]{0} multiply(f32[896]{0} %reduce.746, f32[896]{0} %broadcast.552), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1703 = f32[896]{0} parameter(1)
  %multiply.1537 = f32[896]{0} multiply(f32[896]{0} %param_1.1703, f32[896]{0} %broadcast.552), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.518 = f32[896]{0} multiply(f32[896]{0} %multiply.1537, f32[896]{0} %multiply.1537), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.28 = f32[896]{0} subtract(f32[896]{0} %multiply.519, f32[896]{0} %multiply.518), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.291 (param_0.513: f32[7168], param_1.1317: f32[1,1,1,7168], param_2.1631: f32[7168], param_3.1426: f32[16,7168]) -> (f32[7168], f32[7168]) {
  %param_0.513 = f32[7168]{0} parameter(0)
  %param_3.1426 = f32[16,7168]{1,0} parameter(3)
  %constant_1725 = f32[] constant(0)
  %reduce.752.clone.1 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_3.1426, f32[] %constant_1725), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_1701_clone_1 = f32[] constant(0.00127551018)
  %broadcast.567.clone.1 = f32[7168]{0} broadcast(f32[] %constant_1701_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.536.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %reduce.752.clone.1, f32[7168]{0} %broadcast.567.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1631 = f32[7168]{0} parameter(2)
  %multiply.1523.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.1631, f32[7168]{0} %broadcast.567.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.535.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %multiply.1523.clone.1, f32[7168]{0} %multiply.1523.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.31.clone.1 = f32[7168]{0} subtract(f32[7168]{0} %multiply.536.clone.1, f32[7168]{0} %multiply.535.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.2223 = f32[7168]{0} broadcast(f32[] %constant_1725), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.345 = f32[7168]{0} maximum(f32[7168]{0} %subtract.31.clone.1, f32[7168]{0} %broadcast.2223), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1724 = f32[] constant(1e-05)
  %broadcast.2222 = f32[7168]{0} broadcast(f32[] %constant_1724), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.535 = f32[7168]{0} add(f32[7168]{0} %maximum.345, f32[7168]{0} %broadcast.2222), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1368 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.535), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.45 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1368), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1317 = f32[1,1,1,7168]{3,2,1,0} parameter(1)
  %multiply.522 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.45, f32[1,1,1,7168]{3,2,1,0} %param_1.1317), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.691 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.522), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reshape[new_sizes=(7168,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.148 = f32[7168]{0} add(f32[7168]{0} %param_0.513, f32[7168]{0} %bitcast.691), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  ROOT %tuple.66 = (f32[7168]{0}, f32[7168]{0}) tuple(f32[7168]{0} %add.148, f32[7168]{0} %subtract.31.clone.1)
}

%fused_computation.292 (param_0.516: f32[1,1,3584,7168], param_1.753: f32[1,1,3584,7168]) -> f32[1,1,3584,7168] {
  %param_1.753 = f32[1,1,3584,7168]{3,2,1,0} parameter(1)
  %copy.155 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %param_1.753), metadata={op_name="2$start"}
  %param_0.516 = f32[1,1,3584,7168]{1,0,2,3} parameter(0)
  %add.149 = f32[1,1,3584,7168]{1,0,2,3} add(f32[1,1,3584,7168]{1,0,2,3} %copy.155, f32[1,1,3584,7168]{1,0,2,3} %param_0.516), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  ROOT %copy.154 = f32[1,1,3584,7168]{3,2,1,0} copy(f32[1,1,3584,7168]{1,0,2,3} %add.149), metadata={op_name="tuple.79"}
}

%fused_computation.294 (param_0.1249: f32[16,7,7,7168], param_1.1701: f32[7168], param_2.888: f32[7168], param_3.1439: f32[7168], param_4.1274: f32[7168]) -> (f32[16,7168], f32[16,7168], f32[16,7168]) {
  %param_0.1249 = f32[16,7,7,7168]{2,1,3,0} parameter(0)
  %param_2.888 = f32[7168]{0} parameter(2)
  %constant_471 = f32[] constant(0)
  %broadcast.2235 = f32[7168]{0} broadcast(f32[] %constant_471), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.349 = f32[7168]{0} maximum(f32[7168]{0} %param_2.888, f32[7168]{0} %broadcast.2235), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1734 = f32[] constant(1e-05)
  %broadcast.2234 = f32[7168]{0} broadcast(f32[] %constant_1734), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.539 = f32[7168]{0} add(f32[7168]{0} %maximum.349, f32[7168]{0} %broadcast.2234), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1380 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.539), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.259 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1380), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1701 = f32[7168]{0} parameter(1)
  %bitcast.1379 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_1.1701), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1533 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.259, f32[1,1,1,7168]{3,2,1,0} %bitcast.1379), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1378 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1533), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2233 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.1378), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1532 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_0.1249, f32[16,7,7,7168]{2,1,3,0} %broadcast.2233), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.32 = f32[16,7,7,7168]{2,1,3,0} negate(f32[16,7,7,7168]{2,1,3,0} %multiply.1532), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.45 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %negate.32), dimensions={0,3,1,2}
  %bitcast.693 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.45), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.749 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.693, f32[] %constant_471), dimensions={2}, to_apply=%region_57.4114.2
  %param_4.1274 = f32[7168]{0} parameter(4)
  %maximum.307.clone.1 = f32[7168]{0} maximum(f32[7168]{0} %param_4.1274, f32[7168]{0} %broadcast.2235), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.481.clone.1 = f32[7168]{0} add(f32[7168]{0} %maximum.307.clone.1, f32[7168]{0} %broadcast.2234), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1278.clone.1 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.481.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.227.clone.1 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1278.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_3.1439 = f32[7168]{0} parameter(3)
  %bitcast.1277.clone.1 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_3.1439), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1445.clone.1 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.227.clone.1, f32[1,1,1,7168]{3,2,1,0} %bitcast.1277.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1276.clone.1 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1445.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2037.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.1276.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1444.clone.1 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_0.1249, f32[16,7,7,7168]{2,1,3,0} %broadcast.2037.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.38.clone.1 = f32[16,7,7,7168]{2,1,3,0} negate(f32[16,7,7,7168]{2,1,3,0} %multiply.1444.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.46 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %negate.38.clone.1), dimensions={0,3,1,2}
  %bitcast.715.clone.1 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.46), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.766.clone.1 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.715.clone.1, f32[] %constant_471), dimensions={2}, to_apply=%region_57.4114.2
  %transpose.47 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %param_0.1249), dimensions={0,3,1,2}
  %bitcast.700.clone.1 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.47), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %reduce.755.clone.1 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.700.clone.1, f32[] %constant_471), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.76 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.749, f32[16,7168]{1,0} %reduce.766.clone.1, f32[16,7168]{1,0} %reduce.755.clone.1)
}

%fused_computation.295 (param_0.523: f32[16,7168]) -> f32[1,1,1,7168] {
  %param_0.523 = f32[16,7168]{1,0} parameter(0)
  %constant_469 = f32[] constant(0)
  %reduce.750 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_0.523, f32[] %constant_469), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.694 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %reduce.750), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.305 (param_0.539: f32[7168], param_1.1320: f32[1,1,1,7168], param_2.1635: f32[7168], param_3.1431: f32[16,7168]) -> (f32[7168], f32[7168]) {
  %param_0.539 = f32[7168]{0} parameter(0)
  %param_3.1431 = f32[16,7168]{1,0} parameter(3)
  %constant_1582 = f32[] constant(0)
  %reduce.769.clone.1 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_3.1431, f32[] %constant_1582), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_1558_clone_1 = f32[] constant(0.00127551018)
  %broadcast.601.clone.1 = f32[7168]{0} broadcast(f32[] %constant_1558_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.577.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %reduce.769.clone.1, f32[7168]{0} %broadcast.601.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_2.1635 = f32[7168]{0} parameter(2)
  %multiply.1435.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_2.1635, f32[7168]{0} %broadcast.601.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.576.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %multiply.1435.clone.1, f32[7168]{0} %multiply.1435.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %subtract.33.clone.1 = f32[7168]{0} subtract(f32[7168]{0} %multiply.577.clone.1, f32[7168]{0} %multiply.576.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.2027 = f32[7168]{0} broadcast(f32[] %constant_1582), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.303 = f32[7168]{0} maximum(f32[7168]{0} %subtract.33.clone.1, f32[7168]{0} %broadcast.2027), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1581 = f32[] constant(1e-05)
  %broadcast.2026 = f32[7168]{0} broadcast(f32[] %constant_1581), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.477 = f32[7168]{0} add(f32[7168]{0} %maximum.303, f32[7168]{0} %broadcast.2026), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1266 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.477), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.48 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1266), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1320 = f32[1,1,1,7168]{3,2,1,0} parameter(1)
  %multiply.539 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.48, f32[1,1,1,7168]{3,2,1,0} %param_1.1320), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.701 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.539), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reshape[new_sizes=(7168,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.154 = f32[7168]{0} add(f32[7168]{0} %param_0.539, f32[7168]{0} %bitcast.701), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  ROOT %tuple.73 = (f32[7168]{0}, f32[7168]{0}) tuple(f32[7168]{0} %add.154, f32[7168]{0} %subtract.33.clone.1)
}

%fused_computation.306 (param_0.542: f32[1,1,3584,7168], param_1.794: f32[1,1,3584,7168]) -> f32[1,1,3584,7168] {
  %param_1.794 = f32[1,1,3584,7168]{3,2,1,0} parameter(1)
  %copy.157 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %param_1.794), metadata={op_name="2$start"}
  %param_0.542 = f32[1,1,3584,7168]{1,0,2,3} parameter(0)
  %add.155 = f32[1,1,3584,7168]{1,0,2,3} add(f32[1,1,3584,7168]{1,0,2,3} %copy.157, f32[1,1,3584,7168]{1,0,2,3} %param_0.542), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  ROOT %copy.156 = f32[1,1,3584,7168]{3,2,1,0} copy(f32[1,1,3584,7168]{1,0,2,3} %add.155), metadata={op_name="tuple.79"}
}

%fused_computation.308 (param_0.1221: f32[16,7,7,3584], param_1.1664: f32[3584], param_2.830: f32[3584], param_3.635: f32[3584], param_4.578: f32[16,7,7,3584], param_5.576: f32[3584]) -> (f32[16,3584], f32[16,3584], f32[16,3584]) {
  %param_4.578 = f32[16,7,7,3584]{2,1,3,0} parameter(4)
  %param_5.576 = f32[3584]{0} parameter(5)
  %constant_1619 = f32[] constant(0.00127551018)
  %broadcast.2081 = f32[3584]{0} broadcast(f32[] %constant_1619), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1463 = f32[3584]{0} multiply(f32[3584]{0} %param_5.576, f32[3584]{0} %broadcast.2081), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2080 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1463), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.160 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_4.578, f32[16,7,7,3584]{2,1,3,0} %broadcast.2080), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.635 = f32[3584]{0} parameter(3)
  %constant_481 = f32[] constant(0)
  %broadcast.2079 = f32[3584]{0} broadcast(f32[] %constant_481), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.313 = f32[3584]{0} maximum(f32[3584]{0} %param_3.635, f32[3584]{0} %broadcast.2079), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1617 = f32[] constant(1e-05)
  %broadcast.2078 = f32[3584]{0} broadcast(f32[] %constant_1617), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.493 = f32[3584]{0} add(f32[3584]{0} %maximum.313, f32[3584]{0} %broadcast.2078), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1296 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.493), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.233 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1296), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.830 = f32[3584]{0} parameter(2)
  %bitcast.1295 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_2.830), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1462 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.233, f32[1,1,1,3584]{3,2,1,0} %bitcast.1295), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1294 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1462), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2077 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1294), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1461 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.160, f32[16,7,7,3584]{2,1,3,0} %broadcast.2077), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1664 = f32[3584]{0} parameter(1)
  %broadcast.2076 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.1664), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.492 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1461, f32[16,7,7,3584]{2,1,3,0} %broadcast.2076), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2075 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_481), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %compare.201 = pred[16,7,7,3584]{2,1,3,0} compare(f32[16,7,7,3584]{2,1,3,0} %add.492, f32[16,7,7,3584]{2,1,3,0} %broadcast.2075), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1221 = f32[16,7,7,3584]{2,1,3,0} parameter(0)
  %select.201 = f32[16,7,7,3584]{2,1,3,0} select(pred[16,7,7,3584]{2,1,3,0} %compare.201, f32[16,7,7,3584]{2,1,3,0} %param_0.1221, f32[16,7,7,3584]{2,1,3,0} %broadcast.2075), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.48 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %select.201), dimensions={0,3,1,2}
  %bitcast.702 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.48), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.757 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.702, f32[] %constant_481), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1479.clone.1 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %select.201, f32[16,7,7,3584]{2,1,3,0} %broadcast.2077), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.36.clone.1 = f32[16,7,7,3584]{2,1,3,0} negate(f32[16,7,7,3584]{2,1,3,0} %multiply.1479.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.49 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %negate.36.clone.1), dimensions={0,3,1,2}
  %bitcast.711.clone.1 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.49), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.763.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.711.clone.1, f32[] %constant_481), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.562.clone.1 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.160, f32[16,7,7,3584]{2,1,3,0} %select.201), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.50 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %multiply.562.clone.1), dimensions={0,3,1,2}
  %bitcast.713.clone.1 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.50), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.765.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.713.clone.1, f32[] %constant_481), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.72 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.757, f32[16,3584]{1,0} %reduce.763.clone.1, f32[16,3584]{1,0} %reduce.765.clone.1)
}

%fused_computation.310 (param_0.549: f32[3,3,1792,3584], param_1.803: f32[3,3,1792,3584]) -> f32[3,3,1792,3584] {
  %param_1.803 = f32[3,3,1792,3584]{3,2,1,0} parameter(1)
  %copy.159 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %param_1.803), metadata={op_name="2$start"}
  %param_0.549 = f32[3,3,1792,3584]{1,0,2,3} parameter(0)
  %add.158 = f32[3,3,1792,3584]{1,0,2,3} add(f32[3,3,1792,3584]{1,0,2,3} %copy.159, f32[3,3,1792,3584]{1,0,2,3} %param_0.549), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  ROOT %copy.158 = f32[3,3,1792,3584]{3,2,1,0} copy(f32[3,3,1792,3584]{1,0,2,3} %add.158), metadata={op_name="tuple.79"}
}

%fused_computation.312 (param_0.1233: f32[16,15,15,1792], param_1.1683: f32[1792], param_2.858: f32[1792], param_3.668: f32[1792], param_4.614: f32[16,14,14,1792], param_5.619: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.614 = f32[16,14,14,1792]{2,1,3,0} parameter(4)
  %param_5.619 = f32[1792]{0} parameter(5)
  %constant_1672 = f32[] constant(0.000318877544)
  %broadcast.2163 = f32[1792]{0} broadcast(f32[] %constant_1672), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1501 = f32[1792]{0} multiply(f32[1792]{0} %param_5.619, f32[1792]{0} %broadcast.2163), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2162 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1501), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.221 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_4.614, f32[16,14,14,1792]{2,1,3,0} %broadcast.2162), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.668 = f32[1792]{0} parameter(3)
  %constant_483 = f32[] constant(0)
  %broadcast.2161 = f32[1792]{0} broadcast(f32[] %constant_483), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.327 = f32[1792]{0} maximum(f32[1792]{0} %param_3.668, f32[1792]{0} %broadcast.2161), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1670 = f32[] constant(1e-05)
  %broadcast.2160 = f32[1792]{0} broadcast(f32[] %constant_1670), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.517 = f32[1792]{0} add(f32[1792]{0} %maximum.327, f32[1792]{0} %broadcast.2160), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1338 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.517), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.247 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1338), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.858 = f32[1792]{0} parameter(2)
  %bitcast.1337 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.858), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1500 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.247, f32[1,1,1,1792]{3,2,1,0} %bitcast.1337), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1336 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1500), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2159 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1336), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1499 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.221, f32[16,14,14,1792]{2,1,3,0} %broadcast.2159), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1683 = f32[1792]{0} parameter(1)
  %broadcast.2158 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.1683), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.516 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1499, f32[16,14,14,1792]{2,1,3,0} %broadcast.2158), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2157 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_483), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.211 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.516, f32[16,14,14,1792]{2,1,3,0} %broadcast.2157), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1233 = f32[16,15,15,1792]{2,1,3,0} parameter(0)
  %slice.7 = f32[16,14,14,1792]{2,1,3,0} slice(f32[16,15,15,1792]{2,1,3,0} %param_0.1233), slice={[0:16], [0:14], [0:14], [0:1792]}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %select.211 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.211, f32[16,14,14,1792]{2,1,3,0} %slice.7, f32[16,14,14,1792]{2,1,3,0} %broadcast.2157), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.51 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %select.211), dimensions={0,3,1,2}
  %bitcast.704 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.51), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.759 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.704, f32[] %constant_483), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1517.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.211, f32[16,14,14,1792]{2,1,3,0} %broadcast.2159), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.34.clone.1 = f32[16,14,14,1792]{2,1,3,0} negate(f32[16,14,14,1792]{2,1,3,0} %multiply.1517.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.52 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %negate.34.clone.1), dimensions={0,3,1,2}
  %bitcast.707.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.52), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.760.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.707.clone.1, f32[] %constant_483), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.551.clone.1 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.221, f32[16,14,14,1792]{2,1,3,0} %select.211), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.53 = f32[16,1792,14,14]{3,2,1,0} transpose(f32[16,14,14,1792]{2,1,3,0} %multiply.551.clone.1), dimensions={0,3,1,2}
  %bitcast.709.clone.1 = f32[16,1792,196]{2,1,0} bitcast(f32[16,1792,14,14]{3,2,1,0} %transpose.53), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.762.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %bitcast.709.clone.1, f32[] %constant_483), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.70 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.759, f32[16,1792]{1,0} %reduce.760.clone.1, f32[16,1792]{1,0} %reduce.762.clone.1)
}

%fused_computation.314 (param_0.556: f32[1,1,3584,1792], param_1.812: f32[1,1,3584,1792]) -> f32[1,1,3584,1792] {
  %param_1.812 = f32[1,1,3584,1792]{3,2,1,0} parameter(1)
  %copy.161 = f32[1,1,3584,1792]{1,0,2,3} copy(f32[1,1,3584,1792]{3,2,1,0} %param_1.812), metadata={op_name="2$start"}
  %param_0.556 = f32[1,1,3584,1792]{1,0,2,3} parameter(0)
  %add.161 = f32[1,1,3584,1792]{1,0,2,3} add(f32[1,1,3584,1792]{1,0,2,3} %copy.161, f32[1,1,3584,1792]{1,0,2,3} %param_0.556), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  ROOT %copy.160 = f32[1,1,3584,1792]{3,2,1,0} copy(f32[1,1,3584,1792]{1,0,2,3} %add.161), metadata={op_name="tuple.79"}
}

%fused_computation.315 (param_0.559: f32[1792], param_1.818: f32[1792], param_2.860: f32[16,14,14,1792], param_3.670: f32[1792], param_4.616: f32[1,1,1,1792], param_5.621: f32[1792], param_6.449: f32[16,15,15,1792], param_7.499: f32[1792]) -> f32[16,14,14,1792] {
  %param_2.860 = f32[16,14,14,1792]{2,1,3,0} parameter(2)
  %param_1.818 = f32[1792]{0} parameter(1)
  %constant_485 = f32[] constant(0.000318877544)
  %broadcast.2183 = f32[1792]{0} broadcast(f32[] %constant_485), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1511 = f32[1792]{0} multiply(f32[1792]{0} %param_1.818, f32[1792]{0} %broadcast.2183), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2182 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1511), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.223 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_2.860, f32[16,14,14,1792]{2,1,3,0} %broadcast.2182), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.670 = f32[1792]{0} parameter(3)
  %constant_488 = f32[] constant(0)
  %broadcast.2181 = f32[1792]{0} broadcast(f32[] %constant_488), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.331 = f32[1792]{0} maximum(f32[1792]{0} %param_3.670, f32[1792]{0} %broadcast.2181), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1468 = f32[] constant(1e-05)
  %broadcast.2180 = f32[1792]{0} broadcast(f32[] %constant_1468), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.523 = f32[1792]{0} add(f32[1792]{0} %maximum.331, f32[1792]{0} %broadcast.2180), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1350 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.523), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.251 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1350), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.621 = f32[1792]{0} parameter(5)
  %bitcast.1349 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1510 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.251, f32[1,1,1,1792]{3,2,1,0} %bitcast.1349), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1348 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1510), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2179 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1348), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1509 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.223, f32[16,14,14,1792]{2,1,3,0} %broadcast.2179), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.499 = f32[1792]{0} parameter(7)
  %broadcast.2178 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.499), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.522 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1509, f32[16,14,14,1792]{2,1,3,0} %broadcast.2178), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2177 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_488), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.213 = pred[16,14,14,1792]{2,1,3,0} compare(f32[16,14,14,1792]{2,1,3,0} %add.522, f32[16,14,14,1792]{2,1,3,0} %broadcast.2177), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.449 = f32[16,15,15,1792]{2,1,3,0} parameter(6)
  %slice.9 = f32[16,14,14,1792]{2,1,3,0} slice(f32[16,15,15,1792]{2,1,3,0} %param_6.449), slice={[0:16], [0:14], [0:14], [0:1792]}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %select.213 = f32[16,14,14,1792]{2,1,3,0} select(pred[16,14,14,1792]{2,1,3,0} %compare.213, f32[16,14,14,1792]{2,1,3,0} %slice.9, f32[16,14,14,1792]{2,1,3,0} %broadcast.2177), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1507 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %select.213, f32[16,14,14,1792]{2,1,3,0} %broadcast.2179), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.616 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.550 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.616, f32[1,1,1,1792]{3,2,1,0} %bitcast.1349), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.34 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.251, f32[1,1,1,1792]{3,2,1,0} %bitcast.1350), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_486 = f32[] constant(-0.5)
  %broadcast.575 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_486), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.549 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.34, f32[1,1,1,1792]{3,2,1,0} %broadcast.575), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.548 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.550, f32[1,1,1,1792]{3,2,1,0} %multiply.549), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.706 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.548), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.49 = pred[1792]{0} compare(f32[1792]{0} %param_3.670, f32[1792]{0} %maximum.331), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_489 = f32[] constant(1)
  %broadcast.574 = f32[1792]{0} broadcast(f32[] %constant_489), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.49 = f32[1792]{0} select(pred[1792]{0} %compare.49, f32[1792]{0} %broadcast.574, f32[1792]{0} %broadcast.2181), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.48 = pred[1792]{0} compare(f32[1792]{0} %broadcast.2181, f32[1792]{0} %maximum.331), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_487 = f32[] constant(2)
  %broadcast.573 = f32[1792]{0} broadcast(f32[] %constant_487), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.48 = f32[1792]{0} select(pred[1792]{0} %compare.48, f32[1792]{0} %broadcast.573, f32[1792]{0} %broadcast.574), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.33 = f32[1792]{0} divide(f32[1792]{0} %select.49, f32[1792]{0} %select.48), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.547 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.706, f32[1792]{0} %divide.33), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_484 = f32[] constant(0.000637755089)
  %broadcast.571 = f32[1792]{0} broadcast(f32[] %constant_484), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.546 = f32[1792]{0} multiply(f32[1792]{0} %multiply.547, f32[1792]{0} %broadcast.571), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.570 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.546), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.545 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %param_2.860, f32[16,14,14,1792]{2,1,3,0} %broadcast.570), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.164 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1507, f32[16,14,14,1792]{2,1,3,0} %multiply.545), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.559 = f32[1792]{0} parameter(0)
  %negate.33 = f32[1792]{0} negate(f32[1792]{0} %multiply.547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.544 = f32[1792]{0} multiply(f32[1792]{0} %param_1.818, f32[1792]{0} %broadcast.571), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.543 = f32[1792]{0} multiply(f32[1792]{0} %negate.33, f32[1792]{0} %multiply.544), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.163 = f32[1792]{0} add(f32[1792]{0} %param_0.559, f32[1792]{0} %multiply.543), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.542 = f32[1792]{0} multiply(f32[1792]{0} %add.163, f32[1792]{0} %broadcast.2183), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.569 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.542), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/broadcast_in_dim[shape=(16, 14, 14, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.162 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %add.164, f32[16,14,14,1792]{2,1,3,0} %broadcast.569), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.317 (param_0.563: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.563 = f32[16,1792]{1,0} parameter(0)
  %constant_490 = f32[] constant(0)
  %reduce.761 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.563, f32[] %constant_490), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.708 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.761), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.321 (param_0.572: f32[3584], param_1.837: f32[3584], param_2.832: f32[16,7,7,3584], param_3.637: f32[3584], param_4.580: f32[1,1,1,3584], param_5.578: f32[3584], param_6.423: f32[16,7,7,3584], param_7.480: f32[3584]) -> f32[16,7,7,3584] {
  %param_2.832 = f32[16,7,7,3584]{2,1,3,0} parameter(2)
  %param_1.837 = f32[3584]{0} parameter(1)
  %constant_497 = f32[] constant(0.00127551018)
  %broadcast.2101 = f32[3584]{0} broadcast(f32[] %constant_497), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1473 = f32[3584]{0} multiply(f32[3584]{0} %param_1.837, f32[3584]{0} %broadcast.2101), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2100 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1473), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.213 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_2.832, f32[16,7,7,3584]{2,1,3,0} %broadcast.2100), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.637 = f32[3584]{0} parameter(3)
  %constant_498 = f32[] constant(0)
  %broadcast.2099 = f32[3584]{0} broadcast(f32[] %constant_498), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.317 = f32[3584]{0} maximum(f32[3584]{0} %param_3.637, f32[3584]{0} %broadcast.2099), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1525 = f32[] constant(1e-05)
  %broadcast.2098 = f32[3584]{0} broadcast(f32[] %constant_1525), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.499 = f32[3584]{0} add(f32[3584]{0} %maximum.317, f32[3584]{0} %broadcast.2098), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1308 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.499), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.237 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1308), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.578 = f32[3584]{0} parameter(5)
  %bitcast.1307 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.578), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1472 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.237, f32[1,1,1,3584]{3,2,1,0} %bitcast.1307), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1306 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1472), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2097 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1306), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1471 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.213, f32[16,7,7,3584]{2,1,3,0} %broadcast.2097), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.480 = f32[3584]{0} parameter(7)
  %broadcast.2096 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_7.480), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.498 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1471, f32[16,7,7,3584]{2,1,3,0} %broadcast.2096), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.2095 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_498), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %compare.203 = pred[16,7,7,3584]{2,1,3,0} compare(f32[16,7,7,3584]{2,1,3,0} %add.498, f32[16,7,7,3584]{2,1,3,0} %broadcast.2095), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.423 = f32[16,7,7,3584]{2,1,3,0} parameter(6)
  %select.203 = f32[16,7,7,3584]{2,1,3,0} select(pred[16,7,7,3584]{2,1,3,0} %compare.203, f32[16,7,7,3584]{2,1,3,0} %param_6.423, f32[16,7,7,3584]{2,1,3,0} %broadcast.2095), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1469 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %select.203, f32[16,7,7,3584]{2,1,3,0} %broadcast.2097), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.580 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.561 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.580, f32[1,1,1,3584]{3,2,1,0} %bitcast.1307), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.36 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.237, f32[1,1,1,3584]{3,2,1,0} %bitcast.1308), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_494 = f32[] constant(-0.5)
  %broadcast.584 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_494), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.560 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.36, f32[1,1,1,3584]{3,2,1,0} %broadcast.584), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.559 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.561, f32[1,1,1,3584]{3,2,1,0} %multiply.560), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.710 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.559), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.52 = pred[3584]{0} compare(f32[3584]{0} %param_3.637, f32[3584]{0} %maximum.317), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_499 = f32[] constant(1)
  %broadcast.583 = f32[3584]{0} broadcast(f32[] %constant_499), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.52 = f32[3584]{0} select(pred[3584]{0} %compare.52, f32[3584]{0} %broadcast.583, f32[3584]{0} %broadcast.2099), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.51 = pred[3584]{0} compare(f32[3584]{0} %broadcast.2099, f32[3584]{0} %maximum.317), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_495 = f32[] constant(2)
  %broadcast.582 = f32[3584]{0} broadcast(f32[] %constant_495), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.51 = f32[3584]{0} select(pred[3584]{0} %compare.51, f32[3584]{0} %broadcast.582, f32[3584]{0} %broadcast.583), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.35 = f32[3584]{0} divide(f32[3584]{0} %select.52, f32[3584]{0} %select.51), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.558 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.710, f32[3584]{0} %divide.35), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_496 = f32[] constant(0.00255102036)
  %broadcast.581 = f32[3584]{0} broadcast(f32[] %constant_496), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.557 = f32[3584]{0} multiply(f32[3584]{0} %multiply.558, f32[3584]{0} %broadcast.581), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.580 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.557), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.556 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %param_2.832, f32[16,7,7,3584]{2,1,3,0} %broadcast.580), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.167 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1469, f32[16,7,7,3584]{2,1,3,0} %multiply.556), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.572 = f32[3584]{0} parameter(0)
  %negate.35 = f32[3584]{0} negate(f32[3584]{0} %multiply.558), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.555 = f32[3584]{0} multiply(f32[3584]{0} %param_1.837, f32[3584]{0} %broadcast.581), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.554 = f32[3584]{0} multiply(f32[3584]{0} %negate.35, f32[3584]{0} %multiply.555), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.166 = f32[3584]{0} add(f32[3584]{0} %param_0.572, f32[3584]{0} %multiply.554), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.553 = f32[3584]{0} multiply(f32[3584]{0} %add.166, f32[3584]{0} %broadcast.2101), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.579 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.553), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/broadcast_in_dim[shape=(16, 7, 7, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.165 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %add.167, f32[16,7,7,3584]{2,1,3,0} %broadcast.579), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.323 (param_0.576: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.576 = f32[16,3584]{1,0} parameter(0)
  %constant_500 = f32[] constant(0)
  %reduce.764 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.576, f32[] %constant_500), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.712 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.764), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.327 (param_0.584: f32[7168], param_1.855: f32[7168], param_2.809: f32[16,7,7,7168], param_3.612: f32[7168], param_4.554: f32[1,1,1,7168], param_5.548: f32[7168], param_6.403: f32[16,7,7,7168], param_7.1240: f32[7168], param_8.937: f32[7168], param_9.564: f32[16,7,7,7168], param_10.437: f32[7168], param_11.412: f32[1,1,1,7168], param_12.343: f32[7168]) -> (f32[16,7,7,7168], f32[16,7,7,7168]) {
  %param_6.403 = f32[16,7,7,7168]{2,1,3,0} parameter(6)
  %param_3.612 = f32[7168]{0} parameter(3)
  %constant_508 = f32[] constant(0)
  %broadcast.2033 = f32[7168]{0} broadcast(f32[] %constant_508), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.305 = f32[7168]{0} maximum(f32[7168]{0} %param_3.612, f32[7168]{0} %broadcast.2033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1576 = f32[] constant(1e-05)
  %broadcast.2032 = f32[7168]{0} broadcast(f32[] %constant_1576), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.479 = f32[7168]{0} add(f32[7168]{0} %maximum.305, f32[7168]{0} %broadcast.2032), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1272 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.479), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.225 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1272), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.548 = f32[7168]{0} parameter(5)
  %bitcast.1271 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_5.548), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1441 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.225, f32[1,1,1,7168]{3,2,1,0} %bitcast.1271), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1270 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1441), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2031 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.1270), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1440 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_6.403, f32[16,7,7,7168]{2,1,3,0} %broadcast.2031), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.809 = f32[16,7,7,7168]{2,1,3,0} parameter(2)
  %param_4.554 = f32[1,1,1,7168]{3,2,1,0} parameter(4)
  %multiply.572 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %param_4.554, f32[1,1,1,7168]{3,2,1,0} %bitcast.1271), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.38 = f32[1,1,1,7168]{3,2,1,0} divide(f32[1,1,1,7168]{3,2,1,0} %rsqrt.225, f32[1,1,1,7168]{3,2,1,0} %bitcast.1272), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_504 = f32[] constant(-0.5)
  %broadcast.594 = f32[1,1,1,7168]{3,2,1,0} broadcast(f32[] %constant_504), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.571 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %divide.38, f32[1,1,1,7168]{3,2,1,0} %broadcast.594), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.570 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %multiply.572, f32[1,1,1,7168]{3,2,1,0} %multiply.571), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.714 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.570), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reshape[new_sizes=(7168,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.55 = pred[7168]{0} compare(f32[7168]{0} %param_3.612, f32[7168]{0} %maximum.305), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_509 = f32[] constant(1)
  %broadcast.593 = f32[7168]{0} broadcast(f32[] %constant_509), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/broadcast_in_dim[shape=(7168,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.55 = f32[7168]{0} select(pred[7168]{0} %compare.55, f32[7168]{0} %broadcast.593, f32[7168]{0} %broadcast.2033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.54 = pred[7168]{0} compare(f32[7168]{0} %broadcast.2033, f32[7168]{0} %maximum.305), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_505 = f32[] constant(2)
  %broadcast.592 = f32[7168]{0} broadcast(f32[] %constant_505), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.54 = f32[7168]{0} select(pred[7168]{0} %compare.54, f32[7168]{0} %broadcast.592, f32[7168]{0} %broadcast.593), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.37 = f32[7168]{0} divide(f32[7168]{0} %select.55, f32[7168]{0} %select.54), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.569 = f32[7168]{0} multiply(f32[7168]{0} %bitcast.714, f32[7168]{0} %divide.37), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_506 = f32[] constant(0.00255102036)
  %broadcast.591 = f32[7168]{0} broadcast(f32[] %constant_506), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.568 = f32[7168]{0} multiply(f32[7168]{0} %multiply.569, f32[7168]{0} %broadcast.591), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.590 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.568), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.567 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_2.809, f32[16,7,7,7168]{2,1,3,0} %broadcast.590), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.170 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.1440, f32[16,7,7,7168]{2,1,3,0} %multiply.567), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.584 = f32[7168]{0} parameter(0)
  %negate.37 = f32[7168]{0} negate(f32[7168]{0} %multiply.569), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.855 = f32[7168]{0} parameter(1)
  %multiply.566 = f32[7168]{0} multiply(f32[7168]{0} %param_1.855, f32[7168]{0} %broadcast.591), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.565 = f32[7168]{0} multiply(f32[7168]{0} %negate.37, f32[7168]{0} %multiply.566), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.169 = f32[7168]{0} add(f32[7168]{0} %param_0.584, f32[7168]{0} %multiply.565), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_507 = f32[] constant(0.00127551018)
  %broadcast.596 = f32[7168]{0} broadcast(f32[] %constant_507), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.564 = f32[7168]{0} multiply(f32[7168]{0} %add.169, f32[7168]{0} %broadcast.596), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.589 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.564), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/broadcast_in_dim[shape=(16, 7, 7, 7168) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %add.168 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %add.170, f32[16,7,7,7168]{2,1,3,0} %broadcast.589), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %param_10.437 = f32[7168]{0} parameter(10)
  %maximum.347.clone.1 = f32[7168]{0} maximum(f32[7168]{0} %param_10.437, f32[7168]{0} %broadcast.2033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.537.clone.1 = f32[7168]{0} add(f32[7168]{0} %maximum.347.clone.1, f32[7168]{0} %broadcast.2032), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1374.clone.1 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.537.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.257.clone.1 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1374.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_12.343 = f32[7168]{0} parameter(12)
  %bitcast.1373.clone.1 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_12.343), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1529.clone.1 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.257.clone.1, f32[1,1,1,7168]{3,2,1,0} %bitcast.1373.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1372.clone.1 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1529.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2227.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.1372.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1528.clone.1 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_6.403, f32[16,7,7,7168]{2,1,3,0} %broadcast.2227.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_9.564 = f32[16,7,7,7168]{2,1,3,0} parameter(9)
  %param_11.412 = f32[1,1,1,7168]{3,2,1,0} parameter(11)
  %multiply.531.clone.1 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %param_11.412, f32[1,1,1,7168]{3,2,1,0} %bitcast.1373.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.32.clone.1 = f32[1,1,1,7168]{3,2,1,0} divide(f32[1,1,1,7168]{3,2,1,0} %rsqrt.257.clone.1, f32[1,1,1,7168]{3,2,1,0} %bitcast.1374.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.530.clone.1 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %divide.32.clone.1, f32[1,1,1,7168]{3,2,1,0} %broadcast.594), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.529.clone.1 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %multiply.531.clone.1, f32[1,1,1,7168]{3,2,1,0} %multiply.530.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.692.clone.1 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.529.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reshape[new_sizes=(7168,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.47.clone.1 = pred[7168]{0} compare(f32[7168]{0} %param_10.437, f32[7168]{0} %maximum.347.clone.1), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.47.clone.1 = f32[7168]{0} select(pred[7168]{0} %compare.47.clone.1, f32[7168]{0} %broadcast.593, f32[7168]{0} %broadcast.2033), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.46.clone.1 = pred[7168]{0} compare(f32[7168]{0} %broadcast.2033, f32[7168]{0} %maximum.347.clone.1), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.46.clone.1 = f32[7168]{0} select(pred[7168]{0} %compare.46.clone.1, f32[7168]{0} %broadcast.592, f32[7168]{0} %broadcast.593), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.31.clone.1 = f32[7168]{0} divide(f32[7168]{0} %select.47.clone.1, f32[7168]{0} %select.46.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.528.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %bitcast.692.clone.1, f32[7168]{0} %divide.31.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.527.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %multiply.528.clone.1, f32[7168]{0} %broadcast.591), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.556.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.527.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.526.clone.1 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_9.564, f32[16,7,7,7168]{2,1,3,0} %broadcast.556.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.152.clone.1 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.1528.clone.1, f32[16,7,7,7168]{2,1,3,0} %multiply.526.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_7.1240 = f32[7168]{0} parameter(7)
  %negate.31.clone.1 = f32[7168]{0} negate(f32[7168]{0} %multiply.528.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_8.937 = f32[7168]{0} parameter(8)
  %multiply.525.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_8.937, f32[7168]{0} %broadcast.591), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.524.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %negate.31.clone.1, f32[7168]{0} %multiply.525.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.151.clone.1 = f32[7168]{0} add(f32[7168]{0} %param_7.1240, f32[7168]{0} %multiply.524.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.523.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %add.151.clone.1, f32[7168]{0} %broadcast.596), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.555.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.523.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/broadcast_in_dim[shape=(16, 7, 7, 7168) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %add.150.clone.1 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %add.152.clone.1, f32[16,7,7,7168]{2,1,3,0} %broadcast.555.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %tuple.78 = (f32[16,7,7,7168]{2,1,3,0}, f32[16,7,7,7168]{2,1,3,0}) tuple(f32[16,7,7,7168]{2,1,3,0} %add.168, f32[16,7,7,7168]{2,1,3,0} %add.150.clone.1)
}

%fused_computation.329 (param_0.588: f32[16,7168]) -> f32[1,1,1,7168] {
  %param_0.588 = f32[16,7168]{1,0} parameter(0)
  %constant_510 = f32[] constant(0)
  %reduce.767 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_0.588, f32[] %constant_510), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.716 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %reduce.767), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.338 (param_0.1202: f32[3584], param_1.1644: f32[3584], param_2.798: f32[3584], param_3.601: f32[16,7,7,3584], param_4.552: f32[3584]) -> f32[16,7,7,3584] {
  %param_3.601 = f32[16,7,7,3584]{2,1,3,0} parameter(3)
  %param_4.552 = f32[3584]{0} parameter(4)
  %constant_1555 = f32[] constant(0.00127551018)
  %broadcast.2007 = f32[3584]{0} broadcast(f32[] %constant_1555), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1433 = f32[3584]{0} multiply(f32[3584]{0} %param_4.552, f32[3584]{0} %broadcast.2007), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.2006 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1433), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.154 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_3.601, f32[16,7,7,3584]{2,1,3,0} %broadcast.2006), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.798 = f32[3584]{0} parameter(2)
  %constant_520 = f32[] constant(0)
  %broadcast.2005 = f32[3584]{0} broadcast(f32[] %constant_520), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.293 = f32[3584]{0} maximum(f32[3584]{0} %param_2.798, f32[3584]{0} %broadcast.2005), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1553 = f32[] constant(1e-05)
  %broadcast.2004 = f32[3584]{0} broadcast(f32[] %constant_1553), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.471 = f32[3584]{0} add(f32[3584]{0} %maximum.293, f32[3584]{0} %broadcast.2004), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1260 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.471), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.223 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1260), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1644 = f32[3584]{0} parameter(1)
  %bitcast.1259 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.1644), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1432 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.223, f32[1,1,1,3584]{3,2,1,0} %bitcast.1259), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1258 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1432), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.2003 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1258), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1431 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.154, f32[16,7,7,3584]{2,1,3,0} %broadcast.2003), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1202 = f32[3584]{0} parameter(0)
  %broadcast.2002 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_0.1202), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.470 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1431, f32[16,7,7,3584]{2,1,3,0} %broadcast.2002), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.603 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_520), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.29 = f32[16,7,7,3584]{2,1,3,0} maximum(f32[16,7,7,3584]{2,1,3,0} %add.470, f32[16,7,7,3584]{2,1,3,0} %broadcast.603), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.343 (param_0.1187: f32[16,3584], param_1.1621: f32[3584]) -> f32[3584] {
  %param_0.1187 = f32[16,3584]{1,0} parameter(0)
  %constant_524 = f32[] constant(0)
  %reduce.772 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.1187, f32[] %constant_524), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_523 = f32[] constant(0.00127551018)
  %broadcast.608 = f32[3584]{0} broadcast(f32[] %constant_523), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.583 = f32[3584]{0} multiply(f32[3584]{0} %reduce.772, f32[3584]{0} %broadcast.608), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1621 = f32[3584]{0} parameter(1)
  %multiply.1413 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1621, f32[3584]{0} %broadcast.608), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.582 = f32[3584]{0} multiply(f32[3584]{0} %multiply.1413, f32[3584]{0} %multiply.1413), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.34 = f32[3584]{0} subtract(f32[3584]{0} %multiply.583, f32[3584]{0} %multiply.582), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.348 (param_0.1184: f32[1792], param_1.1619: f32[1792], param_2.764: f32[1792], param_3.570: f32[16,14,14,1792], param_4.527: f32[1792]) -> f32[16,15,15,1792] {
  %param_3.570 = f32[16,14,14,1792]{2,1,3,0} parameter(3)
  %param_4.527 = f32[1792]{0} parameter(4)
  %constant_1498 = f32[] constant(0.000318877544)
  %broadcast.1947 = f32[1792]{0} broadcast(f32[] %constant_1498), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1409 = f32[1792]{0} multiply(f32[1792]{0} %param_4.527, f32[1792]{0} %broadcast.1947), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1946 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1409), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.146 = f32[16,14,14,1792]{2,1,3,0} subtract(f32[16,14,14,1792]{2,1,3,0} %param_3.570, f32[16,14,14,1792]{2,1,3,0} %broadcast.1946), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.764 = f32[1792]{0} parameter(2)
  %constant_528 = f32[] constant(0)
  %broadcast.1945 = f32[1792]{0} broadcast(f32[] %constant_528), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.275 = f32[1792]{0} maximum(f32[1792]{0} %param_2.764, f32[1792]{0} %broadcast.1945), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1496 = f32[] constant(1e-05)
  %broadcast.1944 = f32[1792]{0} broadcast(f32[] %constant_1496), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.453 = f32[1792]{0} add(f32[1792]{0} %maximum.275, f32[1792]{0} %broadcast.1944), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1230 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.453), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.215 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1230), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1619 = f32[1792]{0} parameter(1)
  %bitcast.1229 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1619), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1408 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.215, f32[1,1,1,1792]{3,2,1,0} %bitcast.1229), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1228 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1408), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1943 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1228), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1407 = f32[16,14,14,1792]{2,1,3,0} multiply(f32[16,14,14,1792]{2,1,3,0} %subtract.146, f32[16,14,14,1792]{2,1,3,0} %broadcast.1943), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1184 = f32[1792]{0} parameter(0)
  %broadcast.1942 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1184), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.452 = f32[16,14,14,1792]{2,1,3,0} add(f32[16,14,14,1792]{2,1,3,0} %multiply.1407, f32[16,14,14,1792]{2,1,3,0} %broadcast.1942), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.611 = f32[16,14,14,1792]{2,1,3,0} broadcast(f32[] %constant_528), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %maximum.31 = f32[16,14,14,1792]{2,1,3,0} maximum(f32[16,14,14,1792]{2,1,3,0} %add.452, f32[16,14,14,1792]{2,1,3,0} %broadcast.611), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %pad.2 = f32[16,15,15,1792]{2,1,3,0} pad(f32[16,14,14,1792]{2,1,3,0} %maximum.31, f32[] %constant_528), padding=0_0x0_1x0_1x0_0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.353 (param_0.1169: f32[16,1792], param_1.1596: f32[1792]) -> f32[1792] {
  %param_0.1169 = f32[16,1792]{1,0} parameter(0)
  %constant_532 = f32[] constant(0)
  %reduce.775 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1169, f32[] %constant_532), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_531 = f32[] constant(0.000318877544)
  %broadcast.616 = f32[1792]{0} broadcast(f32[] %constant_531), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.589 = f32[1792]{0} multiply(f32[1792]{0} %reduce.775, f32[1792]{0} %broadcast.616), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1596 = f32[1792]{0} parameter(1)
  %multiply.1389 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1596, f32[1792]{0} %broadcast.616), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.588 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1389, f32[1792]{0} %multiply.1389), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.36 = f32[1792]{0} subtract(f32[1792]{0} %multiply.589, f32[1792]{0} %multiply.588), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.358 (param_0.636: f32[16,7,7,7168], param_1.934: f32[16,7,7,7168]) -> f32[16,7,7,7168] {
  %param_1.934 = f32[16,7,7,7168]{2,1,3,0} parameter(1)
  %constant_536 = f32[] constant(0)
  %broadcast.619 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[] %constant_536), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.56 = pred[16,7,7,7168]{2,1,3,0} compare(f32[16,7,7,7168]{2,1,3,0} %param_1.934, f32[16,7,7,7168]{2,1,3,0} %broadcast.619), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.636 = f32[16,7,7,7168]{2,1,3,0} parameter(0)
  ROOT %select.56 = f32[16,7,7,7168]{2,1,3,0} select(pred[16,7,7,7168]{2,1,3,0} %compare.56, f32[16,7,7,7168]{2,1,3,0} %param_0.636, f32[16,7,7,7168]{2,1,3,0} %broadcast.619), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.362 (param_0.643: f32[1,1,3584,7168], param_1.943: f32[1,1,3584,7168]) -> f32[1,1,3584,7168] {
  %param_1.943 = f32[1,1,3584,7168]{3,2,1,0} parameter(1)
  %copy.163 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %param_1.943), metadata={op_name="2$start"}
  %param_0.643 = f32[1,1,3584,7168]{1,0,2,3} parameter(0)
  %add.178 = f32[1,1,3584,7168]{1,0,2,3} add(f32[1,1,3584,7168]{1,0,2,3} %copy.163, f32[1,1,3584,7168]{1,0,2,3} %param_0.643), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  ROOT %copy.162 = f32[1,1,3584,7168]{3,2,1,0} copy(f32[1,1,3584,7168]{1,0,2,3} %add.178), metadata={op_name="tuple.79"}
}

%fused_computation.364 (param_0.1151: f32[16,7,7,3584], param_1.1568: f32[3584], param_2.694: f32[3584], param_3.496: f32[3584], param_4.458: f32[16,7,7,3584], param_5.457: f32[3584]) -> (f32[16,3584], f32[16,3584], f32[16,3584]) {
  %param_4.458 = f32[16,7,7,3584]{2,1,3,0} parameter(4)
  %param_5.457 = f32[3584]{0} parameter(5)
  %constant_1362 = f32[] constant(0.00127551018)
  %broadcast.1765 = f32[3584]{0} broadcast(f32[] %constant_1362), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1327 = f32[3584]{0} multiply(f32[3584]{0} %param_5.457, f32[3584]{0} %broadcast.1765), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1764 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1327), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.124 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_4.458, f32[16,7,7,3584]{2,1,3,0} %broadcast.1764), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.496 = f32[3584]{0} parameter(3)
  %constant_540 = f32[] constant(0)
  %broadcast.1763 = f32[3584]{0} broadcast(f32[] %constant_540), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.235 = f32[3584]{0} maximum(f32[3584]{0} %param_3.496, f32[3584]{0} %broadcast.1763), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1360 = f32[] constant(1e-05)
  %broadcast.1762 = f32[3584]{0} broadcast(f32[] %constant_1360), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.399 = f32[3584]{0} add(f32[3584]{0} %maximum.235, f32[3584]{0} %broadcast.1762), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1134 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.399), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.185 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1134), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.694 = f32[3584]{0} parameter(2)
  %bitcast.1133 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_2.694), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1326 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.185, f32[1,1,1,3584]{3,2,1,0} %bitcast.1133), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1132 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1326), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1761 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1132), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1325 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.124, f32[16,7,7,3584]{2,1,3,0} %broadcast.1761), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1568 = f32[3584]{0} parameter(1)
  %broadcast.1760 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.1568), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.398 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1325, f32[16,7,7,3584]{2,1,3,0} %broadcast.1760), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1759 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_540), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %compare.181 = pred[16,7,7,3584]{2,1,3,0} compare(f32[16,7,7,3584]{2,1,3,0} %add.398, f32[16,7,7,3584]{2,1,3,0} %broadcast.1759), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1151 = f32[16,7,7,3584]{2,1,3,0} parameter(0)
  %select.181 = f32[16,7,7,3584]{2,1,3,0} select(pred[16,7,7,3584]{2,1,3,0} %compare.181, f32[16,7,7,3584]{2,1,3,0} %param_0.1151, f32[16,7,7,3584]{2,1,3,0} %broadcast.1759), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.54 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %select.181), dimensions={0,3,1,2}
  %bitcast.732 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.54), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.781 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.732, f32[] %constant_540), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1343.clone.1 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %select.181, f32[16,7,7,3584]{2,1,3,0} %broadcast.1761), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.42.clone.1 = f32[16,7,7,3584]{2,1,3,0} negate(f32[16,7,7,3584]{2,1,3,0} %multiply.1343.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.55 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %negate.42.clone.1), dimensions={0,3,1,2}
  %bitcast.741.clone.1 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.55), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.787.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.741.clone.1, f32[] %constant_540), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.615.clone.1 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.124, f32[16,7,7,3584]{2,1,3,0} %select.181), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.56 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %multiply.615.clone.1), dimensions={0,3,1,2}
  %bitcast.743.clone.1 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.56), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.789.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.743.clone.1, f32[] %constant_540), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.84 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.781, f32[16,3584]{1,0} %reduce.787.clone.1, f32[16,3584]{1,0} %reduce.789.clone.1)
}

%fused_computation.366 (param_0.650: f32[3,3,1792,3584], param_1.952: f32[3,3,1792,3584]) -> f32[3,3,1792,3584] {
  %param_1.952 = f32[3,3,1792,3584]{3,2,1,0} parameter(1)
  %copy.165 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %param_1.952), metadata={op_name="2$start"}
  %param_0.650 = f32[3,3,1792,3584]{1,0,2,3} parameter(0)
  %add.181 = f32[3,3,1792,3584]{1,0,2,3} add(f32[3,3,1792,3584]{1,0,2,3} %copy.165, f32[3,3,1792,3584]{1,0,2,3} %param_0.650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  ROOT %copy.164 = f32[3,3,1792,3584]{3,2,1,0} copy(f32[3,3,1792,3584]{1,0,2,3} %add.181), metadata={op_name="tuple.79"}
}

%fused_computation.368 (param_0.1162: f32[16,7,7,1792], param_1.1586: f32[1792], param_2.719: f32[1792], param_3.527: f32[1792], param_4.492: f32[16,7,7,1792], param_5.500: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.492 = f32[16,7,7,1792]{2,1,3,0} parameter(4)
  %param_5.500 = f32[1792]{0} parameter(5)
  %constant_1415 = f32[] constant(0.00127551018)
  %broadcast.1847 = f32[1792]{0} broadcast(f32[] %constant_1415), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1365 = f32[1792]{0} multiply(f32[1792]{0} %param_5.500, f32[1792]{0} %broadcast.1847), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1846 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1365), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.134 = f32[16,7,7,1792]{2,1,3,0} subtract(f32[16,7,7,1792]{2,1,3,0} %param_4.492, f32[16,7,7,1792]{2,1,3,0} %broadcast.1846), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.527 = f32[1792]{0} parameter(3)
  %constant_542 = f32[] constant(0)
  %broadcast.1845 = f32[1792]{0} broadcast(f32[] %constant_542), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.249 = f32[1792]{0} maximum(f32[1792]{0} %param_3.527, f32[1792]{0} %broadcast.1845), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1413 = f32[] constant(1e-05)
  %broadcast.1844 = f32[1792]{0} broadcast(f32[] %constant_1413), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.423 = f32[1792]{0} add(f32[1792]{0} %maximum.249, f32[1792]{0} %broadcast.1844), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1176 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.423), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.199 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1176), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.719 = f32[1792]{0} parameter(2)
  %bitcast.1175 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.719), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1364 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.199, f32[1,1,1,1792]{3,2,1,0} %bitcast.1175), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1174 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1364), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1843 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1174), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1363 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.134, f32[16,7,7,1792]{2,1,3,0} %broadcast.1843), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1586 = f32[1792]{0} parameter(1)
  %broadcast.1842 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.1586), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.422 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.1363, f32[16,7,7,1792]{2,1,3,0} %broadcast.1842), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1841 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[] %constant_542), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.191 = pred[16,7,7,1792]{2,1,3,0} compare(f32[16,7,7,1792]{2,1,3,0} %add.422, f32[16,7,7,1792]{2,1,3,0} %broadcast.1841), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1162 = f32[16,7,7,1792]{2,1,3,0} parameter(0)
  %select.191 = f32[16,7,7,1792]{2,1,3,0} select(pred[16,7,7,1792]{2,1,3,0} %compare.191, f32[16,7,7,1792]{2,1,3,0} %param_0.1162, f32[16,7,7,1792]{2,1,3,0} %broadcast.1841), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.57 = f32[16,1792,7,7]{3,2,1,0} transpose(f32[16,7,7,1792]{2,1,3,0} %select.191), dimensions={0,3,1,2}
  %bitcast.734 = f32[16,1792,49]{2,1,0} bitcast(f32[16,1792,7,7]{3,2,1,0} %transpose.57), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.783 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %bitcast.734, f32[] %constant_542), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1381.clone.1 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %select.191, f32[16,7,7,1792]{2,1,3,0} %broadcast.1843), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.40.clone.1 = f32[16,7,7,1792]{2,1,3,0} negate(f32[16,7,7,1792]{2,1,3,0} %multiply.1381.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.58 = f32[16,1792,7,7]{3,2,1,0} transpose(f32[16,7,7,1792]{2,1,3,0} %negate.40.clone.1), dimensions={0,3,1,2}
  %bitcast.737.clone.1 = f32[16,1792,49]{2,1,0} bitcast(f32[16,1792,7,7]{3,2,1,0} %transpose.58), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.784.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %bitcast.737.clone.1, f32[] %constant_542), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.604.clone.1 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.134, f32[16,7,7,1792]{2,1,3,0} %select.191), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.59 = f32[16,1792,7,7]{3,2,1,0} transpose(f32[16,7,7,1792]{2,1,3,0} %multiply.604.clone.1), dimensions={0,3,1,2}
  %bitcast.739.clone.1 = f32[16,1792,49]{2,1,0} bitcast(f32[16,1792,7,7]{3,2,1,0} %transpose.59), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.786.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %bitcast.739.clone.1, f32[] %constant_542), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.82 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.783, f32[16,1792]{1,0} %reduce.784.clone.1, f32[16,1792]{1,0} %reduce.786.clone.1)
}

%fused_computation.370 (param_0.657: f32[1,1,7168,1792], param_1.961: f32[1,1,7168,1792]) -> f32[1,1,7168,1792] {
  %param_1.961 = f32[1,1,7168,1792]{3,2,1,0} parameter(1)
  %copy.167 = f32[1,1,7168,1792]{1,0,2,3} copy(f32[1,1,7168,1792]{3,2,1,0} %param_1.961), metadata={op_name="2$start"}
  %param_0.657 = f32[1,1,7168,1792]{1,0,2,3} parameter(0)
  %add.184 = f32[1,1,7168,1792]{1,0,2,3} add(f32[1,1,7168,1792]{1,0,2,3} %copy.167, f32[1,1,7168,1792]{1,0,2,3} %param_0.657), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  ROOT %copy.166 = f32[1,1,7168,1792]{3,2,1,0} copy(f32[1,1,7168,1792]{1,0,2,3} %add.184), metadata={op_name="tuple.79"}
}

%fused_computation.371 (param_0.660: f32[1792], param_1.967: f32[1792], param_2.721: f32[16,7,7,1792], param_3.529: f32[1792], param_4.494: f32[1,1,1,1792], param_5.502: f32[1792], param_6.387: f32[16,7,7,1792], param_7.438: f32[1792]) -> f32[16,7,7,1792] {
  %param_2.721 = f32[16,7,7,1792]{2,1,3,0} parameter(2)
  %param_1.967 = f32[1792]{0} parameter(1)
  %constant_546 = f32[] constant(0.00127551018)
  %broadcast.1867 = f32[1792]{0} broadcast(f32[] %constant_546), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1375 = f32[1792]{0} multiply(f32[1792]{0} %param_1.967, f32[1792]{0} %broadcast.1867), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1866 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1375), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.136 = f32[16,7,7,1792]{2,1,3,0} subtract(f32[16,7,7,1792]{2,1,3,0} %param_2.721, f32[16,7,7,1792]{2,1,3,0} %broadcast.1866), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.529 = f32[1792]{0} parameter(3)
  %constant_547 = f32[] constant(0)
  %broadcast.1865 = f32[1792]{0} broadcast(f32[] %constant_547), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.253 = f32[1792]{0} maximum(f32[1792]{0} %param_3.529, f32[1792]{0} %broadcast.1865), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1195 = f32[] constant(1e-05)
  %broadcast.1864 = f32[1792]{0} broadcast(f32[] %constant_1195), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.429 = f32[1792]{0} add(f32[1792]{0} %maximum.253, f32[1792]{0} %broadcast.1864), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1188 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.429), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.203 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1188), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.502 = f32[1792]{0} parameter(5)
  %bitcast.1187 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.502), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1374 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.203, f32[1,1,1,1792]{3,2,1,0} %bitcast.1187), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1186 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1374), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1863 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1186), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1373 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.136, f32[16,7,7,1792]{2,1,3,0} %broadcast.1863), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.438 = f32[1792]{0} parameter(7)
  %broadcast.1862 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.438), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.428 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.1373, f32[16,7,7,1792]{2,1,3,0} %broadcast.1862), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1861 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[] %constant_547), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.193 = pred[16,7,7,1792]{2,1,3,0} compare(f32[16,7,7,1792]{2,1,3,0} %add.428, f32[16,7,7,1792]{2,1,3,0} %broadcast.1861), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.387 = f32[16,7,7,1792]{2,1,3,0} parameter(6)
  %select.193 = f32[16,7,7,1792]{2,1,3,0} select(pred[16,7,7,1792]{2,1,3,0} %compare.193, f32[16,7,7,1792]{2,1,3,0} %param_6.387, f32[16,7,7,1792]{2,1,3,0} %broadcast.1861), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1371 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %select.193, f32[16,7,7,1792]{2,1,3,0} %broadcast.1863), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.494 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.603 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.494, f32[1,1,1,1792]{3,2,1,0} %bitcast.1187), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.40 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.203, f32[1,1,1,1792]{3,2,1,0} %bitcast.1188), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_543 = f32[] constant(-0.5)
  %broadcast.625 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_543), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.602 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.40, f32[1,1,1,1792]{3,2,1,0} %broadcast.625), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.601 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.603, f32[1,1,1,1792]{3,2,1,0} %multiply.602), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.736 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.601), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.58 = pred[1792]{0} compare(f32[1792]{0} %param_3.529, f32[1792]{0} %maximum.253), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_548 = f32[] constant(1)
  %broadcast.624 = f32[1792]{0} broadcast(f32[] %constant_548), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.58 = f32[1792]{0} select(pred[1792]{0} %compare.58, f32[1792]{0} %broadcast.624, f32[1792]{0} %broadcast.1865), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.57 = pred[1792]{0} compare(f32[1792]{0} %broadcast.1865, f32[1792]{0} %maximum.253), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_544 = f32[] constant(2)
  %broadcast.623 = f32[1792]{0} broadcast(f32[] %constant_544), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.57 = f32[1792]{0} select(pred[1792]{0} %compare.57, f32[1792]{0} %broadcast.623, f32[1792]{0} %broadcast.624), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.39 = f32[1792]{0} divide(f32[1792]{0} %select.58, f32[1792]{0} %select.57), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.600 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.736, f32[1792]{0} %divide.39), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_545 = f32[] constant(0.00255102036)
  %broadcast.622 = f32[1792]{0} broadcast(f32[] %constant_545), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.599 = f32[1792]{0} multiply(f32[1792]{0} %multiply.600, f32[1792]{0} %broadcast.622), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.621 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.599), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.598 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %param_2.721, f32[16,7,7,1792]{2,1,3,0} %broadcast.621), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.187 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.1371, f32[16,7,7,1792]{2,1,3,0} %multiply.598), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.660 = f32[1792]{0} parameter(0)
  %negate.39 = f32[1792]{0} negate(f32[1792]{0} %multiply.600), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.597 = f32[1792]{0} multiply(f32[1792]{0} %param_1.967, f32[1792]{0} %broadcast.622), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.596 = f32[1792]{0} multiply(f32[1792]{0} %negate.39, f32[1792]{0} %multiply.597), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.186 = f32[1792]{0} add(f32[1792]{0} %param_0.660, f32[1792]{0} %multiply.596), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.595 = f32[1792]{0} multiply(f32[1792]{0} %add.186, f32[1792]{0} %broadcast.1867), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.620 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.595), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/broadcast_in_dim[shape=(16, 7, 7, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.185 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %add.187, f32[16,7,7,1792]{2,1,3,0} %broadcast.620), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.373 (param_0.664: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.664 = f32[16,1792]{1,0} parameter(0)
  %constant_549 = f32[] constant(0)
  %reduce.785 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.664, f32[] %constant_549), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.738 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.785), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.377 (param_0.672: f32[3584], param_1.985: f32[3584], param_2.696: f32[16,7,7,3584], param_3.498: f32[3584], param_4.460: f32[1,1,1,3584], param_5.459: f32[3584], param_6.362: f32[16,7,7,3584], param_7.420: f32[3584]) -> f32[16,7,7,3584] {
  %param_2.696 = f32[16,7,7,3584]{2,1,3,0} parameter(2)
  %param_1.985 = f32[3584]{0} parameter(1)
  %constant_556 = f32[] constant(0.00127551018)
  %broadcast.1785 = f32[3584]{0} broadcast(f32[] %constant_556), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1337 = f32[3584]{0} multiply(f32[3584]{0} %param_1.985, f32[3584]{0} %broadcast.1785), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1784 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1337), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.126 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_2.696, f32[16,7,7,3584]{2,1,3,0} %broadcast.1784), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.498 = f32[3584]{0} parameter(3)
  %constant_557 = f32[] constant(0)
  %broadcast.1783 = f32[3584]{0} broadcast(f32[] %constant_557), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.239 = f32[3584]{0} maximum(f32[3584]{0} %param_3.498, f32[3584]{0} %broadcast.1783), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1252 = f32[] constant(1e-05)
  %broadcast.1782 = f32[3584]{0} broadcast(f32[] %constant_1252), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.405 = f32[3584]{0} add(f32[3584]{0} %maximum.239, f32[3584]{0} %broadcast.1782), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1146 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.405), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.189 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1146), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.459 = f32[3584]{0} parameter(5)
  %bitcast.1145 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.459), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1336 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.189, f32[1,1,1,3584]{3,2,1,0} %bitcast.1145), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1144 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1336), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1781 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1144), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1335 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.126, f32[16,7,7,3584]{2,1,3,0} %broadcast.1781), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.420 = f32[3584]{0} parameter(7)
  %broadcast.1780 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_7.420), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.404 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1335, f32[16,7,7,3584]{2,1,3,0} %broadcast.1780), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1779 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_557), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %compare.183 = pred[16,7,7,3584]{2,1,3,0} compare(f32[16,7,7,3584]{2,1,3,0} %add.404, f32[16,7,7,3584]{2,1,3,0} %broadcast.1779), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.362 = f32[16,7,7,3584]{2,1,3,0} parameter(6)
  %select.183 = f32[16,7,7,3584]{2,1,3,0} select(pred[16,7,7,3584]{2,1,3,0} %compare.183, f32[16,7,7,3584]{2,1,3,0} %param_6.362, f32[16,7,7,3584]{2,1,3,0} %broadcast.1779), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1333 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %select.183, f32[16,7,7,3584]{2,1,3,0} %broadcast.1781), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.460 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.614 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.460, f32[1,1,1,3584]{3,2,1,0} %bitcast.1145), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.42 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.189, f32[1,1,1,3584]{3,2,1,0} %bitcast.1146), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_553 = f32[] constant(-0.5)
  %broadcast.635 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_553), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.613 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.42, f32[1,1,1,3584]{3,2,1,0} %broadcast.635), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.612 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.614, f32[1,1,1,3584]{3,2,1,0} %multiply.613), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.740 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.612), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.61 = pred[3584]{0} compare(f32[3584]{0} %param_3.498, f32[3584]{0} %maximum.239), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_558 = f32[] constant(1)
  %broadcast.634 = f32[3584]{0} broadcast(f32[] %constant_558), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.61 = f32[3584]{0} select(pred[3584]{0} %compare.61, f32[3584]{0} %broadcast.634, f32[3584]{0} %broadcast.1783), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.60 = pred[3584]{0} compare(f32[3584]{0} %broadcast.1783, f32[3584]{0} %maximum.239), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_554 = f32[] constant(2)
  %broadcast.633 = f32[3584]{0} broadcast(f32[] %constant_554), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.60 = f32[3584]{0} select(pred[3584]{0} %compare.60, f32[3584]{0} %broadcast.633, f32[3584]{0} %broadcast.634), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.41 = f32[3584]{0} divide(f32[3584]{0} %select.61, f32[3584]{0} %select.60), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.611 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.740, f32[3584]{0} %divide.41), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_555 = f32[] constant(0.00255102036)
  %broadcast.632 = f32[3584]{0} broadcast(f32[] %constant_555), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.610 = f32[3584]{0} multiply(f32[3584]{0} %multiply.611, f32[3584]{0} %broadcast.632), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.631 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.610), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.609 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %param_2.696, f32[16,7,7,3584]{2,1,3,0} %broadcast.631), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.190 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1333, f32[16,7,7,3584]{2,1,3,0} %multiply.609), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.672 = f32[3584]{0} parameter(0)
  %negate.41 = f32[3584]{0} negate(f32[3584]{0} %multiply.611), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.608 = f32[3584]{0} multiply(f32[3584]{0} %param_1.985, f32[3584]{0} %broadcast.632), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.607 = f32[3584]{0} multiply(f32[3584]{0} %negate.41, f32[3584]{0} %multiply.608), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.189 = f32[3584]{0} add(f32[3584]{0} %param_0.672, f32[3584]{0} %multiply.607), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.606 = f32[3584]{0} multiply(f32[3584]{0} %add.189, f32[3584]{0} %broadcast.1785), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.630 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.606), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/broadcast_in_dim[shape=(16, 7, 7, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.188 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %add.190, f32[16,7,7,3584]{2,1,3,0} %broadcast.630), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.379 (param_0.676: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.676 = f32[16,3584]{1,0} parameter(0)
  %constant_559 = f32[] constant(0)
  %reduce.788 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.676, f32[] %constant_559), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.742 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.788), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.383 (param_0.684: f32[7168], param_1.1003: f32[7168], param_2.673: f32[16,7,7,7168], param_3.473: f32[7168], param_4.434: f32[1,1,1,7168], param_5.429: f32[7168], param_6.342: f32[16,7,7,7168]) -> f32[16,7,7,7168] {
  %param_6.342 = f32[16,7,7,7168]{2,1,3,0} parameter(6)
  %param_3.473 = f32[7168]{0} parameter(3)
  %constant_567 = f32[] constant(0)
  %broadcast.1717 = f32[7168]{0} broadcast(f32[] %constant_567), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.227 = f32[7168]{0} maximum(f32[7168]{0} %param_3.473, f32[7168]{0} %broadcast.1717), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1309 = f32[] constant(1e-05)
  %broadcast.1716 = f32[7168]{0} broadcast(f32[] %constant_1309), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.385 = f32[7168]{0} add(f32[7168]{0} %maximum.227, f32[7168]{0} %broadcast.1716), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1110 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.385), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.177 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1110), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.429 = f32[7168]{0} parameter(5)
  %bitcast.1109 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_5.429), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1305 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.177, f32[1,1,1,7168]{3,2,1,0} %bitcast.1109), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1108 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1305), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1715 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.1108), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1304 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_6.342, f32[16,7,7,7168]{2,1,3,0} %broadcast.1715), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.673 = f32[16,7,7,7168]{2,1,3,0} parameter(2)
  %param_4.434 = f32[1,1,1,7168]{3,2,1,0} parameter(4)
  %multiply.625 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %param_4.434, f32[1,1,1,7168]{3,2,1,0} %bitcast.1109), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.44 = f32[1,1,1,7168]{3,2,1,0} divide(f32[1,1,1,7168]{3,2,1,0} %rsqrt.177, f32[1,1,1,7168]{3,2,1,0} %bitcast.1110), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_563 = f32[] constant(-0.5)
  %broadcast.645 = f32[1,1,1,7168]{3,2,1,0} broadcast(f32[] %constant_563), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.624 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %divide.44, f32[1,1,1,7168]{3,2,1,0} %broadcast.645), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.623 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %multiply.625, f32[1,1,1,7168]{3,2,1,0} %multiply.624), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.744 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.623), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reshape[new_sizes=(7168,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.64 = pred[7168]{0} compare(f32[7168]{0} %param_3.473, f32[7168]{0} %maximum.227), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_568 = f32[] constant(1)
  %broadcast.644 = f32[7168]{0} broadcast(f32[] %constant_568), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/broadcast_in_dim[shape=(7168,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.64 = f32[7168]{0} select(pred[7168]{0} %compare.64, f32[7168]{0} %broadcast.644, f32[7168]{0} %broadcast.1717), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.63 = pred[7168]{0} compare(f32[7168]{0} %broadcast.1717, f32[7168]{0} %maximum.227), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_564 = f32[] constant(2)
  %broadcast.643 = f32[7168]{0} broadcast(f32[] %constant_564), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.63 = f32[7168]{0} select(pred[7168]{0} %compare.63, f32[7168]{0} %broadcast.643, f32[7168]{0} %broadcast.644), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.43 = f32[7168]{0} divide(f32[7168]{0} %select.64, f32[7168]{0} %select.63), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.622 = f32[7168]{0} multiply(f32[7168]{0} %bitcast.744, f32[7168]{0} %divide.43), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_565 = f32[] constant(0.00255102036)
  %broadcast.642 = f32[7168]{0} broadcast(f32[] %constant_565), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.621 = f32[7168]{0} multiply(f32[7168]{0} %multiply.622, f32[7168]{0} %broadcast.642), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.641 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.621), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.620 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_2.673, f32[16,7,7,7168]{2,1,3,0} %broadcast.641), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.193 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.1304, f32[16,7,7,7168]{2,1,3,0} %multiply.620), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.684 = f32[7168]{0} parameter(0)
  %negate.43 = f32[7168]{0} negate(f32[7168]{0} %multiply.622), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.1003 = f32[7168]{0} parameter(1)
  %multiply.619 = f32[7168]{0} multiply(f32[7168]{0} %param_1.1003, f32[7168]{0} %broadcast.642), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.618 = f32[7168]{0} multiply(f32[7168]{0} %negate.43, f32[7168]{0} %multiply.619), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.192 = f32[7168]{0} add(f32[7168]{0} %param_0.684, f32[7168]{0} %multiply.618), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_566 = f32[] constant(0.00127551018)
  %broadcast.647 = f32[7168]{0} broadcast(f32[] %constant_566), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.617 = f32[7168]{0} multiply(f32[7168]{0} %add.192, f32[7168]{0} %broadcast.647), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.640 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.617), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/broadcast_in_dim[shape=(16, 7, 7, 7168) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.191 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %add.193, f32[16,7,7,7168]{2,1,3,0} %broadcast.640), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.384 (param_0.1144: f32[16,7,7,7168], param_1.1558: f32[7168], param_2.680: f32[7168], param_3.1447: f32[16,7,7,7168], param_4.1282: f32[7168]) -> (f32[16,7168], f32[16,7168], f32[16,7168]) {
  %param_0.1144 = f32[16,7,7,7168]{2,1,3,0} parameter(0)
  %param_2.680 = f32[7168]{0} parameter(2)
  %constant_571 = f32[] constant(0)
  %broadcast.1723 = f32[7168]{0} broadcast(f32[] %constant_571), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.229 = f32[7168]{0} maximum(f32[7168]{0} %param_2.680, f32[7168]{0} %broadcast.1723), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1334 = f32[] constant(1e-05)
  %broadcast.1722 = f32[7168]{0} broadcast(f32[] %constant_1334), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.387 = f32[7168]{0} add(f32[7168]{0} %maximum.229, f32[7168]{0} %broadcast.1722), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1116 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.387), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.179 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1116), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1558 = f32[7168]{0} parameter(1)
  %bitcast.1115 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_1.1558), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1309 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.179, f32[1,1,1,7168]{3,2,1,0} %bitcast.1115), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1114 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1309), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1721 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.1114), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1308 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_0.1144, f32[16,7,7,7168]{2,1,3,0} %broadcast.1721), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.44 = f32[16,7,7,7168]{2,1,3,0} negate(f32[16,7,7,7168]{2,1,3,0} %multiply.1308), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.60 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %negate.44), dimensions={0,3,1,2}
  %bitcast.745 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.60), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.790 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.745, f32[] %constant_571), dimensions={2}, to_apply=%region_57.4114.2
  %param_3.1447 = f32[16,7,7,7168]{2,1,3,0} parameter(3)
  %param_4.1282 = f32[7168]{0} parameter(4)
  %constant_1294_clone_1 = f32[] constant(0.00127551018)
  %broadcast.1687.clone.1 = f32[7168]{0} broadcast(f32[] %constant_1294_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1297.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_4.1282, f32[7168]{0} %broadcast.1687.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1686.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.1297.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.118.clone.1 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_3.1447, f32[16,7,7,7168]{2,1,3,0} %broadcast.1686.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.626.clone.1 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.118.clone.1, f32[16,7,7,7168]{2,1,3,0} %param_0.1144), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.61 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %multiply.626.clone.1), dimensions={0,3,1,2}
  %bitcast.747.clone.1 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.61), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.792.clone.1 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.747.clone.1, f32[] %constant_571), dimensions={2}, to_apply=%region_57.4114.2
  %transpose.62 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %param_0.1144), dimensions={0,3,1,2}
  %bitcast.730.clone.1 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.62), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.779.clone.1 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.730.clone.1, f32[] %constant_571), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.86 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.790, f32[16,7168]{1,0} %reduce.792.clone.1, f32[16,7168]{1,0} %reduce.779.clone.1)
}

%fused_computation.385 (param_0.688: f32[16,7168]) -> f32[1,1,1,7168] {
  %param_0.688 = f32[16,7168]{1,0} parameter(0)
  %constant_569 = f32[] constant(0)
  %reduce.791 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_0.688, f32[] %constant_569), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.746 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %reduce.791), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.388 (param_0.693: f32[16,7,7,7168], param_1.1015: f32[16,7,7,7168], param_2.312: f32[7168], param_3.468: f32[16,7,7,7168], param_4.433: f32[7168], param_5.428: f32[7168], param_6.341: f32[7168]) -> f32[16,7,7,7168] {
  %param_1.1015 = f32[16,7,7,7168]{2,1,3,0} parameter(1)
  %param_3.468 = f32[16,7,7,7168]{2,1,3,0} parameter(3)
  %param_4.433 = f32[7168]{0} parameter(4)
  %constant_1291 = f32[] constant(0.00127551018)
  %broadcast.1683 = f32[7168]{0} broadcast(f32[] %constant_1291), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1295 = f32[7168]{0} multiply(f32[7168]{0} %param_4.433, f32[7168]{0} %broadcast.1683), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1682 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.1295), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.116 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_3.468, f32[16,7,7,7168]{2,1,3,0} %broadcast.1682), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_6.341 = f32[7168]{0} parameter(6)
  %constant_572 = f32[] constant(0)
  %broadcast.1707 = f32[7168]{0} broadcast(f32[] %constant_572), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.223 = f32[7168]{0} maximum(f32[7168]{0} %param_6.341, f32[7168]{0} %broadcast.1707), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1319 = f32[] constant(1e-05)
  %broadcast.1706 = f32[7168]{0} broadcast(f32[] %constant_1319), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.381 = f32[7168]{0} add(f32[7168]{0} %maximum.223, f32[7168]{0} %broadcast.1706), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1098 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.381), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.173 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.1098), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.428 = f32[7168]{0} parameter(5)
  %bitcast.1097 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_5.428), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1299 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.173, f32[1,1,1,7168]{3,2,1,0} %bitcast.1097), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1096 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1299), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.650 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.1096), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.628 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.116, f32[16,7,7,7168]{2,1,3,0} %broadcast.650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.312 = f32[7168]{0} parameter(2)
  %broadcast.649 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_2.312), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.195 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.628, f32[16,7,7,7168]{2,1,3,0} %broadcast.649), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.194 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %param_1.1015, f32[16,7,7,7168]{2,1,3,0} %add.195), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.651 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[] %constant_572), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.65 = pred[16,7,7,7168]{2,1,3,0} compare(f32[16,7,7,7168]{2,1,3,0} %add.194, f32[16,7,7,7168]{2,1,3,0} %broadcast.651), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.693 = f32[16,7,7,7168]{2,1,3,0} parameter(0)
  ROOT %select.65 = f32[16,7,7,7168]{2,1,3,0} select(pred[16,7,7,7168]{2,1,3,0} %compare.65, f32[16,7,7,7168]{2,1,3,0} %param_0.693, f32[16,7,7,7168]{2,1,3,0} %broadcast.651), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.392 (param_0.1130: f32[16,7168], param_1.1538: f32[7168]) -> f32[7168] {
  %param_0.1130 = f32[16,7168]{1,0} parameter(0)
  %constant_576 = f32[] constant(0)
  %reduce.793 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_0.1130, f32[] %constant_576), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_575 = f32[] constant(0.00127551018)
  %broadcast.654 = f32[7168]{0} broadcast(f32[] %constant_575), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.631 = f32[7168]{0} multiply(f32[7168]{0} %reduce.793, f32[7168]{0} %broadcast.654), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1538 = f32[7168]{0} parameter(1)
  %multiply.1293 = f32[7168]{0} multiply(f32[7168]{0} %param_1.1538, f32[7168]{0} %broadcast.654), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.630 = f32[7168]{0} multiply(f32[7168]{0} %multiply.1293, f32[7168]{0} %multiply.1293), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.38 = f32[7168]{0} subtract(f32[7168]{0} %multiply.631, f32[7168]{0} %multiply.630), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.397 (param_0.1126: f32[3584], param_1.1533: f32[3584], param_2.646: f32[3584], param_3.453: f32[16,7,7,3584], param_4.422: f32[3584]) -> f32[16,7,7,3584] {
  %param_3.453 = f32[16,7,7,3584]{2,1,3,0} parameter(3)
  %param_4.422 = f32[3584]{0} parameter(4)
  %constant_1275 = f32[] constant(0.00127551018)
  %broadcast.1663 = f32[3584]{0} broadcast(f32[] %constant_1275), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1283 = f32[3584]{0} multiply(f32[3584]{0} %param_4.422, f32[3584]{0} %broadcast.1663), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1662 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1283), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.112 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_3.453, f32[16,7,7,3584]{2,1,3,0} %broadcast.1662), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.646 = f32[3584]{0} parameter(2)
  %constant_785 = f32[] constant(0)
  %broadcast.1661 = f32[3584]{0} broadcast(f32[] %constant_785), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.209 = f32[3584]{0} maximum(f32[3584]{0} %param_2.646, f32[3584]{0} %broadcast.1661), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1273 = f32[] constant(1e-05)
  %broadcast.1660 = f32[3584]{0} broadcast(f32[] %constant_1273), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.369 = f32[3584]{0} add(f32[3584]{0} %maximum.209, f32[3584]{0} %broadcast.1660), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1080 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.369), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.169 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.1080), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1533 = f32[3584]{0} parameter(1)
  %bitcast.1079 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.1533), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1282 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.169, f32[1,1,1,3584]{3,2,1,0} %bitcast.1079), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1078 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1282), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1659 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.1078), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1281 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.112, f32[16,7,7,3584]{2,1,3,0} %broadcast.1659), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1126 = f32[3584]{0} parameter(0)
  %broadcast.1658 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_0.1126), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.368 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1281, f32[16,7,7,3584]{2,1,3,0} %broadcast.1658), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.657 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_785), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.34 = f32[16,7,7,3584]{2,1,3,0} maximum(f32[16,7,7,3584]{2,1,3,0} %add.368, f32[16,7,7,3584]{2,1,3,0} %broadcast.657), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.402 (param_0.1112: f32[16,3584], param_1.1513: f32[3584]) -> f32[3584] {
  %param_0.1112 = f32[16,3584]{1,0} parameter(0)
  %constant_789 = f32[] constant(0)
  %reduce.796 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.1112, f32[] %constant_789), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_788 = f32[] constant(0.00127551018)
  %broadcast.662 = f32[3584]{0} broadcast(f32[] %constant_788), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.637 = f32[3584]{0} multiply(f32[3584]{0} %reduce.796, f32[3584]{0} %broadcast.662), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1513 = f32[3584]{0} parameter(1)
  %multiply.1269 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1513, f32[3584]{0} %broadcast.662), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.636 = f32[3584]{0} multiply(f32[3584]{0} %multiply.1269, f32[3584]{0} %multiply.1269), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.40 = f32[3584]{0} subtract(f32[3584]{0} %multiply.637, f32[3584]{0} %multiply.636), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.407 (param_0.1108: f32[1792], param_1.1508: f32[1792], param_2.612: f32[1792], param_3.422: f32[16,7,7,1792], param_4.397: f32[1792]) -> f32[16,7,7,1792] {
  %param_3.422 = f32[16,7,7,1792]{2,1,3,0} parameter(3)
  %param_4.397 = f32[1792]{0} parameter(4)
  %constant_1218 = f32[] constant(0.00127551018)
  %broadcast.1589 = f32[1792]{0} broadcast(f32[] %constant_1218), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1259 = f32[1792]{0} multiply(f32[1792]{0} %param_4.397, f32[1792]{0} %broadcast.1589), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1587 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1259), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.104 = f32[16,7,7,1792]{2,1,3,0} subtract(f32[16,7,7,1792]{2,1,3,0} %param_3.422, f32[16,7,7,1792]{2,1,3,0} %broadcast.1587), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.612 = f32[1792]{0} parameter(2)
  %constant_793 = f32[] constant(0)
  %broadcast.1585 = f32[1792]{0} broadcast(f32[] %constant_793), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.146 = f32[1792]{0} maximum(f32[1792]{0} %param_2.612, f32[1792]{0} %broadcast.1585), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1216 = f32[] constant(1e-05)
  %broadcast.1526 = f32[1792]{0} broadcast(f32[] %constant_1216), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.351 = f32[1792]{0} add(f32[1792]{0} %maximum.146, f32[1792]{0} %broadcast.1526), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1050 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.351), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.161 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1050), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1508 = f32[1792]{0} parameter(1)
  %bitcast.1049 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1508), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1258 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.161, f32[1,1,1,1792]{3,2,1,0} %bitcast.1049), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1048 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1258), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1524 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1048), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1257 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.104, f32[16,7,7,1792]{2,1,3,0} %broadcast.1524), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1108 = f32[1792]{0} parameter(0)
  %broadcast.1521 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1108), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.350 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.1257, f32[16,7,7,1792]{2,1,3,0} %broadcast.1521), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.665 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[] %constant_793), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.36 = f32[16,7,7,1792]{2,1,3,0} maximum(f32[16,7,7,1792]{2,1,3,0} %add.350, f32[16,7,7,1792]{2,1,3,0} %broadcast.665), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.412 (param_0.1094: f32[16,1792], param_1.1488: f32[1792]) -> f32[1792] {
  %param_0.1094 = f32[16,1792]{1,0} parameter(0)
  %constant_797 = f32[] constant(0)
  %reduce.799 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1094, f32[] %constant_797), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_796 = f32[] constant(0.00127551018)
  %broadcast.670 = f32[1792]{0} broadcast(f32[] %constant_796), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.643 = f32[1792]{0} multiply(f32[1792]{0} %reduce.799, f32[1792]{0} %broadcast.670), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1488 = f32[1792]{0} parameter(1)
  %multiply.1245 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1488, f32[1792]{0} %broadcast.670), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.642 = f32[1792]{0} multiply(f32[1792]{0} %multiply.1245, f32[1792]{0} %multiply.1245), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.42 = f32[1792]{0} subtract(f32[1792]{0} %multiply.643, f32[1792]{0} %multiply.642), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.417 (param_0.739: f32[16,7,7,7168]) -> f32[16,7,7,7168] {
  %param_0.739 = f32[16,7,7,7168]{2,1,3,0} parameter(0)
  %constant_801 = f32[] constant(0)
  %broadcast.673 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[] %constant_801), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %maximum.38 = f32[16,7,7,7168]{2,1,3,0} maximum(f32[16,7,7,7168]{2,1,3,0} %param_0.739, f32[16,7,7,7168]{2,1,3,0} %broadcast.673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.422 (param_0.747: f32[1,1,3584,7168], param_1.1095: f32[1,1,3584,7168]) -> f32[1,1,3584,7168] {
  %param_1.1095 = f32[1,1,3584,7168]{3,2,1,0} parameter(1)
  %copy.169 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %param_1.1095), metadata={op_name="2$start"}
  %param_0.747 = f32[1,1,3584,7168]{1,0,2,3} parameter(0)
  %add.204 = f32[1,1,3584,7168]{1,0,2,3} add(f32[1,1,3584,7168]{1,0,2,3} %copy.169, f32[1,1,3584,7168]{1,0,2,3} %param_0.747), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  ROOT %copy.168 = f32[1,1,3584,7168]{3,2,1,0} copy(f32[1,1,3584,7168]{1,0,2,3} %add.204), metadata={op_name="tuple.79"}
}

%fused_computation.424 (param_0.1076: f32[16,7,7,3584], param_1.1460: f32[3584], param_2.547: f32[3584], param_3.355: f32[3584], param_4.336: f32[16,7,7,3584], param_5.332: f32[3584]) -> (f32[16,3584], f32[16,3584], f32[16,3584]) {
  %param_4.336 = f32[16,7,7,3584]{2,1,3,0} parameter(4)
  %param_5.332 = f32[3584]{0} parameter(5)
  %constant_1089 = f32[] constant(0.00127551018)
  %broadcast.989 = f32[3584]{0} broadcast(f32[] %constant_1089), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1183 = f32[3584]{0} multiply(f32[3584]{0} %param_5.332, f32[3584]{0} %broadcast.989), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.988 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1183), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.84 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_4.336, f32[16,7,7,3584]{2,1,3,0} %broadcast.988), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.355 = f32[3584]{0} parameter(3)
  %constant_806 = f32[] constant(0)
  %broadcast.987 = f32[3584]{0} broadcast(f32[] %constant_806), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.108 = f32[3584]{0} maximum(f32[3584]{0} %param_3.355, f32[3584]{0} %broadcast.987), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1087 = f32[] constant(1e-05)
  %broadcast.986 = f32[3584]{0} broadcast(f32[] %constant_1087), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.301 = f32[3584]{0} add(f32[3584]{0} %maximum.108, f32[3584]{0} %broadcast.986), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.960 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.301), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.133 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.960), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.547 = f32[3584]{0} parameter(2)
  %bitcast.959 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_2.547), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1182 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.133, f32[1,1,1,3584]{3,2,1,0} %bitcast.959), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.958 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1182), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.985 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.958), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1181 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.84, f32[16,7,7,3584]{2,1,3,0} %broadcast.985), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1460 = f32[3584]{0} parameter(1)
  %broadcast.984 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_1.1460), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.300 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1181, f32[16,7,7,3584]{2,1,3,0} %broadcast.984), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.983 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_806), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %compare.161 = pred[16,7,7,3584]{2,1,3,0} compare(f32[16,7,7,3584]{2,1,3,0} %add.300, f32[16,7,7,3584]{2,1,3,0} %broadcast.983), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_0.1076 = f32[16,7,7,3584]{2,1,3,0} parameter(0)
  %select.161 = f32[16,7,7,3584]{2,1,3,0} select(pred[16,7,7,3584]{2,1,3,0} %compare.161, f32[16,7,7,3584]{2,1,3,0} %param_0.1076, f32[16,7,7,3584]{2,1,3,0} %broadcast.983), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %transpose.63 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %select.161), dimensions={0,3,1,2}
  %bitcast.762 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.63), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %reduce.806 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.762, f32[] %constant_806), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1199.clone.1 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %select.161, f32[16,7,7,3584]{2,1,3,0} %broadcast.985), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.48.clone.1 = f32[16,7,7,3584]{2,1,3,0} negate(f32[16,7,7,3584]{2,1,3,0} %multiply.1199.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.64 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %negate.48.clone.1), dimensions={0,3,1,2}
  %bitcast.771.clone.1 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.64), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.812.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.771.clone.1, f32[] %constant_806), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.669.clone.1 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.84, f32[16,7,7,3584]{2,1,3,0} %select.161), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.65 = f32[16,3584,7,7]{3,2,1,0} transpose(f32[16,7,7,3584]{2,1,3,0} %multiply.669.clone.1), dimensions={0,3,1,2}
  %bitcast.773.clone.1 = f32[16,3584,49]{2,1,0} bitcast(f32[16,3584,7,7]{3,2,1,0} %transpose.65), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.814.clone.1 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %bitcast.773.clone.1, f32[] %constant_806), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.93 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.806, f32[16,3584]{1,0} %reduce.812.clone.1, f32[16,3584]{1,0} %reduce.814.clone.1)
}

%fused_computation.426 (param_0.754: f32[3,3,1792,3584], param_1.1104: f32[3,3,1792,3584]) -> f32[3,3,1792,3584] {
  %param_1.1104 = f32[3,3,1792,3584]{3,2,1,0} parameter(1)
  %copy.171 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %param_1.1104), metadata={op_name="2$start"}
  %param_0.754 = f32[3,3,1792,3584]{1,0,2,3} parameter(0)
  %add.207 = f32[3,3,1792,3584]{1,0,2,3} add(f32[3,3,1792,3584]{1,0,2,3} %copy.171, f32[3,3,1792,3584]{1,0,2,3} %param_0.754), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  ROOT %copy.170 = f32[3,3,1792,3584]{3,2,1,0} copy(f32[3,3,1792,3584]{1,0,2,3} %add.207), metadata={op_name="tuple.79"}
}

%fused_computation.428 (param_0.1087: f32[16,7,7,1792], param_1.1478: f32[1792], param_2.572: f32[1792], param_3.386: f32[1792], param_4.370: f32[16,7,7,1792], param_5.375: f32[1792]) -> (f32[16,1792], f32[16,1792], f32[16,1792]) {
  %param_4.370 = f32[16,7,7,1792]{2,1,3,0} parameter(4)
  %param_5.375 = f32[1792]{0} parameter(5)
  %constant_1142 = f32[] constant(0.00127551018)
  %broadcast.1071 = f32[1792]{0} broadcast(f32[] %constant_1142), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1221 = f32[1792]{0} multiply(f32[1792]{0} %param_5.375, f32[1792]{0} %broadcast.1071), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1070 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1221), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.94 = f32[16,7,7,1792]{2,1,3,0} subtract(f32[16,7,7,1792]{2,1,3,0} %param_4.370, f32[16,7,7,1792]{2,1,3,0} %broadcast.1070), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.386 = f32[1792]{0} parameter(3)
  %constant_808 = f32[] constant(0)
  %broadcast.1069 = f32[1792]{0} broadcast(f32[] %constant_808), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.122 = f32[1792]{0} maximum(f32[1792]{0} %param_3.386, f32[1792]{0} %broadcast.1069), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1140 = f32[] constant(1e-05)
  %broadcast.1068 = f32[1792]{0} broadcast(f32[] %constant_1140), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.325 = f32[1792]{0} add(f32[1792]{0} %maximum.122, f32[1792]{0} %broadcast.1068), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1002 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.325), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.147 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1002), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.572 = f32[1792]{0} parameter(2)
  %bitcast.1001 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_2.572), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1220 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.147, f32[1,1,1,1792]{3,2,1,0} %bitcast.1001), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1000 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1220), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1067 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1000), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1219 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.94, f32[16,7,7,1792]{2,1,3,0} %broadcast.1067), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1478 = f32[1792]{0} parameter(1)
  %broadcast.1066 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_1.1478), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.324 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.1219, f32[16,7,7,1792]{2,1,3,0} %broadcast.1066), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1065 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[] %constant_808), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.171 = pred[16,7,7,1792]{2,1,3,0} compare(f32[16,7,7,1792]{2,1,3,0} %add.324, f32[16,7,7,1792]{2,1,3,0} %broadcast.1065), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_0.1087 = f32[16,7,7,1792]{2,1,3,0} parameter(0)
  %select.171 = f32[16,7,7,1792]{2,1,3,0} select(pred[16,7,7,1792]{2,1,3,0} %compare.171, f32[16,7,7,1792]{2,1,3,0} %param_0.1087, f32[16,7,7,1792]{2,1,3,0} %broadcast.1065), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %transpose.66 = f32[16,1792,7,7]{3,2,1,0} transpose(f32[16,7,7,1792]{2,1,3,0} %select.171), dimensions={0,3,1,2}
  %bitcast.764 = f32[16,1792,49]{2,1,0} bitcast(f32[16,1792,7,7]{3,2,1,0} %transpose.66), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %reduce.808 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %bitcast.764, f32[] %constant_808), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.1237.clone.1 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %select.171, f32[16,7,7,1792]{2,1,3,0} %broadcast.1067), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.46.clone.1 = f32[16,7,7,1792]{2,1,3,0} negate(f32[16,7,7,1792]{2,1,3,0} %multiply.1237.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.67 = f32[16,1792,7,7]{3,2,1,0} transpose(f32[16,7,7,1792]{2,1,3,0} %negate.46.clone.1), dimensions={0,3,1,2}
  %bitcast.767.clone.1 = f32[16,1792,49]{2,1,0} bitcast(f32[16,1792,7,7]{3,2,1,0} %transpose.67), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.809.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %bitcast.767.clone.1, f32[] %constant_808), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.658.clone.1 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.94, f32[16,7,7,1792]{2,1,3,0} %select.171), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.68 = f32[16,1792,7,7]{3,2,1,0} transpose(f32[16,7,7,1792]{2,1,3,0} %multiply.658.clone.1), dimensions={0,3,1,2}
  %bitcast.769.clone.1 = f32[16,1792,49]{2,1,0} bitcast(f32[16,1792,7,7]{3,2,1,0} %transpose.68), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.811.clone.1 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %bitcast.769.clone.1, f32[] %constant_808), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.91 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.808, f32[16,1792]{1,0} %reduce.809.clone.1, f32[16,1792]{1,0} %reduce.811.clone.1)
}

%fused_computation.430 (param_0.761: f32[1,1,7168,1792], param_1.1113: f32[1,1,7168,1792]) -> f32[1,1,7168,1792] {
  %param_1.1113 = f32[1,1,7168,1792]{3,2,1,0} parameter(1)
  %copy.173 = f32[1,1,7168,1792]{1,0,2,3} copy(f32[1,1,7168,1792]{3,2,1,0} %param_1.1113), metadata={op_name="2$start"}
  %param_0.761 = f32[1,1,7168,1792]{1,0,2,3} parameter(0)
  %add.210 = f32[1,1,7168,1792]{1,0,2,3} add(f32[1,1,7168,1792]{1,0,2,3} %copy.173, f32[1,1,7168,1792]{1,0,2,3} %param_0.761), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  ROOT %copy.172 = f32[1,1,7168,1792]{3,2,1,0} copy(f32[1,1,7168,1792]{1,0,2,3} %add.210), metadata={op_name="tuple.79"}
}

%fused_computation.431 (param_0.764: f32[1792], param_1.1119: f32[1792], param_2.574: f32[16,7,7,1792], param_3.388: f32[1792], param_4.372: f32[1,1,1,1792], param_5.377: f32[1792], param_6.318: f32[16,7,7,1792], param_7.374: f32[1792]) -> f32[16,7,7,1792] {
  %param_2.574 = f32[16,7,7,1792]{2,1,3,0} parameter(2)
  %param_1.1119 = f32[1792]{0} parameter(1)
  %constant_812 = f32[] constant(0.00127551018)
  %broadcast.1202 = f32[1792]{0} broadcast(f32[] %constant_812), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1231 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1119, f32[1792]{0} %broadcast.1202), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1200 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.1231), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.96 = f32[16,7,7,1792]{2,1,3,0} subtract(f32[16,7,7,1792]{2,1,3,0} %param_2.574, f32[16,7,7,1792]{2,1,3,0} %broadcast.1200), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.388 = f32[1792]{0} parameter(3)
  %constant_813 = f32[] constant(0)
  %broadcast.1198 = f32[1792]{0} broadcast(f32[] %constant_813), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.126 = f32[1792]{0} maximum(f32[1792]{0} %param_3.388, f32[1792]{0} %broadcast.1198), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_906 = f32[] constant(1e-05)
  %broadcast.1196 = f32[1792]{0} broadcast(f32[] %constant_906), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.331 = f32[1792]{0} add(f32[1792]{0} %maximum.126, f32[1792]{0} %broadcast.1196), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.1014 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.331), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.151 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.1014), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.377 = f32[1792]{0} parameter(5)
  %bitcast.1013 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_5.377), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1230 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.151, f32[1,1,1,1792]{3,2,1,0} %bitcast.1013), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.1012 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.1230), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1194 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.1012), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1229 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.96, f32[16,7,7,1792]{2,1,3,0} %broadcast.1194), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.374 = f32[1792]{0} parameter(7)
  %broadcast.1192 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_7.374), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.330 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.1229, f32[16,7,7,1792]{2,1,3,0} %broadcast.1192), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1190 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[] %constant_813), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %compare.173 = pred[16,7,7,1792]{2,1,3,0} compare(f32[16,7,7,1792]{2,1,3,0} %add.330, f32[16,7,7,1792]{2,1,3,0} %broadcast.1190), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %param_6.318 = f32[16,7,7,1792]{2,1,3,0} parameter(6)
  %select.173 = f32[16,7,7,1792]{2,1,3,0} select(pred[16,7,7,1792]{2,1,3,0} %compare.173, f32[16,7,7,1792]{2,1,3,0} %param_6.318, f32[16,7,7,1792]{2,1,3,0} %broadcast.1190), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %multiply.1227 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %select.173, f32[16,7,7,1792]{2,1,3,0} %broadcast.1194), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.372 = f32[1,1,1,1792]{3,2,1,0} parameter(4)
  %multiply.657 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %param_4.372, f32[1,1,1,1792]{3,2,1,0} %bitcast.1013), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.46 = f32[1,1,1,1792]{3,2,1,0} divide(f32[1,1,1,1792]{3,2,1,0} %rsqrt.151, f32[1,1,1,1792]{3,2,1,0} %bitcast.1014), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_809 = f32[] constant(-0.5)
  %broadcast.679 = f32[1,1,1,1792]{3,2,1,0} broadcast(f32[] %constant_809), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.656 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %divide.46, f32[1,1,1,1792]{3,2,1,0} %broadcast.679), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.655 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %multiply.657, f32[1,1,1,1792]{3,2,1,0} %multiply.656), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.766 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.655), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.67 = pred[1792]{0} compare(f32[1792]{0} %param_3.388, f32[1792]{0} %maximum.126), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_814 = f32[] constant(1)
  %broadcast.678 = f32[1792]{0} broadcast(f32[] %constant_814), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(1792,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.67 = f32[1792]{0} select(pred[1792]{0} %compare.67, f32[1792]{0} %broadcast.678, f32[1792]{0} %broadcast.1198), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.66 = pred[1792]{0} compare(f32[1792]{0} %broadcast.1198, f32[1792]{0} %maximum.126), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_810 = f32[] constant(2)
  %broadcast.677 = f32[1792]{0} broadcast(f32[] %constant_810), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.66 = f32[1792]{0} select(pred[1792]{0} %compare.66, f32[1792]{0} %broadcast.677, f32[1792]{0} %broadcast.678), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.45 = f32[1792]{0} divide(f32[1792]{0} %select.67, f32[1792]{0} %select.66), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.654 = f32[1792]{0} multiply(f32[1792]{0} %bitcast.766, f32[1792]{0} %divide.45), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_811 = f32[] constant(0.00255102036)
  %broadcast.676 = f32[1792]{0} broadcast(f32[] %constant_811), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.653 = f32[1792]{0} multiply(f32[1792]{0} %multiply.654, f32[1792]{0} %broadcast.676), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.675 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.653), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.652 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %param_2.574, f32[16,7,7,1792]{2,1,3,0} %broadcast.675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.213 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.1227, f32[16,7,7,1792]{2,1,3,0} %multiply.652), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.764 = f32[1792]{0} parameter(0)
  %negate.45 = f32[1792]{0} negate(f32[1792]{0} %multiply.654), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.651 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1119, f32[1792]{0} %broadcast.676), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.650 = f32[1792]{0} multiply(f32[1792]{0} %negate.45, f32[1792]{0} %multiply.651), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.212 = f32[1792]{0} add(f32[1792]{0} %param_0.764, f32[1792]{0} %multiply.650), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.649 = f32[1792]{0} multiply(f32[1792]{0} %add.212, f32[1792]{0} %broadcast.1202), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.674 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.649), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/broadcast_in_dim[shape=(16, 7, 7, 1792) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.211 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %add.213, f32[16,7,7,1792]{2,1,3,0} %broadcast.674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.433 (param_0.768: f32[16,1792]) -> f32[1,1,1,1792] {
  %param_0.768 = f32[16,1792]{1,0} parameter(0)
  %constant_815 = f32[] constant(0)
  %reduce.810 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.768, f32[] %constant_815), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.768 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %reduce.810), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.437 (param_0.776: f32[3584], param_1.1137: f32[3584], param_2.549: f32[16,7,7,3584], param_3.357: f32[3584], param_4.338: f32[1,1,1,3584], param_5.334: f32[3584], param_6.293: f32[16,7,7,3584], param_7.356: f32[3584]) -> f32[16,7,7,3584] {
  %param_2.549 = f32[16,7,7,3584]{2,1,3,0} parameter(2)
  %param_1.1137 = f32[3584]{0} parameter(1)
  %constant_822 = f32[] constant(0.00127551018)
  %broadcast.1009 = f32[3584]{0} broadcast(f32[] %constant_822), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.1193 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1137, f32[3584]{0} %broadcast.1009), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.1008 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.1193), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.86 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_2.549, f32[16,7,7,3584]{2,1,3,0} %broadcast.1008), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.357 = f32[3584]{0} parameter(3)
  %constant_823 = f32[] constant(0)
  %broadcast.1007 = f32[3584]{0} broadcast(f32[] %constant_823), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.112 = f32[3584]{0} maximum(f32[3584]{0} %param_3.357, f32[3584]{0} %broadcast.1007), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_963 = f32[] constant(1e-05)
  %broadcast.1006 = f32[3584]{0} broadcast(f32[] %constant_963), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.307 = f32[3584]{0} add(f32[3584]{0} %maximum.112, f32[3584]{0} %broadcast.1006), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.972 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.307), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.137 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.972), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.334 = f32[3584]{0} parameter(5)
  %bitcast.971 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_5.334), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1192 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.137, f32[1,1,1,3584]{3,2,1,0} %bitcast.971), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.970 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.1192), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.1005 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.970), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1191 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.86, f32[16,7,7,3584]{2,1,3,0} %broadcast.1005), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7.356 = f32[3584]{0} parameter(7)
  %broadcast.1004 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_7.356), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.306 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1191, f32[16,7,7,3584]{2,1,3,0} %broadcast.1004), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.1003 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_823), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %compare.163 = pred[16,7,7,3584]{2,1,3,0} compare(f32[16,7,7,3584]{2,1,3,0} %add.306, f32[16,7,7,3584]{2,1,3,0} %broadcast.1003), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %param_6.293 = f32[16,7,7,3584]{2,1,3,0} parameter(6)
  %select.163 = f32[16,7,7,3584]{2,1,3,0} select(pred[16,7,7,3584]{2,1,3,0} %compare.163, f32[16,7,7,3584]{2,1,3,0} %param_6.293, f32[16,7,7,3584]{2,1,3,0} %broadcast.1003), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %multiply.1189 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %select.163, f32[16,7,7,3584]{2,1,3,0} %broadcast.1005), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_4.338 = f32[1,1,1,3584]{3,2,1,0} parameter(4)
  %multiply.668 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %param_4.338, f32[1,1,1,3584]{3,2,1,0} %bitcast.971), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.48 = f32[1,1,1,3584]{3,2,1,0} divide(f32[1,1,1,3584]{3,2,1,0} %rsqrt.137, f32[1,1,1,3584]{3,2,1,0} %bitcast.972), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_819 = f32[] constant(-0.5)
  %broadcast.689 = f32[1,1,1,3584]{3,2,1,0} broadcast(f32[] %constant_819), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.667 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %divide.48, f32[1,1,1,3584]{3,2,1,0} %broadcast.689), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.666 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %multiply.668, f32[1,1,1,3584]{3,2,1,0} %multiply.667), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.770 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.666), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.70 = pred[3584]{0} compare(f32[3584]{0} %param_3.357, f32[3584]{0} %maximum.112), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_824 = f32[] constant(1)
  %broadcast.688 = f32[3584]{0} broadcast(f32[] %constant_824), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(3584,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.70 = f32[3584]{0} select(pred[3584]{0} %compare.70, f32[3584]{0} %broadcast.688, f32[3584]{0} %broadcast.1007), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.69 = pred[3584]{0} compare(f32[3584]{0} %broadcast.1007, f32[3584]{0} %maximum.112), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_820 = f32[] constant(2)
  %broadcast.687 = f32[3584]{0} broadcast(f32[] %constant_820), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.69 = f32[3584]{0} select(pred[3584]{0} %compare.69, f32[3584]{0} %broadcast.687, f32[3584]{0} %broadcast.688), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.47 = f32[3584]{0} divide(f32[3584]{0} %select.70, f32[3584]{0} %select.69), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.665 = f32[3584]{0} multiply(f32[3584]{0} %bitcast.770, f32[3584]{0} %divide.47), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_821 = f32[] constant(0.00255102036)
  %broadcast.686 = f32[3584]{0} broadcast(f32[] %constant_821), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.664 = f32[3584]{0} multiply(f32[3584]{0} %multiply.665, f32[3584]{0} %broadcast.686), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.685 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.664), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.663 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %param_2.549, f32[16,7,7,3584]{2,1,3,0} %broadcast.685), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.216 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.1189, f32[16,7,7,3584]{2,1,3,0} %multiply.663), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.776 = f32[3584]{0} parameter(0)
  %negate.47 = f32[3584]{0} negate(f32[3584]{0} %multiply.665), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.662 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1137, f32[3584]{0} %broadcast.686), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.661 = f32[3584]{0} multiply(f32[3584]{0} %negate.47, f32[3584]{0} %multiply.662), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.215 = f32[3584]{0} add(f32[3584]{0} %param_0.776, f32[3584]{0} %multiply.661), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.660 = f32[3584]{0} multiply(f32[3584]{0} %add.215, f32[3584]{0} %broadcast.1009), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.684 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.660), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/broadcast_in_dim[shape=(16, 7, 7, 3584) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.214 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %add.216, f32[16,7,7,3584]{2,1,3,0} %broadcast.684), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.439 (param_0.780: f32[16,3584]) -> f32[1,1,1,3584] {
  %param_0.780 = f32[16,3584]{1,0} parameter(0)
  %constant_825 = f32[] constant(0)
  %reduce.813 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.780, f32[] %constant_825), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.772 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %reduce.813), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.443 (param_0.788: f32[7168], param_1.1155: f32[7168], param_2.526: f32[16,7,7,7168], param_3.332: f32[7168], param_4.312: f32[1,1,1,7168], param_5.304: f32[7168], param_6.273: f32[16,7,7,7168]) -> f32[16,7,7,7168] {
  %param_6.273 = f32[16,7,7,7168]{2,1,3,0} parameter(6)
  %param_3.332 = f32[7168]{0} parameter(3)
  %constant_833 = f32[] constant(0)
  %broadcast.941 = f32[7168]{0} broadcast(f32[] %constant_833), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.100 = f32[7168]{0} maximum(f32[7168]{0} %param_3.332, f32[7168]{0} %broadcast.941), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1020 = f32[] constant(1e-05)
  %broadcast.940 = f32[7168]{0} broadcast(f32[] %constant_1020), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.287 = f32[7168]{0} add(f32[7168]{0} %maximum.100, f32[7168]{0} %broadcast.940), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.936 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.287), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.125 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.936), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5.304 = f32[7168]{0} parameter(5)
  %bitcast.935 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_5.304), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1161 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.125, f32[1,1,1,7168]{3,2,1,0} %bitcast.935), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.934 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1161), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.939 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.934), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1160 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_6.273, f32[16,7,7,7168]{2,1,3,0} %broadcast.939), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.526 = f32[16,7,7,7168]{2,1,3,0} parameter(2)
  %param_4.312 = f32[1,1,1,7168]{3,2,1,0} parameter(4)
  %multiply.679 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %param_4.312, f32[1,1,1,7168]{3,2,1,0} %bitcast.935), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %divide.50 = f32[1,1,1,7168]{3,2,1,0} divide(f32[1,1,1,7168]{3,2,1,0} %rsqrt.125, f32[1,1,1,7168]{3,2,1,0} %bitcast.936), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %constant_829 = f32[] constant(-0.5)
  %broadcast.699 = f32[1,1,1,7168]{3,2,1,0} broadcast(f32[] %constant_829), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.678 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %divide.50, f32[1,1,1,7168]{3,2,1,0} %broadcast.699), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %multiply.677 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %multiply.679, f32[1,1,1,7168]{3,2,1,0} %multiply.678), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.774 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.677), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reshape[new_sizes=(7168,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=132}
  %compare.73 = pred[7168]{0} compare(f32[7168]{0} %param_3.332, f32[7168]{0} %maximum.100), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_834 = f32[] constant(1)
  %broadcast.698 = f32[7168]{0} broadcast(f32[] %constant_834), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/broadcast_in_dim[shape=(7168,) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %select.73 = f32[7168]{0} select(pred[7168]{0} %compare.73, f32[7168]{0} %broadcast.698, f32[7168]{0} %broadcast.941), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %compare.72 = pred[7168]{0} compare(f32[7168]{0} %broadcast.941, f32[7168]{0} %maximum.100), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_830 = f32[] constant(2)
  %broadcast.697 = f32[7168]{0} broadcast(f32[] %constant_830), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %select.72 = f32[7168]{0} select(pred[7168]{0} %compare.72, f32[7168]{0} %broadcast.697, f32[7168]{0} %broadcast.698), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %divide.49 = f32[7168]{0} divide(f32[7168]{0} %select.73, f32[7168]{0} %select.72), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %multiply.676 = f32[7168]{0} multiply(f32[7168]{0} %bitcast.774, f32[7168]{0} %divide.49), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_831 = f32[] constant(0.00255102036)
  %broadcast.696 = f32[7168]{0} broadcast(f32[] %constant_831), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.675 = f32[7168]{0} multiply(f32[7168]{0} %multiply.676, f32[7168]{0} %broadcast.696), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %broadcast.695 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.675), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.674 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_2.526, f32[16,7,7,7168]{2,1,3,0} %broadcast.695), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.219 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.1160, f32[16,7,7,7168]{2,1,3,0} %multiply.674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %param_0.788 = f32[7168]{0} parameter(0)
  %negate.49 = f32[7168]{0} negate(f32[7168]{0} %multiply.676), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %param_1.1155 = f32[7168]{0} parameter(1)
  %multiply.673 = f32[7168]{0} multiply(f32[7168]{0} %param_1.1155, f32[7168]{0} %broadcast.696), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %multiply.672 = f32[7168]{0} multiply(f32[7168]{0} %negate.49, f32[7168]{0} %multiply.673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %add.218 = f32[7168]{0} add(f32[7168]{0} %param_0.788, f32[7168]{0} %multiply.672), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_832 = f32[] constant(0.00127551018)
  %broadcast.701 = f32[7168]{0} broadcast(f32[] %constant_832), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.671 = f32[7168]{0} multiply(f32[7168]{0} %add.218, f32[7168]{0} %broadcast.701), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.694 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.671), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/broadcast_in_dim[shape=(16, 7, 7, 7168) broadcast_dimensions=(3,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  ROOT %add.217 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %add.219, f32[16,7,7,7168]{2,1,3,0} %broadcast.694), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
}

%fused_computation.444 (param_0.1069: f32[16,7,7,7168], param_1.1450: f32[7168], param_2.533: f32[7168], param_3.1451: f32[16,7,7,7168], param_4.1286: f32[7168]) -> (f32[16,7168], f32[16,7168], f32[16,7168]) {
  %param_0.1069 = f32[16,7,7,7168]{2,1,3,0} parameter(0)
  %param_2.533 = f32[7168]{0} parameter(2)
  %constant_837 = f32[] constant(0)
  %broadcast.947 = f32[7168]{0} broadcast(f32[] %constant_837), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.102 = f32[7168]{0} maximum(f32[7168]{0} %param_2.533, f32[7168]{0} %broadcast.947), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1061 = f32[] constant(1e-05)
  %broadcast.946 = f32[7168]{0} broadcast(f32[] %constant_1061), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.289 = f32[7168]{0} add(f32[7168]{0} %maximum.102, f32[7168]{0} %broadcast.946), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.942 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.289), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.127 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.942), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1450 = f32[7168]{0} parameter(1)
  %bitcast.941 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_1.1450), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.1165 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.127, f32[1,1,1,7168]{3,2,1,0} %bitcast.941), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.940 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.1165), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.945 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.940), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.1164 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %param_0.1069, f32[16,7,7,7168]{2,1,3,0} %broadcast.945), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %negate.50 = f32[16,7,7,7168]{2,1,3,0} negate(f32[16,7,7,7168]{2,1,3,0} %multiply.1164), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.69 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %negate.50), dimensions={0,3,1,2}
  %bitcast.775 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.69), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %reduce.815 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.775, f32[] %constant_837), dimensions={2}, to_apply=%region_57.4114.2
  %param_3.1451 = f32[16,7,7,7168]{2,1,3,0} parameter(3)
  %param_4.1286 = f32[7168]{0} parameter(4)
  %constant_1005_clone_1 = f32[] constant(0.00127551018)
  %broadcast.883.clone.1 = f32[7168]{0} broadcast(f32[] %constant_1005_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.767.clone.1 = f32[7168]{0} multiply(f32[7168]{0} %param_4.1286, f32[7168]{0} %broadcast.883.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.882.clone.1 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.767.clone.1), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.70.clone.1 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_3.1451, f32[16,7,7,7168]{2,1,3,0} %broadcast.882.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.680.clone.1 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.70.clone.1, f32[16,7,7,7168]{2,1,3,0} %param_0.1069), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %transpose.70 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %multiply.680.clone.1), dimensions={0,3,1,2}
  %bitcast.777.clone.1 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.70), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.817.clone.1 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.777.clone.1, f32[] %constant_837), dimensions={2}, to_apply=%region_57.4114.2
  %transpose.71 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %param_0.1069), dimensions={0,3,1,2}
  %bitcast.760.clone.1 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.71), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %reduce.804.clone.1 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.760.clone.1, f32[] %constant_837), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.95 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.815, f32[16,7168]{1,0} %reduce.817.clone.1, f32[16,7168]{1,0} %reduce.804.clone.1)
}

%fused_computation.445 (param_0.792: f32[16,7168]) -> f32[1,1,1,7168] {
  %param_0.792 = f32[16,7168]{1,0} parameter(0)
  %constant_835 = f32[] constant(0)
  %reduce.816 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_0.792, f32[] %constant_835), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  ROOT %bitcast.776 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %reduce.816), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
}

%fused_computation.448 (param_0.798: f32[16,7168], param_1.1433: f32[16,7,7,7168], param_2.516: f32[7168], param_3.323: f32[7168], param_4.301: f32[7168], param_5.293: f32[16,7,7,7168], param_6.270: f32[7168]) -> f32[16,7,7,7168] {
  %param_1.1433 = f32[16,7,7,7168]{2,1,3,0} parameter(1)
  %param_5.293 = f32[16,7,7,7168]{2,1,3,0} parameter(5)
  %param_6.270 = f32[7168]{0} parameter(6)
  %constant_1043 = f32[] constant(0.00127551018)
  %broadcast.919 = f32[7168]{0} broadcast(f32[] %constant_1043), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.777 = f32[7168]{0} multiply(f32[7168]{0} %param_6.270, f32[7168]{0} %broadcast.919), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.918 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.777), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.72 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_5.293, f32[16,7,7,7168]{2,1,3,0} %broadcast.918), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_4.301 = f32[7168]{0} parameter(4)
  %constant_838 = f32[] constant(0)
  %broadcast.917 = f32[7168]{0} broadcast(f32[] %constant_838), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.96 = f32[7168]{0} maximum(f32[7168]{0} %param_4.301, f32[7168]{0} %broadcast.917), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1041 = f32[] constant(1e-05)
  %broadcast.916 = f32[7168]{0} broadcast(f32[] %constant_1041), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.279 = f32[7168]{0} add(f32[7168]{0} %maximum.96, f32[7168]{0} %broadcast.916), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.924 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.279), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.121 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.924), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_3.323 = f32[7168]{0} parameter(3)
  %bitcast.923 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_3.323), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.776 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.121, f32[1,1,1,7168]{3,2,1,0} %bitcast.923), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.922 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.776), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.915 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.922), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.775 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.72, f32[16,7,7,7168]{2,1,3,0} %broadcast.915), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_2.516 = f32[7168]{0} parameter(2)
  %broadcast.914 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_2.516), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.278 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.775, f32[16,7,7,7168]{2,1,3,0} %broadcast.914), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.277 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %param_1.1433, f32[16,7,7,7168]{2,1,3,0} %add.278), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.704 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[] %constant_838), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %compare.74 = pred[16,7,7,7168]{2,1,3,0} compare(f32[16,7,7,7168]{2,1,3,0} %add.277, f32[16,7,7,7168]{2,1,3,0} %broadcast.704), direction=GT, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/gt" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %param_0.798 = f32[16,7168]{1,0} parameter(0)
  %broadcast.703 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[16,7168]{1,0} %param_0.798), dimensions={0,3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/broadcast_in_dim[shape=(16, 7, 7, 7168) broadcast_dimensions=(0, 3)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
  ROOT %select.74 = f32[16,7,7,7168]{2,1,3,0} select(pred[16,7,7,7168]{2,1,3,0} %compare.74, f32[16,7,7,7168]{2,1,3,0} %broadcast.703, f32[16,7,7,7168]{2,1,3,0} %broadcast.704), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
}

%fused_computation.449 (param_0.1066: f32[16], param_1.1443: f32[16], param_2.524: f32[], param_3.331: s32[16], param_4.311: f32[16,1024], param_5.303: f32[16]) -> f32[16,1024] {
  %param_3.331 = s32[16]{0} parameter(3)
  %broadcast.751 = s32[16,1024]{1,0} broadcast(s32[16]{0} %param_3.331), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %iota.8 = s32[16,1024]{1,0} iota(), iota_dimension=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %compare.79 = pred[16,1024]{1,0} compare(s32[16,1024]{1,0} %broadcast.751, s32[16,1024]{1,0} %iota.8), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %constant_879 = f32[] constant(1)
  %broadcast.750 = f32[16,1024]{1,0} broadcast(f32[] %constant_879), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %constant_878 = f32[] constant(0)
  %broadcast.749 = f32[16,1024]{1,0} broadcast(f32[] %constant_878), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %select.79 = f32[16,1024]{1,0} select(pred[16,1024]{1,0} %compare.79, f32[16,1024]{1,0} %broadcast.750, f32[16,1024]{1,0} %broadcast.749), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %param_2.524 = f32[] parameter(2)
  %constant_877 = f32[] constant(0.0625)
  %multiply.711 = f32[] multiply(f32[] %param_2.524, f32[] %constant_877), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=113}
  %negate.108 = f32[] negate(f32[] %multiply.711), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %broadcast.748 = f32[16,1024]{1,0} broadcast(f32[] %negate.108), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=(0,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %multiply.710 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %select.79, f32[16,1024]{1,0} %broadcast.748), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %param_0.1066 = f32[16]{0} parameter(0)
  %param_1.1443 = f32[16]{0} parameter(1)
  %divide.51 = f32[16]{0} divide(f32[16]{0} %param_0.1066, f32[16]{0} %param_1.1443), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %broadcast.705 = f32[16,1024]{1,0} broadcast(f32[16]{0} %divide.51), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=(0,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %param_4.311 = f32[16,1024]{1,0} parameter(4)
  %param_5.303 = f32[16]{0} parameter(5)
  %broadcast.935 = f32[16,1024]{1,0} broadcast(f32[16]{0} %param_5.303), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %subtract.78 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %param_4.311, f32[16,1024]{1,0} %broadcast.935), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %exponential.5 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %subtract.78), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/exp" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %multiply.682 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %broadcast.705, f32[16,1024]{1,0} %exponential.5), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  ROOT %add.220 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.710, f32[16,1024]{1,0} %multiply.682), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
}

%fused_computation.451 (param_0.802: f32[16,7168]) -> f32[16,7168] {
  %param_0.802 = f32[16,7168]{1,0} parameter(0)
  %constant_163 = f32[] constant(0.0204081628)
  %broadcast.707 = f32[16,7168]{1,0} broadcast(f32[] %constant_163), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
  ROOT %multiply.683 = f32[16,7168]{1,0} multiply(f32[16,7168]{1,0} %param_0.802, f32[16,7168]{1,0} %broadcast.707), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
}

%fused_computation.452 (param_0.1061: f32[16,7,7,7168], param_1.1437: f32[7168], param_2.521: f32[7168], param_3.330: f32[7168], param_4.309: f32[16,7,7,7168], param_5.301: f32[7168]) -> f32[16,7168] {
  %param_0.1061 = f32[16,7,7,7168]{2,1,3,0} parameter(0)
  %param_4.309 = f32[16,7,7,7168]{2,1,3,0} parameter(4)
  %param_5.301 = f32[7168]{0} parameter(5)
  %constant_1050 = f32[] constant(0.00127551018)
  %broadcast.931 = f32[7168]{0} broadcast(f32[] %constant_1050), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.783 = f32[7168]{0} multiply(f32[7168]{0} %param_5.301, f32[7168]{0} %broadcast.931), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.930 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.783), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.74 = f32[16,7,7,7168]{2,1,3,0} subtract(f32[16,7,7,7168]{2,1,3,0} %param_4.309, f32[16,7,7,7168]{2,1,3,0} %broadcast.930), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_3.330 = f32[7168]{0} parameter(3)
  %constant_840 = f32[] constant(0)
  %broadcast.929 = f32[7168]{0} broadcast(f32[] %constant_840), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.98 = f32[7168]{0} maximum(f32[7168]{0} %param_3.330, f32[7168]{0} %broadcast.929), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_1048 = f32[] constant(1e-05)
  %broadcast.928 = f32[7168]{0} broadcast(f32[] %constant_1048), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.285 = f32[7168]{0} add(f32[7168]{0} %maximum.98, f32[7168]{0} %broadcast.928), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.930 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.285), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.123 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.930), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2.521 = f32[7168]{0} parameter(2)
  %bitcast.929 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %param_2.521), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.782 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.123, f32[1,1,1,7168]{3,2,1,0} %bitcast.929), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.928 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.782), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.927 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %bitcast.928), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.781 = f32[16,7,7,7168]{2,1,3,0} multiply(f32[16,7,7,7168]{2,1,3,0} %subtract.74, f32[16,7,7,7168]{2,1,3,0} %broadcast.927), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_1.1437 = f32[7168]{0} parameter(1)
  %broadcast.926 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %param_1.1437), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.284 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %multiply.781, f32[16,7,7,7168]{2,1,3,0} %broadcast.926), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.283 = f32[16,7,7,7168]{2,1,3,0} add(f32[16,7,7,7168]{2,1,3,0} %param_0.1061, f32[16,7,7,7168]{2,1,3,0} %add.284), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/add" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %broadcast.708 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[] %constant_840), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %maximum.39 = f32[16,7,7,7168]{2,1,3,0} maximum(f32[16,7,7,7168]{2,1,3,0} %add.283, f32[16,7,7,7168]{2,1,3,0} %broadcast.708), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %transpose.72 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %maximum.39), dimensions={0,3,1,2}
  %bitcast.778 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.72), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  ROOT %reduce.818 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %bitcast.778, f32[] %constant_840), dimensions={2}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/reduce_sum[axes=(1, 2)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
}

%fused_computation.459 (param_0.1047: f32[16,7168], param_1.1418: f32[7168]) -> f32[7168] {
  %param_0.1047 = f32[16,7168]{1,0} parameter(0)
  %constant_844 = f32[] constant(0)
  %reduce.820 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_0.1047, f32[] %constant_844), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_843 = f32[] constant(0.00127551018)
  %broadcast.717 = f32[7168]{0} broadcast(f32[] %constant_843), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.689 = f32[7168]{0} multiply(f32[7168]{0} %reduce.820, f32[7168]{0} %broadcast.717), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1418 = f32[7168]{0} parameter(1)
  %multiply.763 = f32[7168]{0} multiply(f32[7168]{0} %param_1.1418, f32[7168]{0} %broadcast.717), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.688 = f32[7168]{0} multiply(f32[7168]{0} %multiply.763, f32[7168]{0} %multiply.763), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.45 = f32[7168]{0} subtract(f32[7168]{0} %multiply.689, f32[7168]{0} %multiply.688), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.464 (param_0.1043: f32[3584], param_1.1413: f32[3584], param_2.485: f32[3584], param_3.299: f32[16,7,7,3584], param_4.279: f32[3584]) -> f32[16,7,7,3584] {
  %param_3.299 = f32[16,7,7,3584]{2,1,3,0} parameter(3)
  %param_4.279 = f32[3584]{0} parameter(4)
  %constant_986 = f32[] constant(0.00127551018)
  %broadcast.859 = f32[3584]{0} broadcast(f32[] %constant_986), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.753 = f32[3584]{0} multiply(f32[3584]{0} %param_4.279, f32[3584]{0} %broadcast.859), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.858 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.753), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.64 = f32[16,7,7,3584]{2,1,3,0} subtract(f32[16,7,7,3584]{2,1,3,0} %param_3.299, f32[16,7,7,3584]{2,1,3,0} %broadcast.858), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.485 = f32[3584]{0} parameter(2)
  %constant_848 = f32[] constant(0)
  %broadcast.857 = f32[3584]{0} broadcast(f32[] %constant_848), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.78 = f32[3584]{0} maximum(f32[3584]{0} %param_2.485, f32[3584]{0} %broadcast.857), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_984 = f32[] constant(1e-05)
  %broadcast.856 = f32[3584]{0} broadcast(f32[] %constant_984), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.259 = f32[3584]{0} add(f32[3584]{0} %maximum.78, f32[3584]{0} %broadcast.856), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.894 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.259), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.113 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.894), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1413 = f32[3584]{0} parameter(1)
  %bitcast.893 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %param_1.1413), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.752 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.113, f32[1,1,1,3584]{3,2,1,0} %bitcast.893), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.892 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.752), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.855 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %bitcast.892), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.751 = f32[16,7,7,3584]{2,1,3,0} multiply(f32[16,7,7,3584]{2,1,3,0} %subtract.64, f32[16,7,7,3584]{2,1,3,0} %broadcast.855), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1043 = f32[3584]{0} parameter(0)
  %broadcast.854 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[3584]{0} %param_0.1043), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.258 = f32[16,7,7,3584]{2,1,3,0} add(f32[16,7,7,3584]{2,1,3,0} %multiply.751, f32[16,7,7,3584]{2,1,3,0} %broadcast.854), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.720 = f32[16,7,7,3584]{2,1,3,0} broadcast(f32[] %constant_848), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  ROOT %maximum.41 = f32[16,7,7,3584]{2,1,3,0} maximum(f32[16,7,7,3584]{2,1,3,0} %add.258, f32[16,7,7,3584]{2,1,3,0} %broadcast.720), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
}

%fused_computation.469 (param_0.1029: f32[16,3584], param_1.1393: f32[3584]) -> f32[3584] {
  %param_0.1029 = f32[16,3584]{1,0} parameter(0)
  %constant_852 = f32[] constant(0)
  %reduce.823 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0.1029, f32[] %constant_852), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_851 = f32[] constant(0.00127551018)
  %broadcast.725 = f32[3584]{0} broadcast(f32[] %constant_851), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.695 = f32[3584]{0} multiply(f32[3584]{0} %reduce.823, f32[3584]{0} %broadcast.725), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1393 = f32[3584]{0} parameter(1)
  %multiply.739 = f32[3584]{0} multiply(f32[3584]{0} %param_1.1393, f32[3584]{0} %broadcast.725), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.694 = f32[3584]{0} multiply(f32[3584]{0} %multiply.739, f32[3584]{0} %multiply.739), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.47 = f32[3584]{0} subtract(f32[3584]{0} %multiply.695, f32[3584]{0} %multiply.694), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.474 (param_0.1025: f32[1792], param_1.1388: f32[1792], param_2.451: f32[1792], param_3.268: f32[16,7,7,1792], param_4.254: f32[1792]) -> f32[16,7,7,1792] {
  %param_3.268 = f32[16,7,7,1792]{2,1,3,0} parameter(3)
  %param_4.254 = f32[1792]{0} parameter(4)
  %constant_929 = f32[] constant(0.00127551018)
  %broadcast.799 = f32[1792]{0} broadcast(f32[] %constant_929), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.729 = f32[1792]{0} multiply(f32[1792]{0} %param_4.254, f32[1792]{0} %broadcast.799), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.798 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %multiply.729), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %subtract.56 = f32[16,7,7,1792]{2,1,3,0} subtract(f32[16,7,7,1792]{2,1,3,0} %param_3.268, f32[16,7,7,1792]{2,1,3,0} %broadcast.798), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_2.451 = f32[1792]{0} parameter(2)
  %constant_856 = f32[] constant(0)
  %broadcast.797 = f32[1792]{0} broadcast(f32[] %constant_856), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.60 = f32[1792]{0} maximum(f32[1792]{0} %param_2.451, f32[1792]{0} %broadcast.797), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_927 = f32[] constant(1e-05)
  %broadcast.796 = f32[1792]{0} broadcast(f32[] %constant_927), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.241 = f32[1792]{0} add(f32[1792]{0} %maximum.60, f32[1792]{0} %broadcast.796), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.864 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.241), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.105 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.864), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1.1388 = f32[1792]{0} parameter(1)
  %bitcast.863 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %param_1.1388), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %multiply.728 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.105, f32[1,1,1,1792]{3,2,1,0} %bitcast.863), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.862 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.728), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %broadcast.795 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %bitcast.862), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %multiply.727 = f32[16,7,7,1792]{2,1,3,0} multiply(f32[16,7,7,1792]{2,1,3,0} %subtract.56, f32[16,7,7,1792]{2,1,3,0} %broadcast.795), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_0.1025 = f32[1792]{0} parameter(0)
  %broadcast.794 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[1792]{0} %param_0.1025), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.240 = f32[16,7,7,1792]{2,1,3,0} add(f32[16,7,7,1792]{2,1,3,0} %multiply.727, f32[16,7,7,1792]{2,1,3,0} %broadcast.794), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %broadcast.728 = f32[16,7,7,1792]{2,1,3,0} broadcast(f32[] %constant_856), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  ROOT %maximum.43 = f32[16,7,7,1792]{2,1,3,0} maximum(f32[16,7,7,1792]{2,1,3,0} %add.240, f32[16,7,7,1792]{2,1,3,0} %broadcast.728), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
}

%fused_computation.479 (param_0.1011: f32[16,1792], param_1.1368: f32[1792]) -> f32[1792] {
  %param_0.1011 = f32[16,1792]{1,0} parameter(0)
  %constant_860 = f32[] constant(0)
  %reduce.826 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_0.1011, f32[] %constant_860), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %constant_859 = f32[] constant(0.00127551018)
  %broadcast.733 = f32[1792]{0} broadcast(f32[] %constant_859), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.701 = f32[1792]{0} multiply(f32[1792]{0} %reduce.826, f32[1792]{0} %broadcast.733), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=83}
  %param_1.1368 = f32[1792]{0} parameter(1)
  %multiply.715 = f32[1792]{0} multiply(f32[1792]{0} %param_1.1368, f32[1792]{0} %broadcast.733), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.700 = f32[1792]{0} multiply(f32[1792]{0} %multiply.715, f32[1792]{0} %multiply.715), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  ROOT %subtract.49 = f32[1792]{0} subtract(f32[1792]{0} %multiply.701, f32[1792]{0} %multiply.700), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
}

%fused_computation.484 (param_0.1621: f32[16,1024], param_1.2279: f32[16], param_2.1647: f32[], param_3.1458: s32[16]) -> (f32[16], f32[16]) {
  %param_0.1621 = f32[16,1024]{1,0} parameter(0)
  %param_1.2279 = f32[16]{0} parameter(1)
  %broadcast.933 = f32[16,1024]{1,0} broadcast(f32[16]{0} %param_1.2279), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %subtract.76 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %param_0.1621, f32[16,1024]{1,0} %broadcast.933), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %exponential.2 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %subtract.76), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/exp" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %constant_3086 = f32[] constant(0)
  %reduce.829 = f32[16]{0} reduce(f32[16,1024]{1,0} %exponential.2, f32[] %constant_3086), dimensions={1}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/reduce_sum[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %param_3.1458 = s32[16]{0} parameter(3)
  %broadcast.743.clone.1 = s32[16,1024]{1,0} broadcast(s32[16]{0} %param_3.1458), dimensions={0}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %iota.5.clone.1 = s32[16,1024]{1,0} iota(), iota_dimension=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %compare.77.clone.1 = pred[16,1024]{1,0} compare(s32[16,1024]{1,0} %broadcast.743.clone.1, s32[16,1024]{1,0} %iota.5.clone.1), direction=EQ, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/eq" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=102}
  %constant_872_clone_1 = f32[] constant(1)
  %broadcast.742.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_872_clone_1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %broadcast.741.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_3086), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=()]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %select.77.clone.1 = f32[16,1024]{1,0} select(pred[16,1024]{1,0} %compare.77.clone.1, f32[16,1024]{1,0} %broadcast.742.clone.1, f32[16,1024]{1,0} %broadcast.741.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/select_n" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/training/common_utils.py" source_line=103}
  %param_2.1647 = f32[] parameter(2)
  %constant_870_clone_1 = f32[] constant(0.0625)
  %multiply.707.clone.1 = f32[] multiply(f32[] %param_2.1647, f32[] %constant_870_clone_1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/trainer/wide_resnet_trainer.py" source_line=113}
  %negate.106.clone.1 = f32[] negate(f32[] %multiply.707.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %broadcast.740.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %negate.106.clone.1), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/broadcast_in_dim[shape=(16, 1024) broadcast_dimensions=(0,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %multiply.706.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %select.77.clone.1, f32[16,1024]{1,0} %broadcast.740.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %negate.51.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %multiply.706.clone.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/neg" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %reduce.819.clone.1 = f32[16]{0} reduce(f32[16,1024]{1,0} %negate.51.clone.1, f32[] %constant_3086), dimensions={1}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/reduce_sum[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  ROOT %tuple.101 = (f32[16]{0}, f32[16]{0}) tuple(f32[16]{0} %reduce.829, f32[16]{0} %reduce.819.clone.1)
}

%fused_computation.485 (param_0.1620: f32[7168], param_1.2261: f32[16,7168]) -> (f32[7168], f32[7168]) {
  %param_0.1620 = f32[7168]{0} parameter(0)
  %param_1.2261 = f32[16,7168]{1,0} parameter(1)
  %constant_3085 = f32[] constant(0)
  %reduce.830 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_1.2261, f32[] %constant_3085), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1241 = f32[7168]{0} add(f32[7168]{0} %param_0.1620, f32[7168]{0} %reduce.830), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  ROOT %tuple.68 = (f32[7168]{0}, f32[7168]{0}) tuple(f32[7168]{0} %add.1241, f32[7168]{0} %reduce.830)
}

%horizontally_fused_computation (param_0_0: f32[3584], param_0_1: f32[16,3584], param_1_0: f32[3584], param_1_1: f32[16,3584], param_2_0: f32[1792], param_2_1: f32[16,1792], param_3_0: f32[896], param_3_1: f32[16,896], param_4_0: f32[3584], param_4_1: f32[16,3584], param_5_0: f32[1792], param_5_1: f32[16,1792], param_6_0: f32[896], param_6_1: f32[16,896], param_7_0: f32[3584], param_7_1: f32[16,3584], param_8_0: f32[1792], param_8_1: f32[16,1792], param_9_0: f32[896], param_9_1: f32[16,896], param_10_0: f32[3584], param_10_1: f32[16,3584], param_11_0: f32[1792], param_11_1: f32[16,1792], param_12_0: f32[896], param_12_1: f32[16,896], param_13_0: f32[1792], param_13_1: f32[16,1792], param_14_0: f32[896], param_14_1: f32[16,896], param_15_0: f32[7168], param_15_1: f32[16,7168], param_16_0: f32[1792], param_16_1: f32[16,1792], param_17_0: f32[3584], param_17_1: f32[16,3584], param_18_0: f32[3584], param_18_1: f32[16,3584], param_19_0: f32[1024], param_19_1: f32[16,1024], param_20_0: f32[7168], param_20_1: f32[16,7168], param_21_0: f32[3584], param_21_1: f32[16,3584], param_22_0: f32[1792], param_22_1: f32[16,1792], param_23_0: f32[1792], param_23_1: f32[16,1792]) -> (f32[3584], f32[3584], f32[1792], f32[896], f32[3584], /*index=5*/f32[1792], f32[896], f32[3584], f32[1792], f32[896], /*index=10*/f32[3584], f32[1792], f32[896], f32[1792], f32[896], /*index=15*/f32[7168], f32[1792], f32[3584], f32[3584], f32[1024], /*index=20*/f32[7168], f32[3584], f32[1792], f32[1792]) {
  %param_0_0 = f32[3584]{0} parameter(0)
  %param_0_1 = f32[16,3584]{1,0} parameter(1)
  %constant_3087 = f32[] constant(0)
  %reduce.831 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_0_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1242 = f32[3584]{0} add(f32[3584]{0} %param_0_0, f32[3584]{0} %reduce.831), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %param_1_0 = f32[3584]{0} parameter(2)
  %param_1_1 = f32[16,3584]{1,0} parameter(3)
  %reduce.832 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_1_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1243 = f32[3584]{0} add(f32[3584]{0} %param_1_0, f32[3584]{0} %reduce.832), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %param_2_0 = f32[1792]{0} parameter(4)
  %param_2_1 = f32[16,1792]{1,0} parameter(5)
  %reduce.833 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_2_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1244 = f32[1792]{0} add(f32[1792]{0} %param_2_0, f32[1792]{0} %reduce.833), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %param_3_0 = f32[896]{0} parameter(6)
  %param_3_1 = f32[16,896]{1,0} parameter(7)
  %reduce.834 = f32[896]{0} reduce(f32[16,896]{1,0} %param_3_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1245 = f32[896]{0} add(f32[896]{0} %param_3_0, f32[896]{0} %reduce.834), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %param_4_0 = f32[3584]{0} parameter(8)
  %param_4_1 = f32[16,3584]{1,0} parameter(9)
  %reduce.835 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_4_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1246 = f32[3584]{0} add(f32[3584]{0} %param_4_0, f32[3584]{0} %reduce.835), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %param_5_0 = f32[1792]{0} parameter(10)
  %param_5_1 = f32[16,1792]{1,0} parameter(11)
  %reduce.836 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_5_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1247 = f32[1792]{0} add(f32[1792]{0} %param_5_0, f32[1792]{0} %reduce.836), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %param_6_0 = f32[896]{0} parameter(12)
  %param_6_1 = f32[16,896]{1,0} parameter(13)
  %reduce.837 = f32[896]{0} reduce(f32[16,896]{1,0} %param_6_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1248 = f32[896]{0} add(f32[896]{0} %param_6_0, f32[896]{0} %reduce.837), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %param_7_0 = f32[3584]{0} parameter(14)
  %param_7_1 = f32[16,3584]{1,0} parameter(15)
  %reduce.838 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_7_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1249 = f32[3584]{0} add(f32[3584]{0} %param_7_0, f32[3584]{0} %reduce.838), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %param_8_0 = f32[1792]{0} parameter(16)
  %param_8_1 = f32[16,1792]{1,0} parameter(17)
  %reduce.839 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_8_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1250 = f32[1792]{0} add(f32[1792]{0} %param_8_0, f32[1792]{0} %reduce.839), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %param_9_0 = f32[896]{0} parameter(18)
  %param_9_1 = f32[16,896]{1,0} parameter(19)
  %reduce.840 = f32[896]{0} reduce(f32[16,896]{1,0} %param_9_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1251 = f32[896]{0} add(f32[896]{0} %param_9_0, f32[896]{0} %reduce.840), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %param_10_0 = f32[3584]{0} parameter(20)
  %param_10_1 = f32[16,3584]{1,0} parameter(21)
  %reduce.841 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_10_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1252 = f32[3584]{0} add(f32[3584]{0} %param_10_0, f32[3584]{0} %reduce.841), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %param_11_0 = f32[1792]{0} parameter(22)
  %param_11_1 = f32[16,1792]{1,0} parameter(23)
  %reduce.842 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_11_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1253 = f32[1792]{0} add(f32[1792]{0} %param_11_0, f32[1792]{0} %reduce.842), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %param_12_0 = f32[896]{0} parameter(24)
  %param_12_1 = f32[16,896]{1,0} parameter(25)
  %reduce.843 = f32[896]{0} reduce(f32[16,896]{1,0} %param_12_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1254 = f32[896]{0} add(f32[896]{0} %param_12_0, f32[896]{0} %reduce.843), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %param_13_0 = f32[1792]{0} parameter(26)
  %param_13_1 = f32[16,1792]{1,0} parameter(27)
  %reduce.844 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_13_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1255 = f32[1792]{0} add(f32[1792]{0} %param_13_0, f32[1792]{0} %reduce.844), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %param_14_0 = f32[896]{0} parameter(28)
  %param_14_1 = f32[16,896]{1,0} parameter(29)
  %reduce.845 = f32[896]{0} reduce(f32[16,896]{1,0} %param_14_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1256 = f32[896]{0} add(f32[896]{0} %param_14_0, f32[896]{0} %reduce.845), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %param_15_0 = f32[7168]{0} parameter(30)
  %param_15_1 = f32[16,7168]{1,0} parameter(31)
  %reduce.846 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_15_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1257 = f32[7168]{0} add(f32[7168]{0} %param_15_0, f32[7168]{0} %reduce.846), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %param_16_0 = f32[1792]{0} parameter(32)
  %param_16_1 = f32[16,1792]{1,0} parameter(33)
  %reduce.847 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_16_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1258 = f32[1792]{0} add(f32[1792]{0} %param_16_0, f32[1792]{0} %reduce.847), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %param_17_0 = f32[3584]{0} parameter(34)
  %param_17_1 = f32[16,3584]{1,0} parameter(35)
  %reduce.848 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_17_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1259 = f32[3584]{0} add(f32[3584]{0} %param_17_0, f32[3584]{0} %reduce.848), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %param_18_0 = f32[3584]{0} parameter(36)
  %param_18_1 = f32[16,3584]{1,0} parameter(37)
  %reduce.849 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_18_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1260 = f32[3584]{0} add(f32[3584]{0} %param_18_0, f32[3584]{0} %reduce.849), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %param_19_0 = f32[1024]{0} parameter(38)
  %param_19_1 = f32[16,1024]{1,0} parameter(39)
  %reduce.850 = f32[1024]{0} reduce(f32[16,1024]{1,0} %param_19_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/Dense_0/reduce_sum[axes=(0,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=200}
  %add.1261 = f32[1024]{0} add(f32[1024]{0} %param_19_0, f32[1024]{0} %reduce.850), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %param_20_0 = f32[7168]{0} parameter(40)
  %param_20_1 = f32[16,7168]{1,0} parameter(41)
  %reduce.851 = f32[7168]{0} reduce(f32[16,7168]{1,0} %param_20_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1262 = f32[7168]{0} add(f32[7168]{0} %param_20_0, f32[7168]{0} %reduce.851), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %param_21_0 = f32[3584]{0} parameter(42)
  %param_21_1 = f32[16,3584]{1,0} parameter(43)
  %reduce.852 = f32[3584]{0} reduce(f32[16,3584]{1,0} %param_21_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1263 = f32[3584]{0} add(f32[3584]{0} %param_21_0, f32[3584]{0} %reduce.852), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %param_22_0 = f32[1792]{0} parameter(44)
  %param_22_1 = f32[16,1792]{1,0} parameter(45)
  %reduce.853 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_22_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1264 = f32[1792]{0} add(f32[1792]{0} %param_22_0, f32[1792]{0} %reduce.853), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %param_23_0 = f32[1792]{0} parameter(46)
  %param_23_1 = f32[16,1792]{1,0} parameter(47)
  %reduce.854 = f32[1792]{0} reduce(f32[16,1792]{1,0} %param_23_1, f32[] %constant_3087), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=150}
  %add.1265 = f32[1792]{0} add(f32[1792]{0} %param_23_0, f32[1792]{0} %reduce.854), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %concatenate = f32[62848]{0} concatenate(f32[3584]{0} %add.1242, f32[3584]{0} %add.1243, f32[1792]{0} %add.1244, f32[896]{0} %add.1245, f32[3584]{0} %add.1246, /*index=5*/f32[1792]{0} %add.1247, f32[896]{0} %add.1248, f32[3584]{0} %add.1249, f32[1792]{0} %add.1250, f32[896]{0} %add.1251, /*index=10*/f32[3584]{0} %add.1252, f32[1792]{0} %add.1253, f32[896]{0} %add.1254, f32[1792]{0} %add.1255, f32[896]{0} %add.1256, /*index=15*/f32[7168]{0} %add.1257, f32[1792]{0} %add.1258, f32[3584]{0} %add.1259, f32[3584]{0} %add.1260, f32[1024]{0} %add.1261, /*index=20*/f32[7168]{0} %add.1262, f32[3584]{0} %add.1263, f32[1792]{0} %add.1264, f32[1792]{0} %add.1265), dimensions={0}
  %slice.12 = f32[3584]{0} slice(f32[62848]{0} %concatenate), slice={[0:3584]}
  %slice.13 = f32[3584]{0} slice(f32[62848]{0} %concatenate), slice={[3584:7168]}
  %slice.14 = f32[1792]{0} slice(f32[62848]{0} %concatenate), slice={[7168:8960]}
  %slice.15 = f32[896]{0} slice(f32[62848]{0} %concatenate), slice={[8960:9856]}
  %slice.16 = f32[3584]{0} slice(f32[62848]{0} %concatenate), slice={[9856:13440]}
  %slice.17 = f32[1792]{0} slice(f32[62848]{0} %concatenate), slice={[13440:15232]}
  %slice.18 = f32[896]{0} slice(f32[62848]{0} %concatenate), slice={[15232:16128]}
  %slice.19 = f32[3584]{0} slice(f32[62848]{0} %concatenate), slice={[16128:19712]}
  %slice.20 = f32[1792]{0} slice(f32[62848]{0} %concatenate), slice={[19712:21504]}
  %slice.21 = f32[896]{0} slice(f32[62848]{0} %concatenate), slice={[21504:22400]}
  %slice.22 = f32[3584]{0} slice(f32[62848]{0} %concatenate), slice={[22400:25984]}
  %slice.23 = f32[1792]{0} slice(f32[62848]{0} %concatenate), slice={[25984:27776]}
  %slice.24 = f32[896]{0} slice(f32[62848]{0} %concatenate), slice={[27776:28672]}
  %slice.25 = f32[1792]{0} slice(f32[62848]{0} %concatenate), slice={[28672:30464]}
  %slice.26 = f32[896]{0} slice(f32[62848]{0} %concatenate), slice={[30464:31360]}
  %slice.27 = f32[7168]{0} slice(f32[62848]{0} %concatenate), slice={[31360:38528]}
  %slice.28 = f32[1792]{0} slice(f32[62848]{0} %concatenate), slice={[38528:40320]}
  %slice.29 = f32[3584]{0} slice(f32[62848]{0} %concatenate), slice={[40320:43904]}
  %slice.30 = f32[3584]{0} slice(f32[62848]{0} %concatenate), slice={[43904:47488]}
  %slice.31 = f32[1024]{0} slice(f32[62848]{0} %concatenate), slice={[47488:48512]}
  %slice.32 = f32[7168]{0} slice(f32[62848]{0} %concatenate), slice={[48512:55680]}
  %slice.33 = f32[3584]{0} slice(f32[62848]{0} %concatenate), slice={[55680:59264]}
  %slice.34 = f32[1792]{0} slice(f32[62848]{0} %concatenate), slice={[59264:61056]}
  %slice.35 = f32[1792]{0} slice(f32[62848]{0} %concatenate), slice={[61056:62848]}
  ROOT %tuple.99 = (f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) tuple(f32[3584]{0} %slice.12, f32[3584]{0} %slice.13, f32[1792]{0} %slice.14, f32[896]{0} %slice.15, f32[3584]{0} %slice.16, /*index=5*/f32[1792]{0} %slice.17, f32[896]{0} %slice.18, f32[3584]{0} %slice.19, f32[1792]{0} %slice.20, f32[896]{0} %slice.21, /*index=10*/f32[3584]{0} %slice.22, f32[1792]{0} %slice.23, f32[896]{0} %slice.24, f32[1792]{0} %slice.25, f32[896]{0} %slice.26, /*index=15*/f32[7168]{0} %slice.27, f32[1792]{0} %slice.28, f32[3584]{0} %slice.29, f32[3584]{0} %slice.30, f32[1024]{0} %slice.31, /*index=20*/f32[7168]{0} %slice.32, f32[3584]{0} %slice.33, f32[1792]{0} %slice.34, f32[1792]{0} %slice.35), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
}

%horizontally_fused_computation.1 (param_0_0.1: f32[896], param_0_1.1: f32[1,1,1,896], param_0_2: f32[896], param_1_0.1: f32[7168], param_1_1.1: f32[1,1,1,7168], param_1_2: f32[7168], param_2_0.1: f32[3584], param_2_1.1: f32[1,1,1,3584], param_2_2: f32[3584], param_3_0.1: f32[3584], param_3_1.1: f32[1,1,1,3584], param_3_2: f32[3584], param_4_0.1: f32[1792], param_4_1.1: f32[1,1,1,1792], param_4_2: f32[1792], param_5_0.1: f32[1792], param_5_1.1: f32[1,1,1,1792], param_5_2: f32[1792], param_6_0.1: f32[896], param_6_1.1: f32[1,1,1,896], param_6_2: f32[896], param_7_0.1: f32[3584], param_7_1.1: f32[1,1,1,3584], param_7_2: f32[3584], param_8_0.1: f32[1792], param_8_1.1: f32[1,1,1,1792], param_8_2: f32[1792], param_9_0.1: f32[3584], param_9_1.1: f32[1,1,1,3584], param_9_2: f32[3584], param_10_0.1: f32[1792], param_10_1.1: f32[1,1,1,1792], param_10_2: f32[1792], param_11_0.1: f32[896], param_11_1.1: f32[1,1,1,896], param_11_2: f32[896], param_12_0.1: f32[3584], param_12_1.1: f32[1,1,1,3584], param_12_2: f32[3584], param_13_0.1: f32[7168], param_13_1.1: f32[1,1,1,7168], param_13_2: f32[7168], param_14_0.1: f32[1792], param_14_1.1: f32[1,1,1,1792], param_14_2: f32[1792], param_15_0.1: f32[896], param_15_1.1: f32[1,1,1,896], param_15_2: f32[896], param_16_0.1: f32[1792], param_16_1.1: f32[1,1,1,1792], param_16_2: f32[1792], param_17_0.1: f32[3584], param_17_1.1: f32[1,1,1,3584], param_17_2: f32[3584], param_18_0.1: f32[1792], param_18_1.1: f32[1,1,1,1792], param_18_2: f32[1792], param_19_0.1: f32[1792], param_19_1.1: f32[1,1,1,1792], param_19_2: f32[1792], param_20_0.1: f32[896], param_20_1.1: f32[1,1,1,896], param_20_2: f32[896], param_21_0.1: f32[3584], param_21_1.1: f32[1,1,1,3584], param_21_2: f32[3584]) -> (f32[896], f32[7168], f32[3584], f32[3584], f32[1792], /*index=5*/f32[1792], f32[896], f32[3584], f32[1792], f32[3584], /*index=10*/f32[1792], f32[896], f32[3584], f32[7168], f32[1792], /*index=15*/f32[896], f32[1792], f32[3584], f32[1792], f32[1792], /*index=20*/f32[896], f32[3584]) {
  %param_0_0.1 = f32[896]{0} parameter(0)
  %param_0_2 = f32[896]{0} parameter(2)
  %constant_3111 = f32[] constant(0)
  %broadcast.3880 = f32[896]{0} broadcast(f32[] %constant_3111), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.756 = f32[896]{0} maximum(f32[896]{0} %param_0_2, f32[896]{0} %broadcast.3880), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %constant_3112 = f32[] constant(1e-05)
  %broadcast.3881 = f32[896]{0} broadcast(f32[] %constant_3112), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1266 = f32[896]{0} add(f32[896]{0} %maximum.756, f32[896]{0} %broadcast.3881), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2239 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1266), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.516 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2239), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_0_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(1)
  %multiply.2246 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.516, f32[1,1,1,896]{3,2,1,0} %param_0_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2240 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2246), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1267 = f32[896]{0} add(f32[896]{0} %param_0_0.1, f32[896]{0} %bitcast.2240), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %param_1_0.1 = f32[7168]{0} parameter(3)
  %param_1_2 = f32[7168]{0} parameter(5)
  %broadcast.3882 = f32[7168]{0} broadcast(f32[] %constant_3111), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.757 = f32[7168]{0} maximum(f32[7168]{0} %param_1_2, f32[7168]{0} %broadcast.3882), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.3883 = f32[7168]{0} broadcast(f32[] %constant_3112), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1268 = f32[7168]{0} add(f32[7168]{0} %maximum.757, f32[7168]{0} %broadcast.3883), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2241 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.1268), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.517 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.2241), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_1_1.1 = f32[1,1,1,7168]{3,2,1,0} parameter(4)
  %multiply.2247 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.517, f32[1,1,1,7168]{3,2,1,0} %param_1_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2242 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.2247), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reshape[new_sizes=(7168,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1269 = f32[7168]{0} add(f32[7168]{0} %param_1_0.1, f32[7168]{0} %bitcast.2242), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %param_2_0.1 = f32[3584]{0} parameter(6)
  %param_2_2 = f32[3584]{0} parameter(8)
  %broadcast.3884 = f32[3584]{0} broadcast(f32[] %constant_3111), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.758 = f32[3584]{0} maximum(f32[3584]{0} %param_2_2, f32[3584]{0} %broadcast.3884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.3885 = f32[3584]{0} broadcast(f32[] %constant_3112), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1270 = f32[3584]{0} add(f32[3584]{0} %maximum.758, f32[3584]{0} %broadcast.3885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2243 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1270), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.518 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2243), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_2_1.1 = f32[1,1,1,3584]{3,2,1,0} parameter(7)
  %multiply.2248 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.518, f32[1,1,1,3584]{3,2,1,0} %param_2_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2244 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2248), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1271 = f32[3584]{0} add(f32[3584]{0} %param_2_0.1, f32[3584]{0} %bitcast.2244), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %param_3_0.1 = f32[3584]{0} parameter(9)
  %param_3_2 = f32[3584]{0} parameter(11)
  %maximum.759 = f32[3584]{0} maximum(f32[3584]{0} %param_3_2, f32[3584]{0} %broadcast.3884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1272 = f32[3584]{0} add(f32[3584]{0} %maximum.759, f32[3584]{0} %broadcast.3885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2245 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1272), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.519 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2245), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_3_1.1 = f32[1,1,1,3584]{3,2,1,0} parameter(10)
  %multiply.2249 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.519, f32[1,1,1,3584]{3,2,1,0} %param_3_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2246 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2249), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1273 = f32[3584]{0} add(f32[3584]{0} %param_3_0.1, f32[3584]{0} %bitcast.2246), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %param_4_0.1 = f32[1792]{0} parameter(12)
  %param_4_2 = f32[1792]{0} parameter(14)
  %broadcast.3888 = f32[1792]{0} broadcast(f32[] %constant_3111), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %maximum.760 = f32[1792]{0} maximum(f32[1792]{0} %param_4_2, f32[1792]{0} %broadcast.3888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %broadcast.3889 = f32[1792]{0} broadcast(f32[] %constant_3112), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %add.1274 = f32[1792]{0} add(f32[1792]{0} %maximum.760, f32[1792]{0} %broadcast.3889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2247 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1274), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.520 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2247), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_4_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(13)
  %multiply.2250 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.520, f32[1,1,1,1792]{3,2,1,0} %param_4_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2248 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2250), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1275 = f32[1792]{0} add(f32[1792]{0} %param_4_0.1, f32[1792]{0} %bitcast.2248), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %param_5_0.1 = f32[1792]{0} parameter(15)
  %param_5_2 = f32[1792]{0} parameter(17)
  %maximum.761 = f32[1792]{0} maximum(f32[1792]{0} %param_5_2, f32[1792]{0} %broadcast.3888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1276 = f32[1792]{0} add(f32[1792]{0} %maximum.761, f32[1792]{0} %broadcast.3889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2249 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1276), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.521 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2249), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_5_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(16)
  %multiply.2251 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.521, f32[1,1,1,1792]{3,2,1,0} %param_5_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2250 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2251), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1277 = f32[1792]{0} add(f32[1792]{0} %param_5_0.1, f32[1792]{0} %bitcast.2250), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %param_6_0.1 = f32[896]{0} parameter(18)
  %param_6_2 = f32[896]{0} parameter(20)
  %maximum.762 = f32[896]{0} maximum(f32[896]{0} %param_6_2, f32[896]{0} %broadcast.3880), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1278 = f32[896]{0} add(f32[896]{0} %maximum.762, f32[896]{0} %broadcast.3881), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2251 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1278), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.522 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2251), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_6_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(19)
  %multiply.2252 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.522, f32[1,1,1,896]{3,2,1,0} %param_6_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2252 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2252), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1279 = f32[896]{0} add(f32[896]{0} %param_6_0.1, f32[896]{0} %bitcast.2252), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %param_7_0.1 = f32[3584]{0} parameter(21)
  %param_7_2 = f32[3584]{0} parameter(23)
  %maximum.763 = f32[3584]{0} maximum(f32[3584]{0} %param_7_2, f32[3584]{0} %broadcast.3884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1280 = f32[3584]{0} add(f32[3584]{0} %maximum.763, f32[3584]{0} %broadcast.3885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2253 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1280), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.523 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2253), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_7_1.1 = f32[1,1,1,3584]{3,2,1,0} parameter(22)
  %multiply.2253 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.523, f32[1,1,1,3584]{3,2,1,0} %param_7_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2254 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2253), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1281 = f32[3584]{0} add(f32[3584]{0} %param_7_0.1, f32[3584]{0} %bitcast.2254), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %param_8_0.1 = f32[1792]{0} parameter(24)
  %param_8_2 = f32[1792]{0} parameter(26)
  %maximum.764 = f32[1792]{0} maximum(f32[1792]{0} %param_8_2, f32[1792]{0} %broadcast.3888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1282 = f32[1792]{0} add(f32[1792]{0} %maximum.764, f32[1792]{0} %broadcast.3889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2255 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1282), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.524 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2255), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_8_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(25)
  %multiply.2254 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.524, f32[1,1,1,1792]{3,2,1,0} %param_8_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2256 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2254), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1283 = f32[1792]{0} add(f32[1792]{0} %param_8_0.1, f32[1792]{0} %bitcast.2256), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %param_9_0.1 = f32[3584]{0} parameter(27)
  %param_9_2 = f32[3584]{0} parameter(29)
  %maximum.765 = f32[3584]{0} maximum(f32[3584]{0} %param_9_2, f32[3584]{0} %broadcast.3884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1284 = f32[3584]{0} add(f32[3584]{0} %maximum.765, f32[3584]{0} %broadcast.3885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2257 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1284), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.525 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2257), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_9_1.1 = f32[1,1,1,3584]{3,2,1,0} parameter(28)
  %multiply.2255 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.525, f32[1,1,1,3584]{3,2,1,0} %param_9_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2258 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2255), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1285 = f32[3584]{0} add(f32[3584]{0} %param_9_0.1, f32[3584]{0} %bitcast.2258), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %param_10_0.1 = f32[1792]{0} parameter(30)
  %param_10_2 = f32[1792]{0} parameter(32)
  %maximum.766 = f32[1792]{0} maximum(f32[1792]{0} %param_10_2, f32[1792]{0} %broadcast.3888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1286 = f32[1792]{0} add(f32[1792]{0} %maximum.766, f32[1792]{0} %broadcast.3889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2259 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1286), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.526 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2259), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_10_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(31)
  %multiply.2256 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.526, f32[1,1,1,1792]{3,2,1,0} %param_10_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2260 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2256), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1287 = f32[1792]{0} add(f32[1792]{0} %param_10_0.1, f32[1792]{0} %bitcast.2260), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %param_11_0.1 = f32[896]{0} parameter(33)
  %param_11_2 = f32[896]{0} parameter(35)
  %maximum.767 = f32[896]{0} maximum(f32[896]{0} %param_11_2, f32[896]{0} %broadcast.3880), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1288 = f32[896]{0} add(f32[896]{0} %maximum.767, f32[896]{0} %broadcast.3881), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2261 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1288), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.527 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2261), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_11_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(34)
  %multiply.2257 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.527, f32[1,1,1,896]{3,2,1,0} %param_11_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2262 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2257), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1289 = f32[896]{0} add(f32[896]{0} %param_11_0.1, f32[896]{0} %bitcast.2262), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %param_12_0.1 = f32[3584]{0} parameter(36)
  %param_12_2 = f32[3584]{0} parameter(38)
  %maximum.768 = f32[3584]{0} maximum(f32[3584]{0} %param_12_2, f32[3584]{0} %broadcast.3884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1290 = f32[3584]{0} add(f32[3584]{0} %maximum.768, f32[3584]{0} %broadcast.3885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2263 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1290), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.528 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2263), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_12_1.1 = f32[1,1,1,3584]{3,2,1,0} parameter(37)
  %multiply.2258 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.528, f32[1,1,1,3584]{3,2,1,0} %param_12_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2264 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2258), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1291 = f32[3584]{0} add(f32[3584]{0} %param_12_0.1, f32[3584]{0} %bitcast.2264), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %param_13_0.1 = f32[7168]{0} parameter(39)
  %param_13_2 = f32[7168]{0} parameter(41)
  %maximum.769 = f32[7168]{0} maximum(f32[7168]{0} %param_13_2, f32[7168]{0} %broadcast.3882), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1292 = f32[7168]{0} add(f32[7168]{0} %maximum.769, f32[7168]{0} %broadcast.3883), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2265 = f32[1,1,1,7168]{3,2,1,0} bitcast(f32[7168]{0} %add.1292), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.529 = f32[1,1,1,7168]{3,2,1,0} rsqrt(f32[1,1,1,7168]{3,2,1,0} %bitcast.2265), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_13_1.1 = f32[1,1,1,7168]{3,2,1,0} parameter(40)
  %multiply.2259 = f32[1,1,1,7168]{3,2,1,0} multiply(f32[1,1,1,7168]{3,2,1,0} %rsqrt.529, f32[1,1,1,7168]{3,2,1,0} %param_13_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2266 = f32[7168]{0} bitcast(f32[1,1,1,7168]{3,2,1,0} %multiply.2259), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reshape[new_sizes=(7168,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1293 = f32[7168]{0} add(f32[7168]{0} %param_13_0.1, f32[7168]{0} %bitcast.2266), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %param_14_0.1 = f32[1792]{0} parameter(42)
  %param_14_2 = f32[1792]{0} parameter(44)
  %maximum.770 = f32[1792]{0} maximum(f32[1792]{0} %param_14_2, f32[1792]{0} %broadcast.3888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1294 = f32[1792]{0} add(f32[1792]{0} %maximum.770, f32[1792]{0} %broadcast.3889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2267 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1294), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.530 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2267), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_14_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(43)
  %multiply.2260 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.530, f32[1,1,1,1792]{3,2,1,0} %param_14_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2268 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2260), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1295 = f32[1792]{0} add(f32[1792]{0} %param_14_0.1, f32[1792]{0} %bitcast.2268), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %param_15_0.1 = f32[896]{0} parameter(45)
  %param_15_2 = f32[896]{0} parameter(47)
  %maximum.771 = f32[896]{0} maximum(f32[896]{0} %param_15_2, f32[896]{0} %broadcast.3880), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1296 = f32[896]{0} add(f32[896]{0} %maximum.771, f32[896]{0} %broadcast.3881), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2269 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1296), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.531 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2269), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_15_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(46)
  %multiply.2261 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.531, f32[1,1,1,896]{3,2,1,0} %param_15_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2270 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2261), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1297 = f32[896]{0} add(f32[896]{0} %param_15_0.1, f32[896]{0} %bitcast.2270), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %param_16_0.1 = f32[1792]{0} parameter(48)
  %param_16_2 = f32[1792]{0} parameter(50)
  %maximum.772 = f32[1792]{0} maximum(f32[1792]{0} %param_16_2, f32[1792]{0} %broadcast.3888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1298 = f32[1792]{0} add(f32[1792]{0} %maximum.772, f32[1792]{0} %broadcast.3889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2271 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1298), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.532 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2271), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_16_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(49)
  %multiply.2262 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.532, f32[1,1,1,1792]{3,2,1,0} %param_16_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2272 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2262), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1299 = f32[1792]{0} add(f32[1792]{0} %param_16_0.1, f32[1792]{0} %bitcast.2272), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %param_17_0.1 = f32[3584]{0} parameter(51)
  %param_17_2 = f32[3584]{0} parameter(53)
  %maximum.773 = f32[3584]{0} maximum(f32[3584]{0} %param_17_2, f32[3584]{0} %broadcast.3884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1300 = f32[3584]{0} add(f32[3584]{0} %maximum.773, f32[3584]{0} %broadcast.3885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2273 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1300), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.533 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2273), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_17_1.1 = f32[1,1,1,3584]{3,2,1,0} parameter(52)
  %multiply.2263 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.533, f32[1,1,1,3584]{3,2,1,0} %param_17_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2274 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2263), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1301 = f32[3584]{0} add(f32[3584]{0} %param_17_0.1, f32[3584]{0} %bitcast.2274), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %param_18_0.1 = f32[1792]{0} parameter(54)
  %param_18_2 = f32[1792]{0} parameter(56)
  %maximum.774 = f32[1792]{0} maximum(f32[1792]{0} %param_18_2, f32[1792]{0} %broadcast.3888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1302 = f32[1792]{0} add(f32[1792]{0} %maximum.774, f32[1792]{0} %broadcast.3889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2275 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1302), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.534 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2275), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_18_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(55)
  %multiply.2264 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.534, f32[1,1,1,1792]{3,2,1,0} %param_18_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2276 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2264), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1303 = f32[1792]{0} add(f32[1792]{0} %param_18_0.1, f32[1792]{0} %bitcast.2276), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %param_19_0.1 = f32[1792]{0} parameter(57)
  %param_19_2 = f32[1792]{0} parameter(59)
  %maximum.775 = f32[1792]{0} maximum(f32[1792]{0} %param_19_2, f32[1792]{0} %broadcast.3888), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1304 = f32[1792]{0} add(f32[1792]{0} %maximum.775, f32[1792]{0} %broadcast.3889), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2277 = f32[1,1,1,1792]{3,2,1,0} bitcast(f32[1792]{0} %add.1304), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.535 = f32[1,1,1,1792]{3,2,1,0} rsqrt(f32[1,1,1,1792]{3,2,1,0} %bitcast.2277), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_19_1.1 = f32[1,1,1,1792]{3,2,1,0} parameter(58)
  %multiply.2265 = f32[1,1,1,1792]{3,2,1,0} multiply(f32[1,1,1,1792]{3,2,1,0} %rsqrt.535, f32[1,1,1,1792]{3,2,1,0} %param_19_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2278 = f32[1792]{0} bitcast(f32[1,1,1,1792]{3,2,1,0} %multiply.2265), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reshape[new_sizes=(1792,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1305 = f32[1792]{0} add(f32[1792]{0} %param_19_0.1, f32[1792]{0} %bitcast.2278), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %param_20_0.1 = f32[896]{0} parameter(60)
  %param_20_2 = f32[896]{0} parameter(62)
  %maximum.776 = f32[896]{0} maximum(f32[896]{0} %param_20_2, f32[896]{0} %broadcast.3880), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1306 = f32[896]{0} add(f32[896]{0} %maximum.776, f32[896]{0} %broadcast.3881), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2279 = f32[1,1,1,896]{3,2,1,0} bitcast(f32[896]{0} %add.1306), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.536 = f32[1,1,1,896]{3,2,1,0} rsqrt(f32[1,1,1,896]{3,2,1,0} %bitcast.2279), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_20_1.1 = f32[1,1,1,896]{3,2,1,0} parameter(61)
  %multiply.2266 = f32[1,1,1,896]{3,2,1,0} multiply(f32[1,1,1,896]{3,2,1,0} %rsqrt.536, f32[1,1,1,896]{3,2,1,0} %param_20_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2280 = f32[896]{0} bitcast(f32[1,1,1,896]{3,2,1,0} %multiply.2266), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reshape[new_sizes=(896,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1307 = f32[896]{0} add(f32[896]{0} %param_20_0.1, f32[896]{0} %bitcast.2280), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %param_21_0.1 = f32[3584]{0} parameter(63)
  %param_21_2 = f32[3584]{0} parameter(65)
  %maximum.777 = f32[3584]{0} maximum(f32[3584]{0} %param_21_2, f32[3584]{0} %broadcast.3884), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %add.1308 = f32[3584]{0} add(f32[3584]{0} %maximum.777, f32[3584]{0} %broadcast.3885), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %bitcast.2281 = f32[1,1,1,3584]{3,2,1,0} bitcast(f32[3584]{0} %add.1308), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %rsqrt.537 = f32[1,1,1,3584]{3,2,1,0} rsqrt(f32[1,1,1,3584]{3,2,1,0} %bitcast.2281), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/rsqrt" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=139}
  %param_21_1.1 = f32[1,1,1,3584]{3,2,1,0} parameter(64)
  %multiply.2267 = f32[1,1,1,3584]{3,2,1,0} multiply(f32[1,1,1,3584]{3,2,1,0} %rsqrt.537, f32[1,1,1,3584]{3,2,1,0} %param_21_1.1), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=144}
  %bitcast.2282 = f32[3584]{0} bitcast(f32[1,1,1,3584]{3,2,1,0} %multiply.2267), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reshape[new_sizes=(3584,) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=142}
  %add.1309 = f32[3584]{0} add(f32[3584]{0} %param_21_0.1, f32[3584]{0} %bitcast.2282), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %concatenate.1 = f32[58240]{0} concatenate(f32[896]{0} %add.1267, f32[7168]{0} %add.1269, f32[3584]{0} %add.1271, f32[3584]{0} %add.1273, f32[1792]{0} %add.1275, /*index=5*/f32[1792]{0} %add.1277, f32[896]{0} %add.1279, f32[3584]{0} %add.1281, f32[1792]{0} %add.1283, f32[3584]{0} %add.1285, /*index=10*/f32[1792]{0} %add.1287, f32[896]{0} %add.1289, f32[3584]{0} %add.1291, f32[7168]{0} %add.1293, f32[1792]{0} %add.1295, /*index=15*/f32[896]{0} %add.1297, f32[1792]{0} %add.1299, f32[3584]{0} %add.1301, f32[1792]{0} %add.1303, f32[1792]{0} %add.1305, /*index=20*/f32[896]{0} %add.1307, f32[3584]{0} %add.1309), dimensions={0}
  %slice.36 = f32[896]{0} slice(f32[58240]{0} %concatenate.1), slice={[0:896]}
  %slice.37 = f32[7168]{0} slice(f32[58240]{0} %concatenate.1), slice={[896:8064]}
  %slice.38 = f32[3584]{0} slice(f32[58240]{0} %concatenate.1), slice={[8064:11648]}
  %slice.39 = f32[3584]{0} slice(f32[58240]{0} %concatenate.1), slice={[11648:15232]}
  %slice.40 = f32[1792]{0} slice(f32[58240]{0} %concatenate.1), slice={[15232:17024]}
  %slice.41 = f32[1792]{0} slice(f32[58240]{0} %concatenate.1), slice={[17024:18816]}
  %slice.42 = f32[896]{0} slice(f32[58240]{0} %concatenate.1), slice={[18816:19712]}
  %slice.43 = f32[3584]{0} slice(f32[58240]{0} %concatenate.1), slice={[19712:23296]}
  %slice.44 = f32[1792]{0} slice(f32[58240]{0} %concatenate.1), slice={[23296:25088]}
  %slice.45 = f32[3584]{0} slice(f32[58240]{0} %concatenate.1), slice={[25088:28672]}
  %slice.46 = f32[1792]{0} slice(f32[58240]{0} %concatenate.1), slice={[28672:30464]}
  %slice.47 = f32[896]{0} slice(f32[58240]{0} %concatenate.1), slice={[30464:31360]}
  %slice.48 = f32[3584]{0} slice(f32[58240]{0} %concatenate.1), slice={[31360:34944]}
  %slice.49 = f32[7168]{0} slice(f32[58240]{0} %concatenate.1), slice={[34944:42112]}
  %slice.50 = f32[1792]{0} slice(f32[58240]{0} %concatenate.1), slice={[42112:43904]}
  %slice.51 = f32[896]{0} slice(f32[58240]{0} %concatenate.1), slice={[43904:44800]}
  %slice.52 = f32[1792]{0} slice(f32[58240]{0} %concatenate.1), slice={[44800:46592]}
  %slice.53 = f32[3584]{0} slice(f32[58240]{0} %concatenate.1), slice={[46592:50176]}
  %slice.54 = f32[1792]{0} slice(f32[58240]{0} %concatenate.1), slice={[50176:51968]}
  %slice.55 = f32[1792]{0} slice(f32[58240]{0} %concatenate.1), slice={[51968:53760]}
  %slice.56 = f32[896]{0} slice(f32[58240]{0} %concatenate.1), slice={[53760:54656]}
  %slice.57 = f32[3584]{0} slice(f32[58240]{0} %concatenate.1), slice={[54656:58240]}
  ROOT %tuple.100 = (f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) tuple(f32[896]{0} %slice.36, f32[7168]{0} %slice.37, f32[3584]{0} %slice.38, f32[3584]{0} %slice.39, f32[1792]{0} %slice.40, /*index=5*/f32[1792]{0} %slice.41, f32[896]{0} %slice.42, f32[3584]{0} %slice.43, f32[1792]{0} %slice.44, f32[3584]{0} %slice.45, /*index=10*/f32[1792]{0} %slice.46, f32[896]{0} %slice.47, f32[3584]{0} %slice.48, f32[7168]{0} %slice.49, f32[1792]{0} %slice.50, /*index=15*/f32[896]{0} %slice.51, f32[1792]{0} %slice.52, f32[3584]{0} %slice.53, f32[1792]{0} %slice.54, f32[1792]{0} %slice.55, /*index=20*/f32[896]{0} %slice.56, f32[3584]{0} %slice.57), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
}

%fused_computation.28.clone (param_0.1623: f32[16,3584,196], param_1.2281: f32[16,3584,196], param_2.1648: f32[3584]) -> f32[16,3584] {
  %param_1.2281 = f32[16,3584,196]{2,1,0} parameter(1)
  %param_2.1648 = f32[3584]{0} parameter(2)
  %constant_3156 = f32[] constant(0.000318877544)
  %broadcast.3925 = f32[3584]{0} broadcast(f32[] %constant_3156), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2269 = f32[3584]{0} multiply(f32[3584]{0} %param_2.1648, f32[3584]{0} %broadcast.3925), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3924 = f32[16,14,14,3584]{2,1,3,0} broadcast(f32[3584]{0} %multiply.2269), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.73 = f32[16,3584,14,14]{3,2,1,0} transpose(f32[16,14,14,3584]{2,1,3,0} %broadcast.3924), dimensions={0,3,1,2}
  %bitcast.2288 = f32[16,3584,196]{2,1,0} bitcast(f32[16,3584,14,14]{3,2,1,0} %transpose.73)
  %subtract.423 = f32[16,3584,196]{2,1,0} subtract(f32[16,3584,196]{2,1,0} %param_1.2281, f32[16,3584,196]{2,1,0} %bitcast.2288), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_0.1623 = f32[16,3584,196]{2,1,0} parameter(0)
  %multiply.2270 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %subtract.423, f32[16,3584,196]{2,1,0} %param_0.1623), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %constant_3155 = f32[] constant(0)
  ROOT %reduce.855 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.2270, f32[] %constant_3155), dimensions={2}, to_apply=%region_57.4114.2
}

%fused_computation.35.clone (param_0.1625: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1625 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2272 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.1625, f32[16,3584,196]{2,1,0} %param_0.1625), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3157 = f32[] constant(0)
  %reduce.856 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.2272, f32[] %constant_3157), dimensions={2}, to_apply=%region_57.4114.2
  %reduce.645.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.1625, f32[] %constant_3157), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.102 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.856, f32[16,3584]{1,0} %reduce.645.clone.2)
}

%fused_computation.45.clone (param_0.1627: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1627 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3158 = f32[] constant(0)
  %reduce.857 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.1627, f32[] %constant_3158), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.298.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.1627, f32[16,1792,196]{2,1,0} %param_0.1627), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.648.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.298.clone.3, f32[] %constant_3158), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.103 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.857, f32[16,1792]{1,0} %reduce.648.clone.2)
}

%fused_computation.55.clone (param_0.1629: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.1629 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3159 = f32[] constant(0)
  %reduce.858 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.1629, f32[] %constant_3159), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.304.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.1629, f32[16,896,196]{2,1,0} %param_0.1629), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.651.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.304.clone.3, f32[] %constant_3159), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.104 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.858, f32[16,896]{1,0} %reduce.651.clone.2)
}

%fused_computation.95.clone (param_0.1631: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1631 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3160 = f32[] constant(0)
  %reduce.859 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.1631, f32[] %constant_3160), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.346.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.1631, f32[16,3584,196]{2,1,0} %param_0.1631), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.669.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.346.clone.3, f32[] %constant_3160), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.105 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.859, f32[16,3584]{1,0} %reduce.669.clone.2)
}

%fused_computation.105.clone (param_0.1633: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1633 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3161 = f32[] constant(0)
  %reduce.860 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.1633, f32[] %constant_3161), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.352.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.1633, f32[16,1792,196]{2,1,0} %param_0.1633), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.672.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.352.clone.3, f32[] %constant_3161), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.106 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.860, f32[16,1792]{1,0} %reduce.672.clone.2)
}

%fused_computation.115.clone (param_0.1635: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.1635 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3162 = f32[] constant(0)
  %reduce.861 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.1635, f32[] %constant_3162), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.358.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.1635, f32[16,896,196]{2,1,0} %param_0.1635), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.675.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.358.clone.3, f32[] %constant_3162), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.107 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.861, f32[16,896]{1,0} %reduce.675.clone.2)
}

%fused_computation.154.clone (param_0.1637: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1637 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3163 = f32[] constant(0)
  %reduce.862 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.1637, f32[] %constant_3163), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.400.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.1637, f32[16,3584,196]{2,1,0} %param_0.1637), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.693.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.400.clone.3, f32[] %constant_3163), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.108 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.862, f32[16,3584]{1,0} %reduce.693.clone.2)
}

%fused_computation.164.clone (param_0.1639: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1639 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3164 = f32[] constant(0)
  %reduce.863 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.1639, f32[] %constant_3164), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.406.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.1639, f32[16,1792,196]{2,1,0} %param_0.1639), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.696.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.406.clone.3, f32[] %constant_3164), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.109 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.863, f32[16,1792]{1,0} %reduce.696.clone.2)
}

%fused_computation.174.clone (param_0.1641: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.1641 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3165 = f32[] constant(0)
  %reduce.864 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.1641, f32[] %constant_3165), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.412.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.1641, f32[16,896,196]{2,1,0} %param_0.1641), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.699.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.412.clone.3, f32[] %constant_3165), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.110 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.864, f32[16,896]{1,0} %reduce.699.clone.2)
}

%fused_computation.212.clone (param_0.1643: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1643 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3166 = f32[] constant(0)
  %reduce.865 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.1643, f32[] %constant_3166), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.454.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.1643, f32[16,3584,196]{2,1,0} %param_0.1643), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.717.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.454.clone.3, f32[] %constant_3166), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.111 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.865, f32[16,3584]{1,0} %reduce.717.clone.2)
}

%fused_computation.222.clone (param_0.1645: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1645 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3167 = f32[] constant(0)
  %reduce.866 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.1645, f32[] %constant_3167), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.460.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.1645, f32[16,1792,196]{2,1,0} %param_0.1645), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.720.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.460.clone.3, f32[] %constant_3167), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.112 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.866, f32[16,1792]{1,0} %reduce.720.clone.2)
}

%fused_computation.232.clone (param_0.1647: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.1647 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3168 = f32[] constant(0)
  %reduce.867 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.1647, f32[] %constant_3168), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.466.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.1647, f32[16,896,196]{2,1,0} %param_0.1647), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.723.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.466.clone.3, f32[] %constant_3168), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.113 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.867, f32[16,896]{1,0} %reduce.723.clone.2)
}

%fused_computation.270.clone (param_0.1649: f32[16,3584,196]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1649 = f32[16,3584,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3169 = f32[] constant(0)
  %reduce.868 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %param_0.1649, f32[] %constant_3169), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.508.clone.3 = f32[16,3584,196]{2,1,0} multiply(f32[16,3584,196]{2,1,0} %param_0.1649, f32[16,3584,196]{2,1,0} %param_0.1649), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.741.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,196]{2,1,0} %multiply.508.clone.3, f32[] %constant_3169), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.114 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.868, f32[16,3584]{1,0} %reduce.741.clone.2)
}

%fused_computation.280.clone (param_0.1651: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1651 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3170 = f32[] constant(0)
  %reduce.869 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.1651, f32[] %constant_3170), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.514.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.1651, f32[16,1792,196]{2,1,0} %param_0.1651), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.744.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.514.clone.3, f32[] %constant_3170), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.115 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.869, f32[16,1792]{1,0} %reduce.744.clone.2)
}

%fused_computation.290.clone (param_0.1653: f32[16,896,196]) -> (f32[16,896], f32[16,896]) {
  %param_0.1653 = f32[16,896,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3171 = f32[] constant(0)
  %reduce.870 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %param_0.1653, f32[] %constant_3171), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.520.clone.3 = f32[16,896,196]{2,1,0} multiply(f32[16,896,196]{2,1,0} %param_0.1653, f32[16,896,196]{2,1,0} %param_0.1653), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.747.clone.2 = f32[16,896]{1,0} reduce(f32[16,896,196]{2,1,0} %multiply.520.clone.3, f32[] %constant_3171), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.116 = (f32[16,896]{1,0}, f32[16,896]{1,0}) tuple(f32[16,896]{1,0} %reduce.870, f32[16,896]{1,0} %reduce.747.clone.2)
}

%fused_computation.296.clone (param_0.1655: f32[16,7168,49], param_1.2283: f32[16,7168,49], param_2.1649: f32[7168], param_3.1460: f32[16,7168,49], param_4.1295: f32[7168]) -> (f32[16,7168], f32[16,7168]) {
  %param_1.2283 = f32[16,7168,49]{2,1,0} parameter(1)
  %param_2.1649 = f32[7168]{0} parameter(2)
  %constant_3173 = f32[] constant(0.00127551018)
  %broadcast.3927 = f32[7168]{0} broadcast(f32[] %constant_3173), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %multiply.2274 = f32[7168]{0} multiply(f32[7168]{0} %param_2.1649, f32[7168]{0} %broadcast.3927), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.3926 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.2274), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.74 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %broadcast.3926), dimensions={0,3,1,2}
  %bitcast.2360 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.74)
  %subtract.425 = f32[16,7168,49]{2,1,0} subtract(f32[16,7168,49]{2,1,0} %param_1.2283, f32[16,7168,49]{2,1,0} %bitcast.2360), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %param_0.1655 = f32[16,7168,49]{2,1,0} parameter(0)
  %multiply.2275 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %subtract.425, f32[16,7168,49]{2,1,0} %param_0.1655), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %constant_3172 = f32[] constant(0)
  %reduce.871 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.2275, f32[] %constant_3172), dimensions={2}, to_apply=%region_57.4114.2
  %param_3.1460 = f32[16,7168,49]{2,1,0} parameter(3)
  %param_4.1295 = f32[7168]{0} parameter(4)
  %multiply.1437.clone.2 = f32[7168]{0} multiply(f32[7168]{0} %param_4.1295, f32[7168]{0} %broadcast.3927), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/div" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %broadcast.597.clone.2 = f32[16,7,7,7168]{2,1,3,0} broadcast(f32[7168]{0} %multiply.1437.clone.2), dimensions={3}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %transpose.75 = f32[16,7168,7,7]{3,2,1,0} transpose(f32[16,7,7,7168]{2,1,3,0} %broadcast.597.clone.2), dimensions={0,3,1,2}
  %bitcast.2354 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7168,7,7]{3,2,1,0} %transpose.75)
  %subtract.32.clone.3 = f32[16,7168,49]{2,1,0} subtract(f32[16,7168,49]{2,1,0} %param_3.1460, f32[16,7168,49]{2,1,0} %bitcast.2354), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %multiply.573.clone.3 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %subtract.32.clone.3, f32[16,7168,49]{2,1,0} %param_0.1655), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %reduce.768.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.573.clone.3, f32[] %constant_3172), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.117 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.871, f32[16,7168]{1,0} %reduce.768.clone.2)
}

%fused_computation.303.clone (param_0.1657: f32[16,7168,49]) -> (f32[16,7168], f32[16,7168]) {
  %param_0.1657 = f32[16,7168,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2277 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %param_0.1657, f32[16,7168,49]{2,1,0} %param_0.1657), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3174 = f32[] constant(0)
  %reduce.872 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.2277, f32[] %constant_3174), dimensions={2}, to_apply=%region_57.4114.2
  %reduce.753.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %param_0.1657, f32[] %constant_3174), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.118 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.872, f32[16,7168]{1,0} %reduce.753.clone.2)
}

%fused_computation.337.clone (param_0.1659: f32[16,7168,49]) -> (f32[16,7168], f32[16,7168]) {
  %param_0.1659 = f32[16,7168,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %multiply.2279 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %param_0.1659, f32[16,7168,49]{2,1,0} %param_0.1659), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %constant_3175 = f32[] constant(0)
  %reduce.873 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.2279, f32[] %constant_3175), dimensions={2}, to_apply=%region_57.4114.2
  %reduce.770.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %param_0.1659, f32[] %constant_3175), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.119 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.873, f32[16,7168]{1,0} %reduce.770.clone.2)
}

%fused_computation.347.clone (param_0.1661: f32[16,3584,49]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1661 = f32[16,3584,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3176 = f32[] constant(0)
  %reduce.874 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %param_0.1661, f32[] %constant_3176), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.584.clone.3 = f32[16,3584,49]{2,1,0} multiply(f32[16,3584,49]{2,1,0} %param_0.1661, f32[16,3584,49]{2,1,0} %param_0.1661), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.773.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %multiply.584.clone.3, f32[] %constant_3176), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.120 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.874, f32[16,3584]{1,0} %reduce.773.clone.2)
}

%fused_computation.357.clone (param_0.1663: f32[16,1792,196]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1663 = f32[16,1792,196]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3177 = f32[] constant(0)
  %reduce.875 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %param_0.1663, f32[] %constant_3177), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.590.clone.3 = f32[16,1792,196]{2,1,0} multiply(f32[16,1792,196]{2,1,0} %param_0.1663, f32[16,1792,196]{2,1,0} %param_0.1663), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.776.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,196]{2,1,0} %multiply.590.clone.3, f32[] %constant_3177), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.121 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.875, f32[16,1792]{1,0} %reduce.776.clone.2)
}

%fused_computation.396.clone (param_0.1665: f32[16,7168,49]) -> (f32[16,7168], f32[16,7168]) {
  %param_0.1665 = f32[16,7168,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3178 = f32[] constant(0)
  %reduce.876 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %param_0.1665, f32[] %constant_3178), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.632.clone.3 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %param_0.1665, f32[16,7168,49]{2,1,0} %param_0.1665), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.794.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.632.clone.3, f32[] %constant_3178), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.122 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.876, f32[16,7168]{1,0} %reduce.794.clone.2)
}

%fused_computation.406.clone (param_0.1667: f32[16,3584,49]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1667 = f32[16,3584,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3179 = f32[] constant(0)
  %reduce.877 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %param_0.1667, f32[] %constant_3179), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.638.clone.3 = f32[16,3584,49]{2,1,0} multiply(f32[16,3584,49]{2,1,0} %param_0.1667, f32[16,3584,49]{2,1,0} %param_0.1667), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.797.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %multiply.638.clone.3, f32[] %constant_3179), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.123 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.877, f32[16,3584]{1,0} %reduce.797.clone.2)
}

%fused_computation.416.clone (param_0.1669: f32[16,1792,49]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1669 = f32[16,1792,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3180 = f32[] constant(0)
  %reduce.878 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %param_0.1669, f32[] %constant_3180), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.644.clone.3 = f32[16,1792,49]{2,1,0} multiply(f32[16,1792,49]{2,1,0} %param_0.1669, f32[16,1792,49]{2,1,0} %param_0.1669), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.800.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %multiply.644.clone.3, f32[] %constant_3180), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.124 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.878, f32[16,1792]{1,0} %reduce.800.clone.2)
}

%fused_computation.463.clone (param_0.1671: f32[16,7168,49]) -> (f32[16,7168], f32[16,7168]) {
  %param_0.1671 = f32[16,7168,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3181 = f32[] constant(0)
  %reduce.879 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %param_0.1671, f32[] %constant_3181), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.690.clone.3 = f32[16,7168,49]{2,1,0} multiply(f32[16,7168,49]{2,1,0} %param_0.1671, f32[16,7168,49]{2,1,0} %param_0.1671), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.821.clone.2 = f32[16,7168]{1,0} reduce(f32[16,7168,49]{2,1,0} %multiply.690.clone.3, f32[] %constant_3181), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.125 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) tuple(f32[16,7168]{1,0} %reduce.879, f32[16,7168]{1,0} %reduce.821.clone.2)
}

%fused_computation.473.clone (param_0.1673: f32[16,3584,49]) -> (f32[16,3584], f32[16,3584]) {
  %param_0.1673 = f32[16,3584,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3182 = f32[] constant(0)
  %reduce.880 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %param_0.1673, f32[] %constant_3182), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.696.clone.3 = f32[16,3584,49]{2,1,0} multiply(f32[16,3584,49]{2,1,0} %param_0.1673, f32[16,3584,49]{2,1,0} %param_0.1673), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.824.clone.2 = f32[16,3584]{1,0} reduce(f32[16,3584,49]{2,1,0} %multiply.696.clone.3, f32[] %constant_3182), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.126 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) tuple(f32[16,3584]{1,0} %reduce.880, f32[16,3584]{1,0} %reduce.824.clone.2)
}

%fused_computation.483.clone (param_0.1675: f32[16,1792,49]) -> (f32[16,1792], f32[16,1792]) {
  %param_0.1675 = f32[16,1792,49]{2,1,0} parameter(0), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %constant_3183 = f32[] constant(0)
  %reduce.881 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %param_0.1675, f32[] %constant_3183), dimensions={2}, to_apply=%region_57.4114.2
  %multiply.702.clone.3 = f32[16,1792,49]{2,1,0} multiply(f32[16,1792,49]{2,1,0} %param_0.1675, f32[16,1792,49]{2,1,0} %param_0.1675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/mul" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=46}
  %reduce.827.clone.2 = f32[16,1792]{1,0} reduce(f32[16,1792,49]{2,1,0} %multiply.702.clone.3, f32[] %constant_3183), dimensions={2}, to_apply=%region_57.4114.2
  ROOT %tuple.127 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) tuple(f32[16,1792]{1,0} %reduce.881, f32[16,1792]{1,0} %reduce.827.clone.2)
}

ENTRY %main.10683-2 (param_0: f32[1,1,7168,1792], param_1: f32[1792], param_2: f32[1792], param_3: f32[3,3,1792,3584], param_4: f32[3584], param_5: f32[3584], param_6: f32[1,1,3584,7168], param_7: f32[7168], param_8: f32[7168], param_9: f32[7168,1024], param_10: f32[1024], param_11: f32[1,1,7168,1792], param_12: f32[1792], param_13: f32[1792], param_14: f32[3,3,1792,3584], param_15: f32[3584], param_16: f32[3584], param_17: f32[1,1,3584,7168], param_18: f32[7168], param_19: f32[7168], param_20: f32[1,1,3584,1792], param_21: f32[1792], param_22: f32[1792], param_23: f32[3,3,1792,3584], param_24: f32[3584], param_25: f32[3584], param_26: f32[1,1,3584,7168], param_27: f32[7168], param_28: f32[7168], param_29: f32[1,1,3584,7168], param_30: f32[7168], param_31: f32[7168], param_32: f32[1,1,3584,896], param_33: f32[896], param_34: f32[896], param_35: f32[3,3,896,1792], param_36: f32[1792], param_37: f32[1792], param_38: f32[1,1,1792,3584], param_39: f32[3584], param_40: f32[3584], param_41: f32[1,1,3584,896], param_42: f32[896], param_43: f32[896], param_44: f32[3,3,896,1792], param_45: f32[1792], param_46: f32[1792], param_47: f32[1,1,1792,3584], param_48: f32[3584], param_49: f32[3584], param_50: f32[1,1,3584,896], param_51: f32[896], param_52: f32[896], param_53: f32[3,3,896,1792], param_54: f32[1792], param_55: f32[1792], param_56: f32[1,1,1792,3584], param_57: f32[3584], param_58: f32[3584], param_59: f32[1,1,3584,896], param_60: f32[896], param_61: f32[896], param_62: f32[3,3,896,1792], param_63: f32[1792], param_64: f32[1792], param_65: f32[1,1,1792,3584], param_66: f32[3584], param_67: f32[3584], param_68: f32[1,1,3584,896], param_69: f32[896], param_70: f32[896], param_71: f32[3,3,896,1792], param_72: f32[1792], param_73: f32[1792], param_74: f32[1,1,1792,3584], param_75: f32[3584], param_76: f32[3584], param_77: s32[16], param_78: f32[16,7,7,7168], param_79: f32[1,1,7168,1792], param_80: f32[1792], param_81: f32[1792], param_82: f32[3,3,1792,3584], param_83: f32[3584], param_84: f32[3584], param_85: f32[1,1,3584,7168], param_86: f32[7168], param_87: f32[7168], param_88: f32[7168,1024], param_89: f32[1024], param_90: f32[16,7,7,7168], param_91: f32[1,1,7168,1792], param_92: f32[1792], param_93: f32[1792], param_94: f32[3,3,1792,3584], param_95: f32[3584], param_96: f32[3584], param_97: f32[1,1,3584,7168], param_98: f32[7168], param_99: f32[7168], param_100: f32[16,14,14,3584], param_101: f32[1,1,3584,1792], param_102: f32[1792], param_103: f32[1792], param_104: f32[3,3,1792,3584], param_105: f32[3584], param_106: f32[3584], param_107: f32[1,1,3584,7168], param_108: f32[7168], param_109: f32[1,1,3584,7168], param_110: f32[7168], param_111: f32[16,14,14,3584], param_112: f32[1,1,3584,896], param_113: f32[896], param_114: f32[896], param_115: f32[3,3,896,1792], param_116: f32[1792], param_117: f32[1792], param_118: f32[1,1,1792,3584], param_119: f32[3584], param_120: f32[3584], param_121: f32[16,14,14,3584], param_122: f32[1,1,3584,896], param_123: f32[896], param_124: f32[896], param_125: f32[3,3,896,1792], param_126: f32[1792], param_127: f32[1792], param_128: f32[1,1,1792,3584], param_129: f32[3584], param_130: f32[3584], param_131: f32[16,14,14,3584], param_132: f32[1,1,3584,896], param_133: f32[896], param_134: f32[896], param_135: f32[3,3,896,1792], param_136: f32[1792], param_137: f32[1792], param_138: f32[1,1,1792,3584], param_139: f32[3584], param_140: f32[3584], param_141: f32[16,14,14,3584], param_142: f32[1,1,3584,896], param_143: f32[896], param_144: f32[896], param_145: f32[3,3,896,1792], param_146: f32[1792], param_147: f32[1792], param_148: f32[1,1,1792,3584], param_149: f32[3584], param_150: f32[3584], param_151: f32[16,14,14,3584], param_152: f32[1,1,3584,896], param_153: f32[896], param_154: f32[896], param_155: f32[3,3,896,1792], param_156: f32[1792], param_157: f32[1792], param_158: f32[1,1,1792,3584], param_159: f32[3584]) -> (f32[1,1,7168,1792], f32[1792], f32[1792], f32[3,3,1792,3584], f32[3584], /*index=5*/f32[3584], f32[1,1,3584,7168], f32[7168], f32[7168], f32[7168,1024], /*index=10*/f32[1024], f32[1,1,7168,1792], f32[1792], f32[1792], f32[3,3,1792,3584], /*index=15*/f32[3584], f32[3584], f32[1,1,3584,7168], f32[7168], f32[7168], /*index=20*/f32[1,1,3584,1792], f32[1792], f32[1792], f32[3,3,1792,3584], f32[3584], /*index=25*/f32[3584], f32[1,1,3584,7168], f32[7168], f32[7168], f32[1,1,3584,7168], /*index=30*/f32[7168], f32[7168], f32[1,1,3584,896], f32[896], f32[896], /*index=35*/f32[3,3,896,1792], f32[1792], f32[1792], f32[1,1,1792,3584], f32[3584], /*index=40*/f32[3584], f32[1,1,3584,896], f32[896], f32[896], f32[3,3,896,1792], /*index=45*/f32[1792], f32[1792], f32[1,1,1792,3584], f32[3584], f32[3584], /*index=50*/f32[1,1,3584,896], f32[896], f32[896], f32[3,3,896,1792], f32[1792], /*index=55*/f32[1792], f32[1,1,1792,3584], f32[3584], f32[3584], f32[1,1,3584,896], /*index=60*/f32[896], f32[896], f32[3,3,896,1792], f32[1792], f32[1792], /*index=65*/f32[1,1,1792,3584], f32[3584], f32[3584], f32[1,1,3584,896], f32[896], /*index=70*/f32[896], f32[3,3,896,1792], f32[1792], f32[1792], f32[1,1,1792,3584], /*index=75*/f32[3584], f32[3584], f32[16,14,14,3584]) {
  %param_78 = f32[16,7,7,7168]{3,2,1,0} parameter(78), metadata={op_name="2$start"}
  %param_79 = f32[1,1,7168,1792]{3,2,1,0} parameter(79), metadata={op_name="2$start"}
  %param_80 = f32[1792]{0} parameter(80), metadata={op_name="2$start"}
  %param_81 = f32[1792]{0} parameter(81), metadata={op_name="2$start"}
  %param_82 = f32[3,3,1792,3584]{3,2,1,0} parameter(82), metadata={op_name="2$start"}
  %param_83 = f32[3584]{0} parameter(83), metadata={op_name="2$start"}
  %param_84 = f32[3584]{0} parameter(84), metadata={op_name="2$start"}
  %param_85 = f32[1,1,3584,7168]{3,2,1,0} parameter(85), metadata={op_name="2$start"}
  %param_86 = f32[7168]{0} parameter(86), metadata={op_name="2$start"}
  %param_87 = f32[7168]{0} parameter(87), metadata={op_name="2$start"}
  %param_88 = f32[7168,1024]{1,0} parameter(88), metadata={op_name="2$start"}
  %param_89 = f32[1024]{0} parameter(89), metadata={op_name="2$start"}
  %param_77 = s32[16]{0} parameter(77), metadata={op_name="2$start"}
  %constant_577 = f32[] constant(1)
  %tuple.45 = (f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) tuple(f32[16,7,7,7168]{3,2,1,0} %param_78, f32[1,1,7168,1792]{3,2,1,0} %param_79, f32[1792]{0} %param_80, f32[1792]{0} %param_81, f32[3,3,1792,3584]{3,2,1,0} %param_82, /*index=5*/f32[3584]{0} %param_83, f32[3584]{0} %param_84, f32[1,1,3584,7168]{3,2,1,0} %param_85, f32[7168]{0} %param_86, f32[7168]{0} %param_87, /*index=10*/f32[7168,1024]{1,0} %param_88, f32[1024]{0} %param_89, s32[16]{0} %param_77, f32[] %constant_577), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2402 = (f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) bitcast((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %tuple.45)
  %get-tuple-element.560 = f32[16,7,7,7168]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.7 = f32[16,7,7,7168]{2,1,3,0} copy(f32[16,7,7,7168]{3,2,1,0} %get-tuple-element.560), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.569 = f32[7168]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.568 = f32[7168]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.566 = f32[3584]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.565 = f32[3584]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.563 = f32[1792]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.562 = f32[1792]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.561 = f32[1,1,7168,1792]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.1 = f32[1,1,7168,1792]{1,0,2,3} copy(f32[1,1,7168,1792]{3,2,1,0} %get-tuple-element.561), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv = (f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %copy.7, f32[1,1,7168,1792]{1,0,2,3} %copy.1), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element = f32[16,7,7,1792]{2,1,3,0} get-tuple-element((f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2401 = f32[16,1792,49]{2,1,0} bitcast(f32[16,7,7,1792]{2,1,3,0} %get-tuple-element)
  %fusion.483 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,49]{2,1,0} %bitcast.2401), kind=kInput, calls=%fused_computation.483.clone
  %get-tuple-element.295 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.483), index=1
  %get-tuple-element.294 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.483), index=0
  %constant_758 = f32[] constant(0)
  %reduce.246 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.294, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.479 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.295, f32[1792]{0} %reduce.246), kind=kLoop, calls=%fused_computation.479, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.474 = f32[16,7,7,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.563, f32[1792]{0} %get-tuple-element.562, f32[1792]{0} %fusion.479, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element, f32[1792]{0} %reduce.246), kind=kLoop, calls=%fused_computation.474, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.564 = f32[3,3,1792,3584]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.2 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %get-tuple-element.564), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.1 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,1792]{2,1,3,0} %fusion.474, f32[3,3,1792,3584]{1,0,2,3} %copy.2), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.1 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.1), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2397 = f32[16,3584,49]{2,1,0} bitcast(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.1)
  %fusion.473 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,49]{2,1,0} %bitcast.2397), kind=kInput, calls=%fused_computation.473.clone
  %get-tuple-element.293 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.473), index=1
  %get-tuple-element.292 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.473), index=0
  %reduce.248 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.292, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.469 = f32[3584]{0} fusion(f32[16,3584]{1,0} %get-tuple-element.293, f32[3584]{0} %reduce.248), kind=kLoop, calls=%fused_computation.469, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.464 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %get-tuple-element.566, f32[3584]{0} %get-tuple-element.565, f32[3584]{0} %fusion.469, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.1, f32[3584]{0} %reduce.248), kind=kLoop, calls=%fused_computation.464, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.567 = f32[1,1,3584,7168]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.3 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %get-tuple-element.567), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.2 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.464, f32[1,1,3584,7168]{1,0,2,3} %copy.3), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.2 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv.2), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2393 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.2)
  %fusion.463 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.2393), kind=kInput, calls=%fused_computation.463.clone
  %get-tuple-element.291 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.463), index=1
  %get-tuple-element.290 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.463), index=0
  %reduce.250 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.290, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.459 = f32[7168]{0} fusion(f32[16,7168]{1,0} %get-tuple-element.291, f32[7168]{0} %reduce.250), kind=kLoop, calls=%fused_computation.459, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.452 = f32[16,7168]{1,0} fusion(f32[16,7,7,7168]{2,1,3,0} %copy.7, f32[7168]{0} %get-tuple-element.569, f32[7168]{0} %get-tuple-element.568, f32[7168]{0} %fusion.459, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.2, /*index=5*/f32[7168]{0} %reduce.250), kind=kInput, calls=%fused_computation.452, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/reduce_sum[axes=(1, 2)]" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
  %fusion.451 = f32[16,7168]{1,0} fusion(f32[16,7168]{1,0} %fusion.452), kind=kLoop, calls=%fused_computation.451, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/div" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=135}
  %get-tuple-element.572 = f32[7168,1024]{1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.573 = f32[1024]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %broadcast.1125 = f32[16,1024]{1,0} broadcast(f32[1024]{0} %get-tuple-element.573), dimensions={1}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/Dense_0/add" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=200}
  %cublas-gemm.3 = f32[16,1024]{1,0} custom-call(f32[16,7168]{1,0} %fusion.451, f32[7168,1024]{1,0} %get-tuple-element.572, f32[16,1024]{1,0} %broadcast.1125), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/Dense_0/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=196}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  %constant_595 = f32[] constant(-inf)
  %reduce.254 = f32[16]{0} reduce(f32[16,1024]{1,0} %cublas-gemm.3, f32[] %constant_595), dimensions={1}, to_apply=%region_64.4142.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/reduce_max[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %get-tuple-element.571 = f32[] get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=13, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.570 = s32[16]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[7168,1024]{1,0}, f32[1024]{0}, s32[16]{0}, f32[]) %bitcast.2402), index=12, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.484 = (f32[16]{0}, f32[16]{0}) fusion(f32[16,1024]{1,0} %cublas-gemm.3, f32[16]{0} %reduce.254, f32[] %get-tuple-element.571, s32[16]{0} %get-tuple-element.570), kind=kInput, calls=%fused_computation.484, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/reduce_sum[axes=(1,)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %get-tuple-element.343 = f32[16]{0} get-tuple-element((f32[16]{0}, f32[16]{0}) %fusion.484), index=1
  %get-tuple-element.342 = f32[16]{0} get-tuple-element((f32[16]{0}, f32[16]{0}) %fusion.484), index=0
  %fusion.449 = f32[16,1024]{1,0} fusion(f32[16]{0} %get-tuple-element.343, f32[16]{0} %get-tuple-element.342, f32[] %get-tuple-element.571, s32[16]{0} %get-tuple-element.570, f32[16,1024]{1,0} %cublas-gemm.3, /*index=5*/f32[16]{0} %reduce.254), kind=kLoop, calls=%fused_computation.449, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/optax/_src/loss.py" source_line=170}
  %cublas-gemm.5 = f32[16,7168]{1,0} custom-call(f32[16,1024]{1,0} %fusion.449, f32[7168,1024]{1,0} %get-tuple-element.572), custom_call_target="__cublas$gemm", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/Dense_0/dot_general[dimension_numbers=(((1,), (1,)), ((), ())) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=196}, backend_config="{\"alpha_real\":0.020408162847161293,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  %fusion.448 = f32[16,7,7,7168]{2,1,3,0} fusion(f32[16,7168]{1,0} %cublas-gemm.5, f32[16,7,7,7168]{2,1,3,0} %copy.7, f32[7168]{0} %get-tuple-element.569, f32[7168]{0} %get-tuple-element.568, f32[7168]{0} %fusion.459, /*index=5*/f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.2, f32[7168]{0} %reduce.250), kind=kLoop, calls=%fused_computation.448, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.444 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7,7,7168]{2,1,3,0} %fusion.448, f32[7168]{0} %get-tuple-element.568, f32[7168]{0} %fusion.459, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.2, f32[7168]{0} %reduce.250), kind=kInput, calls=%fused_computation.444
  %get-tuple-element.287 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.444), index=0
  %reduce.258 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.287, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.288 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.444), index=1
  %fusion.445 = f32[1,1,1,7168]{3,2,1,0} fusion(f32[16,7168]{1,0} %get-tuple-element.288), kind=kLoop, calls=%fused_computation.445, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.443 = f32[16,7,7,7168]{2,1,3,0} fusion(f32[7168]{0} %reduce.258, f32[7168]{0} %reduce.250, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.2, f32[7168]{0} %fusion.459, f32[1,1,1,7168]{3,2,1,0} %fusion.445, /*index=5*/f32[7168]{0} %get-tuple-element.568, f32[16,7,7,7168]{2,1,3,0} %fusion.448), kind=kLoop, calls=%fused_computation.443, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.270 = f32[1,1,3584,7168]{1,0,3,2} bitcast(f32[1,1,3584,7168]{3,2,1,0} %get-tuple-element.567), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.3 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %fusion.443, f32[1,1,3584,7168]{1,0,3,2} %bitcast.270), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.4 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.3), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.424 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.4, f32[3584]{0} %get-tuple-element.566, f32[3584]{0} %get-tuple-element.565, f32[3584]{0} %fusion.469, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.1, /*index=5*/f32[3584]{0} %reduce.248), kind=kInput, calls=%fused_computation.424
  %get-tuple-element.285 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.424), index=1
  %reduce.260 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.285, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.286 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.424), index=2
  %fusion.439 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.286), kind=kLoop, calls=%fused_computation.439, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.437 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %reduce.260, f32[3584]{0} %reduce.248, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.1, f32[3584]{0} %fusion.469, f32[1,1,1,3584]{3,2,1,0} %fusion.439, /*index=5*/f32[3584]{0} %get-tuple-element.565, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.4, f32[3584]{0} %get-tuple-element.566), kind=kLoop, calls=%fused_computation.437, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input = (f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.437, f32[3,3,1792,3584]{1,0,2,3} %copy.2), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.6 = f32[16,7,7,1792]{2,1,3,0} get-tuple-element((f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.428 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.6, f32[1792]{0} %get-tuple-element.563, f32[1792]{0} %get-tuple-element.562, f32[1792]{0} %fusion.479, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element, /*index=5*/f32[1792]{0} %reduce.246), kind=kInput, calls=%fused_computation.428
  %get-tuple-element.282 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.428), index=1
  %reduce.262 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.282, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.283 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.428), index=2
  %fusion.433 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.283), kind=kLoop, calls=%fused_computation.433, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.431 = f32[16,7,7,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.262, f32[1792]{0} %reduce.246, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element, f32[1792]{0} %fusion.479, f32[1,1,1,1792]{3,2,1,0} %fusion.433, /*index=5*/f32[1792]{0} %get-tuple-element.562, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.6, f32[1792]{0} %get-tuple-element.563), kind=kLoop, calls=%fused_computation.431, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-filter.2 = (f32[1,1,7168,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %copy.7, f32[16,7,7,1792]{2,1,3,0} %fusion.431), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(16, 7, 7, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.7 = f32[1,1,7168,1792]{1,0,2,3} get-tuple-element((f32[1,1,7168,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.2), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(16, 7, 7, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_0 = f32[1,1,7168,1792]{3,2,1,0} parameter(0), metadata={op_name="2$start"}
  %fusion.430 = f32[1,1,7168,1792]{3,2,1,0} fusion(f32[1,1,7168,1792]{1,0,2,3} %get-tuple-element.7, f32[1,1,7168,1792]{3,2,1,0} %param_0), kind=kLoop, calls=%fused_computation.430, metadata={op_name="tuple.79"}
  %param_69 = f32[896]{0} parameter(69), metadata={op_name="2$start"}
  %param_151 = f32[16,14,14,3584]{3,2,1,0} parameter(151), metadata={op_name="2$start"}
  %param_152 = f32[1,1,3584,896]{3,2,1,0} parameter(152), metadata={op_name="2$start"}
  %param_153 = f32[896]{0} parameter(153), metadata={op_name="2$start"}
  %param_154 = f32[896]{0} parameter(154), metadata={op_name="2$start"}
  %param_155 = f32[3,3,896,1792]{3,2,1,0} parameter(155), metadata={op_name="2$start"}
  %param_156 = f32[1792]{0} parameter(156), metadata={op_name="2$start"}
  %param_157 = f32[1792]{0} parameter(157), metadata={op_name="2$start"}
  %param_158 = f32[1,1,1792,3584]{3,2,1,0} parameter(158), metadata={op_name="2$start"}
  %param_159 = f32[3584]{0} parameter(159), metadata={op_name="2$start"}
  %param_141 = f32[16,14,14,3584]{3,2,1,0} parameter(141), metadata={op_name="2$start"}
  %param_142 = f32[1,1,3584,896]{3,2,1,0} parameter(142), metadata={op_name="2$start"}
  %param_143 = f32[896]{0} parameter(143), metadata={op_name="2$start"}
  %param_144 = f32[896]{0} parameter(144), metadata={op_name="2$start"}
  %param_145 = f32[3,3,896,1792]{3,2,1,0} parameter(145), metadata={op_name="2$start"}
  %param_146 = f32[1792]{0} parameter(146), metadata={op_name="2$start"}
  %param_147 = f32[1792]{0} parameter(147), metadata={op_name="2$start"}
  %param_148 = f32[1,1,1792,3584]{3,2,1,0} parameter(148), metadata={op_name="2$start"}
  %param_149 = f32[3584]{0} parameter(149), metadata={op_name="2$start"}
  %param_150 = f32[3584]{0} parameter(150), metadata={op_name="2$start"}
  %param_131 = f32[16,14,14,3584]{3,2,1,0} parameter(131), metadata={op_name="2$start"}
  %param_132 = f32[1,1,3584,896]{3,2,1,0} parameter(132), metadata={op_name="2$start"}
  %param_133 = f32[896]{0} parameter(133), metadata={op_name="2$start"}
  %param_134 = f32[896]{0} parameter(134), metadata={op_name="2$start"}
  %param_135 = f32[3,3,896,1792]{3,2,1,0} parameter(135), metadata={op_name="2$start"}
  %param_136 = f32[1792]{0} parameter(136), metadata={op_name="2$start"}
  %param_137 = f32[1792]{0} parameter(137), metadata={op_name="2$start"}
  %param_138 = f32[1,1,1792,3584]{3,2,1,0} parameter(138), metadata={op_name="2$start"}
  %param_139 = f32[3584]{0} parameter(139), metadata={op_name="2$start"}
  %param_140 = f32[3584]{0} parameter(140), metadata={op_name="2$start"}
  %param_121 = f32[16,14,14,3584]{3,2,1,0} parameter(121), metadata={op_name="2$start"}
  %param_122 = f32[1,1,3584,896]{3,2,1,0} parameter(122), metadata={op_name="2$start"}
  %param_123 = f32[896]{0} parameter(123), metadata={op_name="2$start"}
  %param_124 = f32[896]{0} parameter(124), metadata={op_name="2$start"}
  %param_125 = f32[3,3,896,1792]{3,2,1,0} parameter(125), metadata={op_name="2$start"}
  %param_126 = f32[1792]{0} parameter(126), metadata={op_name="2$start"}
  %param_127 = f32[1792]{0} parameter(127), metadata={op_name="2$start"}
  %param_128 = f32[1,1,1792,3584]{3,2,1,0} parameter(128), metadata={op_name="2$start"}
  %param_129 = f32[3584]{0} parameter(129), metadata={op_name="2$start"}
  %param_130 = f32[3584]{0} parameter(130), metadata={op_name="2$start"}
  %param_111 = f32[16,14,14,3584]{3,2,1,0} parameter(111), metadata={op_name="2$start"}
  %param_112 = f32[1,1,3584,896]{3,2,1,0} parameter(112), metadata={op_name="2$start"}
  %param_113 = f32[896]{0} parameter(113), metadata={op_name="2$start"}
  %param_114 = f32[896]{0} parameter(114), metadata={op_name="2$start"}
  %param_115 = f32[3,3,896,1792]{3,2,1,0} parameter(115), metadata={op_name="2$start"}
  %param_116 = f32[1792]{0} parameter(116), metadata={op_name="2$start"}
  %param_117 = f32[1792]{0} parameter(117), metadata={op_name="2$start"}
  %param_118 = f32[1,1,1792,3584]{3,2,1,0} parameter(118), metadata={op_name="2$start"}
  %param_119 = f32[3584]{0} parameter(119), metadata={op_name="2$start"}
  %param_120 = f32[3584]{0} parameter(120), metadata={op_name="2$start"}
  %param_100 = f32[16,14,14,3584]{3,2,1,0} parameter(100), metadata={op_name="2$start"}
  %param_101 = f32[1,1,3584,1792]{3,2,1,0} parameter(101), metadata={op_name="2$start"}
  %param_102 = f32[1792]{0} parameter(102), metadata={op_name="2$start"}
  %param_103 = f32[1792]{0} parameter(103), metadata={op_name="2$start"}
  %param_104 = f32[3,3,1792,3584]{3,2,1,0} parameter(104), metadata={op_name="2$start"}
  %param_105 = f32[3584]{0} parameter(105), metadata={op_name="2$start"}
  %param_106 = f32[3584]{0} parameter(106), metadata={op_name="2$start"}
  %param_107 = f32[1,1,3584,7168]{3,2,1,0} parameter(107), metadata={op_name="2$start"}
  %param_108 = f32[7168]{0} parameter(108), metadata={op_name="2$start"}
  %param_109 = f32[1,1,3584,7168]{3,2,1,0} parameter(109), metadata={op_name="2$start"}
  %param_110 = f32[7168]{0} parameter(110), metadata={op_name="2$start"}
  %param_90 = f32[16,7,7,7168]{3,2,1,0} parameter(90), metadata={op_name="2$start"}
  %param_91 = f32[1,1,7168,1792]{3,2,1,0} parameter(91), metadata={op_name="2$start"}
  %param_92 = f32[1792]{0} parameter(92), metadata={op_name="2$start"}
  %param_93 = f32[1792]{0} parameter(93), metadata={op_name="2$start"}
  %param_94 = f32[3,3,1792,3584]{3,2,1,0} parameter(94), metadata={op_name="2$start"}
  %param_95 = f32[3584]{0} parameter(95), metadata={op_name="2$start"}
  %param_96 = f32[3584]{0} parameter(96), metadata={op_name="2$start"}
  %param_97 = f32[1,1,3584,7168]{3,2,1,0} parameter(97), metadata={op_name="2$start"}
  %param_98 = f32[7168]{0} parameter(98), metadata={op_name="2$start"}
  %param_99 = f32[7168]{0} parameter(99), metadata={op_name="2$start"}
  %bitcast.285 = f32[1,1,7168,1792]{1,0,3,2} bitcast(f32[1,1,7168,1792]{3,2,1,0} %get-tuple-element.561), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %broadcast.1108 = f32[7168]{0} broadcast(f32[] %constant_758), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_2/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %cudnn-conv-bias-activation.2 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,1792]{2,1,3,0} %fusion.431, f32[1,1,7168,1792]{1,0,3,2} %bitcast.285, f32[7168]{0} %broadcast.1108, f32[16,7,7,7168]{2,1,3,0} %fusion.448), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.75 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.2), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.47 = (f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) tuple(f32[16,7,7,7168]{3,2,1,0} %param_90, f32[1,1,7168,1792]{3,2,1,0} %param_91, f32[1792]{0} %param_92, f32[1792]{0} %param_93, f32[3,3,1792,3584]{3,2,1,0} %param_94, /*index=5*/f32[3584]{0} %param_95, f32[3584]{0} %param_96, f32[1,1,3584,7168]{3,2,1,0} %param_97, f32[7168]{0} %param_98, f32[7168]{0} %param_99, /*index=10*/f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.75), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2403 = (f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) bitcast((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %tuple.47)
  %get-tuple-element.596 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.586 = f32[16,7,7,7168]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.12 = f32[16,7,7,7168]{2,1,3,0} copy(f32[16,7,7,7168]{3,2,1,0} %get-tuple-element.586), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.417 = f32[16,7,7,7168]{2,1,3,0} fusion(f32[16,7,7,7168]{2,1,3,0} %copy.12), kind=kLoop, calls=%fused_computation.417, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.595 = f32[7168]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.592 = f32[3584]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.591 = f32[3584]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.589 = f32[1792]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.588 = f32[1792]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.587 = f32[1,1,7168,1792]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.13 = f32[1,1,7168,1792]{1,0,2,3} copy(f32[1,1,7168,1792]{3,2,1,0} %get-tuple-element.587), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.5 = (f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %fusion.417, f32[1,1,7168,1792]{1,0,2,3} %copy.13), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.9 = f32[16,7,7,1792]{2,1,3,0} get-tuple-element((f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.5), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2389 = f32[16,1792,49]{2,1,0} bitcast(f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.9)
  %fusion.416 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,49]{2,1,0} %bitcast.2389), kind=kInput, calls=%fused_computation.416.clone
  %get-tuple-element.280 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.416), index=1
  %get-tuple-element.279 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.416), index=0
  %reduce.267 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.279, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.412 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.280, f32[1792]{0} %reduce.267), kind=kLoop, calls=%fused_computation.412, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.407 = f32[16,7,7,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.589, f32[1792]{0} %get-tuple-element.588, f32[1792]{0} %fusion.412, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.9, f32[1792]{0} %reduce.267), kind=kLoop, calls=%fused_computation.407, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.590 = f32[3,3,1792,3584]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.14 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %get-tuple-element.590), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.6 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,1792]{2,1,3,0} %fusion.407, f32[3,3,1792,3584]{1,0,2,3} %copy.14), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.10 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.6), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2385 = f32[16,3584,49]{2,1,0} bitcast(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.10)
  %fusion.406 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,49]{2,1,0} %bitcast.2385), kind=kInput, calls=%fused_computation.406.clone
  %get-tuple-element.278 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.406), index=1
  %get-tuple-element.277 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.406), index=0
  %reduce.269 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.277, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.402 = f32[3584]{0} fusion(f32[16,3584]{1,0} %get-tuple-element.278, f32[3584]{0} %reduce.269), kind=kLoop, calls=%fused_computation.402, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.397 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %get-tuple-element.592, f32[3584]{0} %get-tuple-element.591, f32[3584]{0} %fusion.402, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.10, f32[3584]{0} %reduce.269), kind=kLoop, calls=%fused_computation.397, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.593 = f32[1,1,3584,7168]{3,2,1,0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.15 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %get-tuple-element.593), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.7 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.397, f32[1,1,3584,7168]{1,0,2,3} %copy.15), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.11 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv.7), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2381 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.11)
  %fusion.396 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.2381), kind=kInput, calls=%fused_computation.396.clone
  %get-tuple-element.275 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.396), index=0
  %reduce.271 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.275, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.594 = f32[7168]{0} get-tuple-element((f32[16,7,7,7168]{3,2,1,0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=10*/f32[16,7,7,7168]{2,1,3,0}) %bitcast.2403), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.276 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.396), index=1
  %fusion.392 = f32[7168]{0} fusion(f32[16,7168]{1,0} %get-tuple-element.276, f32[7168]{0} %reduce.271), kind=kLoop, calls=%fused_computation.392, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.388 = f32[16,7,7,7168]{2,1,3,0} fusion(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.596, f32[16,7,7,7168]{2,1,3,0} %fusion.417, f32[7168]{0} %get-tuple-element.595, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.11, f32[7168]{0} %reduce.271, /*index=5*/f32[7168]{0} %get-tuple-element.594, f32[7168]{0} %fusion.392), kind=kLoop, calls=%fused_computation.388, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.384 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7,7,7168]{2,1,3,0} %fusion.388, f32[7168]{0} %get-tuple-element.594, f32[7168]{0} %fusion.392, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.11, f32[7168]{0} %reduce.271), kind=kInput, calls=%fused_computation.384
  %get-tuple-element.272 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.384), index=0
  %reduce.274 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.272, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.273 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.384), index=1
  %fusion.385 = f32[1,1,1,7168]{3,2,1,0} fusion(f32[16,7168]{1,0} %get-tuple-element.273), kind=kLoop, calls=%fused_computation.385, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.383 = f32[16,7,7,7168]{2,1,3,0} fusion(f32[7168]{0} %reduce.274, f32[7168]{0} %reduce.271, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.11, f32[7168]{0} %fusion.392, f32[1,1,1,7168]{3,2,1,0} %fusion.385, /*index=5*/f32[7168]{0} %get-tuple-element.594, f32[16,7,7,7168]{2,1,3,0} %fusion.388), kind=kLoop, calls=%fused_computation.383, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.305 = f32[1,1,3584,7168]{1,0,3,2} bitcast(f32[1,1,3584,7168]{3,2,1,0} %get-tuple-element.593), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.8 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %fusion.383, f32[1,1,3584,7168]{1,0,3,2} %bitcast.305), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.13 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.364 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.13, f32[3584]{0} %get-tuple-element.592, f32[3584]{0} %get-tuple-element.591, f32[3584]{0} %fusion.402, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.10, /*index=5*/f32[3584]{0} %reduce.269), kind=kInput, calls=%fused_computation.364
  %get-tuple-element.270 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.364), index=1
  %reduce.276 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.270, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.271 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.364), index=2
  %fusion.379 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.271), kind=kLoop, calls=%fused_computation.379, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.377 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %reduce.276, f32[3584]{0} %reduce.269, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.10, f32[3584]{0} %fusion.402, f32[1,1,1,3584]{3,2,1,0} %fusion.379, /*index=5*/f32[3584]{0} %get-tuple-element.591, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.13, f32[3584]{0} %get-tuple-element.592), kind=kLoop, calls=%fused_computation.377, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.1 = (f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.377, f32[3,3,1792,3584]{1,0,2,3} %copy.14), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.15 = f32[16,7,7,1792]{2,1,3,0} get-tuple-element((f32[16,7,7,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.1), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.368 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.15, f32[1792]{0} %get-tuple-element.589, f32[1792]{0} %get-tuple-element.588, f32[1792]{0} %fusion.412, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.9, /*index=5*/f32[1792]{0} %reduce.267), kind=kInput, calls=%fused_computation.368
  %get-tuple-element.267 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.368), index=1
  %reduce.278 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.267, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.268 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.368), index=2
  %fusion.373 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.268), kind=kLoop, calls=%fused_computation.373, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.371 = f32[16,7,7,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.278, f32[1792]{0} %reduce.267, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.9, f32[1792]{0} %fusion.412, f32[1,1,1,1792]{3,2,1,0} %fusion.373, /*index=5*/f32[1792]{0} %get-tuple-element.588, f32[16,7,7,1792]{2,1,3,0} %get-tuple-element.15, f32[1792]{0} %get-tuple-element.589), kind=kLoop, calls=%fused_computation.371, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.320 = f32[1,1,7168,1792]{1,0,3,2} bitcast(f32[1,1,7168,1792]{3,2,1,0} %get-tuple-element.587), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.5 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,1792]{2,1,3,0} %fusion.371, f32[1,1,7168,1792]{1,0,3,2} %bitcast.320, f32[7168]{0} %broadcast.1108, f32[16,7,7,7168]{2,1,3,0} %fusion.388), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(1, 1, 7168, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.76 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.5), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.358 = f32[16,7,7,7168]{2,1,3,0} fusion(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.76, f32[16,7,7,7168]{2,1,3,0} %copy.12), kind=kLoop, calls=%fused_computation.358, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %tuple.49 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) tuple(f32[16,14,14,3584]{3,2,1,0} %param_100, f32[1,1,3584,1792]{3,2,1,0} %param_101, f32[1792]{0} %param_102, f32[1792]{0} %param_103, f32[3,3,1792,3584]{3,2,1,0} %param_104, /*index=5*/f32[3584]{0} %param_105, f32[3584]{0} %param_106, f32[1,1,3584,7168]{3,2,1,0} %param_107, f32[7168]{0} %param_108, f32[1,1,3584,7168]{3,2,1,0} %param_109, /*index=10*/f32[7168]{0} %param_110, f32[16,7,7,7168]{2,1,3,0} %fusion.358), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2404 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) bitcast((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %tuple.49)
  %get-tuple-element.607 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.610 = f32[7168]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_30 = f32[7168]{0} parameter(30), metadata={op_name="2$start"}
  %bitcast.2358 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.607)
  %get-tuple-element.608 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.29 = f32[16,14,14,3584]{2,1,3,0} copy(f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.608), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.609 = f32[1,1,3584,7168]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.34 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %get-tuple-element.609), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.10 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.29, f32[1,1,3584,7168]{1,0,2,3} %copy.34), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.18 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv.10), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(2, 2) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2361 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.18)
  %bitcast.2365 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.18)
  %fusion.303 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.2365), kind=kInput, calls=%fused_computation.303.clone
  %get-tuple-element.242 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.303), index=1
  %reduce.283 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.242, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.616 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.615 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.613 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.612 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.611 = f32[1,1,3584,1792]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.24 = f32[1,1,3584,1792]{1,0,2,3} copy(f32[1,1,3584,1792]{3,2,1,0} %get-tuple-element.611), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.11 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.29, f32[1,1,3584,1792]{1,0,2,3} %copy.24), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.20 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.11), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2377 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.20)
  %fusion.357 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.2377), kind=kInput, calls=%fused_computation.357.clone
  %get-tuple-element.265 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.357), index=1
  %get-tuple-element.264 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.357), index=0
  %reduce.286 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.264, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.353 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.265, f32[1792]{0} %reduce.286), kind=kLoop, calls=%fused_computation.353, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.348 = f32[16,15,15,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.613, f32[1792]{0} %get-tuple-element.612, f32[1792]{0} %fusion.353, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.20, f32[1792]{0} %reduce.286), kind=kLoop, calls=%fused_computation.348, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.614 = f32[3,3,1792,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.25 = f32[3,3,1792,3584]{1,0,2,3} copy(f32[3,3,1792,3584]{3,2,1,0} %get-tuple-element.614), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.12 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,15,15,1792]{2,1,3,0} %fusion.348, f32[3,3,1792,3584]{1,0,2,3} %copy.25), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.21 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.12), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(2, 2) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2373 = f32[16,3584,49]{2,1,0} bitcast(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.21)
  %fusion.347 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,49]{2,1,0} %bitcast.2373), kind=kInput, calls=%fused_computation.347.clone
  %get-tuple-element.263 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.347), index=1
  %get-tuple-element.262 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.347), index=0
  %reduce.288 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.262, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.343 = f32[3584]{0} fusion(f32[16,3584]{1,0} %get-tuple-element.263, f32[3584]{0} %reduce.288), kind=kLoop, calls=%fused_computation.343, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.338 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %get-tuple-element.616, f32[3584]{0} %get-tuple-element.615, f32[3584]{0} %fusion.343, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.21, f32[3584]{0} %reduce.288), kind=kLoop, calls=%fused_computation.338, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.617 = f32[1,1,3584,7168]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.26 = f32[1,1,3584,7168]{1,0,2,3} copy(f32[1,1,3584,7168]{3,2,1,0} %get-tuple-element.617), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.13 = (f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.338, f32[1,1,3584,7168]{1,0,2,3} %copy.26), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.22 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, u8[0]{0}) %cudnn-conv.13), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2355 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.22)
  %bitcast.2369 = f32[16,7168,49]{2,1,0} bitcast(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.22)
  %fusion.337 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.2369), kind=kInput, calls=%fused_computation.337.clone
  %get-tuple-element.254 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.337), index=1
  %reduce.291 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.254, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.296 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7168,49]{2,1,0} %bitcast.2358, f32[16,7168,49]{2,1,0} %bitcast.2361, f32[7168]{0} %reduce.283, f32[16,7168,49]{2,1,0} %bitcast.2355, f32[7168]{0} %reduce.291), kind=kInput, calls=%fused_computation.296.clone
  %get-tuple-element.258 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.296), index=0
  %fusion.295 = f32[1,1,1,7168]{3,2,1,0} fusion(f32[16,7168]{1,0} %get-tuple-element.258), kind=kLoop, calls=%fused_computation.295, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.241 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.303), index=0
  %fusion.291 = (f32[7168]{0}, f32[7168]{0}) fusion(f32[7168]{0} %param_30, f32[1,1,1,7168]{3,2,1,0} %fusion.295, f32[7168]{0} %reduce.283, f32[16,7168]{1,0} %get-tuple-element.241), kind=kLoop, calls=%fused_computation.291, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %get-tuple-element.240 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}) %fusion.291), index=1
  %get-tuple-element.618 = f32[7168]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=5*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=10*/f32[7168]{0}, f32[16,7,7,7168]{2,1,3,0}) %bitcast.2404), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_27 = f32[7168]{0} parameter(27), metadata={op_name="2$start"}
  %get-tuple-element.259 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.296), index=1
  %fusion.329 = f32[1,1,1,7168]{3,2,1,0} fusion(f32[16,7168]{1,0} %get-tuple-element.259), kind=kLoop, calls=%fused_computation.329, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 7168) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.253 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.337), index=0
  %fusion.305 = (f32[7168]{0}, f32[7168]{0}) fusion(f32[7168]{0} %param_27, f32[1,1,1,7168]{3,2,1,0} %fusion.329, f32[7168]{0} %reduce.291, f32[16,7168]{1,0} %get-tuple-element.253), kind=kLoop, calls=%fused_computation.305, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %get-tuple-element.252 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}) %fusion.305), index=1
  %fusion.294 = (f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) fusion(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.607, f32[7168]{0} %get-tuple-element.610, f32[7168]{0} %get-tuple-element.240, f32[7168]{0} %get-tuple-element.618, f32[7168]{0} %get-tuple-element.252), kind=kInput, calls=%fused_computation.294
  %get-tuple-element.256 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.294), index=1
  %reduce.293 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.256, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.255 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.294), index=0
  %reduce.285 = f32[7168]{0} reduce(f32[16,7168]{1,0} %get-tuple-element.255, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/norm_proj/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.327 = (f32[16,7,7,7168]{2,1,3,0}, f32[16,7,7,7168]{2,1,3,0}) fusion(f32[7168]{0} %reduce.293, f32[7168]{0} %reduce.291, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.22, f32[7168]{0} %get-tuple-element.252, f32[1,1,1,7168]{3,2,1,0} %fusion.329, /*index=5*/f32[7168]{0} %get-tuple-element.618, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.607, f32[7168]{0} %reduce.285, f32[7168]{0} %reduce.283, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.18, /*index=10*/f32[7168]{0} %get-tuple-element.240, f32[1,1,1,7168]{3,2,1,0} %fusion.295, f32[7168]{0} %get-tuple-element.610), kind=kLoop, calls=%fused_computation.327, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.260 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, f32[16,7,7,7168]{2,1,3,0}) %fusion.327), index=0
  %bitcast.340 = f32[1,1,3584,7168]{1,0,3,2} bitcast(f32[1,1,3584,7168]{3,2,1,0} %get-tuple-element.617), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.14 = (f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.260, f32[1,1,3584,7168]{1,0,3,2} %bitcast.340), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.24 = f32[16,7,7,3584]{2,1,3,0} get-tuple-element((f32[16,7,7,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.14), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.308 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.24, f32[3584]{0} %get-tuple-element.616, f32[3584]{0} %get-tuple-element.615, f32[3584]{0} %fusion.343, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.21, /*index=5*/f32[3584]{0} %reduce.288), kind=kInput, calls=%fused_computation.308
  %get-tuple-element.249 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.308), index=1
  %reduce.295 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.249, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.250 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.308), index=2
  %fusion.323 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.250), kind=kLoop, calls=%fused_computation.323, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.321 = f32[16,7,7,3584]{2,1,3,0} fusion(f32[3584]{0} %reduce.295, f32[3584]{0} %reduce.288, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.21, f32[3584]{0} %fusion.343, f32[1,1,1,3584]{3,2,1,0} %fusion.323, /*index=5*/f32[3584]{0} %get-tuple-element.615, f32[16,7,7,3584]{2,1,3,0} %get-tuple-element.24, f32[3584]{0} %get-tuple-element.616), kind=kLoop, calls=%fused_computation.321, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.9 = (f32[16,15,15,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.321, f32[3,3,1792,3584]{1,0,2,3} %copy.25), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((2, 1), (2, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(3, 3, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.83 = f32[16,15,15,1792]{2,1,3,0} get-tuple-element((f32[16,15,15,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.9), index=0
  %fusion.312 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,15,15,1792]{2,1,3,0} %get-tuple-element.83, f32[1792]{0} %get-tuple-element.613, f32[1792]{0} %get-tuple-element.612, f32[1792]{0} %fusion.353, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.20, /*index=5*/f32[1792]{0} %reduce.286), kind=kInput, calls=%fused_computation.312
  %get-tuple-element.246 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.312), index=1
  %reduce.297 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.246, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.247 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.312), index=2
  %fusion.317 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.247), kind=kLoop, calls=%fused_computation.317, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.315 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.297, f32[1792]{0} %reduce.286, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.20, f32[1792]{0} %fusion.353, f32[1,1,1,1792]{3,2,1,0} %fusion.317, /*index=5*/f32[1792]{0} %get-tuple-element.612, f32[16,15,15,1792]{2,1,3,0} %get-tuple-element.83, f32[1792]{0} %get-tuple-element.613), kind=kLoop, calls=%fused_computation.315, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.365 = f32[1,1,3584,1792]{1,0,3,2} bitcast(f32[1,1,3584,1792]{3,2,1,0} %get-tuple-element.611), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %broadcast.1098 = f32[3584]{0} broadcast(f32[] %constant_758), dimensions={}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/BatchNorm_1/max" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %get-tuple-element.261 = f32[16,7,7,7168]{2,1,3,0} get-tuple-element((f32[16,7,7,7168]{2,1,3,0}, f32[16,7,7,7168]{2,1,3,0}) %fusion.327), index=1
  %cudnn-conv-bw-input.3 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.261, f32[1,1,3584,7168]{1,0,2,3} %copy.34), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.29 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.3), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(2, 2) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(1, 1, 3584, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %cudnn-conv-bias-activation.8 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.315, f32[1,1,3584,1792]{1,0,3,2} %bitcast.365, f32[3584]{0} %broadcast.1098, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.29), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 3584, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.77 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.51 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) tuple(f32[16,14,14,3584]{3,2,1,0} %param_111, f32[1,1,3584,896]{3,2,1,0} %param_112, f32[896]{0} %param_113, f32[896]{0} %param_114, f32[3,3,896,1792]{3,2,1,0} %param_115, /*index=5*/f32[1792]{0} %param_116, f32[1792]{0} %param_117, f32[1,1,1792,3584]{3,2,1,0} %param_118, f32[3584]{0} %param_119, f32[3584]{0} %param_120, /*index=10*/f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.77), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2405 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) bitcast((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %tuple.51)
  %get-tuple-element.642 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.632 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.46 = f32[16,14,14,3584]{2,1,3,0} copy(f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.632), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.641 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.638 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.637 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.635 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.634 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.633 = f32[1,1,3584,896]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.40 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.633), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.16 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.46, f32[1,1,3584,896]{1,0,2,3} %copy.40), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.30 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.16), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2349 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.30)
  %fusion.290 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.2349), kind=kInput, calls=%fused_computation.290.clone
  %get-tuple-element.238 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.290), index=1
  %get-tuple-element.237 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.290), index=0
  %reduce.302 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.237, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.286 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.238, f32[896]{0} %reduce.302), kind=kLoop, calls=%fused_computation.286, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.281 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.635, f32[896]{0} %get-tuple-element.634, f32[896]{0} %fusion.286, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.30, f32[896]{0} %reduce.302), kind=kLoop, calls=%fused_computation.281, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.636 = f32[3,3,896,1792]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.41 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %get-tuple-element.636), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.17 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.281, f32[3,3,896,1792]{1,0,2,3} %copy.41), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.31 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.17), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2345 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.31)
  %fusion.280 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.2345), kind=kInput, calls=%fused_computation.280.clone
  %get-tuple-element.236 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.280), index=1
  %get-tuple-element.235 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.280), index=0
  %reduce.304 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.235, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.276 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.236, f32[1792]{0} %reduce.304), kind=kLoop, calls=%fused_computation.276, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.271 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.638, f32[1792]{0} %get-tuple-element.637, f32[1792]{0} %fusion.276, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.31, f32[1792]{0} %reduce.304), kind=kLoop, calls=%fused_computation.271, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.639 = f32[1,1,1792,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.42 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.639), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.18 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.271, f32[1,1,1792,3584]{1,0,2,3} %copy.42), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.32 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.18), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2341 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.32)
  %fusion.270 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.2341), kind=kInput, calls=%fused_computation.270.clone
  %get-tuple-element.233 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.270), index=0
  %reduce.306 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.233, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.640 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2405), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.234 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.270), index=1
  %fusion.266 = f32[3584]{0} fusion(f32[16,3584]{1,0} %get-tuple-element.234, f32[3584]{0} %reduce.306), kind=kLoop, calls=%fused_computation.266, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.262 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.642, f32[16,14,14,3584]{2,1,3,0} %copy.46, f32[3584]{0} %get-tuple-element.641, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.32, f32[3584]{0} %reduce.306, /*index=5*/f32[3584]{0} %get-tuple-element.640, f32[3584]{0} %fusion.266), kind=kLoop, calls=%fused_computation.262, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.258 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %fusion.262, f32[3584]{0} %get-tuple-element.640, f32[3584]{0} %fusion.266, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.32, f32[3584]{0} %reduce.306), kind=kInput, calls=%fused_computation.258
  %get-tuple-element.230 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.258), index=0
  %reduce.309 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.230, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.231 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.258), index=1
  %fusion.259 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.231), kind=kLoop, calls=%fused_computation.259, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.257 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[3584]{0} %reduce.309, f32[3584]{0} %reduce.306, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.32, f32[3584]{0} %fusion.266, f32[1,1,1,3584]{3,2,1,0} %fusion.259, /*index=5*/f32[3584]{0} %get-tuple-element.640, f32[16,14,14,3584]{2,1,3,0} %fusion.262), kind=kLoop, calls=%fused_computation.257, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.385 = f32[1,1,1792,3584]{1,0,3,2} bitcast(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.639), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.19 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.257, f32[1,1,1792,3584]{1,0,3,2} %bitcast.385), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.34 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.19), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.238 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.34, f32[1792]{0} %get-tuple-element.638, f32[1792]{0} %get-tuple-element.637, f32[1792]{0} %fusion.276, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.31, /*index=5*/f32[1792]{0} %reduce.304), kind=kInput, calls=%fused_computation.238
  %get-tuple-element.228 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.238), index=1
  %reduce.311 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.228, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.229 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.238), index=2
  %fusion.253 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.229), kind=kLoop, calls=%fused_computation.253, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.251 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.311, f32[1792]{0} %reduce.304, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.31, f32[1792]{0} %fusion.276, f32[1,1,1,1792]{3,2,1,0} %fusion.253, /*index=5*/f32[1792]{0} %get-tuple-element.637, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.34, f32[1792]{0} %get-tuple-element.638), kind=kLoop, calls=%fused_computation.251, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.4 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.251, f32[3,3,896,1792]{1,0,2,3} %copy.41), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.36 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.4), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.242 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.36, f32[896]{0} %get-tuple-element.635, f32[896]{0} %get-tuple-element.634, f32[896]{0} %fusion.286, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.30, /*index=5*/f32[896]{0} %reduce.302), kind=kInput, calls=%fused_computation.242
  %get-tuple-element.225 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.242), index=1
  %reduce.313 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.225, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.226 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.242), index=2
  %fusion.247 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.226), kind=kLoop, calls=%fused_computation.247, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.245 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %reduce.313, f32[896]{0} %reduce.302, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.30, f32[896]{0} %fusion.286, f32[1,1,1,896]{3,2,1,0} %fusion.247, /*index=5*/f32[896]{0} %get-tuple-element.634, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.36, f32[896]{0} %get-tuple-element.635), kind=kLoop, calls=%fused_computation.245, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.400 = f32[1,1,3584,896]{1,0,3,2} bitcast(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.633), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.11 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.245, f32[1,1,3584,896]{1,0,3,2} %bitcast.400, f32[3584]{0} %broadcast.1098, f32[16,14,14,3584]{2,1,3,0} %fusion.262), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.78 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.11), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.53 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) tuple(f32[16,14,14,3584]{3,2,1,0} %param_121, f32[1,1,3584,896]{3,2,1,0} %param_122, f32[896]{0} %param_123, f32[896]{0} %param_124, f32[3,3,896,1792]{3,2,1,0} %param_125, /*index=5*/f32[1792]{0} %param_126, f32[1792]{0} %param_127, f32[1,1,1792,3584]{3,2,1,0} %param_128, f32[3584]{0} %param_129, f32[3584]{0} %param_130, /*index=10*/f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.78), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2406 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) bitcast((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %tuple.53)
  %get-tuple-element.663 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.653 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.58 = f32[16,14,14,3584]{2,1,3,0} copy(f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.653), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.662 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.659 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.658 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.656 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.655 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.654 = f32[1,1,3584,896]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.52 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.654), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.21 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.58, f32[1,1,3584,896]{1,0,2,3} %copy.52), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.39 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.21), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2337 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.39)
  %fusion.232 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.2337), kind=kInput, calls=%fused_computation.232.clone
  %get-tuple-element.223 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.232), index=1
  %get-tuple-element.222 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.232), index=0
  %reduce.317 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.222, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.228 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.223, f32[896]{0} %reduce.317), kind=kLoop, calls=%fused_computation.228, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.223 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.656, f32[896]{0} %get-tuple-element.655, f32[896]{0} %fusion.228, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.39, f32[896]{0} %reduce.317), kind=kLoop, calls=%fused_computation.223, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.657 = f32[3,3,896,1792]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.53 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %get-tuple-element.657), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.22 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.223, f32[3,3,896,1792]{1,0,2,3} %copy.53), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.40 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.22), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2333 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.40)
  %fusion.222 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.2333), kind=kInput, calls=%fused_computation.222.clone
  %get-tuple-element.221 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.222), index=1
  %get-tuple-element.220 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.222), index=0
  %reduce.319 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.220, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.218 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.221, f32[1792]{0} %reduce.319), kind=kLoop, calls=%fused_computation.218, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.213 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.659, f32[1792]{0} %get-tuple-element.658, f32[1792]{0} %fusion.218, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.40, f32[1792]{0} %reduce.319), kind=kLoop, calls=%fused_computation.213, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.660 = f32[1,1,1792,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.54 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.660), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.23 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.213, f32[1,1,1792,3584]{1,0,2,3} %copy.54), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.41 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.23), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2329 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.41)
  %fusion.212 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.2329), kind=kInput, calls=%fused_computation.212.clone
  %get-tuple-element.218 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.212), index=0
  %reduce.321 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.218, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.661 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2406), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.219 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.212), index=1
  %fusion.208 = f32[3584]{0} fusion(f32[16,3584]{1,0} %get-tuple-element.219, f32[3584]{0} %reduce.321), kind=kLoop, calls=%fused_computation.208, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.204 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.663, f32[16,14,14,3584]{2,1,3,0} %copy.58, f32[3584]{0} %get-tuple-element.662, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.41, f32[3584]{0} %reduce.321, /*index=5*/f32[3584]{0} %get-tuple-element.661, f32[3584]{0} %fusion.208), kind=kLoop, calls=%fused_computation.204, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.200 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %fusion.204, f32[3584]{0} %get-tuple-element.661, f32[3584]{0} %fusion.208, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.41, f32[3584]{0} %reduce.321), kind=kInput, calls=%fused_computation.200
  %get-tuple-element.215 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.200), index=0
  %reduce.324 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.215, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.216 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.200), index=1
  %fusion.201 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.216), kind=kLoop, calls=%fused_computation.201, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.199 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[3584]{0} %reduce.324, f32[3584]{0} %reduce.321, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.41, f32[3584]{0} %fusion.208, f32[1,1,1,3584]{3,2,1,0} %fusion.201, /*index=5*/f32[3584]{0} %get-tuple-element.661, f32[16,14,14,3584]{2,1,3,0} %fusion.204), kind=kLoop, calls=%fused_computation.199, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.420 = f32[1,1,1792,3584]{1,0,3,2} bitcast(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.660), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.24 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.199, f32[1,1,1792,3584]{1,0,3,2} %bitcast.420), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.43 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.24), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.180 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.43, f32[1792]{0} %get-tuple-element.659, f32[1792]{0} %get-tuple-element.658, f32[1792]{0} %fusion.218, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.40, /*index=5*/f32[1792]{0} %reduce.319), kind=kInput, calls=%fused_computation.180
  %get-tuple-element.213 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.180), index=1
  %reduce.326 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.213, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.214 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.180), index=2
  %fusion.195 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.214), kind=kLoop, calls=%fused_computation.195, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.193 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.326, f32[1792]{0} %reduce.319, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.40, f32[1792]{0} %fusion.218, f32[1,1,1,1792]{3,2,1,0} %fusion.195, /*index=5*/f32[1792]{0} %get-tuple-element.658, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.43, f32[1792]{0} %get-tuple-element.659), kind=kLoop, calls=%fused_computation.193, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.5 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.193, f32[3,3,896,1792]{1,0,2,3} %copy.53), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.45 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.5), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.184 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.45, f32[896]{0} %get-tuple-element.656, f32[896]{0} %get-tuple-element.655, f32[896]{0} %fusion.228, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.39, /*index=5*/f32[896]{0} %reduce.317), kind=kInput, calls=%fused_computation.184
  %get-tuple-element.210 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.184), index=1
  %reduce.328 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.210, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.211 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.184), index=2
  %fusion.189 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.211), kind=kLoop, calls=%fused_computation.189, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.187 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %reduce.328, f32[896]{0} %reduce.317, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.39, f32[896]{0} %fusion.228, f32[1,1,1,896]{3,2,1,0} %fusion.189, /*index=5*/f32[896]{0} %get-tuple-element.655, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.45, f32[896]{0} %get-tuple-element.656), kind=kLoop, calls=%fused_computation.187, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.435 = f32[1,1,3584,896]{1,0,3,2} bitcast(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.654), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.14 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.187, f32[1,1,3584,896]{1,0,3,2} %bitcast.435, f32[3584]{0} %broadcast.1098, f32[16,14,14,3584]{2,1,3,0} %fusion.204), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.79 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.14), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.55 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) tuple(f32[16,14,14,3584]{3,2,1,0} %param_131, f32[1,1,3584,896]{3,2,1,0} %param_132, f32[896]{0} %param_133, f32[896]{0} %param_134, f32[3,3,896,1792]{3,2,1,0} %param_135, /*index=5*/f32[1792]{0} %param_136, f32[1792]{0} %param_137, f32[1,1,1792,3584]{3,2,1,0} %param_138, f32[3584]{0} %param_139, f32[3584]{0} %param_140, /*index=10*/f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.79), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2407 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) bitcast((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %tuple.55)
  %get-tuple-element.684 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.674 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.70 = f32[16,14,14,3584]{2,1,3,0} copy(f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.674), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.683 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.680 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.679 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.677 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.676 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.675 = f32[1,1,3584,896]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.64 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.26 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.70, f32[1,1,3584,896]{1,0,2,3} %copy.64), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.48 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.26), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2325 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.48)
  %fusion.174 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.2325), kind=kInput, calls=%fused_computation.174.clone
  %get-tuple-element.208 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.174), index=1
  %get-tuple-element.207 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.174), index=0
  %reduce.332 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.207, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.170 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.208, f32[896]{0} %reduce.332), kind=kLoop, calls=%fused_computation.170, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.165 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.677, f32[896]{0} %get-tuple-element.676, f32[896]{0} %fusion.170, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.48, f32[896]{0} %reduce.332), kind=kLoop, calls=%fused_computation.165, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.678 = f32[3,3,896,1792]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.65 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %get-tuple-element.678), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.27 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.165, f32[3,3,896,1792]{1,0,2,3} %copy.65), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.49 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.27), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2321 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.49)
  %fusion.164 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.2321), kind=kInput, calls=%fused_computation.164.clone
  %get-tuple-element.206 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.164), index=1
  %get-tuple-element.205 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.164), index=0
  %reduce.334 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.205, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.160 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.206, f32[1792]{0} %reduce.334), kind=kLoop, calls=%fused_computation.160, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.155 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.680, f32[1792]{0} %get-tuple-element.679, f32[1792]{0} %fusion.160, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.49, f32[1792]{0} %reduce.334), kind=kLoop, calls=%fused_computation.155, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.681 = f32[1,1,1792,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.66 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.681), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.28 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.155, f32[1,1,1792,3584]{1,0,2,3} %copy.66), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.50 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.28), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2317 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.50)
  %fusion.154 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.2317), kind=kInput, calls=%fused_computation.154.clone
  %get-tuple-element.203 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.154), index=0
  %reduce.336 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.203, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.682 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2407), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.204 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.154), index=1
  %fusion.150 = f32[3584]{0} fusion(f32[16,3584]{1,0} %get-tuple-element.204, f32[3584]{0} %reduce.336), kind=kLoop, calls=%fused_computation.150, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.146 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.684, f32[16,14,14,3584]{2,1,3,0} %copy.70, f32[3584]{0} %get-tuple-element.683, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.50, f32[3584]{0} %reduce.336, /*index=5*/f32[3584]{0} %get-tuple-element.682, f32[3584]{0} %fusion.150), kind=kLoop, calls=%fused_computation.146, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.142 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %fusion.146, f32[3584]{0} %get-tuple-element.682, f32[3584]{0} %fusion.150, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.50, f32[3584]{0} %reduce.336), kind=kInput, calls=%fused_computation.142
  %get-tuple-element.200 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.142), index=0
  %reduce.339 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.200, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.201 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.142), index=1
  %fusion.143 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.201), kind=kLoop, calls=%fused_computation.143, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.141 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[3584]{0} %reduce.339, f32[3584]{0} %reduce.336, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.50, f32[3584]{0} %fusion.150, f32[1,1,1,3584]{3,2,1,0} %fusion.143, /*index=5*/f32[3584]{0} %get-tuple-element.682, f32[16,14,14,3584]{2,1,3,0} %fusion.146), kind=kLoop, calls=%fused_computation.141, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.455 = f32[1,1,1792,3584]{1,0,3,2} bitcast(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.681), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.29 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.141, f32[1,1,1792,3584]{1,0,3,2} %bitcast.455), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.52 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.29), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.122 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.52, f32[1792]{0} %get-tuple-element.680, f32[1792]{0} %get-tuple-element.679, f32[1792]{0} %fusion.160, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.49, /*index=5*/f32[1792]{0} %reduce.334), kind=kInput, calls=%fused_computation.122
  %get-tuple-element.198 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.122), index=1
  %reduce.341 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.198, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.199 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.122), index=2
  %fusion.137 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.199), kind=kLoop, calls=%fused_computation.137, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.135 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.341, f32[1792]{0} %reduce.334, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.49, f32[1792]{0} %fusion.160, f32[1,1,1,1792]{3,2,1,0} %fusion.137, /*index=5*/f32[1792]{0} %get-tuple-element.679, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.52, f32[1792]{0} %get-tuple-element.680), kind=kLoop, calls=%fused_computation.135, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.6 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.135, f32[3,3,896,1792]{1,0,2,3} %copy.65), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.54 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.6), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.126 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.54, f32[896]{0} %get-tuple-element.677, f32[896]{0} %get-tuple-element.676, f32[896]{0} %fusion.170, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.48, /*index=5*/f32[896]{0} %reduce.332), kind=kInput, calls=%fused_computation.126
  %get-tuple-element.195 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.126), index=1
  %reduce.343 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.195, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.196 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.126), index=2
  %fusion.131 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.196), kind=kLoop, calls=%fused_computation.131, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.129 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %reduce.343, f32[896]{0} %reduce.332, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.48, f32[896]{0} %fusion.170, f32[1,1,1,896]{3,2,1,0} %fusion.131, /*index=5*/f32[896]{0} %get-tuple-element.676, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.54, f32[896]{0} %get-tuple-element.677), kind=kLoop, calls=%fused_computation.129, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.470 = f32[1,1,3584,896]{1,0,3,2} bitcast(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.675), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.17 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.129, f32[1,1,3584,896]{1,0,3,2} %bitcast.470, f32[3584]{0} %broadcast.1098, f32[16,14,14,3584]{2,1,3,0} %fusion.146), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.80 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.17), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %tuple.57 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) tuple(f32[16,14,14,3584]{3,2,1,0} %param_141, f32[1,1,3584,896]{3,2,1,0} %param_142, f32[896]{0} %param_143, f32[896]{0} %param_144, f32[3,3,896,1792]{3,2,1,0} %param_145, /*index=5*/f32[1792]{0} %param_146, f32[1792]{0} %param_147, f32[1,1,1792,3584]{3,2,1,0} %param_148, f32[3584]{0} %param_149, f32[3584]{0} %param_150, /*index=10*/f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.80), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2408 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) bitcast((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %tuple.57)
  %get-tuple-element.705 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.695 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.75 = f32[16,14,14,3584]{2,1,3,0} copy(f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.695), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.116 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %copy.75), kind=kLoop, calls=%fused_computation.116, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.704 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.701 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.700 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.698 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.697 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.696 = f32[1,1,3584,896]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.76 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.696), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.31 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.116, f32[1,1,3584,896]{1,0,2,3} %copy.76), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.57 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.31), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2313 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.57)
  %fusion.115 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.2313), kind=kInput, calls=%fused_computation.115.clone
  %get-tuple-element.193 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.115), index=1
  %get-tuple-element.192 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.115), index=0
  %reduce.347 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.192, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.111 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.193, f32[896]{0} %reduce.347), kind=kLoop, calls=%fused_computation.111, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.106 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.698, f32[896]{0} %get-tuple-element.697, f32[896]{0} %fusion.111, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.57, f32[896]{0} %reduce.347), kind=kLoop, calls=%fused_computation.106, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.699 = f32[3,3,896,1792]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.77 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %get-tuple-element.699), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.32 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.106, f32[3,3,896,1792]{1,0,2,3} %copy.77), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.58 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.32), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2309 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.58)
  %fusion.105 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.2309), kind=kInput, calls=%fused_computation.105.clone
  %get-tuple-element.191 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.105), index=1
  %get-tuple-element.190 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.105), index=0
  %reduce.349 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.190, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.101 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.191, f32[1792]{0} %reduce.349), kind=kLoop, calls=%fused_computation.101, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.96 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.701, f32[1792]{0} %get-tuple-element.700, f32[1792]{0} %fusion.101, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.58, f32[1792]{0} %reduce.349), kind=kLoop, calls=%fused_computation.96, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.702 = f32[1,1,1792,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.78 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.702), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.33 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.96, f32[1,1,1792,3584]{1,0,2,3} %copy.78), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.59 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.33), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2305 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.59)
  %fusion.95 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.2305), kind=kInput, calls=%fused_computation.95.clone
  %get-tuple-element.188 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.95), index=0
  %reduce.351 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.188, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %get-tuple-element.703 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=10*/f32[16,14,14,3584]{2,1,3,0}) %bitcast.2408), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.189 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.95), index=1
  %fusion.91 = f32[3584]{0} fusion(f32[16,3584]{1,0} %get-tuple-element.189, f32[3584]{0} %reduce.351), kind=kLoop, calls=%fused_computation.91, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.87 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.705, f32[16,14,14,3584]{2,1,3,0} %fusion.116, f32[3584]{0} %get-tuple-element.704, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.59, f32[3584]{0} %reduce.351, /*index=5*/f32[3584]{0} %get-tuple-element.703, f32[3584]{0} %fusion.91), kind=kLoop, calls=%fused_computation.87, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %fusion.83 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %fusion.87, f32[3584]{0} %get-tuple-element.703, f32[3584]{0} %fusion.91, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.59, f32[3584]{0} %reduce.351), kind=kInput, calls=%fused_computation.83
  %get-tuple-element.185 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.83), index=0
  %reduce.354 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.185, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.186 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.83), index=1
  %fusion.84 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %get-tuple-element.186), kind=kLoop, calls=%fused_computation.84, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.82 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[3584]{0} %reduce.354, f32[3584]{0} %reduce.351, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.59, f32[3584]{0} %fusion.91, f32[1,1,1,3584]{3,2,1,0} %fusion.84, /*index=5*/f32[3584]{0} %get-tuple-element.703, f32[16,14,14,3584]{2,1,3,0} %fusion.87), kind=kLoop, calls=%fused_computation.82, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.490 = f32[1,1,1792,3584]{1,0,3,2} bitcast(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.702), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.34 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.82, f32[1,1,1792,3584]{1,0,3,2} %bitcast.490), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.61 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.34), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.63 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.61, f32[1792]{0} %get-tuple-element.701, f32[1792]{0} %get-tuple-element.700, f32[1792]{0} %fusion.101, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.58, /*index=5*/f32[1792]{0} %reduce.349), kind=kInput, calls=%fused_computation.63
  %get-tuple-element.183 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.63), index=1
  %reduce.356 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.183, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.184 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.63), index=2
  %fusion.78 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.184), kind=kLoop, calls=%fused_computation.78, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.76 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.356, f32[1792]{0} %reduce.349, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.58, f32[1792]{0} %fusion.101, f32[1,1,1,1792]{3,2,1,0} %fusion.78, /*index=5*/f32[1792]{0} %get-tuple-element.700, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.61, f32[1792]{0} %get-tuple-element.701), kind=kLoop, calls=%fused_computation.76, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.7 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.76, f32[3,3,896,1792]{1,0,2,3} %copy.77), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.63 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.7), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.67 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.63, f32[896]{0} %get-tuple-element.698, f32[896]{0} %get-tuple-element.697, f32[896]{0} %fusion.111, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.57, /*index=5*/f32[896]{0} %reduce.347), kind=kInput, calls=%fused_computation.67
  %get-tuple-element.180 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.67), index=1
  %reduce.358 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.180, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.181 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.67), index=2
  %fusion.72 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.181), kind=kLoop, calls=%fused_computation.72, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.70 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %reduce.358, f32[896]{0} %reduce.347, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.57, f32[896]{0} %fusion.111, f32[1,1,1,896]{3,2,1,0} %fusion.72, /*index=5*/f32[896]{0} %get-tuple-element.697, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.63, f32[896]{0} %get-tuple-element.698), kind=kLoop, calls=%fused_computation.70, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.505 = f32[1,1,3584,896]{1,0,3,2} bitcast(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.696), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.20 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.70, f32[1,1,3584,896]{1,0,3,2} %bitcast.505, f32[3584]{0} %broadcast.1098, f32[16,14,14,3584]{2,1,3,0} %fusion.87), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.81 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.20), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.57 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.81, f32[16,14,14,3584]{2,1,3,0} %copy.75), kind=kLoop, calls=%fused_computation.57, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/select_n" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %tuple.59 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) tuple(f32[16,14,14,3584]{3,2,1,0} %param_151, f32[1,1,3584,896]{3,2,1,0} %param_152, f32[896]{0} %param_153, f32[896]{0} %param_154, f32[3,3,896,1792]{3,2,1,0} %param_155, /*index=5*/f32[1792]{0} %param_156, f32[1792]{0} %param_157, f32[1,1,1792,3584]{3,2,1,0} %param_158, f32[3584]{0} %param_159, f32[16,14,14,3584]{2,1,3,0} %fusion.57), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %bitcast.2409 = (f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) bitcast((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %tuple.59)
  %get-tuple-element.717 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.725 = f32[3584]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %param_75 = f32[3584]{0} parameter(75), metadata={op_name="2$start"}
  %bitcast.2286 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.717)
  %get-tuple-element.723 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.722 = f32[1792]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.720 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.719 = f32[896]{0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %get-tuple-element.716 = f32[16,14,14,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.86 = f32[16,14,14,3584]{2,1,3,0} copy(f32[16,14,14,3584]{3,2,1,0} %get-tuple-element.716), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %fusion.56 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[16,14,14,3584]{2,1,3,0} %copy.86), kind=kLoop, calls=%fused_computation.56, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_7/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=98}
  %get-tuple-element.718 = f32[1,1,3584,896]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.87 = f32[1,1,3584,896]{1,0,2,3} copy(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.718), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.36 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.56, f32[1,1,3584,896]{1,0,2,3} %copy.87), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.66 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv.36), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2301 = f32[16,896,196]{2,1,0} bitcast(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.66)
  %fusion.55 = (f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,896,196]{2,1,0} %bitcast.2301), kind=kInput, calls=%fused_computation.55.clone
  %get-tuple-element.178 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.55), index=1
  %get-tuple-element.177 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.55), index=0
  %reduce.362 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.177, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.51 = f32[896]{0} fusion(f32[16,896]{1,0} %get-tuple-element.178, f32[896]{0} %reduce.362), kind=kLoop, calls=%fused_computation.51, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.46 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %get-tuple-element.720, f32[896]{0} %get-tuple-element.719, f32[896]{0} %fusion.51, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.66, f32[896]{0} %reduce.362), kind=kLoop, calls=%fused_computation.46, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=85}
  %get-tuple-element.721 = f32[3,3,896,1792]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.88 = f32[3,3,896,1792]{1,0,2,3} copy(f32[3,3,896,1792]{3,2,1,0} %get-tuple-element.721), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.37 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.46, f32[3,3,896,1792]{1,0,2,3} %copy.88), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.67 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.37), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2297 = f32[16,1792,196]{2,1,0} bitcast(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.67)
  %fusion.45 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,1792,196]{2,1,0} %bitcast.2297), kind=kInput, calls=%fused_computation.45.clone
  %get-tuple-element.176 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.45), index=1
  %get-tuple-element.175 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.45), index=0
  %reduce.364 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.175, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.41 = f32[1792]{0} fusion(f32[16,1792]{1,0} %get-tuple-element.176, f32[1792]{0} %reduce.364), kind=kLoop, calls=%fused_computation.41, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/sub" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=93}
  %fusion.36 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %get-tuple-element.723, f32[1792]{0} %get-tuple-element.722, f32[1792]{0} %fusion.41, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.67, f32[1792]{0} %reduce.364), kind=kLoop, calls=%fused_computation.36, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/max" source_file="/home/cyxue/Projects/crius/Crius/runtime/crius_worker/jax/model/wide_resnet.py" source_line=88}
  %get-tuple-element.724 = f32[1,1,1792,3584]{3,2,1,0} get-tuple-element((f32[16,14,14,3584]{3,2,1,0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=5*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[16,14,14,3584]{2,1,3,0}) %bitcast.2409), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %copy.89 = f32[1,1,1792,3584]{1,0,2,3} copy(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.724), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.38 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.36, f32[1,1,1792,3584]{1,0,2,3} %copy.89), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.68 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv.38), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %bitcast.2289 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.68)
  %bitcast.2293 = f32[16,3584,196]{2,1,0} bitcast(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.68)
  %fusion.35 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,3584,196]{2,1,0} %bitcast.2293), kind=kInput, calls=%fused_computation.35.clone
  %get-tuple-element.172 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.35), index=1
  %reduce.367 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.172, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %fusion.28 = f32[16,3584]{1,0} fusion(f32[16,3584,196]{2,1,0} %bitcast.2286, f32[16,3584,196]{2,1,0} %bitcast.2289, f32[3584]{0} %reduce.367), kind=kInput, calls=%fused_computation.28.clone
  %fusion.27 = f32[1,1,1,3584]{3,2,1,0} fusion(f32[16,3584]{1,0} %fusion.28), kind=kLoop, calls=%fused_computation.27, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reshape[new_sizes=(1, 1, 1, 3584) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %get-tuple-element.171 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.35), index=0
  %fusion.3 = (f32[3584]{0}, f32[3584]{0}) fusion(f32[3584]{0} %param_75, f32[1,1,1,3584]{3,2,1,0} %fusion.27, f32[3584]{0} %reduce.367, f32[16,3584]{1,0} %get-tuple-element.171), kind=kLoop, calls=%fused_computation.3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %get-tuple-element.170 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}) %fusion.3), index=1
  %fusion.26 = (f32[16,3584]{1,0}, f32[16,3584]{1,0}) fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.717, f32[3584]{0} %get-tuple-element.725, f32[3584]{0} %get-tuple-element.170), kind=kInput, calls=%fused_computation.26
  %get-tuple-element.173 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.26), index=0
  %reduce.369 = f32[3584]{0} reduce(f32[16,3584]{1,0} %get-tuple-element.173, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.25 = f32[16,14,14,3584]{2,1,3,0} fusion(f32[3584]{0} %reduce.369, f32[3584]{0} %reduce.367, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.68, f32[3584]{0} %get-tuple-element.170, f32[1,1,1,3584]{3,2,1,0} %fusion.27, /*index=5*/f32[3584]{0} %get-tuple-element.725, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.717), kind=kLoop, calls=%fused_computation.25, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_2/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %bitcast.525 = f32[1,1,1792,3584]{1,0,3,2} bitcast(f32[1,1,1792,3584]{3,2,1,0} %get-tuple-element.724), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv.39 = (f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.25, f32[1,1,1792,3584]{1,0,3,2} %bitcast.525), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.70 = f32[16,14,14,1792]{2,1,3,0} get-tuple-element((f32[16,14,14,1792]{2,1,3,0}, u8[0]{0}) %cudnn-conv.39), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(1, 1, 1792, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.6 = (f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) fusion(f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.70, f32[1792]{0} %get-tuple-element.723, f32[1792]{0} %get-tuple-element.722, f32[1792]{0} %fusion.41, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.67, /*index=5*/f32[1792]{0} %reduce.364), kind=kInput, calls=%fused_computation.6
  %get-tuple-element.167 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.6), index=1
  %reduce.371 = f32[1792]{0} reduce(f32[16,1792]{1,0} %get-tuple-element.167, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %get-tuple-element.168 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.6), index=2
  %fusion.21 = f32[1,1,1,1792]{3,2,1,0} fusion(f32[16,1792]{1,0} %get-tuple-element.168), kind=kLoop, calls=%fused_computation.21, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/reshape[new_sizes=(1, 1, 1, 1792) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %fusion.19 = f32[16,14,14,1792]{2,1,3,0} fusion(f32[1792]{0} %reduce.371, f32[1792]{0} %reduce.364, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.67, f32[1792]{0} %fusion.41, f32[1,1,1,1792]{3,2,1,0} %fusion.21, /*index=5*/f32[1792]{0} %get-tuple-element.722, f32[16,14,14,1792]{2,1,3,0} %get-tuple-element.70, f32[1792]{0} %get-tuple-element.723), kind=kLoop, calls=%fused_computation.19, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_1/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-input.8 = (f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.19, f32[3,3,896,1792]{1,0,2,3} %copy.88), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardInput", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.72 = f32[16,14,14,896]{2,1,3,0} get-tuple-element((f32[16,14,14,896]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bw-input.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(3, 3, 896, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion.10 = (f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) fusion(f32[16,14,14,896]{2,1,3,0} %get-tuple-element.72, f32[896]{0} %get-tuple-element.720, f32[896]{0} %get-tuple-element.719, f32[896]{0} %fusion.51, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.66, /*index=5*/f32[896]{0} %reduce.362), kind=kInput, calls=%fused_computation.10
  %get-tuple-element.165 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.10), index=2
  %fusion.15 = f32[1,1,1,896]{3,2,1,0} fusion(f32[16,896]{1,0} %get-tuple-element.165), kind=kLoop, calls=%fused_computation.15, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reshape[new_sizes=(1, 1, 1, 896) dimensions=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=146}
  %param_7 = f32[7168]{0} parameter(7), metadata={op_name="2$start"}
  %param_66 = f32[3584]{0} parameter(66), metadata={op_name="2$start"}
  %param_15 = f32[3584]{0} parameter(15), metadata={op_name="2$start"}
  %param_63 = f32[1792]{0} parameter(63), metadata={op_name="2$start"}
  %param_72 = f32[1792]{0} parameter(72), metadata={op_name="2$start"}
  %param_60 = f32[896]{0} parameter(60), metadata={op_name="2$start"}
  %param_4 = f32[3584]{0} parameter(4), metadata={op_name="2$start"}
  %param_12 = f32[1792]{0} parameter(12), metadata={op_name="2$start"}
  %param_57 = f32[3584]{0} parameter(57), metadata={op_name="2$start"}
  %param_54 = f32[1792]{0} parameter(54), metadata={op_name="2$start"}
  %param_51 = f32[896]{0} parameter(51), metadata={op_name="2$start"}
  %param_48 = f32[3584]{0} parameter(48), metadata={op_name="2$start"}
  %param_18 = f32[7168]{0} parameter(18), metadata={op_name="2$start"}
  %param_45 = f32[1792]{0} parameter(45), metadata={op_name="2$start"}
  %param_42 = f32[896]{0} parameter(42), metadata={op_name="2$start"}
  %param_1 = f32[1792]{0} parameter(1), metadata={op_name="2$start"}
  %param_39 = f32[3584]{0} parameter(39), metadata={op_name="2$start"}
  %param_21 = f32[1792]{0} parameter(21), metadata={op_name="2$start"}
  %param_36 = f32[1792]{0} parameter(36), metadata={op_name="2$start"}
  %param_33 = f32[896]{0} parameter(33), metadata={op_name="2$start"}
  %param_24 = f32[3584]{0} parameter(24), metadata={op_name="2$start"}
  %fusion.487 = (f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) fusion(f32[896]{0} %param_69, f32[1,1,1,896]{3,2,1,0} %fusion.15, f32[896]{0} %fusion.51, f32[7168]{0} %param_7, f32[1,1,1,7168]{3,2,1,0} %fusion.445, /*index=5*/f32[7168]{0} %fusion.459, f32[3584]{0} %param_66, f32[1,1,1,3584]{3,2,1,0} %fusion.84, f32[3584]{0} %fusion.91, f32[3584]{0} %param_15, /*index=10*/f32[1,1,1,3584]{3,2,1,0} %fusion.379, f32[3584]{0} %fusion.402, f32[1792]{0} %param_63, f32[1,1,1,1792]{3,2,1,0} %fusion.78, f32[1792]{0} %fusion.101, /*index=15*/f32[1792]{0} %param_72, f32[1,1,1,1792]{3,2,1,0} %fusion.21, f32[1792]{0} %fusion.41, f32[896]{0} %param_60, f32[1,1,1,896]{3,2,1,0} %fusion.72, /*index=20*/f32[896]{0} %fusion.111, f32[3584]{0} %param_4, f32[1,1,1,3584]{3,2,1,0} %fusion.439, f32[3584]{0} %fusion.469, f32[1792]{0} %param_12, /*index=25*/f32[1,1,1,1792]{3,2,1,0} %fusion.373, f32[1792]{0} %fusion.412, f32[3584]{0} %param_57, f32[1,1,1,3584]{3,2,1,0} %fusion.143, f32[3584]{0} %fusion.150, /*index=30*/f32[1792]{0} %param_54, f32[1,1,1,1792]{3,2,1,0} %fusion.137, f32[1792]{0} %fusion.160, f32[896]{0} %param_51, f32[1,1,1,896]{3,2,1,0} %fusion.131, /*index=35*/f32[896]{0} %fusion.170, f32[3584]{0} %param_48, f32[1,1,1,3584]{3,2,1,0} %fusion.201, f32[3584]{0} %fusion.208, f32[7168]{0} %param_18, /*index=40*/f32[1,1,1,7168]{3,2,1,0} %fusion.385, f32[7168]{0} %fusion.392, f32[1792]{0} %param_45, f32[1,1,1,1792]{3,2,1,0} %fusion.195, f32[1792]{0} %fusion.218, /*index=45*/f32[896]{0} %param_42, f32[1,1,1,896]{3,2,1,0} %fusion.189, f32[896]{0} %fusion.228, f32[1792]{0} %param_1, f32[1,1,1,1792]{3,2,1,0} %fusion.433, /*index=50*/f32[1792]{0} %fusion.479, f32[3584]{0} %param_39, f32[1,1,1,3584]{3,2,1,0} %fusion.259, f32[3584]{0} %fusion.266, f32[1792]{0} %param_21, /*index=55*/f32[1,1,1,1792]{3,2,1,0} %fusion.317, f32[1792]{0} %fusion.353, f32[1792]{0} %param_36, f32[1,1,1,1792]{3,2,1,0} %fusion.253, f32[1792]{0} %fusion.276, /*index=60*/f32[896]{0} %param_33, f32[1,1,1,896]{3,2,1,0} %fusion.247, f32[896]{0} %fusion.286, f32[3584]{0} %param_24, f32[1,1,1,3584]{3,2,1,0} %fusion.323, /*index=65*/f32[3584]{0} %fusion.343), kind=kInput, calls=%horizontally_fused_computation.1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %get-tuple-element.345 = f32[1792]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=16, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %param_40 = f32[3584]{0} parameter(40), metadata={op_name="2$start"}
  %get-tuple-element.232 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.258), index=2
  %param_76 = f32[3584]{0} parameter(76), metadata={op_name="2$start"}
  %get-tuple-element.174 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.26), index=1
  %param_73 = f32[1792]{0} parameter(73), metadata={op_name="2$start"}
  %get-tuple-element.166 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.6), index=0
  %param_70 = f32[896]{0} parameter(70), metadata={op_name="2$start"}
  %get-tuple-element.163 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.10), index=0
  %param_67 = f32[3584]{0} parameter(67), metadata={op_name="2$start"}
  %get-tuple-element.187 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.83), index=2
  %param_64 = f32[1792]{0} parameter(64), metadata={op_name="2$start"}
  %get-tuple-element.182 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.63), index=0
  %param_61 = f32[896]{0} parameter(61), metadata={op_name="2$start"}
  %get-tuple-element.179 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.67), index=0
  %param_58 = f32[3584]{0} parameter(58), metadata={op_name="2$start"}
  %get-tuple-element.202 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.142), index=2
  %param_55 = f32[1792]{0} parameter(55), metadata={op_name="2$start"}
  %get-tuple-element.197 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.122), index=0
  %param_52 = f32[896]{0} parameter(52), metadata={op_name="2$start"}
  %get-tuple-element.194 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.126), index=0
  %param_49 = f32[3584]{0} parameter(49), metadata={op_name="2$start"}
  %get-tuple-element.217 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.200), index=2
  %param_46 = f32[1792]{0} parameter(46), metadata={op_name="2$start"}
  %get-tuple-element.212 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.180), index=0
  %param_43 = f32[896]{0} parameter(43), metadata={op_name="2$start"}
  %get-tuple-element.209 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.184), index=0
  %param_37 = f32[1792]{0} parameter(37), metadata={op_name="2$start"}
  %get-tuple-element.227 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.238), index=0
  %param_34 = f32[896]{0} parameter(34), metadata={op_name="2$start"}
  %get-tuple-element.224 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.242), index=0
  %param_19 = f32[7168]{0} parameter(19), metadata={op_name="2$start"}
  %get-tuple-element.274 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.384), index=2
  %param_13 = f32[1792]{0} parameter(13), metadata={op_name="2$start"}
  %get-tuple-element.266 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.368), index=0
  %param_25 = f32[3584]{0} parameter(25), metadata={op_name="2$start"}
  %get-tuple-element.248 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.308), index=0
  %param_16 = f32[3584]{0} parameter(16), metadata={op_name="2$start"}
  %get-tuple-element.269 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.364), index=0
  %param_10 = f32[1024]{0} parameter(10), metadata={op_name="2$start"}
  %param_8 = f32[7168]{0} parameter(8), metadata={op_name="2$start"}
  %get-tuple-element.289 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.444), index=2
  %param_5 = f32[3584]{0} parameter(5), metadata={op_name="2$start"}
  %get-tuple-element.284 = f32[16,3584]{1,0} get-tuple-element((f32[16,3584]{1,0}, f32[16,3584]{1,0}, f32[16,3584]{1,0}) %fusion.424), index=0
  %param_22 = f32[1792]{0} parameter(22), metadata={op_name="2$start"}
  %get-tuple-element.245 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.312), index=0
  %param_2 = f32[1792]{0} parameter(2), metadata={op_name="2$start"}
  %get-tuple-element.281 = f32[16,1792]{1,0} get-tuple-element((f32[16,1792]{1,0}, f32[16,1792]{1,0}, f32[16,1792]{1,0}) %fusion.428), index=0
  %fusion.486 = (f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) fusion(f32[3584]{0} %param_40, f32[16,3584]{1,0} %get-tuple-element.232, f32[3584]{0} %param_76, f32[16,3584]{1,0} %get-tuple-element.174, f32[1792]{0} %param_73, /*index=5*/f32[16,1792]{1,0} %get-tuple-element.166, f32[896]{0} %param_70, f32[16,896]{1,0} %get-tuple-element.163, f32[3584]{0} %param_67, f32[16,3584]{1,0} %get-tuple-element.187, /*index=10*/f32[1792]{0} %param_64, f32[16,1792]{1,0} %get-tuple-element.182, f32[896]{0} %param_61, f32[16,896]{1,0} %get-tuple-element.179, f32[3584]{0} %param_58, /*index=15*/f32[16,3584]{1,0} %get-tuple-element.202, f32[1792]{0} %param_55, f32[16,1792]{1,0} %get-tuple-element.197, f32[896]{0} %param_52, f32[16,896]{1,0} %get-tuple-element.194, /*index=20*/f32[3584]{0} %param_49, f32[16,3584]{1,0} %get-tuple-element.217, f32[1792]{0} %param_46, f32[16,1792]{1,0} %get-tuple-element.212, f32[896]{0} %param_43, /*index=25*/f32[16,896]{1,0} %get-tuple-element.209, f32[1792]{0} %param_37, f32[16,1792]{1,0} %get-tuple-element.227, f32[896]{0} %param_34, f32[16,896]{1,0} %get-tuple-element.224, /*index=30*/f32[7168]{0} %param_19, f32[16,7168]{1,0} %get-tuple-element.274, f32[1792]{0} %param_13, f32[16,1792]{1,0} %get-tuple-element.266, f32[3584]{0} %param_25, /*index=35*/f32[16,3584]{1,0} %get-tuple-element.248, f32[3584]{0} %param_16, f32[16,3584]{1,0} %get-tuple-element.269, f32[1024]{0} %param_10, f32[16,1024]{1,0} %fusion.449, /*index=40*/f32[7168]{0} %param_8, f32[16,7168]{1,0} %get-tuple-element.289, f32[3584]{0} %param_5, f32[16,3584]{1,0} %get-tuple-element.284, f32[1792]{0} %param_22, /*index=45*/f32[16,1792]{1,0} %get-tuple-element.245, f32[1792]{0} %param_2, f32[16,1792]{1,0} %get-tuple-element.281), kind=kInput, calls=%horizontally_fused_computation, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %get-tuple-element.346 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=23, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %cudnn-conv-bw-filter.1 = (f32[3,3,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,7,7,1792]{2,1,3,0} %fusion.474, f32[16,7,7,3584]{2,1,3,0} %fusion.437), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(16, 7, 7, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.5 = f32[3,3,1792,3584]{1,0,2,3} get-tuple-element((f32[3,3,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.1), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(16, 7, 7, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_3 = f32[3,3,1792,3584]{3,2,1,0} parameter(3), metadata={op_name="2$start"}
  %fusion.426 = f32[3,3,1792,3584]{3,2,1,0} fusion(f32[3,3,1792,3584]{1,0,2,3} %get-tuple-element.5, f32[3,3,1792,3584]{3,2,1,0} %param_3), kind=kLoop, calls=%fused_computation.426, metadata={op_name="tuple.79"}
  %get-tuple-element.348 = f32[3584]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %get-tuple-element.349 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=21, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %cudnn-conv-bw-filter = (f32[1,1,3584,7168]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.464, f32[16,7,7,7168]{2,1,3,0} %fusion.443), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(16, 7, 7, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.3 = f32[1,1,3584,7168]{1,0,2,3} get-tuple-element((f32[1,1,3584,7168]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_15/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(16, 7, 7, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_6 = f32[1,1,3584,7168]{3,2,1,0} parameter(6), metadata={op_name="2$start"}
  %fusion.422 = f32[1,1,3584,7168]{3,2,1,0} fusion(f32[1,1,3584,7168]{1,0,2,3} %get-tuple-element.3, f32[1,1,3584,7168]{3,2,1,0} %param_6), kind=kLoop, calls=%fused_computation.422, metadata={op_name="tuple.79"}
  %get-tuple-element.351 = f32[7168]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %get-tuple-element.352 = f32[7168]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=20, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %param_9 = f32[7168,1024]{1,0} parameter(9), metadata={op_name="2$start"}
  %cublas-gemm.9 = f32[7168,1024]{1,0} custom-call(f32[16,7168]{1,0} %fusion.451, f32[16,1024]{1,0} %fusion.449, f32[7168,1024]{1,0} %param_9), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/transpose(jvp(remat))/WideResNet/Dense_0/transpose[permutation=(1, 0)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=196}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  %get-tuple-element.354 = f32[1024]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=19, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(20)/add"}
  %cudnn-conv-bw-filter.5 = (f32[1,1,7168,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,7,7,7168]{2,1,3,0} %fusion.417, f32[16,7,7,1792]{2,1,3,0} %fusion.371), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(16, 7, 7, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.16 = f32[1,1,7168,1792]{1,0,2,3} get-tuple-element((f32[1,1,7168,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.5), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 7168) rhs_shape=(16, 7, 7, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_11 = f32[1,1,7168,1792]{3,2,1,0} parameter(11), metadata={op_name="2$start"}
  %fusion.370 = f32[1,1,7168,1792]{3,2,1,0} fusion(f32[1,1,7168,1792]{1,0,2,3} %get-tuple-element.16, f32[1,1,7168,1792]{3,2,1,0} %param_11), kind=kLoop, calls=%fused_computation.370, metadata={op_name="tuple.79"}
  %get-tuple-element.356 = f32[1792]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %get-tuple-element.357 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=16, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %cudnn-conv-bw-filter.4 = (f32[3,3,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,7,7,1792]{2,1,3,0} %fusion.407, f32[16,7,7,3584]{2,1,3,0} %fusion.377), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(16, 7, 7, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.14 = f32[3,3,1792,3584]{1,0,2,3} get-tuple-element((f32[3,3,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.4), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 1792) rhs_shape=(16, 7, 7, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_14 = f32[3,3,1792,3584]{3,2,1,0} parameter(14), metadata={op_name="2$start"}
  %fusion.366 = f32[3,3,1792,3584]{3,2,1,0} fusion(f32[3,3,1792,3584]{1,0,2,3} %get-tuple-element.14, f32[3,3,1792,3584]{3,2,1,0} %param_14), kind=kLoop, calls=%fused_computation.366, metadata={op_name="tuple.79"}
  %get-tuple-element.359 = f32[3584]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %get-tuple-element.360 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=18, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %cudnn-conv-bw-filter.3 = (f32[1,1,3584,7168]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.397, f32[16,7,7,7168]{2,1,3,0} %fusion.383), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(16, 7, 7, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.12 = f32[1,1,3584,7168]{1,0,2,3} get-tuple-element((f32[1,1,3584,7168]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.3), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_14/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(16, 7, 7, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_17 = f32[1,1,3584,7168]{3,2,1,0} parameter(17), metadata={op_name="2$start"}
  %fusion.362 = f32[1,1,3584,7168]{3,2,1,0} fusion(f32[1,1,3584,7168]{1,0,2,3} %get-tuple-element.12, f32[1,1,3584,7168]{3,2,1,0} %param_17), kind=kLoop, calls=%fused_computation.362, metadata={op_name="tuple.79"}
  %get-tuple-element.362 = f32[7168]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=13, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %get-tuple-element.363 = f32[7168]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=15, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(21)/add"}
  %cudnn-conv-bw-filter.9 = (f32[1,1,3584,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.29, f32[16,14,14,1792]{2,1,3,0} %fusion.315), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.27 = f32[1,1,3584,1792]{1,0,2,3} get-tuple-element((f32[1,1,3584,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.9), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_20 = f32[1,1,3584,1792]{3,2,1,0} parameter(20), metadata={op_name="2$start"}
  %fusion.314 = f32[1,1,3584,1792]{3,2,1,0} fusion(f32[1,1,3584,1792]{1,0,2,3} %get-tuple-element.27, f32[1,1,3584,1792]{3,2,1,0} %param_20), kind=kLoop, calls=%fused_computation.314, metadata={op_name="tuple.79"}
  %get-tuple-element.365 = f32[1792]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=18, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %get-tuple-element.366 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=22, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %cudnn-conv-bw-filter.8 = (f32[3,3,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,15,15,1792]{2,1,3,0} %fusion.348, f32[16,7,7,3584]{2,1,3,0} %fusion.321), window={size=3x3 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 7, 7, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.25 = f32[3,3,1792,3584]{1,0,2,3} get-tuple-element((f32[3,3,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.8), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((0, 1), (0, 1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 7, 7, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_23 = f32[3,3,1792,3584]{3,2,1,0} parameter(23), metadata={op_name="2$start"}
  %fusion.310 = f32[3,3,1792,3584]{3,2,1,0} fusion(f32[3,3,1792,3584]{1,0,2,3} %get-tuple-element.25, f32[3,3,1792,3584]{3,2,1,0} %param_23), kind=kLoop, calls=%fused_computation.310, metadata={op_name="tuple.79"}
  %get-tuple-element.368 = f32[3584]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=21, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %get-tuple-element.369 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=17, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %cudnn-conv-bw-filter.7 = (f32[1,1,3584,7168]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,7,7,3584]{2,1,3,0} %fusion.338, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.260), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(16, 7, 7, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.23 = f32[1,1,3584,7168]{1,0,2,3} get-tuple-element((f32[1,1,3584,7168]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.7), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 7, 7, 3584) rhs_shape=(16, 7, 7, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_26 = f32[1,1,3584,7168]{3,2,1,0} parameter(26), metadata={op_name="2$start"}
  %fusion.306 = f32[1,1,3584,7168]{3,2,1,0} fusion(f32[1,1,3584,7168]{1,0,2,3} %get-tuple-element.23, f32[1,1,3584,7168]{3,2,1,0} %param_26), kind=kLoop, calls=%fused_computation.306, metadata={op_name="tuple.79"}
  %get-tuple-element.371 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}) %fusion.305), index=0
  %param_28 = f32[7168]{0} parameter(28), metadata={op_name="2$start"}
  %get-tuple-element.257 = f32[16,7168]{1,0} get-tuple-element((f32[16,7168]{1,0}, f32[16,7168]{1,0}, f32[16,7168]{1,0}) %fusion.294), index=2
  %fusion.485 = (f32[7168]{0}, f32[7168]{0}) fusion(f32[7168]{0} %param_28, f32[16,7168]{1,0} %get-tuple-element.257), kind=kLoop, calls=%fused_computation.485, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %get-tuple-element.372 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}) %fusion.485), index=0
  %cudnn-conv-bw-filter.6 = (f32[1,1,3584,7168]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.29, f32[16,7,7,7168]{2,1,3,0} %get-tuple-element.261), window={size=1x1 stride=2x2}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, -1), (0, -1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 7, 7, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.19 = f32[1,1,3584,7168]{1,0,2,3} get-tuple-element((f32[1,1,3584,7168]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.6), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_13/conv_proj/conv_general_dilated[window_strides=(1, 1) padding=((0, -1), (0, -1)) lhs_dilation=(1, 1) rhs_dilation=(2, 2) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 7, 7, 7168) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_29 = f32[1,1,3584,7168]{3,2,1,0} parameter(29), metadata={op_name="2$start"}
  %fusion.292 = f32[1,1,3584,7168]{3,2,1,0} fusion(f32[1,1,3584,7168]{1,0,2,3} %get-tuple-element.19, f32[1,1,3584,7168]{3,2,1,0} %param_29), kind=kLoop, calls=%fused_computation.292, metadata={op_name="tuple.79"}
  %get-tuple-element.374 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}) %fusion.291), index=0
  %param_31 = f32[7168]{0} parameter(31), metadata={op_name="2$start"}
  %get-tuple-element.244 = f32[7168]{0} get-tuple-element((f32[7168]{0}, f32[7168]{0}) %fusion.485), index=1
  %add.629 = f32[7168]{0} add(f32[7168]{0} %param_31, f32[7168]{0} %get-tuple-element.244), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(22)/add"}
  %cudnn-conv-bw-filter.12 = (f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.46, f32[16,14,14,896]{2,1,3,0} %fusion.245), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.37 = f32[1,1,3584,896]{1,0,2,3} get-tuple-element((f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.12), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_32 = f32[1,1,3584,896]{3,2,1,0} parameter(32), metadata={op_name="2$start"}
  %fusion.244 = f32[1,1,3584,896]{3,2,1,0} fusion(f32[1,1,3584,896]{1,0,2,3} %get-tuple-element.37, f32[1,1,3584,896]{3,2,1,0} %param_32), kind=kLoop, calls=%fused_computation.244, metadata={op_name="tuple.79"}
  %get-tuple-element.377 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=20, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %get-tuple-element.378 = f32[896]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=14, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %cudnn-conv-bw-filter.11 = (f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.281, f32[16,14,14,1792]{2,1,3,0} %fusion.251), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.35 = f32[3,3,896,1792]{1,0,2,3} get-tuple-element((f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.11), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_35 = f32[3,3,896,1792]{3,2,1,0} parameter(35), metadata={op_name="2$start"}
  %fusion.240 = f32[3,3,896,1792]{3,2,1,0} fusion(f32[3,3,896,1792]{1,0,2,3} %get-tuple-element.35, f32[3,3,896,1792]{3,2,1,0} %param_35), kind=kLoop, calls=%fused_computation.240, metadata={op_name="tuple.79"}
  %get-tuple-element.380 = f32[1792]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=19, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %get-tuple-element.381 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=13, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %cudnn-conv-bw-filter.10 = (f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.271, f32[16,14,14,3584]{2,1,3,0} %fusion.257), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.33 = f32[1,1,1792,3584]{1,0,2,3} get-tuple-element((f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.10), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_12/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_38 = f32[1,1,1792,3584]{3,2,1,0} parameter(38), metadata={op_name="2$start"}
  %fusion.236 = f32[1,1,1792,3584]{3,2,1,0} fusion(f32[1,1,1792,3584]{1,0,2,3} %get-tuple-element.33, f32[1,1,1792,3584]{3,2,1,0} %param_38), kind=kLoop, calls=%fused_computation.236, metadata={op_name="tuple.79"}
  %get-tuple-element.383 = f32[3584]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=17, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %get-tuple-element.384 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(23)/add"}
  %cudnn-conv-bw-filter.15 = (f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.58, f32[16,14,14,896]{2,1,3,0} %fusion.187), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.46 = f32[1,1,3584,896]{1,0,2,3} get-tuple-element((f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.15), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_41 = f32[1,1,3584,896]{3,2,1,0} parameter(41), metadata={op_name="2$start"}
  %fusion.186 = f32[1,1,3584,896]{3,2,1,0} fusion(f32[1,1,3584,896]{1,0,2,3} %get-tuple-element.46, f32[1,1,3584,896]{3,2,1,0} %param_41), kind=kLoop, calls=%fused_computation.186, metadata={op_name="tuple.79"}
  %get-tuple-element.386 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=15, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %get-tuple-element.387 = f32[896]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=12, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %cudnn-conv-bw-filter.14 = (f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.223, f32[16,14,14,1792]{2,1,3,0} %fusion.193), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.44 = f32[3,3,896,1792]{1,0,2,3} get-tuple-element((f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.14), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_44 = f32[3,3,896,1792]{3,2,1,0} parameter(44), metadata={op_name="2$start"}
  %fusion.182 = f32[3,3,896,1792]{3,2,1,0} fusion(f32[3,3,896,1792]{1,0,2,3} %get-tuple-element.44, f32[3,3,896,1792]{3,2,1,0} %param_44), kind=kLoop, calls=%fused_computation.182, metadata={op_name="tuple.79"}
  %get-tuple-element.389 = f32[1792]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=14, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %get-tuple-element.390 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %cudnn-conv-bw-filter.13 = (f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.213, f32[16,14,14,3584]{2,1,3,0} %fusion.199), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.42 = f32[1,1,1792,3584]{1,0,2,3} get-tuple-element((f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.13), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_11/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_47 = f32[1,1,1792,3584]{3,2,1,0} parameter(47), metadata={op_name="2$start"}
  %fusion.178 = f32[1,1,1792,3584]{3,2,1,0} fusion(f32[1,1,1792,3584]{1,0,2,3} %get-tuple-element.42, f32[1,1,1792,3584]{3,2,1,0} %param_47), kind=kLoop, calls=%fused_computation.178, metadata={op_name="tuple.79"}
  %get-tuple-element.392 = f32[3584]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=12, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %get-tuple-element.393 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(24)/add"}
  %cudnn-conv-bw-filter.18 = (f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %copy.70, f32[16,14,14,896]{2,1,3,0} %fusion.129), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.55 = f32[1,1,3584,896]{1,0,2,3} get-tuple-element((f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.18), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_50 = f32[1,1,3584,896]{3,2,1,0} parameter(50), metadata={op_name="2$start"}
  %fusion.128 = f32[1,1,3584,896]{3,2,1,0} fusion(f32[1,1,3584,896]{1,0,2,3} %get-tuple-element.55, f32[1,1,3584,896]{3,2,1,0} %param_50), kind=kLoop, calls=%fused_computation.128, metadata={op_name="tuple.79"}
  %get-tuple-element.395 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=11, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %get-tuple-element.396 = f32[896]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %cudnn-conv-bw-filter.17 = (f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.165, f32[16,14,14,1792]{2,1,3,0} %fusion.135), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.53 = f32[3,3,896,1792]{1,0,2,3} get-tuple-element((f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.17), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_53 = f32[3,3,896,1792]{3,2,1,0} parameter(53), metadata={op_name="2$start"}
  %fusion.124 = f32[3,3,896,1792]{3,2,1,0} fusion(f32[3,3,896,1792]{1,0,2,3} %get-tuple-element.53, f32[3,3,896,1792]{3,2,1,0} %param_53), kind=kLoop, calls=%fused_computation.124, metadata={op_name="tuple.79"}
  %get-tuple-element.398 = f32[1792]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=10, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %get-tuple-element.399 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=8, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %cudnn-conv-bw-filter.16 = (f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.155, f32[16,14,14,3584]{2,1,3,0} %fusion.141), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.51 = f32[1,1,1792,3584]{1,0,2,3} get-tuple-element((f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.16), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_10/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_56 = f32[1,1,1792,3584]{3,2,1,0} parameter(56), metadata={op_name="2$start"}
  %fusion.120 = f32[1,1,1792,3584]{3,2,1,0} fusion(f32[1,1,1792,3584]{1,0,2,3} %get-tuple-element.51, f32[1,1,1792,3584]{3,2,1,0} %param_56), kind=kLoop, calls=%fused_computation.120, metadata={op_name="tuple.79"}
  %get-tuple-element.401 = f32[3584]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=9, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %get-tuple-element.402 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=7, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(25)/add"}
  %cudnn-conv-bw-filter.21 = (f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.116, f32[16,14,14,896]{2,1,3,0} %fusion.70), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.64 = f32[1,1,3584,896]{1,0,2,3} get-tuple-element((f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.21), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_59 = f32[1,1,3584,896]{3,2,1,0} parameter(59), metadata={op_name="2$start"}
  %fusion.69 = f32[1,1,3584,896]{3,2,1,0} fusion(f32[1,1,3584,896]{1,0,2,3} %get-tuple-element.64, f32[1,1,3584,896]{3,2,1,0} %param_59), kind=kLoop, calls=%fused_computation.69, metadata={op_name="tuple.79"}
  %get-tuple-element.404 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %get-tuple-element.405 = f32[896]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=6, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %cudnn-conv-bw-filter.20 = (f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.106, f32[16,14,14,1792]{2,1,3,0} %fusion.76), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.62 = f32[3,3,896,1792]{1,0,2,3} get-tuple-element((f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.20), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_62 = f32[3,3,896,1792]{3,2,1,0} parameter(62), metadata={op_name="2$start"}
  %fusion.65 = f32[3,3,896,1792]{3,2,1,0} fusion(f32[3,3,896,1792]{1,0,2,3} %get-tuple-element.62, f32[3,3,896,1792]{3,2,1,0} %param_62), kind=kLoop, calls=%fused_computation.65, metadata={op_name="tuple.79"}
  %get-tuple-element.407 = f32[1792]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %get-tuple-element.408 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %cudnn-conv-bw-filter.19 = (f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.96, f32[16,14,14,3584]{2,1,3,0} %fusion.82), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.60 = f32[1,1,1792,3584]{1,0,2,3} get-tuple-element((f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.19), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_9/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_65 = f32[1,1,1792,3584]{3,2,1,0} parameter(65), metadata={op_name="2$start"}
  %fusion.61 = f32[1,1,1792,3584]{3,2,1,0} fusion(f32[1,1,1792,3584]{1,0,2,3} %get-tuple-element.60, f32[1,1,1792,3584]{3,2,1,0} %param_65), kind=kLoop, calls=%fused_computation.61, metadata={op_name="tuple.79"}
  %get-tuple-element.410 = f32[3584]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %get-tuple-element.411 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=4, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(26)/add"}
  %get-tuple-element.164 = f32[16,896]{1,0} get-tuple-element((f32[16,896]{1,0}, f32[16,896]{1,0}, f32[16,896]{1,0}) %fusion.10), index=1
  %reduce.373 = f32[896]{0} reduce(f32[16,896]{1,0} %get-tuple-element.164, f32[] %constant_758), dimensions={0}, to_apply=%region_57.4114.2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/reduce_sum[axes=(0, 1, 2)]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=138}
  %fusion.13 = f32[16,14,14,896]{2,1,3,0} fusion(f32[896]{0} %reduce.373, f32[896]{0} %reduce.362, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.66, f32[896]{0} %fusion.51, f32[1,1,1,896]{3,2,1,0} %fusion.15, /*index=5*/f32[896]{0} %get-tuple-element.719, f32[16,14,14,896]{2,1,3,0} %get-tuple-element.72, f32[896]{0} %get-tuple-element.720), kind=kLoop, calls=%fused_computation.13, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/BatchNorm_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/normalization.py" source_line=82}
  %cudnn-conv-bw-filter.24 = (f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,3584]{2,1,3,0} %fusion.56, f32[16,14,14,896]{2,1,3,0} %fusion.13), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.73 = f32[1,1,3584,896]{1,0,2,3} get-tuple-element((f32[1,1,3584,896]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.24), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 3584) rhs_shape=(16, 14, 14, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_68 = f32[1,1,3584,896]{3,2,1,0} parameter(68), metadata={op_name="2$start"}
  %fusion.12 = f32[1,1,3584,896]{3,2,1,0} fusion(f32[1,1,3584,896]{1,0,2,3} %get-tuple-element.73, f32[1,1,3584,896]{3,2,1,0} %param_68), kind=kLoop, calls=%fused_computation.12, metadata={op_name="tuple.79"}
  %get-tuple-element.413 = f32[896]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %get-tuple-element.414 = f32[896]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=3, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %cudnn-conv-bw-filter.23 = (f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.46, f32[16,14,14,1792]{2,1,3,0} %fusion.19), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.71 = f32[3,3,896,1792]{1,0,2,3} get-tuple-element((f32[3,3,896,1792]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.23), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_1/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(16, 14, 14, 1792) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_71 = f32[3,3,896,1792]{3,2,1,0} parameter(71), metadata={op_name="2$start"}
  %fusion.8 = f32[3,3,896,1792]{3,2,1,0} fusion(f32[3,3,896,1792]{1,0,2,3} %get-tuple-element.71, f32[3,3,896,1792]{3,2,1,0} %param_71), kind=kLoop, calls=%fused_computation.8, metadata={op_name="tuple.79"}
  %get-tuple-element.416 = f32[1792]{0} get-tuple-element((f32[896]{0}, f32[7168]{0}, f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[3584]{0}, /*index=10*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[7168]{0}, f32[1792]{0}, /*index=15*/f32[896]{0}, f32[1792]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}, /*index=20*/f32[896]{0}, f32[3584]{0}) %fusion.487), index=5, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %get-tuple-element.417 = f32[1792]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=2, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %cudnn-conv-bw-filter.22 = (f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) custom-call(f32[16,14,14,1792]{2,1,3,0} %fusion.36, f32[16,14,14,3584]{2,1,3,0} %fusion.25), window={size=1x1}, dim_labels=b01f_01io->b01f, custom_call_target="__cudnn$convBackwardFilter", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":0}"
  %get-tuple-element.69 = f32[1,1,1792,3584]{1,0,2,3} get-tuple-element((f32[1,1,1792,3584]{1,0,2,3}, u8[0]{0}) %cudnn-conv-bw-filter.22), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_2/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(3, 0, 1, 2), rhs_spec=(3, 0, 1, 2), out_spec=(2, 3, 0, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 1792) rhs_shape=(16, 14, 14, 3584) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %param_74 = f32[1,1,1792,3584]{3,2,1,0} parameter(74), metadata={op_name="2$start"}
  %fusion.4 = f32[1,1,1792,3584]{3,2,1,0} fusion(f32[1,1,1792,3584]{1,0,2,3} %get-tuple-element.69, f32[1,1,1792,3584]{3,2,1,0} %param_74), kind=kLoop, calls=%fused_computation.4, metadata={op_name="tuple.79"}
  %get-tuple-element.419 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}) %fusion.3), index=0
  %get-tuple-element.420 = f32[3584]{0} get-tuple-element((f32[3584]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[3584]{0}, /*index=5*/f32[1792]{0}, f32[896]{0}, f32[3584]{0}, f32[1792]{0}, f32[896]{0}, /*index=10*/f32[3584]{0}, f32[1792]{0}, f32[896]{0}, f32[1792]{0}, f32[896]{0}, /*index=15*/f32[7168]{0}, f32[1792]{0}, f32[3584]{0}, f32[3584]{0}, f32[1024]{0}, /*index=20*/f32[7168]{0}, f32[3584]{0}, f32[1792]{0}, f32[1792]{0}) %fusion.486), index=1, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/add"}
  %bitcast.540 = f32[1,1,3584,896]{1,0,3,2} bitcast(f32[1,1,3584,896]{3,2,1,0} %get-tuple-element.718), metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/optimization_barrier" source_file="/home/cyxue/Projects/playground/alpa/custom_alpa/alpa/pipeline_parallel/layer_construction.py" source_line=535}
  %cudnn-conv-bias-activation.23 = (f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) custom-call(f32[16,14,14,896]{2,1,3,0} %fusion.13, f32[1,1,3584,896]{1,0,3,2} %bitcast.540, f32[3584]{0} %broadcast.1098, f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.717), window={size=1x1}, dim_labels=b01f_01oi->b01f, custom_call_target="__cudnn$convBiasActivationForward", metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_0/conv_general_dilated[window_strides=(1, 1) padding=((0, 0), (0, 0)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(2, 3, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(16, 14, 14, 896) rhs_shape=(1, 1, 3584, 896) precision=None preferred_element_type=None]" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}, backend_config="{\"conv_result_scale\":1,\"activation_mode\":\"0\",\"side_input_scale\":1}"
  %get-tuple-element.82 = f32[16,14,14,3584]{2,1,3,0} get-tuple-element((f32[16,14,14,3584]{2,1,3,0}, u8[0]{0}) %cudnn-conv-bias-activation.23), index=0, metadata={op_name="parallelize(train_step_func_pipeshard_parallel_mesh_1)/jit(main)/jit(2)/jit(27)/transpose(jvp(remat))/WideResNet/BottleneckResNetBlock_8/Conv_0/add_any" source_file="/home/cyxue/miniconda3/envs/alpa/lib/python3.8/site-packages/flax/linen/linear.py" source_line=435}
  %fusion = f32[16,14,14,3584]{3,2,1,0} fusion(f32[16,14,14,3584]{2,1,3,0} %get-tuple-element.82, f32[16,14,14,3584]{2,1,3,0} %copy.86), kind=kInput, calls=%fused_computation, metadata={op_name="tuple.79"}
  ROOT %tuple.128 = (f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, f32[3584]{0}, /*index=5*/f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, f32[7168,1024]{1,0}, /*index=10*/f32[1024]{0}, f32[1,1,7168,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, /*index=15*/f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, /*index=20*/f32[1,1,3584,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[3,3,1792,3584]{3,2,1,0}, f32[3584]{0}, /*index=25*/f32[3584]{0}, f32[1,1,3584,7168]{3,2,1,0}, f32[7168]{0}, f32[7168]{0}, f32[1,1,3584,7168]{3,2,1,0}, /*index=30*/f32[7168]{0}, f32[7168]{0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, /*index=35*/f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, /*index=40*/f32[3584]{0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, /*index=45*/f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, /*index=50*/f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, /*index=55*/f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,896]{3,2,1,0}, /*index=60*/f32[896]{0}, f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, /*index=65*/f32[1,1,1792,3584]{3,2,1,0}, f32[3584]{0}, f32[3584]{0}, f32[1,1,3584,896]{3,2,1,0}, f32[896]{0}, /*index=70*/f32[896]{0}, f32[3,3,896,1792]{3,2,1,0}, f32[1792]{0}, f32[1792]{0}, f32[1,1,1792,3584]{3,2,1,0}, /*index=75*/f32[3584]{0}, f32[3584]{0}, f32[16,14,14,3584]{3,2,1,0}) tuple(f32[1,1,7168,1792]{3,2,1,0} %fusion.430, f32[1792]{0} %get-tuple-element.345, f32[1792]{0} %get-tuple-element.346, f32[3,3,1792,3584]{3,2,1,0} %fusion.426, f32[3584]{0} %get-tuple-element.348, /*index=5*/f32[3584]{0} %get-tuple-element.349, f32[1,1,3584,7168]{3,2,1,0} %fusion.422, f32[7168]{0} %get-tuple-element.351, f32[7168]{0} %get-tuple-element.352, f32[7168,1024]{1,0} %cublas-gemm.9, /*index=10*/f32[1024]{0} %get-tuple-element.354, f32[1,1,7168,1792]{3,2,1,0} %fusion.370, f32[1792]{0} %get-tuple-element.356, f32[1792]{0} %get-tuple-element.357, f32[3,3,1792,3584]{3,2,1,0} %fusion.366, /*index=15*/f32[3584]{0} %get-tuple-element.359, f32[3584]{0} %get-tuple-element.360, f32[1,1,3584,7168]{3,2,1,0} %fusion.362, f32[7168]{0} %get-tuple-element.362, f32[7168]{0} %get-tuple-element.363, /*index=20*/f32[1,1,3584,1792]{3,2,1,0} %fusion.314, f32[1792]{0} %get-tuple-element.365, f32[1792]{0} %get-tuple-element.366, f32[3,3,1792,3584]{3,2,1,0} %fusion.310, f32[3584]{0} %get-tuple-element.368, /*index=25*/f32[3584]{0} %get-tuple-element.369, f32[1,1,3584,7168]{3,2,1,0} %fusion.306, f32[7168]{0} %get-tuple-element.371, f32[7168]{0} %get-tuple-element.372, f32[1,1,3584,7168]{3,2,1,0} %fusion.292, /*index=30*/f32[7168]{0} %get-tuple-element.374, f32[7168]{0} %add.629, f32[1,1,3584,896]{3,2,1,0} %fusion.244, f32[896]{0} %get-tuple-element.377, f32[896]{0} %get-tuple-element.378, /*index=35*/f32[3,3,896,1792]{3,2,1,0} %fusion.240, f32[1792]{0} %get-tuple-element.380, f32[1792]{0} %get-tuple-element.381, f32[1,1,1792,3584]{3,2,1,0} %fusion.236, f32[3584]{0} %get-tuple-element.383, /*index=40*/f32[3584]{0} %get-tuple-element.384, f32[1,1,3584,896]{3,2,1,0} %fusion.186, f32[896]{0} %get-tuple-element.386, f32[896]{0} %get-tuple-element.387, f32[3,3,896,1792]{3,2,1,0} %fusion.182, /*index=45*/f32[1792]{0} %get-tuple-element.389, f32[1792]{0} %get-tuple-element.390, f32[1,1,1792,3584]{3,2,1,0} %fusion.178, f32[3584]{0} %get-tuple-element.392, f32[3584]{0} %get-tuple-element.393, /*index=50*/f32[1,1,3584,896]{3,2,1,0} %fusion.128, f32[896]{0} %get-tuple-element.395, f32[896]{0} %get-tuple-element.396, f32[3,3,896,1792]{3,2,1,0} %fusion.124, f32[1792]{0} %get-tuple-element.398, /*index=55*/f32[1792]{0} %get-tuple-element.399, f32[1,1,1792,3584]{3,2,1,0} %fusion.120, f32[3584]{0} %get-tuple-element.401, f32[3584]{0} %get-tuple-element.402, f32[1,1,3584,896]{3,2,1,0} %fusion.69, /*index=60*/f32[896]{0} %get-tuple-element.404, f32[896]{0} %get-tuple-element.405, f32[3,3,896,1792]{3,2,1,0} %fusion.65, f32[1792]{0} %get-tuple-element.407, f32[1792]{0} %get-tuple-element.408, /*index=65*/f32[1,1,1792,3584]{3,2,1,0} %fusion.61, f32[3584]{0} %get-tuple-element.410, f32[3584]{0} %get-tuple-element.411, f32[1,1,3584,896]{3,2,1,0} %fusion.12, f32[896]{0} %get-tuple-element.413, /*index=70*/f32[896]{0} %get-tuple-element.414, f32[3,3,896,1792]{3,2,1,0} %fusion.8, f32[1792]{0} %get-tuple-element.416, f32[1792]{0} %get-tuple-element.417, f32[1,1,1792,3584]{3,2,1,0} %fusion.4, /*index=75*/f32[3584]{0} %get-tuple-element.419, f32[3584]{0} %get-tuple-element.420, f32[16,14,14,3584]{3,2,1,0} %fusion)
}

